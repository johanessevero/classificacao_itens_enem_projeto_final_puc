{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "04f67161",
   "metadata": {},
   "outputs": [],
   "source": [
    "# importação das bilbiotecas\n",
    "#data\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "#plot\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#ml\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import tensorflow_datasets as tfds\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "#aux\n",
    "from IPython.display import clear_output\n",
    "import os\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "637a3568",
   "metadata": {},
   "source": [
    "## carregar dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db347796",
   "metadata": {},
   "source": [
    "### treinamento o word embbeding próprio treinado com skip-gram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fbda41d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the dataframe object from the pickle file\n",
    "with open(os.path.join('data', 'dataset_param_c_train.pkl'), 'rb') as f:\n",
    "    dataset = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4e05283b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tf_idf</th>\n",
       "      <th>wes</th>\n",
       "      <th>wes_own</th>\n",
       "      <th>classes_param_a_1</th>\n",
       "      <th>classes_param_b_1</th>\n",
       "      <th>classes_param_c_1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1757</th>\n",
       "      <td>[0.1520375028210196, 0.17699962659034899, 0.11...</td>\n",
       "      <td>[[-0.0024, -0.033, 0.0099, 0.0034, -0.1078, -0...</td>\n",
       "      <td>[[-0.15383221, 0.17914692, -0.010291061, 0.344...</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>573</th>\n",
       "      <td>[0.17117729139134427, 0.12149402947247992, 0.1...</td>\n",
       "      <td>[[-0.0312, -0.0228, 0.0538, 0.2069, -0.0707, -...</td>\n",
       "      <td>[[0.124431126, 0.1792577, 0.22388884, 0.179398...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>357</th>\n",
       "      <td>[0.056354022158337326, 0.0900773086241686, 0.0...</td>\n",
       "      <td>[[0.0087, -0.015, 0.073, 0.0244, -0.0139, -0.0...</td>\n",
       "      <td>[[-0.2735036, -0.19421376, 0.26711008, 0.26224...</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1874</th>\n",
       "      <td>[0.06280307748585236, 0.5022780351753088, 0.05...</td>\n",
       "      <td>[[0.0033, 0.0033, 0.0621, -0.0199, -0.0136, -0...</td>\n",
       "      <td>[[0.39825365, 0.03401856, -0.08328956, 0.15628...</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>952</th>\n",
       "      <td>[0.2162069029386577, 0.17003122409083568, 0.21...</td>\n",
       "      <td>[[0.0426, 0.0016, -0.0254, 0.0166, 0.0386, -0....</td>\n",
       "      <td>[[-0.1674651, -0.041456904, 0.089936934, 0.109...</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>469</th>\n",
       "      <td>[0.03344511075801128, 0.03344511075801128, 0.0...</td>\n",
       "      <td>[[-0.022, 0.0315, 0.0752, -0.0268, 0.0625, -0....</td>\n",
       "      <td>[[-0.20457007, 0.2068289, -0.22812223, 0.41948...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1523</th>\n",
       "      <td>[0.1444444525285251, 0.14320885524210786, 0.11...</td>\n",
       "      <td>[[-0.0176, 0.0149, 0.029, -0.018, 0.0394, -0.0...</td>\n",
       "      <td>[[0.15224683, -0.04294147, 0.23700559, 0.45965...</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>184</th>\n",
       "      <td>[0.07487472267235452, 0.08646331108472735, 0.0...</td>\n",
       "      <td>[[0.0392, 0.0332, 0.011, -0.0712, 0.1688, 0.10...</td>\n",
       "      <td>[[-0.613815, 0.052886456, 0.1884509, 0.3149106...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1623</th>\n",
       "      <td>[0.24468841743329098, 0.07221445715635107, 0.0...</td>\n",
       "      <td>[[0.0442, -0.087, 0.0251, 0.015, 0.0006, -0.09...</td>\n",
       "      <td>[[-0.18899466, 0.050661664, 0.13411203, 0.0431...</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1442</th>\n",
       "      <td>[0.11702273888350695, 0.09765272329520391, 0.0...</td>\n",
       "      <td>[[0.0286, 0.0005, -0.0008, 0.0068, 0.0196, -0....</td>\n",
       "      <td>[[-0.2550963, 0.29668498, 0.01296361, 0.290734...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1441 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 tf_idf  \\\n",
       "1757  [0.1520375028210196, 0.17699962659034899, 0.11...   \n",
       "573   [0.17117729139134427, 0.12149402947247992, 0.1...   \n",
       "357   [0.056354022158337326, 0.0900773086241686, 0.0...   \n",
       "1874  [0.06280307748585236, 0.5022780351753088, 0.05...   \n",
       "952   [0.2162069029386577, 0.17003122409083568, 0.21...   \n",
       "...                                                 ...   \n",
       "469   [0.03344511075801128, 0.03344511075801128, 0.0...   \n",
       "1523  [0.1444444525285251, 0.14320885524210786, 0.11...   \n",
       "184   [0.07487472267235452, 0.08646331108472735, 0.0...   \n",
       "1623  [0.24468841743329098, 0.07221445715635107, 0.0...   \n",
       "1442  [0.11702273888350695, 0.09765272329520391, 0.0...   \n",
       "\n",
       "                                                    wes  \\\n",
       "1757  [[-0.0024, -0.033, 0.0099, 0.0034, -0.1078, -0...   \n",
       "573   [[-0.0312, -0.0228, 0.0538, 0.2069, -0.0707, -...   \n",
       "357   [[0.0087, -0.015, 0.073, 0.0244, -0.0139, -0.0...   \n",
       "1874  [[0.0033, 0.0033, 0.0621, -0.0199, -0.0136, -0...   \n",
       "952   [[0.0426, 0.0016, -0.0254, 0.0166, 0.0386, -0....   \n",
       "...                                                 ...   \n",
       "469   [[-0.022, 0.0315, 0.0752, -0.0268, 0.0625, -0....   \n",
       "1523  [[-0.0176, 0.0149, 0.029, -0.018, 0.0394, -0.0...   \n",
       "184   [[0.0392, 0.0332, 0.011, -0.0712, 0.1688, 0.10...   \n",
       "1623  [[0.0442, -0.087, 0.0251, 0.015, 0.0006, -0.09...   \n",
       "1442  [[0.0286, 0.0005, -0.0008, 0.0068, 0.0196, -0....   \n",
       "\n",
       "                                                wes_own classes_param_a_1  \\\n",
       "1757  [[-0.15383221, 0.17914692, -0.010291061, 0.344...                 1   \n",
       "573   [[0.124431126, 0.1792577, 0.22388884, 0.179398...                 0   \n",
       "357   [[-0.2735036, -0.19421376, 0.26711008, 0.26224...                 2   \n",
       "1874  [[0.39825365, 0.03401856, -0.08328956, 0.15628...                 3   \n",
       "952   [[-0.1674651, -0.041456904, 0.089936934, 0.109...                 2   \n",
       "...                                                 ...               ...   \n",
       "469   [[-0.20457007, 0.2068289, -0.22812223, 0.41948...                 0   \n",
       "1523  [[0.15224683, -0.04294147, 0.23700559, 0.45965...                 2   \n",
       "184   [[-0.613815, 0.052886456, 0.1884509, 0.3149106...                 1   \n",
       "1623  [[-0.18899466, 0.050661664, 0.13411203, 0.0431...                 0   \n",
       "1442  [[-0.2550963, 0.29668498, 0.01296361, 0.290734...                 1   \n",
       "\n",
       "     classes_param_b_1 classes_param_c_1  \n",
       "1757                 2                 0  \n",
       "573                  1                 2  \n",
       "357                  0                 0  \n",
       "1874                 1                 3  \n",
       "952                  0                 3  \n",
       "...                ...               ...  \n",
       "469                  0                 0  \n",
       "1523                 3                 3  \n",
       "184                  0                 1  \n",
       "1623                 2                 2  \n",
       "1442                 1                 2  \n",
       "\n",
       "[1441 rows x 6 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "721b4ae4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#X = np.array([x.reshape(x.shape[0], -1, 300) for x in df.iloc[:, 0].values])\n",
    "X = dataset.iloc[:, 2].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cb42485b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(49, 100)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(X[51]).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2bcccf33",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[-0.68453753,\n",
       "  0.055393357,\n",
       "  0.33304712,\n",
       "  0.44751438,\n",
       "  -0.021024648,\n",
       "  -0.49047387,\n",
       "  -0.29921973,\n",
       "  0.7562744,\n",
       "  -0.8446626,\n",
       "  0.39803836,\n",
       "  -0.56546974,\n",
       "  -0.6267599,\n",
       "  -0.4446311,\n",
       "  0.2203117,\n",
       "  -0.34094337,\n",
       "  -0.11009056,\n",
       "  -0.09522413,\n",
       "  -0.08117499,\n",
       "  0.15811528,\n",
       "  -0.56882226,\n",
       "  -0.05616938,\n",
       "  0.27585366,\n",
       "  -0.42443743,\n",
       "  -0.31396857,\n",
       "  0.3669693,\n",
       "  -0.017822519,\n",
       "  -0.65792054,\n",
       "  0.15774801,\n",
       "  0.22833307,\n",
       "  -0.3761058,\n",
       "  0.33013228,\n",
       "  0.5230041,\n",
       "  0.361444,\n",
       "  0.6994262,\n",
       "  -0.24811044,\n",
       "  0.50295717,\n",
       "  0.7939841,\n",
       "  -0.49004132,\n",
       "  0.19715124,\n",
       "  0.44135204,\n",
       "  0.53262794,\n",
       "  -0.45021826,\n",
       "  0.08944859,\n",
       "  -0.25586966,\n",
       "  -0.26918495,\n",
       "  0.49751863,\n",
       "  -0.5060052,\n",
       "  0.35308135,\n",
       "  -0.12467632,\n",
       "  -0.040516663,\n",
       "  0.5571893,\n",
       "  -0.12817758,\n",
       "  -0.32305786,\n",
       "  0.3942313,\n",
       "  -0.41850862,\n",
       "  0.18882385,\n",
       "  0.98204273,\n",
       "  0.3312496,\n",
       "  0.47071287,\n",
       "  -0.02099872,\n",
       "  -0.15967695,\n",
       "  0.22309405,\n",
       "  0.12531249,\n",
       "  0.41419715,\n",
       "  0.16210818,\n",
       "  -0.28688344,\n",
       "  0.027591279,\n",
       "  0.7525992,\n",
       "  -0.2336384,\n",
       "  1.4432662,\n",
       "  -0.600548,\n",
       "  -0.17689498,\n",
       "  -0.018448824,\n",
       "  -0.7947897,\n",
       "  0.05167744,\n",
       "  0.015736246,\n",
       "  -0.029215489,\n",
       "  0.2329933,\n",
       "  0.47435868,\n",
       "  0.11287587,\n",
       "  -0.6668359,\n",
       "  -0.1493358,\n",
       "  -0.6430819,\n",
       "  0.7707712,\n",
       "  0.04873941,\n",
       "  0.7880175,\n",
       "  -0.34711143,\n",
       "  0.18979868,\n",
       "  0.7691177,\n",
       "  0.6556721,\n",
       "  -0.109582864,\n",
       "  0.60092616,\n",
       "  0.22862627,\n",
       "  -0.16548188,\n",
       "  0.7619683,\n",
       "  0.38498965,\n",
       "  -0.2535171,\n",
       "  -0.16891278,\n",
       "  0.37304863,\n",
       "  0.34258205],\n",
       " [-0.45513722,\n",
       "  0.19979239,\n",
       "  0.006163766,\n",
       "  0.4055518,\n",
       "  -0.079755336,\n",
       "  -0.65708303,\n",
       "  -0.18800591,\n",
       "  0.78328496,\n",
       "  -0.92041045,\n",
       "  0.110599235,\n",
       "  -0.58004564,\n",
       "  -0.6386038,\n",
       "  -0.4130003,\n",
       "  0.32564157,\n",
       "  -0.41696602,\n",
       "  -0.09358784,\n",
       "  0.0946234,\n",
       "  -0.41213802,\n",
       "  0.015571343,\n",
       "  -0.8350851,\n",
       "  -0.061706003,\n",
       "  0.19931561,\n",
       "  0.2520219,\n",
       "  0.07632701,\n",
       "  -0.11236639,\n",
       "  0.2954815,\n",
       "  -0.8438346,\n",
       "  0.291935,\n",
       "  0.1826056,\n",
       "  -0.39014098,\n",
       "  0.33865944,\n",
       "  0.4240409,\n",
       "  0.042933423,\n",
       "  0.39483303,\n",
       "  0.04041195,\n",
       "  0.6010253,\n",
       "  0.37545735,\n",
       "  -0.47921243,\n",
       "  -0.005092115,\n",
       "  0.17486717,\n",
       "  0.6173081,\n",
       "  -0.7306107,\n",
       "  0.40431547,\n",
       "  -0.28038615,\n",
       "  0.10368051,\n",
       "  0.46331468,\n",
       "  -0.81860304,\n",
       "  0.64646554,\n",
       "  -0.26881003,\n",
       "  -0.11139789,\n",
       "  0.30890805,\n",
       "  -0.41177177,\n",
       "  -0.20865941,\n",
       "  0.25679645,\n",
       "  -0.6486017,\n",
       "  -0.000994163,\n",
       "  0.71787006,\n",
       "  0.11750531,\n",
       "  0.117811576,\n",
       "  -0.2724754,\n",
       "  0.05066159,\n",
       "  -0.075133756,\n",
       "  0.26991075,\n",
       "  0.67382103,\n",
       "  -0.17414859,\n",
       "  0.03805228,\n",
       "  -0.003817016,\n",
       "  0.61780447,\n",
       "  -0.36183405,\n",
       "  1.1030825,\n",
       "  -0.7008876,\n",
       "  0.044867594,\n",
       "  0.15029305,\n",
       "  -0.52094394,\n",
       "  0.31908458,\n",
       "  -0.025971115,\n",
       "  -0.19560212,\n",
       "  0.2949125,\n",
       "  0.5063612,\n",
       "  0.34402198,\n",
       "  -0.6834615,\n",
       "  -0.15178071,\n",
       "  -0.6511911,\n",
       "  0.85961956,\n",
       "  -0.12122071,\n",
       "  0.76186436,\n",
       "  -0.31343138,\n",
       "  0.689217,\n",
       "  0.9674376,\n",
       "  0.3863829,\n",
       "  0.24958435,\n",
       "  0.5228896,\n",
       "  0.15721771,\n",
       "  0.0026672904,\n",
       "  0.85430086,\n",
       "  0.29907402,\n",
       "  0.1324873,\n",
       "  -0.21914364,\n",
       "  0.37860417,\n",
       "  0.4904519],\n",
       " [-0.9139988,\n",
       "  -0.07499574,\n",
       "  0.10535647,\n",
       "  0.48215172,\n",
       "  0.23575364,\n",
       "  -0.6796231,\n",
       "  -0.4864898,\n",
       "  0.87065357,\n",
       "  -0.97969675,\n",
       "  0.4242349,\n",
       "  -0.6999337,\n",
       "  -0.7366482,\n",
       "  -0.4225162,\n",
       "  0.10914933,\n",
       "  -0.23090343,\n",
       "  -0.20117193,\n",
       "  0.114106745,\n",
       "  -0.5265744,\n",
       "  0.31463942,\n",
       "  -0.82366294,\n",
       "  -0.48091012,\n",
       "  0.12055115,\n",
       "  -0.16878913,\n",
       "  -0.38296378,\n",
       "  0.4723779,\n",
       "  0.38060746,\n",
       "  -0.7022094,\n",
       "  0.3892042,\n",
       "  -0.07678233,\n",
       "  -0.27931824,\n",
       "  0.5936222,\n",
       "  0.577892,\n",
       "  0.19194254,\n",
       "  0.77265674,\n",
       "  -0.0849941,\n",
       "  0.6002264,\n",
       "  0.80762446,\n",
       "  -0.5937653,\n",
       "  0.32967252,\n",
       "  0.38259873,\n",
       "  0.50253755,\n",
       "  -0.72075146,\n",
       "  0.39534384,\n",
       "  -0.48503122,\n",
       "  -0.2876474,\n",
       "  0.65779406,\n",
       "  -0.5339847,\n",
       "  0.9370626,\n",
       "  -0.630548,\n",
       "  -0.22435157,\n",
       "  0.7320324,\n",
       "  -0.30232418,\n",
       "  -0.30549628,\n",
       "  0.308894,\n",
       "  -0.7125104,\n",
       "  0.14961842,\n",
       "  0.809837,\n",
       "  0.4473791,\n",
       "  0.50154585,\n",
       "  -0.1127262,\n",
       "  0.0033250253,\n",
       "  0.14283068,\n",
       "  0.24780764,\n",
       "  0.72241676,\n",
       "  0.2849985,\n",
       "  -0.432743,\n",
       "  -0.122047186,\n",
       "  0.7636648,\n",
       "  -0.35525566,\n",
       "  1.4245142,\n",
       "  -0.68921596,\n",
       "  0.06332134,\n",
       "  0.082420096,\n",
       "  -0.60244626,\n",
       "  0.13709502,\n",
       "  -0.13971898,\n",
       "  -0.022356095,\n",
       "  0.27302969,\n",
       "  0.7076415,\n",
       "  0.115679234,\n",
       "  -0.6101873,\n",
       "  -0.45562747,\n",
       "  -0.78610885,\n",
       "  0.73300403,\n",
       "  0.12540549,\n",
       "  0.9823077,\n",
       "  -0.31041434,\n",
       "  0.47576478,\n",
       "  1.2031978,\n",
       "  0.5232502,\n",
       "  0.03436358,\n",
       "  0.8962952,\n",
       "  0.4621948,\n",
       "  -0.054926287,\n",
       "  0.8179188,\n",
       "  0.26268712,\n",
       "  -0.02800269,\n",
       "  -0.6127318,\n",
       "  0.4340779,\n",
       "  0.26158956],\n",
       " [-0.74662983,\n",
       "  -0.32304916,\n",
       "  -0.13782705,\n",
       "  0.35686964,\n",
       "  0.05376327,\n",
       "  -0.8111726,\n",
       "  -0.3443309,\n",
       "  0.9572094,\n",
       "  -0.7359713,\n",
       "  0.114485204,\n",
       "  -0.5882098,\n",
       "  -0.5309975,\n",
       "  -0.6272488,\n",
       "  -0.36849862,\n",
       "  -0.1410971,\n",
       "  0.07327335,\n",
       "  0.20416889,\n",
       "  -0.6422483,\n",
       "  0.46507174,\n",
       "  -0.9470898,\n",
       "  -0.26034176,\n",
       "  0.071798824,\n",
       "  0.035069678,\n",
       "  -0.031987224,\n",
       "  0.3030957,\n",
       "  -0.01533346,\n",
       "  -0.77355844,\n",
       "  0.29387316,\n",
       "  -0.11838685,\n",
       "  -0.3561389,\n",
       "  0.9831915,\n",
       "  0.5652889,\n",
       "  0.27389795,\n",
       "  0.8335231,\n",
       "  -0.34711185,\n",
       "  0.4264374,\n",
       "  0.5612403,\n",
       "  -0.21721855,\n",
       "  0.5576281,\n",
       "  0.51944077,\n",
       "  0.5482578,\n",
       "  -0.44832164,\n",
       "  0.21235444,\n",
       "  -0.543583,\n",
       "  -0.43225065,\n",
       "  0.77808714,\n",
       "  -0.5450733,\n",
       "  0.9689216,\n",
       "  -0.4011233,\n",
       "  0.58685315,\n",
       "  0.6303528,\n",
       "  -0.07356786,\n",
       "  -0.15059774,\n",
       "  0.093276724,\n",
       "  -0.47550505,\n",
       "  0.21492326,\n",
       "  0.50349575,\n",
       "  0.21714835,\n",
       "  0.45441848,\n",
       "  -0.3497898,\n",
       "  -0.4171792,\n",
       "  0.5382147,\n",
       "  0.5612889,\n",
       "  0.31416723,\n",
       "  -0.27139083,\n",
       "  -0.3087054,\n",
       "  -0.0135381585,\n",
       "  0.62602115,\n",
       "  -0.08000991,\n",
       "  0.970678,\n",
       "  -0.5971908,\n",
       "  0.11895105,\n",
       "  -0.1538269,\n",
       "  -0.79942,\n",
       "  0.27162436,\n",
       "  -0.3191503,\n",
       "  0.07095937,\n",
       "  0.3404059,\n",
       "  0.9038262,\n",
       "  0.14510524,\n",
       "  -0.33468932,\n",
       "  -0.68211406,\n",
       "  -0.611486,\n",
       "  0.8921127,\n",
       "  0.6065046,\n",
       "  0.49795926,\n",
       "  -0.18932419,\n",
       "  0.3520383,\n",
       "  1.1855148,\n",
       "  0.66155165,\n",
       "  -0.189794,\n",
       "  0.9618248,\n",
       "  0.7690652,\n",
       "  0.25870883,\n",
       "  0.9574855,\n",
       "  -0.01972711,\n",
       "  -0.5142628,\n",
       "  -0.36772186,\n",
       "  0.7967493,\n",
       "  0.06216721],\n",
       " [-0.30679902,\n",
       "  0.31339404,\n",
       "  0.15568496,\n",
       "  0.25837502,\n",
       "  -0.022135833,\n",
       "  -0.456206,\n",
       "  -0.05133212,\n",
       "  0.68323594,\n",
       "  -0.5479283,\n",
       "  -0.2329733,\n",
       "  -0.5421428,\n",
       "  -0.7340208,\n",
       "  0.25701955,\n",
       "  0.5199199,\n",
       "  -0.4427631,\n",
       "  0.08817781,\n",
       "  0.13680072,\n",
       "  -0.3371092,\n",
       "  -0.32827246,\n",
       "  -1.0441582,\n",
       "  0.05509401,\n",
       "  0.59405553,\n",
       "  0.15146598,\n",
       "  -0.049744647,\n",
       "  -0.104702145,\n",
       "  0.3780864,\n",
       "  -0.6603612,\n",
       "  0.020328578,\n",
       "  0.19252633,\n",
       "  -0.046021968,\n",
       "  0.09301729,\n",
       "  0.30215088,\n",
       "  0.30810457,\n",
       "  0.3545686,\n",
       "  0.033556134,\n",
       "  0.6259272,\n",
       "  -0.07057844,\n",
       "  -0.40901506,\n",
       "  -0.294581,\n",
       "  -0.42200086,\n",
       "  0.09226179,\n",
       "  -0.26543412,\n",
       "  -0.13042916,\n",
       "  0.08661483,\n",
       "  0.22652003,\n",
       "  0.0649878,\n",
       "  -0.99323213,\n",
       "  0.2701658,\n",
       "  0.1521707,\n",
       "  0.031201256,\n",
       "  -0.35422134,\n",
       "  -0.07343219,\n",
       "  0.16750103,\n",
       "  -0.0061618895,\n",
       "  -0.18974009,\n",
       "  -0.107957184,\n",
       "  0.3425178,\n",
       "  -0.36499313,\n",
       "  -0.08243339,\n",
       "  0.2516088,\n",
       "  0.2111879,\n",
       "  0.1022946,\n",
       "  0.4079455,\n",
       "  0.66300917,\n",
       "  -0.82841605,\n",
       "  -0.026370712,\n",
       "  -0.33035412,\n",
       "  0.5197833,\n",
       "  -0.48508713,\n",
       "  0.26949295,\n",
       "  -0.19308284,\n",
       "  0.106808536,\n",
       "  0.44005424,\n",
       "  -0.30229396,\n",
       "  0.5463758,\n",
       "  -0.1325347,\n",
       "  0.47508106,\n",
       "  -0.042004522,\n",
       "  0.18598828,\n",
       "  0.13376632,\n",
       "  -0.63853526,\n",
       "  0.50007993,\n",
       "  0.16442372,\n",
       "  0.5642119,\n",
       "  -0.2811662,\n",
       "  0.20081645,\n",
       "  -0.2648962,\n",
       "  0.4747797,\n",
       "  0.48805684,\n",
       "  0.530503,\n",
       "  0.85277206,\n",
       "  0.4700058,\n",
       "  0.08972779,\n",
       "  0.26603273,\n",
       "  0.3276284,\n",
       "  0.6105027,\n",
       "  0.17515308,\n",
       "  -0.3188884,\n",
       "  0.21207973,\n",
       "  0.3509063],\n",
       " [-0.11081504,\n",
       "  0.15080136,\n",
       "  -0.12800208,\n",
       "  0.32862318,\n",
       "  -0.025330612,\n",
       "  -0.32957846,\n",
       "  -0.12718366,\n",
       "  0.8583517,\n",
       "  -0.42362848,\n",
       "  -0.12748338,\n",
       "  -0.40809888,\n",
       "  -0.52867603,\n",
       "  -0.2972216,\n",
       "  0.3013267,\n",
       "  -0.39161435,\n",
       "  -0.1038891,\n",
       "  0.14490892,\n",
       "  -0.42222375,\n",
       "  0.098348886,\n",
       "  -0.6970898,\n",
       "  -0.0677233,\n",
       "  0.14990437,\n",
       "  0.20277119,\n",
       "  -0.026489917,\n",
       "  -0.045608792,\n",
       "  0.19925779,\n",
       "  -0.8095025,\n",
       "  -0.048526,\n",
       "  0.39427766,\n",
       "  -0.41566116,\n",
       "  0.23405628,\n",
       "  0.39942503,\n",
       "  -0.0373803,\n",
       "  0.48977587,\n",
       "  -0.078014344,\n",
       "  0.3803792,\n",
       "  0.31192023,\n",
       "  -0.24752009,\n",
       "  -0.05632987,\n",
       "  -0.04934183,\n",
       "  0.21220851,\n",
       "  -0.30161703,\n",
       "  0.67316127,\n",
       "  -0.23560402,\n",
       "  0.14054488,\n",
       "  0.5106756,\n",
       "  -0.47328243,\n",
       "  0.48669142,\n",
       "  -0.255943,\n",
       "  0.09651619,\n",
       "  -0.054397967,\n",
       "  -0.24477729,\n",
       "  -0.21668202,\n",
       "  0.15406181,\n",
       "  -0.5178284,\n",
       "  -0.2274889,\n",
       "  0.4132005,\n",
       "  -0.10728735,\n",
       "  0.15070832,\n",
       "  -0.22087258,\n",
       "  0.18868943,\n",
       "  0.131281,\n",
       "  0.5248811,\n",
       "  0.54350704,\n",
       "  -0.5474585,\n",
       "  -0.10755875,\n",
       "  -0.23872107,\n",
       "  0.30962864,\n",
       "  -0.471215,\n",
       "  0.48549455,\n",
       "  -0.20943612,\n",
       "  -0.008445437,\n",
       "  0.0067091454,\n",
       "  -0.07555505,\n",
       "  0.4753203,\n",
       "  -0.25211537,\n",
       "  -0.017188061,\n",
       "  0.14742438,\n",
       "  0.14085342,\n",
       "  0.3369014,\n",
       "  -0.39782968,\n",
       "  0.003016626,\n",
       "  -0.3324995,\n",
       "  0.6202739,\n",
       "  -0.05803199,\n",
       "  0.37297386,\n",
       "  -0.06468793,\n",
       "  0.6948938,\n",
       "  0.53090155,\n",
       "  0.43482727,\n",
       "  0.0070332615,\n",
       "  0.32439816,\n",
       "  0.039661895,\n",
       "  0.23321986,\n",
       "  0.6728557,\n",
       "  0.4407759,\n",
       "  0.15840755,\n",
       "  -0.05507527,\n",
       "  0.23150714,\n",
       "  0.20667452],\n",
       " [-0.4862073,\n",
       "  0.029851496,\n",
       "  -0.12210908,\n",
       "  0.3812675,\n",
       "  0.012737752,\n",
       "  -0.35997736,\n",
       "  0.03929807,\n",
       "  0.8098106,\n",
       "  -0.4603156,\n",
       "  -0.23822656,\n",
       "  -0.20321055,\n",
       "  -0.39230162,\n",
       "  -0.24389572,\n",
       "  0.24099985,\n",
       "  -0.18477868,\n",
       "  -0.16138928,\n",
       "  0.45954922,\n",
       "  -0.38057885,\n",
       "  0.13647988,\n",
       "  -0.6566277,\n",
       "  -0.3174751,\n",
       "  0.11513941,\n",
       "  0.40165025,\n",
       "  0.08408749,\n",
       "  0.014764166,\n",
       "  0.22304413,\n",
       "  -0.54298085,\n",
       "  0.14443886,\n",
       "  0.112349376,\n",
       "  -0.5086774,\n",
       "  0.45976865,\n",
       "  0.26891622,\n",
       "  -0.10772407,\n",
       "  0.50390595,\n",
       "  -0.057055637,\n",
       "  0.59079707,\n",
       "  0.45111898,\n",
       "  -0.33633244,\n",
       "  -0.28661412,\n",
       "  -0.012158584,\n",
       "  0.23513217,\n",
       "  -0.3213331,\n",
       "  0.6700652,\n",
       "  -0.506637,\n",
       "  0.23834622,\n",
       "  0.46808824,\n",
       "  -0.34926504,\n",
       "  0.6235707,\n",
       "  -0.38351765,\n",
       "  0.010610362,\n",
       "  0.14656404,\n",
       "  -0.30986747,\n",
       "  -0.22539657,\n",
       "  0.18741012,\n",
       "  -0.7204432,\n",
       "  -0.27820945,\n",
       "  0.33150333,\n",
       "  -0.00056966953,\n",
       "  0.068554655,\n",
       "  -0.46459264,\n",
       "  0.21922451,\n",
       "  -0.04438749,\n",
       "  0.39026165,\n",
       "  0.39025813,\n",
       "  -0.5062774,\n",
       "  -0.016557006,\n",
       "  -0.28872663,\n",
       "  0.22070774,\n",
       "  -0.38200063,\n",
       "  0.39092565,\n",
       "  -0.30135453,\n",
       "  0.18122078,\n",
       "  0.1076563,\n",
       "  -0.133591,\n",
       "  0.44532833,\n",
       "  -0.30259588,\n",
       "  -0.11298987,\n",
       "  0.24543196,\n",
       "  0.24274753,\n",
       "  0.27885544,\n",
       "  -0.11841971,\n",
       "  -0.21755205,\n",
       "  -0.5382513,\n",
       "  0.6130728,\n",
       "  0.0707485,\n",
       "  0.31631085,\n",
       "  0.080331326,\n",
       "  0.49079978,\n",
       "  0.629464,\n",
       "  0.24237162,\n",
       "  -0.105184026,\n",
       "  0.27709752,\n",
       "  0.036728848,\n",
       "  0.23792188,\n",
       "  0.86445445,\n",
       "  0.30504346,\n",
       "  0.063390166,\n",
       "  -0.28347537,\n",
       "  0.12092573,\n",
       "  0.20439176],\n",
       " [-0.076835535,\n",
       "  -0.06783262,\n",
       "  -0.35849127,\n",
       "  0.17178366,\n",
       "  -0.2785481,\n",
       "  -0.2753989,\n",
       "  0.1533076,\n",
       "  0.5816764,\n",
       "  -0.31871048,\n",
       "  -0.44695157,\n",
       "  0.49586886,\n",
       "  -0.7664954,\n",
       "  -0.33382004,\n",
       "  0.20069578,\n",
       "  -0.5727632,\n",
       "  0.15743408,\n",
       "  0.5534181,\n",
       "  -0.083482385,\n",
       "  0.4266449,\n",
       "  -0.5491103,\n",
       "  -0.0145913,\n",
       "  0.08191048,\n",
       "  0.7023495,\n",
       "  -0.20863117,\n",
       "  0.141312,\n",
       "  0.29960907,\n",
       "  -0.70521945,\n",
       "  0.3835489,\n",
       "  -0.07159104,\n",
       "  -0.28439346,\n",
       "  0.9635952,\n",
       "  0.7978129,\n",
       "  -0.2400148,\n",
       "  0.630277,\n",
       "  -0.6260701,\n",
       "  0.27886507,\n",
       "  0.24034487,\n",
       "  -0.70304555,\n",
       "  -0.3775805,\n",
       "  0.034558505,\n",
       "  0.62572557,\n",
       "  -0.7209945,\n",
       "  1.0852726,\n",
       "  -1.0104357,\n",
       "  0.3451434,\n",
       "  0.8459137,\n",
       "  -0.6809585,\n",
       "  0.04490798,\n",
       "  -0.21407524,\n",
       "  0.12894876,\n",
       "  -0.040655654,\n",
       "  -0.9159941,\n",
       "  -0.8221975,\n",
       "  0.32142282,\n",
       "  -0.75934327,\n",
       "  -0.044697877,\n",
       "  0.075102136,\n",
       "  -0.23182252,\n",
       "  -0.30660823,\n",
       "  -0.29661798,\n",
       "  -0.33354267,\n",
       "  0.020118536,\n",
       "  0.09817903,\n",
       "  0.19731586,\n",
       "  -0.12693653,\n",
       "  -0.19503546,\n",
       "  -0.5680219,\n",
       "  0.1356216,\n",
       "  -0.52429026,\n",
       "  0.63597125,\n",
       "  -0.16261372,\n",
       "  0.029513415,\n",
       "  0.027112132,\n",
       "  0.16550088,\n",
       "  0.48571652,\n",
       "  -0.18828052,\n",
       "  -0.13703148,\n",
       "  0.11959488,\n",
       "  0.074524656,\n",
       "  0.49853536,\n",
       "  0.42274275,\n",
       "  -0.58490044,\n",
       "  -1.0402874,\n",
       "  0.2039509,\n",
       "  0.22722091,\n",
       "  0.26251104,\n",
       "  0.42868662,\n",
       "  0.07448607,\n",
       "  0.43635365,\n",
       "  -0.36377534,\n",
       "  -0.56222093,\n",
       "  -0.36293492,\n",
       "  -0.22609314,\n",
       "  0.2728773,\n",
       "  0.38553467,\n",
       "  -0.10155565,\n",
       "  0.3594502,\n",
       "  -0.6708935,\n",
       "  0.15212762,\n",
       "  0.49620906],\n",
       " [-0.47336218,\n",
       "  0.20003349,\n",
       "  -0.043594107,\n",
       "  0.22932239,\n",
       "  0.023165487,\n",
       "  -0.11342484,\n",
       "  0.26695442,\n",
       "  0.5336146,\n",
       "  0.1317629,\n",
       "  -0.3741234,\n",
       "  -0.1452374,\n",
       "  -0.16695309,\n",
       "  -0.07436226,\n",
       "  0.13809697,\n",
       "  0.032975912,\n",
       "  -0.2540873,\n",
       "  0.23921083,\n",
       "  0.0389679,\n",
       "  0.032427628,\n",
       "  -0.3885183,\n",
       "  -0.13903728,\n",
       "  -0.10340132,\n",
       "  0.19006059,\n",
       "  0.086405456,\n",
       "  0.23669115,\n",
       "  -0.0631999,\n",
       "  -0.20589107,\n",
       "  -0.16161945,\n",
       "  -0.015037088,\n",
       "  0.13688779,\n",
       "  0.600772,\n",
       "  0.16918123,\n",
       "  -0.13016659,\n",
       "  0.11091307,\n",
       "  -0.036549047,\n",
       "  0.32373616,\n",
       "  0.1930133,\n",
       "  -0.31627283,\n",
       "  -0.047616385,\n",
       "  -0.28717968,\n",
       "  -0.072784394,\n",
       "  -0.3666559,\n",
       "  0.085083224,\n",
       "  -0.37521198,\n",
       "  0.2795677,\n",
       "  0.21004839,\n",
       "  0.13541496,\n",
       "  0.28457928,\n",
       "  -0.12663987,\n",
       "  0.15884247,\n",
       "  0.39131424,\n",
       "  -0.2780108,\n",
       "  -0.14145648,\n",
       "  0.08039207,\n",
       "  -0.2772493,\n",
       "  -0.12831426,\n",
       "  0.2535294,\n",
       "  -0.14505112,\n",
       "  -0.12357985,\n",
       "  -0.43397182,\n",
       "  0.43870166,\n",
       "  -0.0821075,\n",
       "  0.013932641,\n",
       "  -0.14686842,\n",
       "  -0.24390511,\n",
       "  -0.13279876,\n",
       "  0.073886774,\n",
       "  0.18295133,\n",
       "  -0.22782099,\n",
       "  0.47756183,\n",
       "  -0.14803986,\n",
       "  -0.06004305,\n",
       "  0.08998051,\n",
       "  0.22275682,\n",
       "  0.13716838,\n",
       "  0.17381626,\n",
       "  -0.24734461,\n",
       "  0.12250684,\n",
       "  0.10966083,\n",
       "  -0.13867074,\n",
       "  0.033755116,\n",
       "  -0.051531818,\n",
       "  -0.1843435,\n",
       "  0.3284534,\n",
       "  0.18937416,\n",
       "  -0.1280251,\n",
       "  0.23242277,\n",
       "  -0.016522128,\n",
       "  0.15196756,\n",
       "  0.27052477,\n",
       "  -0.13292114,\n",
       "  0.20022872,\n",
       "  -0.061171018,\n",
       "  0.21179472,\n",
       "  0.77113575,\n",
       "  0.25345257,\n",
       "  -0.009174653,\n",
       "  -0.36402464,\n",
       "  0.058031086,\n",
       "  -0.118816204],\n",
       " [-0.26509693,\n",
       "  0.19142126,\n",
       "  -0.16694638,\n",
       "  0.00949949,\n",
       "  0.16430263,\n",
       "  -0.28885603,\n",
       "  0.25627705,\n",
       "  0.34407854,\n",
       "  0.05025671,\n",
       "  -0.2988285,\n",
       "  -0.031234752,\n",
       "  -0.41789305,\n",
       "  0.013207271,\n",
       "  -0.38274544,\n",
       "  0.11144707,\n",
       "  0.023439014,\n",
       "  0.5105923,\n",
       "  -0.5976161,\n",
       "  -0.1897753,\n",
       "  -0.4963417,\n",
       "  -0.09909721,\n",
       "  0.11280027,\n",
       "  0.6810375,\n",
       "  -0.096257426,\n",
       "  -0.2353731,\n",
       "  0.00029733562,\n",
       "  -0.54714537,\n",
       "  -0.10620609,\n",
       "  -0.13312605,\n",
       "  -0.032898676,\n",
       "  0.8091992,\n",
       "  -0.17649817,\n",
       "  0.03705338,\n",
       "  0.25886434,\n",
       "  -0.12488716,\n",
       "  -0.0057449234,\n",
       "  0.071952045,\n",
       "  -0.6367286,\n",
       "  -0.25646344,\n",
       "  -0.0012692751,\n",
       "  -0.092945635,\n",
       "  -0.14711085,\n",
       "  0.25657567,\n",
       "  0.10387892,\n",
       "  0.47606742,\n",
       "  0.18248492,\n",
       "  0.15332657,\n",
       "  0.24016418,\n",
       "  -0.22724888,\n",
       "  0.41913065,\n",
       "  0.06475174,\n",
       "  -0.24823506,\n",
       "  -0.0045965323,\n",
       "  -0.38706174,\n",
       "  -0.5691338,\n",
       "  0.009476093,\n",
       "  0.36039075,\n",
       "  0.13072048,\n",
       "  -0.42031586,\n",
       "  -0.16109407,\n",
       "  -0.3133248,\n",
       "  0.02586777,\n",
       "  0.6923065,\n",
       "  -0.069713496,\n",
       "  -0.73152125,\n",
       "  0.33304957,\n",
       "  -0.090341166,\n",
       "  0.36007327,\n",
       "  -0.6894473,\n",
       "  0.16494887,\n",
       "  -0.4511622,\n",
       "  0.12127337,\n",
       "  0.011663836,\n",
       "  0.106831744,\n",
       "  0.40282324,\n",
       "  -0.20716196,\n",
       "  -0.22505195,\n",
       "  0.14886582,\n",
       "  -0.12892905,\n",
       "  0.07338637,\n",
       "  0.03921921,\n",
       "  0.0040865852,\n",
       "  -0.5167069,\n",
       "  0.54166573,\n",
       "  0.22000086,\n",
       "  0.10054148,\n",
       "  0.39997867,\n",
       "  0.12925118,\n",
       "  0.36621624,\n",
       "  0.48435444,\n",
       "  -0.106295414,\n",
       "  0.5160667,\n",
       "  0.15496592,\n",
       "  0.16718405,\n",
       "  0.4272138,\n",
       "  0.28178304,\n",
       "  0.07392969,\n",
       "  -0.17394263,\n",
       "  0.33193067,\n",
       "  -0.2748796],\n",
       " [0.101777546,\n",
       "  0.5700468,\n",
       "  0.1243671,\n",
       "  -0.014679098,\n",
       "  0.055805568,\n",
       "  -0.031788204,\n",
       "  -0.03350006,\n",
       "  0.42176196,\n",
       "  -0.026775464,\n",
       "  -0.33920792,\n",
       "  -0.21888421,\n",
       "  -0.28173682,\n",
       "  -0.3912667,\n",
       "  -0.19745646,\n",
       "  -0.06734669,\n",
       "  -0.14438832,\n",
       "  0.31290373,\n",
       "  -0.64973664,\n",
       "  -0.123284586,\n",
       "  -0.14889154,\n",
       "  -0.29410172,\n",
       "  0.28999057,\n",
       "  0.259524,\n",
       "  -0.4084603,\n",
       "  -0.02769756,\n",
       "  0.35105133,\n",
       "  -0.6936143,\n",
       "  -0.24561617,\n",
       "  -0.32899246,\n",
       "  0.28869793,\n",
       "  0.50545293,\n",
       "  0.00029148822,\n",
       "  -0.033095557,\n",
       "  0.094235584,\n",
       "  -0.18604746,\n",
       "  0.11249158,\n",
       "  -0.19298238,\n",
       "  -0.032246668,\n",
       "  -0.13468689,\n",
       "  -0.47701812,\n",
       "  -0.5186198,\n",
       "  0.18993115,\n",
       "  0.3329375,\n",
       "  -0.39491823,\n",
       "  0.07751193,\n",
       "  -0.03715035,\n",
       "  -0.2612879,\n",
       "  0.66900265,\n",
       "  0.014308379,\n",
       "  0.3046995,\n",
       "  -0.29862118,\n",
       "  -0.24386577,\n",
       "  0.08377122,\n",
       "  -0.061853893,\n",
       "  -0.35568145,\n",
       "  0.21336575,\n",
       "  0.40013453,\n",
       "  0.23632379,\n",
       "  -0.34217736,\n",
       "  0.14847976,\n",
       "  -0.046438314,\n",
       "  0.62781227,\n",
       "  -0.2431518,\n",
       "  0.3910086,\n",
       "  -0.2872075,\n",
       "  0.00417595,\n",
       "  -0.053176254,\n",
       "  0.004557473,\n",
       "  -0.17608309,\n",
       "  0.26885545,\n",
       "  -0.33379507,\n",
       "  -0.21229722,\n",
       "  0.30983937,\n",
       "  0.036723528,\n",
       "  0.43520215,\n",
       "  0.15226144,\n",
       "  -0.14026518,\n",
       "  -0.006631912,\n",
       "  -0.10234166,\n",
       "  0.08045822,\n",
       "  0.24334201,\n",
       "  0.11743244,\n",
       "  -0.12657891,\n",
       "  0.07313844,\n",
       "  0.054538418,\n",
       "  -0.058852367,\n",
       "  0.16915959,\n",
       "  0.13908572,\n",
       "  0.1418795,\n",
       "  0.22679183,\n",
       "  -0.057910413,\n",
       "  0.10469801,\n",
       "  0.04996738,\n",
       "  0.17533645,\n",
       "  0.3034015,\n",
       "  0.35527542,\n",
       "  0.37184098,\n",
       "  -0.49331158,\n",
       "  0.28828827,\n",
       "  -0.06323124],\n",
       " [-0.40982962,\n",
       "  0.050068676,\n",
       "  -0.20714448,\n",
       "  -0.0019069944,\n",
       "  -0.117920265,\n",
       "  -0.16350989,\n",
       "  -0.051885832,\n",
       "  0.49919486,\n",
       "  0.19008063,\n",
       "  -0.16651621,\n",
       "  -0.11860005,\n",
       "  -0.2955101,\n",
       "  -0.2797202,\n",
       "  -0.13417889,\n",
       "  -0.1993705,\n",
       "  -0.04233915,\n",
       "  0.007578725,\n",
       "  -0.091290705,\n",
       "  0.056188624,\n",
       "  -0.36680564,\n",
       "  0.12369381,\n",
       "  -0.1260112,\n",
       "  0.54032266,\n",
       "  0.19490549,\n",
       "  -0.2667219,\n",
       "  -0.17440173,\n",
       "  -0.012320109,\n",
       "  -0.35703012,\n",
       "  -0.23871683,\n",
       "  -0.23542625,\n",
       "  0.32751384,\n",
       "  0.2270047,\n",
       "  0.06909209,\n",
       "  0.36868718,\n",
       "  0.3543517,\n",
       "  0.022099948,\n",
       "  -0.04229989,\n",
       "  -0.14802904,\n",
       "  -0.66221875,\n",
       "  -0.34842417,\n",
       "  -0.054135766,\n",
       "  -0.076429665,\n",
       "  0.27237466,\n",
       "  -0.40698865,\n",
       "  0.15478238,\n",
       "  0.10492448,\n",
       "  0.06629984,\n",
       "  0.3951825,\n",
       "  -0.048416473,\n",
       "  0.08180043,\n",
       "  0.4058294,\n",
       "  -0.4098433,\n",
       "  -0.3914396,\n",
       "  0.22315635,\n",
       "  -0.46715307,\n",
       "  0.02850387,\n",
       "  0.06387031,\n",
       "  -0.01416174,\n",
       "  -0.2544076,\n",
       "  -0.11645147,\n",
       "  -0.18547796,\n",
       "  0.14954159,\n",
       "  0.013554687,\n",
       "  -0.09383109,\n",
       "  -0.13530917,\n",
       "  -0.010049028,\n",
       "  -0.12171831,\n",
       "  0.5792831,\n",
       "  -0.31579152,\n",
       "  0.33569783,\n",
       "  -0.62484723,\n",
       "  0.066155,\n",
       "  0.1889245,\n",
       "  0.17471665,\n",
       "  0.024213484,\n",
       "  -0.20164904,\n",
       "  -0.2961107,\n",
       "  -0.08999237,\n",
       "  -0.28510383,\n",
       "  0.111515455,\n",
       "  -0.08292989,\n",
       "  0.31251445,\n",
       "  -0.15357207,\n",
       "  0.41870794,\n",
       "  0.18536945,\n",
       "  0.16759706,\n",
       "  -0.07709042,\n",
       "  0.29718,\n",
       "  0.32906696,\n",
       "  0.2668245,\n",
       "  -0.038270023,\n",
       "  0.16654783,\n",
       "  -0.1598796,\n",
       "  0.0037525722,\n",
       "  0.9245722,\n",
       "  0.1505256,\n",
       "  0.04564517,\n",
       "  -0.41945747,\n",
       "  -0.020048182,\n",
       "  0.28766817],\n",
       " [-0.1263594,\n",
       "  0.15392528,\n",
       "  0.04459915,\n",
       "  0.18597084,\n",
       "  0.013291234,\n",
       "  -0.17222302,\n",
       "  0.11125243,\n",
       "  0.4266919,\n",
       "  0.07967219,\n",
       "  -0.1299079,\n",
       "  -0.1336356,\n",
       "  -0.1942742,\n",
       "  -0.086195946,\n",
       "  0.042735014,\n",
       "  -0.00087855983,\n",
       "  -0.11856009,\n",
       "  0.12319672,\n",
       "  -0.15065993,\n",
       "  0.051306706,\n",
       "  -0.24259064,\n",
       "  -0.042819772,\n",
       "  -0.026822919,\n",
       "  0.109351404,\n",
       "  -0.044862453,\n",
       "  0.037337556,\n",
       "  -0.005996667,\n",
       "  -0.22537862,\n",
       "  -0.19718125,\n",
       "  -0.052201144,\n",
       "  0.05811798,\n",
       "  0.37751925,\n",
       "  0.093332365,\n",
       "  -0.04747903,\n",
       "  0.053113155,\n",
       "  -0.022706429,\n",
       "  0.13642728,\n",
       "  0.08987453,\n",
       "  -0.20909531,\n",
       "  -0.0909927,\n",
       "  -0.25328058,\n",
       "  -0.011915984,\n",
       "  -0.19970447,\n",
       "  0.064651795,\n",
       "  -0.1701941,\n",
       "  0.13039231,\n",
       "  0.007959861,\n",
       "  -0.013427423,\n",
       "  0.11875919,\n",
       "  0.00035976723,\n",
       "  0.16146126,\n",
       "  0.2245798,\n",
       "  -0.19891441,\n",
       "  -0.0649988,\n",
       "  0.006528646,\n",
       "  -0.18398485,\n",
       "  0.082433194,\n",
       "  0.20527545,\n",
       "  -0.01012233,\n",
       "  -0.13051389,\n",
       "  -0.0999641,\n",
       "  0.086478405,\n",
       "  0.035801884,\n",
       "  -0.03611875,\n",
       "  0.061067812,\n",
       "  -0.1958051,\n",
       "  0.0012395026,\n",
       "  0.01356926,\n",
       "  0.13351232,\n",
       "  -0.19182606,\n",
       "  0.28873673,\n",
       "  -0.098070115,\n",
       "  -0.06919715,\n",
       "  0.0651904,\n",
       "  0.059426416,\n",
       "  0.13042983,\n",
       "  0.06698645,\n",
       "  -0.107666664,\n",
       "  -0.0044622924,\n",
       "  -0.014399729,\n",
       "  -0.025762532,\n",
       "  -0.01220326,\n",
       "  -0.031772666,\n",
       "  -0.18013926,\n",
       "  0.2240581,\n",
       "  0.097291775,\n",
       "  0.0026907506,\n",
       "  0.06728541,\n",
       "  0.09367553,\n",
       "  0.24506874,\n",
       "  0.14317253,\n",
       "  0.020779464,\n",
       "  0.05345193,\n",
       "  -0.035573117,\n",
       "  0.112726994,\n",
       "  0.38612962,\n",
       "  0.19541767,\n",
       "  4.655597e-05,\n",
       "  -0.23856638,\n",
       "  0.08413175,\n",
       "  -0.010520651],\n",
       " [-0.77106756,\n",
       "  0.23528458,\n",
       "  -0.21174854,\n",
       "  0.27187505,\n",
       "  -0.15571608,\n",
       "  -0.94996065,\n",
       "  0.10667205,\n",
       "  0.7088936,\n",
       "  -0.18941997,\n",
       "  -0.55017364,\n",
       "  0.48452967,\n",
       "  -0.09494304,\n",
       "  0.13884561,\n",
       "  -0.18544285,\n",
       "  0.11759544,\n",
       "  -0.4537671,\n",
       "  0.7328945,\n",
       "  -0.42486784,\n",
       "  0.7533574,\n",
       "  -0.49645877,\n",
       "  -0.04060164,\n",
       "  -0.115242265,\n",
       "  0.5484552,\n",
       "  0.35309356,\n",
       "  -0.20059668,\n",
       "  0.41258883,\n",
       "  -0.13746877,\n",
       "  -0.24378105,\n",
       "  -0.23636346,\n",
       "  -0.11088887,\n",
       "  0.8870399,\n",
       "  0.524634,\n",
       "  -0.20843226,\n",
       "  0.14100967,\n",
       "  0.0514991,\n",
       "  0.54968065,\n",
       "  0.22925374,\n",
       "  -0.67976147,\n",
       "  -0.701528,\n",
       "  -0.026092574,\n",
       "  0.5505168,\n",
       "  -0.1488548,\n",
       "  0.5125103,\n",
       "  -0.64446634,\n",
       "  0.6017319,\n",
       "  0.50191987,\n",
       "  -0.34811395,\n",
       "  0.005406486,\n",
       "  0.11641252,\n",
       "  -0.16155581,\n",
       "  0.24024619,\n",
       "  -0.64171284,\n",
       "  -0.6369382,\n",
       "  -0.20102507,\n",
       "  -0.7399698,\n",
       "  -0.16801555,\n",
       "  -0.01919495,\n",
       "  0.24793428,\n",
       "  0.3216075,\n",
       "  -0.710187,\n",
       "  0.28938037,\n",
       "  -0.22908455,\n",
       "  0.53422683,\n",
       "  0.05628932,\n",
       "  -0.3285423,\n",
       "  -0.68987155,\n",
       "  -0.38463837,\n",
       "  0.14022928,\n",
       "  -0.8157721,\n",
       "  -0.24739207,\n",
       "  0.0061938525,\n",
       "  0.10615112,\n",
       "  0.089385204,\n",
       "  0.3136158,\n",
       "  0.10460293,\n",
       "  -0.5775631,\n",
       "  -0.6318938,\n",
       "  0.7623156,\n",
       "  0.34250015,\n",
       "  -0.03001093,\n",
       "  -0.03970192,\n",
       "  -0.16259903,\n",
       "  -0.3579617,\n",
       "  0.2235136,\n",
       "  0.60073245,\n",
       "  -0.23915105,\n",
       "  0.55542934,\n",
       "  0.3765943,\n",
       "  0.53130126,\n",
       "  0.0833285,\n",
       "  -0.20747231,\n",
       "  0.37090608,\n",
       "  -0.113275394,\n",
       "  -0.2065474,\n",
       "  0.5397589,\n",
       "  -0.28891015,\n",
       "  -0.13412064,\n",
       "  -0.6086182,\n",
       "  0.32866472,\n",
       "  0.16779336],\n",
       " [-0.086189345,\n",
       "  0.16917695,\n",
       "  0.03353002,\n",
       "  0.15967813,\n",
       "  0.033722606,\n",
       "  -0.15694419,\n",
       "  0.09803427,\n",
       "  0.38338286,\n",
       "  0.10245568,\n",
       "  -0.11170441,\n",
       "  -0.1432781,\n",
       "  -0.16281188,\n",
       "  -0.09635158,\n",
       "  0.011204478,\n",
       "  -0.017696077,\n",
       "  -0.11958668,\n",
       "  0.06474323,\n",
       "  -0.15111646,\n",
       "  0.037860684,\n",
       "  -0.21537569,\n",
       "  -0.011823618,\n",
       "  -0.016421402,\n",
       "  0.08742619,\n",
       "  -0.067584075,\n",
       "  -0.0041780425,\n",
       "  -0.0048770616,\n",
       "  -0.21316229,\n",
       "  -0.20800836,\n",
       "  -0.07278517,\n",
       "  0.09369774,\n",
       "  0.33247,\n",
       "  0.051452175,\n",
       "  -0.019465826,\n",
       "  -0.002682694,\n",
       "  0.008119794,\n",
       "  0.095000535,\n",
       "  0.081246346,\n",
       "  -0.15403287,\n",
       "  -0.0628888,\n",
       "  -0.23915355,\n",
       "  -0.018491177,\n",
       "  -0.18305089,\n",
       "  0.024781153,\n",
       "  -0.088137135,\n",
       "  0.11080295,\n",
       "  -0.039385833,\n",
       "  -0.009679707,\n",
       "  0.08885876,\n",
       "  0.030135648,\n",
       "  0.1540005,\n",
       "  0.19379146,\n",
       "  -0.18141857,\n",
       "  -0.047745965,\n",
       "  -0.013021885,\n",
       "  -0.16010684,\n",
       "  0.10699779,\n",
       "  0.19043574,\n",
       "  0.00075509335,\n",
       "  -0.15949641,\n",
       "  -0.049138654,\n",
       "  0.059268933,\n",
       "  0.066363424,\n",
       "  -0.042875562,\n",
       "  0.07856785,\n",
       "  -0.19238143,\n",
       "  0.01396043,\n",
       "  0.023603212,\n",
       "  0.123127975,\n",
       "  -0.216288,\n",
       "  0.23979318,\n",
       "  -0.08777703,\n",
       "  -0.08254146,\n",
       "  0.06286358,\n",
       "  0.07435269,\n",
       "  0.109652355,\n",
       "  0.099073656,\n",
       "  -0.09301964,\n",
       "  -0.008442126,\n",
       "  -0.04092786,\n",
       "  -0.032939058,\n",
       "  -0.02398974,\n",
       "  -0.044247802,\n",
       "  -0.116089225,\n",
       "  0.18837343,\n",
       "  0.065078974,\n",
       "  -0.01190737,\n",
       "  0.030767348,\n",
       "  0.10115031,\n",
       "  0.22152698,\n",
       "  0.11865191,\n",
       "  0.050458968,\n",
       "  0.037654,\n",
       "  -0.029917693,\n",
       "  0.0668091,\n",
       "  0.26078033,\n",
       "  0.18904676,\n",
       "  0.015472521,\n",
       "  -0.21175921,\n",
       "  0.07205963,\n",
       "  0.0030443545],\n",
       " [-0.03132796,\n",
       "  0.32170817,\n",
       "  -0.039681442,\n",
       "  0.16933937,\n",
       "  0.021206442,\n",
       "  -0.070325516,\n",
       "  0.45083898,\n",
       "  0.75837046,\n",
       "  0.29691544,\n",
       "  -0.35529983,\n",
       "  -0.18818888,\n",
       "  -0.03919092,\n",
       "  -0.21785901,\n",
       "  -0.098488875,\n",
       "  0.112363726,\n",
       "  -0.13570496,\n",
       "  0.104315974,\n",
       "  -0.20019878,\n",
       "  -0.2925945,\n",
       "  -0.4044322,\n",
       "  0.13075447,\n",
       "  -0.028644567,\n",
       "  0.11151033,\n",
       "  -0.15362228,\n",
       "  0.030952955,\n",
       "  0.055543892,\n",
       "  -0.45322028,\n",
       "  -0.29384792,\n",
       "  0.13066286,\n",
       "  0.38524714,\n",
       "  0.5348448,\n",
       "  0.0465818,\n",
       "  -0.12442072,\n",
       "  -0.1916844,\n",
       "  -0.14347406,\n",
       "  0.20322095,\n",
       "  -0.1289192,\n",
       "  -0.30182067,\n",
       "  0.14874466,\n",
       "  -0.32919148,\n",
       "  -0.23414356,\n",
       "  -0.30343452,\n",
       "  0.29250798,\n",
       "  -0.13297518,\n",
       "  0.3833516,\n",
       "  -0.04426922,\n",
       "  0.4083283,\n",
       "  0.18207361,\n",
       "  -0.094724365,\n",
       "  0.28937453,\n",
       "  0.14627758,\n",
       "  -0.26148143,\n",
       "  -0.12054399,\n",
       "  -0.31304213,\n",
       "  -0.15918978,\n",
       "  -0.005084542,\n",
       "  0.43976423,\n",
       "  0.20266856,\n",
       "  -0.3062072,\n",
       "  -0.3374306,\n",
       "  -0.049310744,\n",
       "  0.06624929,\n",
       "  0.31728908,\n",
       "  -0.08553947,\n",
       "  -0.549997,\n",
       "  0.10949866,\n",
       "  0.09096471,\n",
       "  0.16307552,\n",
       "  -0.43591663,\n",
       "  0.26874298,\n",
       "  -0.058675077,\n",
       "  -0.19777139,\n",
       "  -0.20592624,\n",
       "  0.349409,\n",
       "  0.30438083,\n",
       "  0.25806952,\n",
       "  -0.21202524,\n",
       "  0.059301954,\n",
       "  -0.25681818,\n",
       "  -0.14276321,\n",
       "  -0.053201426,\n",
       "  0.0012622892,\n",
       "  -0.1976681,\n",
       "  0.4025415,\n",
       "  0.3175159,\n",
       "  -0.25323236,\n",
       "  0.4562103,\n",
       "  0.24575235,\n",
       "  0.13403124,\n",
       "  0.29089114,\n",
       "  0.043681182,\n",
       "  0.2651965,\n",
       "  -0.024718933,\n",
       "  -0.02598579,\n",
       "  0.6360207,\n",
       "  0.40105397,\n",
       "  0.070136905,\n",
       "  -0.058851995,\n",
       "  0.35815427,\n",
       "  -0.33951306],\n",
       " [-0.37130994,\n",
       "  0.5398291,\n",
       "  0.26367855,\n",
       "  -0.013386886,\n",
       "  0.084592566,\n",
       "  -0.2723914,\n",
       "  0.16031432,\n",
       "  0.6032278,\n",
       "  -0.09345168,\n",
       "  -0.33732677,\n",
       "  -0.23245633,\n",
       "  -0.34247065,\n",
       "  -0.023235645,\n",
       "  -0.096456386,\n",
       "  0.09133489,\n",
       "  -0.37108427,\n",
       "  0.4213232,\n",
       "  -0.41663036,\n",
       "  0.052227493,\n",
       "  -0.24580735,\n",
       "  -0.25770667,\n",
       "  0.06553904,\n",
       "  0.20576102,\n",
       "  -0.22231495,\n",
       "  -0.069910765,\n",
       "  0.29285467,\n",
       "  -0.6355951,\n",
       "  -0.1533795,\n",
       "  -0.09240562,\n",
       "  0.0027155634,\n",
       "  0.6694885,\n",
       "  0.3078826,\n",
       "  0.34493774,\n",
       "  0.16712077,\n",
       "  -0.016341941,\n",
       "  0.17421941,\n",
       "  0.6208168,\n",
       "  -0.48103845,\n",
       "  -0.37804294,\n",
       "  -0.02026948,\n",
       "  -0.32720774,\n",
       "  0.06684169,\n",
       "  0.14296398,\n",
       "  -0.15890568,\n",
       "  0.42160532,\n",
       "  -0.0727891,\n",
       "  0.23347123,\n",
       "  0.2936143,\n",
       "  -0.22820775,\n",
       "  0.37470344,\n",
       "  -0.0633117,\n",
       "  -0.109657526,\n",
       "  -0.063228145,\n",
       "  -0.35805488,\n",
       "  -0.13012165,\n",
       "  0.42032093,\n",
       "  0.09652138,\n",
       "  0.24992757,\n",
       "  -0.12065093,\n",
       "  -0.60263824,\n",
       "  0.1433203,\n",
       "  0.17279533,\n",
       "  0.16175917,\n",
       "  0.08914581,\n",
       "  -0.45461714,\n",
       "  -0.089564756,\n",
       "  -0.19106017,\n",
       "  0.109682545,\n",
       "  -0.3428233,\n",
       "  0.26119727,\n",
       "  -0.19421418,\n",
       "  -0.038565565,\n",
       "  0.055664197,\n",
       "  0.43953782,\n",
       "  0.40991625,\n",
       "  0.2694903,\n",
       "  -0.13073513,\n",
       "  0.14557466,\n",
       "  -0.019852074,\n",
       "  -0.2801529,\n",
       "  0.2994238,\n",
       "  0.18598919,\n",
       "  -0.2000923,\n",
       "  0.41229123,\n",
       "  -0.12524399,\n",
       "  -0.070182696,\n",
       "  0.5529308,\n",
       "  -0.107675806,\n",
       "  -0.2057855,\n",
       "  -0.09802939,\n",
       "  0.19120826,\n",
       "  0.070647545,\n",
       "  -0.1511987,\n",
       "  0.20355342,\n",
       "  0.75533843,\n",
       "  0.5851004,\n",
       "  -0.118328296,\n",
       "  -0.103122056,\n",
       "  0.14637429,\n",
       "  -0.30212057],\n",
       " [0.029496726,\n",
       "  0.1816245,\n",
       "  0.2289366,\n",
       "  0.20401736,\n",
       "  0.073074386,\n",
       "  -0.47633433,\n",
       "  0.30031326,\n",
       "  0.6024848,\n",
       "  0.095488936,\n",
       "  -0.24824487,\n",
       "  -0.076462,\n",
       "  -0.29557326,\n",
       "  0.14964984,\n",
       "  0.08679468,\n",
       "  0.10352212,\n",
       "  0.06425573,\n",
       "  0.21812537,\n",
       "  -0.37380403,\n",
       "  -0.2526087,\n",
       "  -0.41801915,\n",
       "  -0.0032376114,\n",
       "  0.303119,\n",
       "  0.090122215,\n",
       "  -0.34181315,\n",
       "  -0.200421,\n",
       "  0.14743951,\n",
       "  -0.24093468,\n",
       "  -0.2891449,\n",
       "  -0.10048175,\n",
       "  0.18962777,\n",
       "  0.41362283,\n",
       "  0.0028270655,\n",
       "  0.14999053,\n",
       "  0.12676431,\n",
       "  0.088570215,\n",
       "  0.28906038,\n",
       "  -0.2001123,\n",
       "  -0.42833906,\n",
       "  -0.457199,\n",
       "  -0.72797674,\n",
       "  -0.16858032,\n",
       "  -0.06608578,\n",
       "  -0.20414011,\n",
       "  -0.09901149,\n",
       "  0.22556199,\n",
       "  -0.47585768,\n",
       "  0.13027439,\n",
       "  0.03252134,\n",
       "  0.29954162,\n",
       "  0.24880634,\n",
       "  0.15804526,\n",
       "  -0.31752238,\n",
       "  -0.04254919,\n",
       "  -0.103322625,\n",
       "  -0.15251264,\n",
       "  0.43919715,\n",
       "  0.163538,\n",
       "  0.17131197,\n",
       "  -0.21119444,\n",
       "  0.42612243,\n",
       "  -0.28870413,\n",
       "  0.10555726,\n",
       "  0.025174074,\n",
       "  0.16831769,\n",
       "  -0.40730098,\n",
       "  0.31813282,\n",
       "  -0.3038801,\n",
       "  0.16686973,\n",
       "  -0.26593095,\n",
       "  -0.011703239,\n",
       "  -0.0287824,\n",
       "  -0.21269189,\n",
       "  0.2753058,\n",
       "  -0.06449075,\n",
       "  0.26399556,\n",
       "  -0.08482212,\n",
       "  -0.008653123,\n",
       "  -0.18087773,\n",
       "  -0.33831576,\n",
       "  0.024633812,\n",
       "  0.09282926,\n",
       "  0.350844,\n",
       "  -0.22475958,\n",
       "  0.23633589,\n",
       "  0.15044917,\n",
       "  -0.0074337726,\n",
       "  0.25757825,\n",
       "  0.11418771,\n",
       "  0.5317481,\n",
       "  0.23824,\n",
       "  0.318103,\n",
       "  0.058137525,\n",
       "  0.08111415,\n",
       "  0.08246446,\n",
       "  0.21569824,\n",
       "  0.030050643,\n",
       "  0.0040492048,\n",
       "  -0.48405275,\n",
       "  0.19298816,\n",
       "  0.0928908],\n",
       " [-0.020727664,\n",
       "  0.26348975,\n",
       "  0.13407825,\n",
       "  0.120569415,\n",
       "  0.08158121,\n",
       "  -0.20014608,\n",
       "  0.078428015,\n",
       "  0.47947833,\n",
       "  0.08102544,\n",
       "  -0.16457716,\n",
       "  -0.3434504,\n",
       "  -0.35525987,\n",
       "  0.008928882,\n",
       "  -0.15028387,\n",
       "  -0.042111725,\n",
       "  -0.2912084,\n",
       "  0.26041448,\n",
       "  -0.51000476,\n",
       "  0.04477353,\n",
       "  -0.25640824,\n",
       "  -0.16978292,\n",
       "  0.10996772,\n",
       "  0.23047228,\n",
       "  -0.12577425,\n",
       "  -0.27821404,\n",
       "  0.12284672,\n",
       "  -0.42853168,\n",
       "  -0.28582552,\n",
       "  -0.10838761,\n",
       "  -0.061536603,\n",
       "  0.53224355,\n",
       "  -0.021313393,\n",
       "  -0.040266626,\n",
       "  0.21310852,\n",
       "  0.038625423,\n",
       "  0.14974637,\n",
       "  0.24651344,\n",
       "  -0.1937154,\n",
       "  -0.3882377,\n",
       "  -0.37276837,\n",
       "  -0.11531475,\n",
       "  0.046094686,\n",
       "  0.08074325,\n",
       "  -0.0917661,\n",
       "  -0.01794956,\n",
       "  -0.08421793,\n",
       "  0.030769054,\n",
       "  0.28931788,\n",
       "  -0.118518874,\n",
       "  0.30211937,\n",
       "  0.008228275,\n",
       "  -0.3509232,\n",
       "  -0.019150686,\n",
       "  -0.19035466,\n",
       "  -0.2503764,\n",
       "  0.0801338,\n",
       "  0.2778839,\n",
       "  0.115003206,\n",
       "  -0.267739,\n",
       "  -0.033683836,\n",
       "  -0.07853395,\n",
       "  0.086672865,\n",
       "  0.054409828,\n",
       "  0.053911537,\n",
       "  -0.29072723,\n",
       "  0.17761387,\n",
       "  -0.15978323,\n",
       "  0.1271204,\n",
       "  -0.33755836,\n",
       "  0.053967442,\n",
       "  -0.2205024,\n",
       "  -0.15207756,\n",
       "  0.016559793,\n",
       "  -0.062118664,\n",
       "  0.38545942,\n",
       "  -0.1270125,\n",
       "  -0.1823423,\n",
       "  0.14637795,\n",
       "  -0.25078884,\n",
       "  0.10537961,\n",
       "  0.09984524,\n",
       "  0.034366865,\n",
       "  -0.2339598,\n",
       "  0.2310353,\n",
       "  0.12601638,\n",
       "  0.028811658,\n",
       "  0.20134641,\n",
       "  0.2069493,\n",
       "  0.28912002,\n",
       "  -0.0019905823,\n",
       "  0.17536652,\n",
       "  0.072457775,\n",
       "  -0.030828645,\n",
       "  0.26419878,\n",
       "  0.3852037,\n",
       "  0.07158104,\n",
       "  0.12495427,\n",
       "  -0.32463554,\n",
       "  0.19604674,\n",
       "  0.024162738],\n",
       " [-0.2112699,\n",
       "  0.051888082,\n",
       "  -0.0694377,\n",
       "  0.17191716,\n",
       "  0.042820834,\n",
       "  -0.14575976,\n",
       "  0.24165292,\n",
       "  0.6449612,\n",
       "  0.19505775,\n",
       "  -0.3805583,\n",
       "  -0.20583396,\n",
       "  -0.34817383,\n",
       "  -0.035498634,\n",
       "  0.19315644,\n",
       "  -0.09425183,\n",
       "  -0.27510884,\n",
       "  0.12601781,\n",
       "  -0.21312526,\n",
       "  0.042894255,\n",
       "  -0.47736531,\n",
       "  0.16083592,\n",
       "  -0.041868772,\n",
       "  0.41384792,\n",
       "  0.002002267,\n",
       "  -0.04058733,\n",
       "  -0.02192963,\n",
       "  -0.08703978,\n",
       "  -0.107885435,\n",
       "  -0.18040226,\n",
       "  0.14562832,\n",
       "  0.4478351,\n",
       "  -0.074599616,\n",
       "  -0.14975356,\n",
       "  0.14685991,\n",
       "  -0.0039042314,\n",
       "  0.14397903,\n",
       "  -0.02675846,\n",
       "  -0.16272421,\n",
       "  -0.46644378,\n",
       "  -0.57155776,\n",
       "  -0.04500823,\n",
       "  -0.10033569,\n",
       "  0.053199958,\n",
       "  -0.12174605,\n",
       "  0.29999956,\n",
       "  -0.040983047,\n",
       "  0.15787429,\n",
       "  -0.104995385,\n",
       "  0.1981651,\n",
       "  0.14427437,\n",
       "  0.00047093298,\n",
       "  -0.24865973,\n",
       "  0.003537501,\n",
       "  -0.16844882,\n",
       "  -0.39226952,\n",
       "  -0.09398212,\n",
       "  -0.003312042,\n",
       "  -0.26834622,\n",
       "  -0.3871856,\n",
       "  -0.12052855,\n",
       "  0.09678957,\n",
       "  -0.06659383,\n",
       "  0.24308944,\n",
       "  0.10306065,\n",
       "  -0.6806316,\n",
       "  0.045656215,\n",
       "  -0.11325812,\n",
       "  0.21016113,\n",
       "  -0.5799629,\n",
       "  0.17829002,\n",
       "  0.09347346,\n",
       "  0.011521899,\n",
       "  0.12558548,\n",
       "  0.34705043,\n",
       "  0.32342327,\n",
       "  -0.051044013,\n",
       "  -0.08310266,\n",
       "  -0.041012373,\n",
       "  -0.28932664,\n",
       "  -0.0076279794,\n",
       "  -0.034677442,\n",
       "  0.23617351,\n",
       "  -0.027476672,\n",
       "  0.20923743,\n",
       "  0.29377824,\n",
       "  -0.23919933,\n",
       "  0.3247793,\n",
       "  0.33137718,\n",
       "  0.09551556,\n",
       "  0.13772279,\n",
       "  0.056872535,\n",
       "  0.21196288,\n",
       "  -0.22072726,\n",
       "  0.122996636,\n",
       "  0.57250166,\n",
       "  0.32066837,\n",
       "  -0.09615256,\n",
       "  -0.3404994,\n",
       "  0.11683802,\n",
       "  0.18034147],\n",
       " [-0.06713868,\n",
       "  0.18292119,\n",
       "  0.06943378,\n",
       "  0.119074054,\n",
       "  0.006128544,\n",
       "  -0.2672872,\n",
       "  0.11658265,\n",
       "  0.43715572,\n",
       "  0.14370638,\n",
       "  -0.12469168,\n",
       "  -0.09974481,\n",
       "  -0.20307027,\n",
       "  -0.08417605,\n",
       "  0.04701881,\n",
       "  0.024436979,\n",
       "  -0.07200258,\n",
       "  0.1620778,\n",
       "  -0.16895086,\n",
       "  -0.008004984,\n",
       "  -0.25937453,\n",
       "  0.01674911,\n",
       "  0.0387108,\n",
       "  0.12152928,\n",
       "  -0.09874731,\n",
       "  -0.028558869,\n",
       "  0.019028403,\n",
       "  -0.25474605,\n",
       "  -0.2909553,\n",
       "  -0.0652708,\n",
       "  0.124933206,\n",
       "  0.4320728,\n",
       "  0.115302406,\n",
       "  0.012284986,\n",
       "  0.026590798,\n",
       "  -0.005835671,\n",
       "  0.15162285,\n",
       "  0.065751486,\n",
       "  -0.24646287,\n",
       "  -0.17615923,\n",
       "  -0.33289582,\n",
       "  -0.087843984,\n",
       "  -0.12866747,\n",
       "  0.07350657,\n",
       "  -0.16586864,\n",
       "  0.15719306,\n",
       "  -0.05899164,\n",
       "  -0.03988831,\n",
       "  0.114278264,\n",
       "  0.12701546,\n",
       "  0.23694524,\n",
       "  0.19964117,\n",
       "  -0.17722084,\n",
       "  -0.03124413,\n",
       "  -0.048439447,\n",
       "  -0.1533611,\n",
       "  0.16369225,\n",
       "  0.22510558,\n",
       "  0.03409933,\n",
       "  -0.17892346,\n",
       "  0.0023215828,\n",
       "  0.034463666,\n",
       "  0.07998957,\n",
       "  -0.06946324,\n",
       "  0.08892841,\n",
       "  -0.2525258,\n",
       "  -0.0054278937,\n",
       "  -0.014897981,\n",
       "  0.09702397,\n",
       "  -0.2741275,\n",
       "  0.28613874,\n",
       "  -0.07617862,\n",
       "  -0.110463664,\n",
       "  0.119348764,\n",
       "  0.03326188,\n",
       "  0.17655078,\n",
       "  0.04883665,\n",
       "  -0.036642343,\n",
       "  -0.032277104,\n",
       "  -0.048539326,\n",
       "  -0.028064976,\n",
       "  -0.017237438,\n",
       "  0.029923655,\n",
       "  -0.19408873,\n",
       "  0.24784708,\n",
       "  0.12096391,\n",
       "  -0.04222529,\n",
       "  0.100016996,\n",
       "  0.040553596,\n",
       "  0.26098645,\n",
       "  0.14396702,\n",
       "  0.101179525,\n",
       "  0.010558246,\n",
       "  -0.031132592,\n",
       "  0.08727317,\n",
       "  0.24805051,\n",
       "  0.24341553,\n",
       "  0.025429562,\n",
       "  -0.32477182,\n",
       "  0.12162434,\n",
       "  0.008574833],\n",
       " [-0.16100244,\n",
       "  -0.20180328,\n",
       "  0.44954884,\n",
       "  0.22014563,\n",
       "  0.26070637,\n",
       "  -0.13888764,\n",
       "  0.28327116,\n",
       "  0.6343581,\n",
       "  -0.30129495,\n",
       "  -0.8243577,\n",
       "  0.16835134,\n",
       "  -0.23816104,\n",
       "  -0.28044668,\n",
       "  0.61542505,\n",
       "  0.19487901,\n",
       "  0.0037240367,\n",
       "  0.57325,\n",
       "  0.38547507,\n",
       "  -0.44282398,\n",
       "  -0.68147844,\n",
       "  -0.1535725,\n",
       "  -0.24924251,\n",
       "  0.5593146,\n",
       "  -0.4710573,\n",
       "  0.58277583,\n",
       "  0.09624735,\n",
       "  -0.0748915,\n",
       "  0.24838062,\n",
       "  0.08099702,\n",
       "  0.6872162,\n",
       "  0.39829487,\n",
       "  0.12308406,\n",
       "  -0.3408038,\n",
       "  -0.32725915,\n",
       "  -0.18141268,\n",
       "  0.9834353,\n",
       "  0.1278045,\n",
       "  -0.22491418,\n",
       "  0.39547887,\n",
       "  -0.2651733,\n",
       "  0.18777111,\n",
       "  -0.41405046,\n",
       "  -0.052088484,\n",
       "  -0.19662578,\n",
       "  0.23041166,\n",
       "  -0.11927523,\n",
       "  0.29702374,\n",
       "  -0.12180918,\n",
       "  -0.16083856,\n",
       "  0.11810642,\n",
       "  0.41617674,\n",
       "  -0.21183941,\n",
       "  -0.09729187,\n",
       "  0.15199646,\n",
       "  -0.13901594,\n",
       "  -0.11262678,\n",
       "  0.42495126,\n",
       "  0.5483658,\n",
       "  -0.5390522,\n",
       "  0.14576931,\n",
       "  -0.18648586,\n",
       "  0.12561214,\n",
       "  0.33587226,\n",
       "  -0.2833969,\n",
       "  -0.3087149,\n",
       "  -0.161669,\n",
       "  -0.0008728707,\n",
       "  0.056185655,\n",
       "  -0.00961661,\n",
       "  0.409367,\n",
       "  -0.08078337,\n",
       "  -0.37627503,\n",
       "  0.4881173,\n",
       "  0.622955,\n",
       "  0.4151015,\n",
       "  -0.15716799,\n",
       "  -0.14182091,\n",
       "  -0.34639868,\n",
       "  0.35075077,\n",
       "  -0.35560772,\n",
       "  -0.29547507,\n",
       "  0.28515413,\n",
       "  0.4125374,\n",
       "  -0.0057943882,\n",
       "  0.3282387,\n",
       "  -0.28408718,\n",
       "  -0.49827918,\n",
       "  -0.34355608,\n",
       "  0.54527044,\n",
       "  -0.04950055,\n",
       "  -0.028871732,\n",
       "  0.39222717,\n",
       "  0.29593408,\n",
       "  -0.14018916,\n",
       "  0.6800066,\n",
       "  0.2560281,\n",
       "  -0.19213858,\n",
       "  -0.4661793,\n",
       "  -0.30056003,\n",
       "  -0.15627988],\n",
       " [-0.15537216,\n",
       "  0.11140434,\n",
       "  0.13517219,\n",
       "  0.20245521,\n",
       "  -0.07644464,\n",
       "  -0.026485212,\n",
       "  0.3602366,\n",
       "  0.47569394,\n",
       "  0.23290631,\n",
       "  -0.36570787,\n",
       "  -0.26834863,\n",
       "  -0.14181301,\n",
       "  -0.13707365,\n",
       "  0.00578788,\n",
       "  0.0940059,\n",
       "  -0.2856062,\n",
       "  0.20051995,\n",
       "  -0.08157191,\n",
       "  0.05737842,\n",
       "  -0.35199302,\n",
       "  -0.10405358,\n",
       "  8.0238744e-05,\n",
       "  0.2148653,\n",
       "  -0.04305433,\n",
       "  0.1370786,\n",
       "  -0.046734054,\n",
       "  -0.19368857,\n",
       "  -0.345256,\n",
       "  0.031840056,\n",
       "  0.3303849,\n",
       "  0.623936,\n",
       "  0.13307089,\n",
       "  -0.08388371,\n",
       "  0.05221074,\n",
       "  -0.07964887,\n",
       "  0.24488775,\n",
       "  0.15767516,\n",
       "  -0.2710174,\n",
       "  -0.21651597,\n",
       "  -0.3584817,\n",
       "  -0.112129316,\n",
       "  -0.20892064,\n",
       "  0.23846412,\n",
       "  -0.29329413,\n",
       "  0.24046788,\n",
       "  0.04559946,\n",
       "  0.15757696,\n",
       "  0.26791912,\n",
       "  0.071395785,\n",
       "  0.18892996,\n",
       "  0.27954036,\n",
       "  -0.36044872,\n",
       "  0.020813277,\n",
       "  -0.027101317,\n",
       "  -0.16510485,\n",
       "  0.010693534,\n",
       "  0.25712556,\n",
       "  0.0074547166,\n",
       "  -0.31764513,\n",
       "  -0.34646297,\n",
       "  0.22247949,\n",
       "  -0.09683926,\n",
       "  0.11511955,\n",
       "  -0.073954076,\n",
       "  -0.29915187,\n",
       "  -0.13393521,\n",
       "  -0.029172475,\n",
       "  0.094640225,\n",
       "  -0.36453196,\n",
       "  0.3394672,\n",
       "  -0.004095813,\n",
       "  -0.17131,\n",
       "  -0.039135035,\n",
       "  0.24610618,\n",
       "  0.1954957,\n",
       "  0.06388329,\n",
       "  -0.2900707,\n",
       "  0.14663051,\n",
       "  -0.14293197,\n",
       "  -0.16307434,\n",
       "  -0.009747256,\n",
       "  -0.118464865,\n",
       "  -0.16635573,\n",
       "  0.13466787,\n",
       "  0.21976085,\n",
       "  -0.2032298,\n",
       "  0.3610675,\n",
       "  0.13229604,\n",
       "  0.17538941,\n",
       "  0.06420311,\n",
       "  -0.048453577,\n",
       "  0.11148096,\n",
       "  -0.27800837,\n",
       "  0.24938889,\n",
       "  0.5154629,\n",
       "  0.28139696,\n",
       "  -0.009004157,\n",
       "  -0.30223748,\n",
       "  0.24116316,\n",
       "  -0.02189895],\n",
       " [0.06758309,\n",
       "  0.1702965,\n",
       "  0.30148804,\n",
       "  0.0866624,\n",
       "  0.005395702,\n",
       "  -0.36008635,\n",
       "  0.14946726,\n",
       "  0.37001947,\n",
       "  0.19654007,\n",
       "  -0.2401534,\n",
       "  0.044913556,\n",
       "  -0.2509847,\n",
       "  -0.08763969,\n",
       "  -0.004752179,\n",
       "  0.1748468,\n",
       "  0.17478697,\n",
       "  0.14794643,\n",
       "  -0.29861638,\n",
       "  -0.18673088,\n",
       "  -0.30751488,\n",
       "  -0.11962405,\n",
       "  0.24302384,\n",
       "  0.4027179,\n",
       "  -0.33730718,\n",
       "  0.0655191,\n",
       "  0.26804549,\n",
       "  -0.26200283,\n",
       "  -0.118641585,\n",
       "  -0.16515055,\n",
       "  0.3792448,\n",
       "  0.6200366,\n",
       "  0.17419113,\n",
       "  0.007689413,\n",
       "  0.15637574,\n",
       "  0.036582667,\n",
       "  0.09763326,\n",
       "  -0.06233022,\n",
       "  -0.3858994,\n",
       "  -0.3981308,\n",
       "  -0.47381282,\n",
       "  -0.36958316,\n",
       "  -0.059753068,\n",
       "  0.25845233,\n",
       "  -0.37634432,\n",
       "  0.1744533,\n",
       "  -0.031920888,\n",
       "  0.073496334,\n",
       "  0.2730194,\n",
       "  0.13678269,\n",
       "  0.52787596,\n",
       "  0.08852603,\n",
       "  -0.2693842,\n",
       "  -0.20488097,\n",
       "  -0.18649927,\n",
       "  -0.18926898,\n",
       "  0.2660594,\n",
       "  0.3926207,\n",
       "  0.32412633,\n",
       "  -0.30881625,\n",
       "  0.14319663,\n",
       "  -0.15416886,\n",
       "  0.40442902,\n",
       "  -0.07573368,\n",
       "  0.3287806,\n",
       "  -0.41452742,\n",
       "  -0.05475336,\n",
       "  -0.13830556,\n",
       "  0.0414108,\n",
       "  -0.30947605,\n",
       "  0.26335055,\n",
       "  -0.13240094,\n",
       "  -0.46938646,\n",
       "  0.2954622,\n",
       "  -0.12209753,\n",
       "  0.28284323,\n",
       "  0.041581433,\n",
       "  0.016174633,\n",
       "  -0.08533409,\n",
       "  -0.20586959,\n",
       "  0.04155094,\n",
       "  -0.0076516587,\n",
       "  0.18572433,\n",
       "  -0.35617512,\n",
       "  0.33634862,\n",
       "  0.24891089,\n",
       "  0.11730801,\n",
       "  0.28779534,\n",
       "  0.082582034,\n",
       "  0.1603481,\n",
       "  0.2855342,\n",
       "  0.10398249,\n",
       "  0.101984516,\n",
       "  0.11392119,\n",
       "  0.14281742,\n",
       "  0.08431464,\n",
       "  0.3253431,\n",
       "  0.15300483,\n",
       "  -0.6648704,\n",
       "  0.26382086,\n",
       "  0.05608924],\n",
       " [-0.3117611,\n",
       "  0.41857308,\n",
       "  -0.0066875555,\n",
       "  -0.082343005,\n",
       "  0.24190953,\n",
       "  -0.34994358,\n",
       "  0.23228896,\n",
       "  0.4274435,\n",
       "  0.48860312,\n",
       "  -0.5436827,\n",
       "  0.29846227,\n",
       "  -0.558842,\n",
       "  -0.2478574,\n",
       "  -0.0432539,\n",
       "  0.15371197,\n",
       "  0.12026884,\n",
       "  0.11877424,\n",
       "  -0.4583431,\n",
       "  -0.10861385,\n",
       "  -0.3813796,\n",
       "  -0.3463461,\n",
       "  0.21022692,\n",
       "  0.5465403,\n",
       "  -0.030999636,\n",
       "  0.019641649,\n",
       "  0.061191298,\n",
       "  -0.61468667,\n",
       "  -0.31667188,\n",
       "  0.19756114,\n",
       "  -0.32066235,\n",
       "  0.4846855,\n",
       "  -0.013785872,\n",
       "  0.15867262,\n",
       "  0.43771625,\n",
       "  0.021882245,\n",
       "  0.03954806,\n",
       "  0.66660583,\n",
       "  -0.5219187,\n",
       "  -0.30012175,\n",
       "  0.09518928,\n",
       "  -0.13209994,\n",
       "  -0.3253314,\n",
       "  0.033945855,\n",
       "  -0.21330583,\n",
       "  0.4720258,\n",
       "  0.3721669,\n",
       "  0.28973916,\n",
       "  0.1991613,\n",
       "  0.10473057,\n",
       "  0.68324816,\n",
       "  0.27148288,\n",
       "  -0.40611362,\n",
       "  0.1303347,\n",
       "  -0.1642395,\n",
       "  -0.24099322,\n",
       "  -0.047746435,\n",
       "  0.6678835,\n",
       "  0.24751748,\n",
       "  -0.22975534,\n",
       "  0.035598233,\n",
       "  -0.2547765,\n",
       "  -0.11064933,\n",
       "  0.10539419,\n",
       "  -0.0561578,\n",
       "  -0.28159705,\n",
       "  0.10621173,\n",
       "  -0.054807536,\n",
       "  0.5591506,\n",
       "  -0.49140862,\n",
       "  0.521534,\n",
       "  -0.65227646,\n",
       "  -0.40432146,\n",
       "  -0.21292734,\n",
       "  0.0006385988,\n",
       "  0.19643794,\n",
       "  -0.04152317,\n",
       "  -0.32657114,\n",
       "  0.3318619,\n",
       "  -0.057508543,\n",
       "  0.20013757,\n",
       "  0.06725053,\n",
       "  0.059267767,\n",
       "  -0.4458758,\n",
       "  0.5681558,\n",
       "  0.24918348,\n",
       "  0.091383204,\n",
       "  0.5412369,\n",
       "  -0.059649896,\n",
       "  -0.28914097,\n",
       "  0.62298054,\n",
       "  -0.0734811,\n",
       "  0.026889525,\n",
       "  0.23024896,\n",
       "  0.2412386,\n",
       "  0.75004715,\n",
       "  0.4135665,\n",
       "  0.17592512,\n",
       "  -0.25746685,\n",
       "  0.26616952,\n",
       "  -0.1784304],\n",
       " [0.13208996,\n",
       "  0.000838668,\n",
       "  -0.086205274,\n",
       "  0.47300345,\n",
       "  0.21526168,\n",
       "  -0.29278123,\n",
       "  0.26860276,\n",
       "  0.8689317,\n",
       "  -0.23475032,\n",
       "  -0.09762186,\n",
       "  -0.5254099,\n",
       "  -0.004187427,\n",
       "  -0.058976065,\n",
       "  0.4003885,\n",
       "  -0.25126404,\n",
       "  -0.23920727,\n",
       "  0.106233485,\n",
       "  -0.08258436,\n",
       "  -0.2081764,\n",
       "  -0.3604877,\n",
       "  -0.15841453,\n",
       "  0.25365987,\n",
       "  0.28098524,\n",
       "  -0.19995667,\n",
       "  0.078384124,\n",
       "  0.04974069,\n",
       "  -0.3743377,\n",
       "  0.028893262,\n",
       "  -0.084693976,\n",
       "  -0.352943,\n",
       "  0.4028549,\n",
       "  0.17467855,\n",
       "  -0.32782033,\n",
       "  0.03277492,\n",
       "  -0.026883407,\n",
       "  0.4287224,\n",
       "  0.36839393,\n",
       "  -0.28110585,\n",
       "  0.03278653,\n",
       "  -0.1175754,\n",
       "  0.26064008,\n",
       "  -0.37485167,\n",
       "  0.16769426,\n",
       "  0.07921327,\n",
       "  0.12881082,\n",
       "  0.6430486,\n",
       "  -0.18961106,\n",
       "  0.39281943,\n",
       "  -0.2291024,\n",
       "  0.19177379,\n",
       "  0.13887227,\n",
       "  -0.2541759,\n",
       "  -0.030302737,\n",
       "  0.20532696,\n",
       "  -0.33043006,\n",
       "  -0.2794091,\n",
       "  0.42971462,\n",
       "  0.06801127,\n",
       "  -0.1519565,\n",
       "  -0.49726418,\n",
       "  0.6452226,\n",
       "  -0.30685169,\n",
       "  0.30813476,\n",
       "  0.18120848,\n",
       "  -0.215678,\n",
       "  0.13744064,\n",
       "  0.077697024,\n",
       "  0.10813407,\n",
       "  -0.22811893,\n",
       "  0.50169814,\n",
       "  -0.1945774,\n",
       "  0.4242588,\n",
       "  0.2274609,\n",
       "  -0.08208924,\n",
       "  0.41112307,\n",
       "  0.01008234,\n",
       "  0.13299897,\n",
       "  0.084657475,\n",
       "  0.3155494,\n",
       "  -0.014313217,\n",
       "  0.06450281,\n",
       "  -0.34466702,\n",
       "  -0.21792363,\n",
       "  0.5786955,\n",
       "  -0.3139843,\n",
       "  0.08002849,\n",
       "  0.027314495,\n",
       "  0.30284408,\n",
       "  0.30358666,\n",
       "  0.39626434,\n",
       "  0.1432045,\n",
       "  0.13699439,\n",
       "  -0.017347706,\n",
       "  -0.013581166,\n",
       "  0.18656786,\n",
       "  0.46824503,\n",
       "  0.24036957,\n",
       "  -0.089942455,\n",
       "  -0.19654402,\n",
       "  -0.24169745],\n",
       " [-0.0878787,\n",
       "  0.31606627,\n",
       "  0.054605603,\n",
       "  0.34135053,\n",
       "  -0.033404466,\n",
       "  -0.48835832,\n",
       "  0.24109347,\n",
       "  0.412761,\n",
       "  0.046641827,\n",
       "  -0.26635632,\n",
       "  -0.27857196,\n",
       "  -0.07285231,\n",
       "  0.09853243,\n",
       "  -0.11239242,\n",
       "  0.03334281,\n",
       "  0.116310485,\n",
       "  0.1706056,\n",
       "  -0.06182857,\n",
       "  0.06769012,\n",
       "  -0.073317386,\n",
       "  -0.3121737,\n",
       "  -0.030863797,\n",
       "  0.47556326,\n",
       "  -0.51059335,\n",
       "  0.40976143,\n",
       "  -0.17949781,\n",
       "  -0.24739857,\n",
       "  -0.29927155,\n",
       "  -0.083278485,\n",
       "  -0.031397037,\n",
       "  0.76345605,\n",
       "  0.16874559,\n",
       "  -0.14221804,\n",
       "  0.19229393,\n",
       "  -0.1208205,\n",
       "  -0.1268116,\n",
       "  -0.019441677,\n",
       "  -0.03861107,\n",
       "  -0.30603722,\n",
       "  -0.3135564,\n",
       "  -0.0059649637,\n",
       "  -0.34119585,\n",
       "  0.33286634,\n",
       "  -0.30976993,\n",
       "  0.23513596,\n",
       "  0.28972086,\n",
       "  0.40611243,\n",
       "  0.05874617,\n",
       "  -0.2760371,\n",
       "  0.4183983,\n",
       "  0.20512126,\n",
       "  -0.43852893,\n",
       "  -0.2793864,\n",
       "  -0.2609247,\n",
       "  -0.20309639,\n",
       "  -0.07375996,\n",
       "  0.11229916,\n",
       "  0.2615889,\n",
       "  -0.56668466,\n",
       "  -0.25807577,\n",
       "  0.036575362,\n",
       "  -0.017531862,\n",
       "  -0.079042874,\n",
       "  0.16169396,\n",
       "  -0.10469864,\n",
       "  0.12439791,\n",
       "  0.3419572,\n",
       "  0.21757881,\n",
       "  -0.5102039,\n",
       "  0.54807234,\n",
       "  0.04616535,\n",
       "  -0.36482933,\n",
       "  0.11919618,\n",
       "  0.031025825,\n",
       "  0.17730732,\n",
       "  0.17290667,\n",
       "  -0.019607816,\n",
       "  -0.049554244,\n",
       "  -0.025204657,\n",
       "  -0.1135302,\n",
       "  -0.05874965,\n",
       "  0.1740834,\n",
       "  -0.37835586,\n",
       "  0.3315136,\n",
       "  0.3107835,\n",
       "  -0.12150482,\n",
       "  0.3615984,\n",
       "  0.069942415,\n",
       "  0.052136403,\n",
       "  0.002142476,\n",
       "  0.13482557,\n",
       "  0.088144526,\n",
       "  -0.26480693,\n",
       "  -0.007850277,\n",
       "  0.07702671,\n",
       "  0.37443295,\n",
       "  0.05141132,\n",
       "  -0.45637575,\n",
       "  0.084157825,\n",
       "  -0.22927757],\n",
       " [-0.1645538,\n",
       "  0.3934366,\n",
       "  -0.1515699,\n",
       "  -0.19031705,\n",
       "  0.31103343,\n",
       "  -0.09721299,\n",
       "  0.42901978,\n",
       "  0.7046471,\n",
       "  -0.08190624,\n",
       "  0.054981865,\n",
       "  -0.3444732,\n",
       "  -0.37296087,\n",
       "  -0.109158754,\n",
       "  -0.07973992,\n",
       "  0.2785256,\n",
       "  0.11431924,\n",
       "  0.74434394,\n",
       "  -0.40703455,\n",
       "  0.14693287,\n",
       "  -0.18349971,\n",
       "  0.049408298,\n",
       "  -0.22343077,\n",
       "  0.29519603,\n",
       "  -0.12597618,\n",
       "  0.20162883,\n",
       "  0.03453917,\n",
       "  -0.24911788,\n",
       "  -0.26402143,\n",
       "  -0.24046479,\n",
       "  0.099328235,\n",
       "  0.5760734,\n",
       "  0.08017532,\n",
       "  -0.33614856,\n",
       "  -0.14666963,\n",
       "  -0.20561,\n",
       "  0.06717178,\n",
       "  -0.0027480002,\n",
       "  -0.12237815,\n",
       "  -0.22549418,\n",
       "  -0.34292907,\n",
       "  -0.33744812,\n",
       "  -0.40722987,\n",
       "  0.0561419,\n",
       "  -0.10900205,\n",
       "  0.4982992,\n",
       "  -0.013466931,\n",
       "  -0.25065145,\n",
       "  0.21873124,\n",
       "  -0.16583963,\n",
       "  0.2898173,\n",
       "  0.14897515,\n",
       "  -0.47160062,\n",
       "  0.04239216,\n",
       "  -0.2991205,\n",
       "  -0.24860263,\n",
       "  0.06735378,\n",
       "  -0.018480472,\n",
       "  0.17676006,\n",
       "  -0.33865196,\n",
       "  -0.44255963,\n",
       "  0.06589133,\n",
       "  -0.4356552,\n",
       "  -0.3081974,\n",
       "  0.028821748,\n",
       "  -0.3074807,\n",
       "  0.18827593,\n",
       "  0.31862357,\n",
       "  0.37958953,\n",
       "  -0.1131989,\n",
       "  0.68919647,\n",
       "  -0.32231498,\n",
       "  -0.107319854,\n",
       "  0.0071351263,\n",
       "  0.24978822,\n",
       "  0.1331616,\n",
       "  0.22855756,\n",
       "  -0.23496437,\n",
       "  0.17262314,\n",
       "  -0.14127935,\n",
       "  0.094678715,\n",
       "  0.29068056,\n",
       "  0.36035478,\n",
       "  -0.10003139,\n",
       "  0.3521072,\n",
       "  0.64790094,\n",
       "  -0.05489313,\n",
       "  0.4122864,\n",
       "  0.038408086,\n",
       "  0.23842561,\n",
       "  0.33914676,\n",
       "  0.14800194,\n",
       "  -0.438307,\n",
       "  0.15585642,\n",
       "  0.017835796,\n",
       "  0.7114292,\n",
       "  0.07627068,\n",
       "  0.4569652,\n",
       "  -0.0064484677,\n",
       "  0.13244866,\n",
       "  -0.4648037],\n",
       " [-0.19282562,\n",
       "  0.016863732,\n",
       "  0.31074283,\n",
       "  -0.111200936,\n",
       "  -0.061514225,\n",
       "  -0.090424664,\n",
       "  0.5796476,\n",
       "  0.5426682,\n",
       "  -0.67358327,\n",
       "  -0.64635485,\n",
       "  0.29397935,\n",
       "  -0.17985596,\n",
       "  -0.47372732,\n",
       "  0.22434491,\n",
       "  0.3383462,\n",
       "  -0.5420965,\n",
       "  0.37431476,\n",
       "  0.089243345,\n",
       "  -0.29291883,\n",
       "  -1.0820862,\n",
       "  -0.059953053,\n",
       "  0.16380264,\n",
       "  0.24758643,\n",
       "  -0.1952948,\n",
       "  0.93165714,\n",
       "  -0.39801148,\n",
       "  0.052367937,\n",
       "  0.42624933,\n",
       "  -0.22355969,\n",
       "  0.2850427,\n",
       "  -0.22024462,\n",
       "  0.60792106,\n",
       "  -0.4419503,\n",
       "  -0.561508,\n",
       "  -0.33505598,\n",
       "  0.75788295,\n",
       "  0.63146454,\n",
       "  -0.33612293,\n",
       "  0.26641315,\n",
       "  -0.44116274,\n",
       "  0.11417023,\n",
       "  -0.31746614,\n",
       "  -0.30277264,\n",
       "  -0.35101485,\n",
       "  -0.13540916,\n",
       "  -0.034060292,\n",
       "  0.29550675,\n",
       "  -0.14223985,\n",
       "  0.26633886,\n",
       "  0.4665429,\n",
       "  0.2808097,\n",
       "  0.08544808,\n",
       "  -0.04942789,\n",
       "  -0.03611582,\n",
       "  0.024471255,\n",
       "  -0.050153986,\n",
       "  0.43339038,\n",
       "  0.31633976,\n",
       "  -0.43349084,\n",
       "  0.2701467,\n",
       "  -0.13280688,\n",
       "  0.3302561,\n",
       "  0.1268016,\n",
       "  -0.23267244,\n",
       "  0.028165242,\n",
       "  -0.40071115,\n",
       "  0.12280773,\n",
       "  0.26673064,\n",
       "  -0.12610854,\n",
       "  0.39307752,\n",
       "  0.16455658,\n",
       "  -0.24067342,\n",
       "  0.47825924,\n",
       "  0.3067179,\n",
       "  0.415467,\n",
       "  0.137197,\n",
       "  -0.2075218,\n",
       "  -0.16138506,\n",
       "  0.5128125,\n",
       "  -0.3371859,\n",
       "  0.06906669,\n",
       "  0.22778425,\n",
       "  0.15237458,\n",
       "  0.13962853,\n",
       "  0.22687927,\n",
       "  -0.18934925,\n",
       "  -0.37809023,\n",
       "  -0.19807552,\n",
       "  0.38835776,\n",
       "  0.2345484,\n",
       "  -0.22377698,\n",
       "  0.51061285,\n",
       "  0.17034067,\n",
       "  -0.13043009,\n",
       "  1.019577,\n",
       "  0.3927775,\n",
       "  -0.28917074,\n",
       "  -0.53399634,\n",
       "  -0.40594155,\n",
       "  0.34755495],\n",
       " [-0.2409186,\n",
       "  0.31947824,\n",
       "  0.14213687,\n",
       "  0.056331627,\n",
       "  0.08710223,\n",
       "  -0.18961355,\n",
       "  0.40403756,\n",
       "  0.534815,\n",
       "  0.3841245,\n",
       "  -0.27873442,\n",
       "  -0.19864872,\n",
       "  -0.05012891,\n",
       "  -0.21713762,\n",
       "  -0.27039987,\n",
       "  0.055946905,\n",
       "  -0.024059353,\n",
       "  0.033879545,\n",
       "  -0.06475613,\n",
       "  -0.18980062,\n",
       "  -0.3166019,\n",
       "  -0.14044881,\n",
       "  0.030133719,\n",
       "  0.20026363,\n",
       "  -0.21165225,\n",
       "  0.13015689,\n",
       "  -0.029572671,\n",
       "  -0.22000009,\n",
       "  -0.2859682,\n",
       "  -0.40824258,\n",
       "  0.413854,\n",
       "  0.84463793,\n",
       "  0.17000861,\n",
       "  -0.014855543,\n",
       "  0.08061063,\n",
       "  0.018240465,\n",
       "  0.080095954,\n",
       "  0.21564656,\n",
       "  -0.38991103,\n",
       "  -0.06810655,\n",
       "  -0.2973222,\n",
       "  -0.3585036,\n",
       "  -0.23569444,\n",
       "  -0.12245874,\n",
       "  -0.17198539,\n",
       "  0.24128748,\n",
       "  -0.007874441,\n",
       "  0.35889494,\n",
       "  0.3339204,\n",
       "  -0.005057982,\n",
       "  0.6104716,\n",
       "  0.39202565,\n",
       "  -0.40888056,\n",
       "  -0.11825752,\n",
       "  -0.1274474,\n",
       "  -0.18621393,\n",
       "  0.10585636,\n",
       "  0.4020426,\n",
       "  0.23181175,\n",
       "  -0.36437947,\n",
       "  -0.1253285,\n",
       "  0.1691518,\n",
       "  0.13419583,\n",
       "  -0.026415823,\n",
       "  -0.17945606,\n",
       "  -0.1805468,\n",
       "  -0.072424054,\n",
       "  0.13609846,\n",
       "  0.42468178,\n",
       "  -0.25132695,\n",
       "  0.4717659,\n",
       "  -0.22534429,\n",
       "  -0.37920472,\n",
       "  0.18773901,\n",
       "  0.24108674,\n",
       "  0.1628836,\n",
       "  0.33790812,\n",
       "  -0.26125252,\n",
       "  0.078170024,\n",
       "  0.010136877,\n",
       "  -0.34665495,\n",
       "  0.14832178,\n",
       "  0.013245169,\n",
       "  -0.19581954,\n",
       "  0.29421955,\n",
       "  0.3170348,\n",
       "  -0.2174457,\n",
       "  0.4086757,\n",
       "  -0.12897773,\n",
       "  -0.0797867,\n",
       "  0.35268837,\n",
       "  0.048913628,\n",
       "  0.25350037,\n",
       "  0.17130749,\n",
       "  0.11706636,\n",
       "  0.7073336,\n",
       "  0.2233273,\n",
       "  0.15926991,\n",
       "  -0.5083063,\n",
       "  0.20671391,\n",
       "  -0.4703328],\n",
       " [-0.5823535,\n",
       "  0.3707398,\n",
       "  -0.06213996,\n",
       "  0.15097354,\n",
       "  0.07086173,\n",
       "  -0.25424287,\n",
       "  0.33152825,\n",
       "  0.67386925,\n",
       "  0.09012036,\n",
       "  -0.49766248,\n",
       "  0.098806486,\n",
       "  -0.14727665,\n",
       "  -0.017989574,\n",
       "  0.038886316,\n",
       "  0.23603812,\n",
       "  -0.19759159,\n",
       "  0.38455647,\n",
       "  -0.040858235,\n",
       "  0.03178318,\n",
       "  -0.47859386,\n",
       "  -0.10334824,\n",
       "  -0.17981637,\n",
       "  0.34166038,\n",
       "  0.0753683,\n",
       "  0.16658068,\n",
       "  -0.1369801,\n",
       "  -0.314931,\n",
       "  -0.06187175,\n",
       "  0.11675116,\n",
       "  0.12359582,\n",
       "  0.5565566,\n",
       "  0.28441027,\n",
       "  -0.02583643,\n",
       "  0.122584134,\n",
       "  -0.17160283,\n",
       "  0.20262311,\n",
       "  0.06939043,\n",
       "  -0.42818177,\n",
       "  -0.26004568,\n",
       "  -0.31303298,\n",
       "  -0.2237173,\n",
       "  -0.34283888,\n",
       "  0.22310778,\n",
       "  -0.5876907,\n",
       "  0.39786854,\n",
       "  0.12519473,\n",
       "  0.25099283,\n",
       "  0.39126232,\n",
       "  -0.22962768,\n",
       "  0.26253223,\n",
       "  0.32413054,\n",
       "  -0.29619798,\n",
       "  -0.2936503,\n",
       "  0.017631214,\n",
       "  -0.39467782,\n",
       "  -0.010336773,\n",
       "  0.18280552,\n",
       "  -0.11444249,\n",
       "  -0.24726841,\n",
       "  -0.23725572,\n",
       "  0.21405768,\n",
       "  -0.08762125,\n",
       "  0.034013364,\n",
       "  -0.19705197,\n",
       "  -0.2915253,\n",
       "  -0.015111991,\n",
       "  0.07205642,\n",
       "  0.27562824,\n",
       "  -0.23041555,\n",
       "  0.4362804,\n",
       "  -0.07834784,\n",
       "  -0.061528746,\n",
       "  0.1482362,\n",
       "  0.34316346,\n",
       "  0.2891478,\n",
       "  0.23441948,\n",
       "  -0.30120492,\n",
       "  0.073807076,\n",
       "  0.06932124,\n",
       "  -0.32358238,\n",
       "  0.22592796,\n",
       "  0.15347111,\n",
       "  -0.21349135,\n",
       "  0.36499533,\n",
       "  0.29026192,\n",
       "  -0.115828305,\n",
       "  0.4724419,\n",
       "  -0.073199704,\n",
       "  0.31305707,\n",
       "  0.16818266,\n",
       "  -0.17642657,\n",
       "  0.18125457,\n",
       "  -0.16872334,\n",
       "  0.30190772,\n",
       "  0.8288493,\n",
       "  0.15028284,\n",
       "  0.0940433,\n",
       "  -0.26001477,\n",
       "  0.25562763,\n",
       "  -0.14696202],\n",
       " [-0.23220849,\n",
       "  0.67941236,\n",
       "  0.19670738,\n",
       "  0.43676674,\n",
       "  0.37906072,\n",
       "  0.021060655,\n",
       "  0.82938296,\n",
       "  0.6563498,\n",
       "  -0.0032120054,\n",
       "  -0.35937494,\n",
       "  0.33184218,\n",
       "  -0.2982844,\n",
       "  0.71589756,\n",
       "  -0.36032298,\n",
       "  0.49272823,\n",
       "  -0.8164553,\n",
       "  0.12837681,\n",
       "  -0.25013456,\n",
       "  0.69961435,\n",
       "  -0.5720501,\n",
       "  0.121327646,\n",
       "  -0.8862585,\n",
       "  -0.45521072,\n",
       "  -0.27054378,\n",
       "  -0.15047652,\n",
       "  -0.6422004,\n",
       "  -0.42891654,\n",
       "  -0.14914942,\n",
       "  -0.5088622,\n",
       "  0.02097487,\n",
       "  0.28889975,\n",
       "  0.322887,\n",
       "  -0.33566147,\n",
       "  0.052258585,\n",
       "  0.1224828,\n",
       "  0.27288112,\n",
       "  -0.17833143,\n",
       "  0.1792846,\n",
       "  0.08894547,\n",
       "  -0.58844954,\n",
       "  0.52523327,\n",
       "  -0.68422437,\n",
       "  0.9063752,\n",
       "  -0.3638123,\n",
       "  0.78625375,\n",
       "  -0.05462498,\n",
       "  0.03265275,\n",
       "  -0.17440024,\n",
       "  -0.16218285,\n",
       "  0.6015051,\n",
       "  0.4618885,\n",
       "  0.1692305,\n",
       "  0.050702065,\n",
       "  0.055214632,\n",
       "  -0.087312125,\n",
       "  0.015122184,\n",
       "  0.503164,\n",
       "  0.6282149,\n",
       "  -0.040685125,\n",
       "  0.11547298,\n",
       "  -0.55680263,\n",
       "  -0.12880214,\n",
       "  0.19476774,\n",
       "  -0.19478975,\n",
       "  0.07790472,\n",
       "  0.26970673,\n",
       "  0.6546586,\n",
       "  0.39466414,\n",
       "  -0.0962407,\n",
       "  -0.4079833,\n",
       "  -0.22327326,\n",
       "  -0.4922633,\n",
       "  0.17860942,\n",
       "  0.8508662,\n",
       "  0.5713639,\n",
       "  0.29949242,\n",
       "  0.11928926,\n",
       "  0.41897503,\n",
       "  0.6337443,\n",
       "  0.22988595,\n",
       "  -0.12194708,\n",
       "  0.34790504,\n",
       "  0.24046947,\n",
       "  0.072778456,\n",
       "  0.29105434,\n",
       "  0.33657297,\n",
       "  0.5717204,\n",
       "  0.5129902,\n",
       "  1.0543091,\n",
       "  -0.11163701,\n",
       "  0.38292834,\n",
       "  0.2725582,\n",
       "  0.18817838,\n",
       "  0.56646985,\n",
       "  1.0359731,\n",
       "  -0.13077135,\n",
       "  -0.30666313,\n",
       "  0.14549714,\n",
       "  0.5010603,\n",
       "  -0.09186646],\n",
       " [0.18152025,\n",
       "  0.39955163,\n",
       "  0.2763804,\n",
       "  0.45351636,\n",
       "  0.013206939,\n",
       "  -0.112353206,\n",
       "  0.50325155,\n",
       "  0.23127134,\n",
       "  -0.04910732,\n",
       "  0.24806258,\n",
       "  -0.41838422,\n",
       "  -0.3041905,\n",
       "  0.4308192,\n",
       "  -0.22101699,\n",
       "  -0.03959098,\n",
       "  -0.035080187,\n",
       "  -0.109325334,\n",
       "  -0.08321201,\n",
       "  -0.3639073,\n",
       "  -0.30650306,\n",
       "  -0.15190819,\n",
       "  0.22729063,\n",
       "  0.6938372,\n",
       "  -0.28318292,\n",
       "  -0.027732005,\n",
       "  -0.095688105,\n",
       "  -0.108647004,\n",
       "  -0.80475223,\n",
       "  -0.28714994,\n",
       "  0.104900904,\n",
       "  0.53475875,\n",
       "  -0.25882694,\n",
       "  0.25282374,\n",
       "  0.40774262,\n",
       "  0.3602369,\n",
       "  -0.015614373,\n",
       "  -0.22317013,\n",
       "  0.16468483,\n",
       "  0.14445493,\n",
       "  -0.56397516,\n",
       "  -0.12191152,\n",
       "  -0.053679243,\n",
       "  0.17504711,\n",
       "  -0.22109795,\n",
       "  -0.15786068,\n",
       "  -0.046071336,\n",
       "  0.10244354,\n",
       "  0.4504697,\n",
       "  0.22416998,\n",
       "  0.02188069,\n",
       "  0.17508554,\n",
       "  -0.54068637,\n",
       "  0.14009674,\n",
       "  -0.35664415,\n",
       "  0.010322022,\n",
       "  -0.021192338,\n",
       "  0.52505934,\n",
       "  -0.041051917,\n",
       "  -0.41496518,\n",
       "  0.020062417,\n",
       "  -0.14724867,\n",
       "  -0.3116863,\n",
       "  0.059165835,\n",
       "  0.0676604,\n",
       "  -0.76679647,\n",
       "  0.13201983,\n",
       "  0.076383784,\n",
       "  0.54049164,\n",
       "  -0.3965079,\n",
       "  0.45372942,\n",
       "  0.26828092,\n",
       "  -0.2623887,\n",
       "  0.5795302,\n",
       "  0.38855937,\n",
       "  0.003106498,\n",
       "  -0.18239,\n",
       "  -0.06381039,\n",
       "  -0.53234494,\n",
       "  -0.109656245,\n",
       "  -0.26400566,\n",
       "  0.24143477,\n",
       "  -0.5097238,\n",
       "  -0.078304596,\n",
       "  0.32210633,\n",
       "  0.20642596,\n",
       "  0.08967644,\n",
       "  -0.019861886,\n",
       "  0.14077623,\n",
       "  0.16264236,\n",
       "  0.2520587,\n",
       "  0.5477,\n",
       "  0.073685125,\n",
       "  0.079648,\n",
       "  0.19601731,\n",
       "  0.22015695,\n",
       "  0.082424,\n",
       "  -0.23753496,\n",
       "  -0.27291325,\n",
       "  -0.047964014,\n",
       "  -0.367463],\n",
       " [-0.123585865,\n",
       "  0.32990536,\n",
       "  0.17693536,\n",
       "  0.061928254,\n",
       "  0.047881555,\n",
       "  -0.30474457,\n",
       "  0.2680296,\n",
       "  0.346351,\n",
       "  0.4049995,\n",
       "  -0.17538835,\n",
       "  -0.026144775,\n",
       "  -0.22077426,\n",
       "  -0.021021172,\n",
       "  -0.12621121,\n",
       "  0.27367008,\n",
       "  0.0052111526,\n",
       "  0.25265083,\n",
       "  -0.10002792,\n",
       "  -0.13316266,\n",
       "  -0.22509547,\n",
       "  0.03919761,\n",
       "  -0.032376442,\n",
       "  0.13585347,\n",
       "  -0.30405536,\n",
       "  0.17542496,\n",
       "  0.0023920122,\n",
       "  -0.29363224,\n",
       "  -0.2936374,\n",
       "  -0.14152282,\n",
       "  0.44055694,\n",
       "  0.68868,\n",
       "  0.13299064,\n",
       "  -0.06462464,\n",
       "  -0.07662479,\n",
       "  -0.032825645,\n",
       "  0.028567437,\n",
       "  0.02606368,\n",
       "  -0.19422624,\n",
       "  -0.103687994,\n",
       "  -0.40442565,\n",
       "  -0.37965533,\n",
       "  -0.1504868,\n",
       "  -0.0986607,\n",
       "  -0.22590029,\n",
       "  0.18574546,\n",
       "  -0.17901823,\n",
       "  0.13642459,\n",
       "  0.08571498,\n",
       "  0.13231663,\n",
       "  0.44602808,\n",
       "  0.26142347,\n",
       "  -0.2683614,\n",
       "  -0.13174154,\n",
       "  -0.21192664,\n",
       "  -0.071833916,\n",
       "  0.34435898,\n",
       "  0.2621652,\n",
       "  0.1207522,\n",
       "  -0.40366942,\n",
       "  0.25895688,\n",
       "  0.0009274215,\n",
       "  0.17079176,\n",
       "  -0.19335155,\n",
       "  0.09978123,\n",
       "  -0.23386125,\n",
       "  -0.072875425,\n",
       "  0.08506423,\n",
       "  0.16432595,\n",
       "  -0.27167773,\n",
       "  0.3528176,\n",
       "  0.00346804,\n",
       "  -0.33262438,\n",
       "  0.24397461,\n",
       "  0.10691341,\n",
       "  0.1755078,\n",
       "  0.31256574,\n",
       "  -0.050737794,\n",
       "  -0.12391592,\n",
       "  -0.1574416,\n",
       "  -0.1959305,\n",
       "  -0.0034173382,\n",
       "  0.08116319,\n",
       "  -0.014717973,\n",
       "  0.17894034,\n",
       "  0.2949131,\n",
       "  -0.24061313,\n",
       "  0.17985404,\n",
       "  -0.16985999,\n",
       "  0.28130135,\n",
       "  0.10975164,\n",
       "  0.13741288,\n",
       "  0.03689405,\n",
       "  0.03576685,\n",
       "  0.14430515,\n",
       "  0.2997921,\n",
       "  0.2642308,\n",
       "  0.09917266,\n",
       "  -0.58719456,\n",
       "  0.076205455,\n",
       "  -0.13657208],\n",
       " [-0.0032023569,\n",
       "  0.28804263,\n",
       "  0.0032439667,\n",
       "  0.4581625,\n",
       "  -0.1028481,\n",
       "  -0.17193411,\n",
       "  0.4096286,\n",
       "  0.7282539,\n",
       "  0.34332746,\n",
       "  -0.12927197,\n",
       "  -0.37559584,\n",
       "  0.033276487,\n",
       "  -0.09115387,\n",
       "  -0.06304526,\n",
       "  0.123753615,\n",
       "  -0.14142558,\n",
       "  -0.039312474,\n",
       "  -0.099013105,\n",
       "  0.030481154,\n",
       "  -0.1392324,\n",
       "  0.054644927,\n",
       "  -0.07518072,\n",
       "  -0.053276114,\n",
       "  -0.20420036,\n",
       "  0.17892317,\n",
       "  -0.21587756,\n",
       "  -0.25988188,\n",
       "  -0.5278174,\n",
       "  -0.1416046,\n",
       "  0.42537588,\n",
       "  0.70464396,\n",
       "  0.17181304,\n",
       "  -0.26398522,\n",
       "  -0.24963596,\n",
       "  -0.103170365,\n",
       "  0.036870386,\n",
       "  0.03861967,\n",
       "  -0.31722847,\n",
       "  0.09857948,\n",
       "  -0.4000183,\n",
       "  -0.07836338,\n",
       "  -0.37815312,\n",
       "  -0.06868682,\n",
       "  -0.11142029,\n",
       "  0.11713115,\n",
       "  0.038038578,\n",
       "  0.24506934,\n",
       "  0.012686055,\n",
       "  -0.03927924,\n",
       "  0.36828795,\n",
       "  0.4709171,\n",
       "  -0.33696932,\n",
       "  -0.10866307,\n",
       "  -0.15434319,\n",
       "  -0.13561179,\n",
       "  0.11772314,\n",
       "  0.34037715,\n",
       "  0.06643458,\n",
       "  -0.29450902,\n",
       "  -0.3382225,\n",
       "  0.31825748,\n",
       "  -0.10850378,\n",
       "  -0.054349016,\n",
       "  -0.105340086,\n",
       "  -0.09847754,\n",
       "  -0.039042078,\n",
       "  0.2780145,\n",
       "  0.16811705,\n",
       "  -0.24126743,\n",
       "  0.4975619,\n",
       "  -0.0022043248,\n",
       "  -0.1346872,\n",
       "  -0.049529556,\n",
       "  0.14942986,\n",
       "  0.06060312,\n",
       "  0.37469268,\n",
       "  -0.24392208,\n",
       "  -0.020312926,\n",
       "  -0.07106708,\n",
       "  -0.34684426,\n",
       "  0.028492408,\n",
       "  -0.27803954,\n",
       "  -0.08542593,\n",
       "  0.29257047,\n",
       "  0.17571445,\n",
       "  -0.27598816,\n",
       "  0.077567875,\n",
       "  0.031245625,\n",
       "  0.16716594,\n",
       "  0.19238476,\n",
       "  -0.062724225,\n",
       "  -0.034726467,\n",
       "  -0.14033999,\n",
       "  0.061040618,\n",
       "  0.36720228,\n",
       "  0.30512446,\n",
       "  -0.043304414,\n",
       "  -0.20586486,\n",
       "  0.19504063,\n",
       "  -0.33511305],\n",
       " [-0.38060543,\n",
       "  0.22172894,\n",
       "  -0.22855099,\n",
       "  0.13747816,\n",
       "  -0.28668332,\n",
       "  -0.13919595,\n",
       "  0.4295356,\n",
       "  0.48474565,\n",
       "  0.01967109,\n",
       "  -0.10626586,\n",
       "  -0.4123874,\n",
       "  -0.29122132,\n",
       "  -0.1036087,\n",
       "  -0.33692205,\n",
       "  -0.1675069,\n",
       "  -0.07692922,\n",
       "  -0.038598537,\n",
       "  -0.01014477,\n",
       "  0.0026381696,\n",
       "  -0.41960794,\n",
       "  0.42244944,\n",
       "  -0.010300013,\n",
       "  0.63779634,\n",
       "  0.1617018,\n",
       "  0.4170774,\n",
       "  -0.14621104,\n",
       "  -0.2325187,\n",
       "  -0.17117852,\n",
       "  0.28324556,\n",
       "  0.42219195,\n",
       "  0.5699721,\n",
       "  -0.07279329,\n",
       "  0.060892407,\n",
       "  -0.26885638,\n",
       "  -0.121810466,\n",
       "  -0.56076086,\n",
       "  0.16445068,\n",
       "  0.21822566,\n",
       "  -0.039699472,\n",
       "  0.31258205,\n",
       "  -0.0054432894,\n",
       "  -0.70561093,\n",
       "  -0.061008055,\n",
       "  -0.23122425,\n",
       "  0.16617137,\n",
       "  0.010235884,\n",
       "  0.06586395,\n",
       "  -0.098641485,\n",
       "  0.37683704,\n",
       "  0.19744761,\n",
       "  0.5397691,\n",
       "  -0.42561957,\n",
       "  -0.20854208,\n",
       "  -0.20265117,\n",
       "  0.10413102,\n",
       "  0.3433523,\n",
       "  0.106264144,\n",
       "  -0.0577675,\n",
       "  -0.6479523,\n",
       "  -0.22978514,\n",
       "  -0.22980274,\n",
       "  -0.2886925,\n",
       "  -0.19443856,\n",
       "  0.3039398,\n",
       "  -0.30292857,\n",
       "  -0.046998423,\n",
       "  0.33626902,\n",
       "  0.56217355,\n",
       "  -0.5597761,\n",
       "  1.0010136,\n",
       "  -0.24861865,\n",
       "  -0.268533,\n",
       "  0.1553675,\n",
       "  0.32358468,\n",
       "  -0.24902022,\n",
       "  0.5046668,\n",
       "  -0.25366327,\n",
       "  -0.15409778,\n",
       "  -0.17361501,\n",
       "  -0.1405529,\n",
       "  -0.26572767,\n",
       "  0.5432043,\n",
       "  0.055652678,\n",
       "  0.27683806,\n",
       "  0.22736202,\n",
       "  -0.46696967,\n",
       "  -0.06819538,\n",
       "  0.22861448,\n",
       "  0.020680076,\n",
       "  0.20195433,\n",
       "  0.25322318,\n",
       "  -0.07982187,\n",
       "  -0.2191355,\n",
       "  0.067631505,\n",
       "  0.49145883,\n",
       "  0.22612089,\n",
       "  0.07011032,\n",
       "  -0.17159724,\n",
       "  -0.017216723,\n",
       "  -0.4202224],\n",
       " [-0.23440112,\n",
       "  -0.011045376,\n",
       "  -0.050501373,\n",
       "  -0.23301038,\n",
       "  0.43743947,\n",
       "  0.094655804,\n",
       "  0.48592466,\n",
       "  0.48574942,\n",
       "  -0.45857236,\n",
       "  -0.5303785,\n",
       "  0.11847888,\n",
       "  -0.5703692,\n",
       "  -0.24340062,\n",
       "  0.2879757,\n",
       "  0.35496047,\n",
       "  -0.52494264,\n",
       "  0.31865394,\n",
       "  0.18928967,\n",
       "  -0.7307335,\n",
       "  -0.76388574,\n",
       "  -0.39972687,\n",
       "  -0.0872216,\n",
       "  0.26151162,\n",
       "  -0.3525297,\n",
       "  1.1157782,\n",
       "  -0.070572846,\n",
       "  -0.21531041,\n",
       "  0.5725766,\n",
       "  0.056457687,\n",
       "  0.4202313,\n",
       "  0.709389,\n",
       "  0.22335057,\n",
       "  -0.51900077,\n",
       "  -0.6547049,\n",
       "  -0.5499589,\n",
       "  0.9792155,\n",
       "  0.3241428,\n",
       "  -0.4599993,\n",
       "  0.20713933,\n",
       "  -0.17954053,\n",
       "  -0.010939335,\n",
       "  -0.334613,\n",
       "  -0.11147572,\n",
       "  -0.23415749,\n",
       "  0.08837649,\n",
       "  -0.0505673,\n",
       "  0.41285914,\n",
       "  -0.10217378,\n",
       "  -0.22886473,\n",
       "  0.1950442,\n",
       "  0.53090084,\n",
       "  -0.092191584,\n",
       "  -0.14035024,\n",
       "  0.007132214,\n",
       "  -0.06585642,\n",
       "  0.058711886,\n",
       "  0.41878334,\n",
       "  0.11061901,\n",
       "  -0.33039433,\n",
       "  0.25580862,\n",
       "  -0.15036228,\n",
       "  0.17189527,\n",
       "  0.48454738,\n",
       "  -0.12124262,\n",
       "  0.008553688,\n",
       "  -0.20659338,\n",
       "  0.22414753,\n",
       "  -0.12619004,\n",
       "  -0.12597072,\n",
       "  0.6549354,\n",
       "  0.32964537,\n",
       "  -0.7238558,\n",
       "  0.61386406,\n",
       "  0.9003353,\n",
       "  0.26469874,\n",
       "  0.15176454,\n",
       "  0.022679726,\n",
       "  -0.33436033,\n",
       "  0.34197715,\n",
       "  0.106511645,\n",
       "  -0.0338166,\n",
       "  0.05803606,\n",
       "  -0.16048081,\n",
       "  -0.34094626,\n",
       "  -0.04007585,\n",
       "  -0.24878807,\n",
       "  -0.52302843,\n",
       "  -0.23001638,\n",
       "  0.605482,\n",
       "  -0.17796588,\n",
       "  -0.26977062,\n",
       "  0.37197796,\n",
       "  0.43968716,\n",
       "  -0.16858631,\n",
       "  0.66495633,\n",
       "  0.50910807,\n",
       "  -0.1330786,\n",
       "  -0.31218818,\n",
       "  -0.22801045,\n",
       "  0.13168806],\n",
       " [-0.22266723,\n",
       "  0.1414642,\n",
       "  0.06443715,\n",
       "  0.21933065,\n",
       "  0.045866102,\n",
       "  -0.16389708,\n",
       "  0.31550634,\n",
       "  0.6034929,\n",
       "  0.11494624,\n",
       "  -0.082347855,\n",
       "  -0.22399165,\n",
       "  -0.07775508,\n",
       "  -0.070134394,\n",
       "  -0.078427896,\n",
       "  0.075396016,\n",
       "  0.008809742,\n",
       "  0.15830334,\n",
       "  -0.10897169,\n",
       "  0.016201572,\n",
       "  -0.28678915,\n",
       "  -0.04211756,\n",
       "  0.01071674,\n",
       "  0.21196197,\n",
       "  -0.20121181,\n",
       "  0.16516171,\n",
       "  -0.05793384,\n",
       "  -0.15257794,\n",
       "  -0.15412654,\n",
       "  -0.09671866,\n",
       "  0.18786618,\n",
       "  0.5283102,\n",
       "  0.10014916,\n",
       "  -0.12389473,\n",
       "  0.060741145,\n",
       "  -0.03530446,\n",
       "  0.03843835,\n",
       "  0.10452648,\n",
       "  -0.19471245,\n",
       "  -0.19847883,\n",
       "  -0.35612917,\n",
       "  -0.11832828,\n",
       "  -0.18677755,\n",
       "  0.10437907,\n",
       "  -0.24324422,\n",
       "  0.2272725,\n",
       "  0.019341234,\n",
       "  0.18260497,\n",
       "  0.19085997,\n",
       "  -0.018948527,\n",
       "  0.30094776,\n",
       "  0.26552123,\n",
       "  -0.22031218,\n",
       "  -0.06704835,\n",
       "  -0.019674808,\n",
       "  -0.24863221,\n",
       "  0.0011887525,\n",
       "  0.26086134,\n",
       "  0.13107477,\n",
       "  -0.2743426,\n",
       "  -0.115188256,\n",
       "  0.11833156,\n",
       "  -0.04641729,\n",
       "  0.020604212,\n",
       "  0.060462356,\n",
       "  -0.2529843,\n",
       "  -0.010783657,\n",
       "  0.14302336,\n",
       "  0.21070758,\n",
       "  -0.28452307,\n",
       "  0.35845485,\n",
       "  -0.11762134,\n",
       "  -0.1639556,\n",
       "  0.023371309,\n",
       "  0.13593599,\n",
       "  0.19922371,\n",
       "  0.044215374,\n",
       "  -0.16532359,\n",
       "  0.018292882,\n",
       "  -0.115917034,\n",
       "  -0.14452496,\n",
       "  0.029766541,\n",
       "  0.035044868,\n",
       "  -0.17820375,\n",
       "  0.3806885,\n",
       "  0.22336566,\n",
       "  -0.10651721,\n",
       "  0.26265246,\n",
       "  0.11940968,\n",
       "  0.123242736,\n",
       "  0.17257576,\n",
       "  -0.0024948975,\n",
       "  0.16920635,\n",
       "  -0.03324573,\n",
       "  0.07963461,\n",
       "  0.5543093,\n",
       "  0.21948506,\n",
       "  0.009137308,\n",
       "  -0.27214968,\n",
       "  0.24244015,\n",
       "  -0.10347705],\n",
       " [-0.12095394,\n",
       "  0.15274458,\n",
       "  0.04221258,\n",
       "  0.16783622,\n",
       "  0.008616012,\n",
       "  -0.14740956,\n",
       "  0.1324338,\n",
       "  0.34873182,\n",
       "  0.0781532,\n",
       "  -0.10789856,\n",
       "  -0.13592736,\n",
       "  -0.13445942,\n",
       "  -0.05869479,\n",
       "  0.03085107,\n",
       "  0.018291572,\n",
       "  -0.094766654,\n",
       "  0.071584344,\n",
       "  -0.08176026,\n",
       "  0.009642302,\n",
       "  -0.22881831,\n",
       "  0.033875242,\n",
       "  0.010917647,\n",
       "  0.07901907,\n",
       "  -0.047839563,\n",
       "  0.022167135,\n",
       "  -0.016140549,\n",
       "  -0.18116666,\n",
       "  -0.16961864,\n",
       "  -0.06068102,\n",
       "  0.124751665,\n",
       "  0.32000896,\n",
       "  0.1022024,\n",
       "  -0.01244462,\n",
       "  -0.011592367,\n",
       "  -0.0072226166,\n",
       "  0.121534824,\n",
       "  0.05846811,\n",
       "  -0.17028837,\n",
       "  -0.08175542,\n",
       "  -0.20471464,\n",
       "  -0.010122799,\n",
       "  -0.20226942,\n",
       "  0.0010145801,\n",
       "  -0.102251895,\n",
       "  0.14621334,\n",
       "  -0.02236927,\n",
       "  -0.005066966,\n",
       "  0.07272357,\n",
       "  0.06784857,\n",
       "  0.15575728,\n",
       "  0.20299883,\n",
       "  -0.1628601,\n",
       "  -0.043900985,\n",
       "  -0.020796884,\n",
       "  -0.1302549,\n",
       "  0.08179216,\n",
       "  0.18347271,\n",
       "  -0.012266678,\n",
       "  -0.15321814,\n",
       "  -0.08182041,\n",
       "  0.1034989,\n",
       "  0.0028038998,\n",
       "  -0.041166857,\n",
       "  0.030943044,\n",
       "  -0.15971273,\n",
       "  -0.015662434,\n",
       "  0.05057835,\n",
       "  0.1281338,\n",
       "  -0.19223861,\n",
       "  0.2624137,\n",
       "  -0.09811085,\n",
       "  -0.081818394,\n",
       "  0.057211865,\n",
       "  0.0478082,\n",
       "  0.114762,\n",
       "  0.10666423,\n",
       "  -0.10593201,\n",
       "  0.003023978,\n",
       "  -0.004344516,\n",
       "  -0.07098456,\n",
       "  -0.042329527,\n",
       "  -0.025679257,\n",
       "  -0.1005556,\n",
       "  0.20179987,\n",
       "  0.062102918,\n",
       "  -0.05937684,\n",
       "  0.051114913,\n",
       "  0.056308925,\n",
       "  0.19660252,\n",
       "  0.12206508,\n",
       "  0.048227374,\n",
       "  0.054136038,\n",
       "  -0.042244557,\n",
       "  0.082098104,\n",
       "  0.27627012,\n",
       "  0.16732813,\n",
       "  0.0053314427,\n",
       "  -0.21294282,\n",
       "  0.08549342,\n",
       "  0.018242868],\n",
       " [-0.29263934,\n",
       "  0.20575741,\n",
       "  -0.0837511,\n",
       "  -0.12742344,\n",
       "  -0.0023299127,\n",
       "  -0.05740589,\n",
       "  0.13797708,\n",
       "  0.5000198,\n",
       "  0.1736965,\n",
       "  -0.32353318,\n",
       "  0.0431048,\n",
       "  -0.11980288,\n",
       "  -0.32460982,\n",
       "  -0.1976596,\n",
       "  0.109404,\n",
       "  -0.15141946,\n",
       "  0.3001373,\n",
       "  -0.0030186211,\n",
       "  -0.15274385,\n",
       "  -0.52716345,\n",
       "  -0.22883768,\n",
       "  -0.1805805,\n",
       "  0.46356747,\n",
       "  -0.15847854,\n",
       "  0.009735996,\n",
       "  0.0048239753,\n",
       "  -0.37819353,\n",
       "  -0.17752609,\n",
       "  0.032338772,\n",
       "  0.47395125,\n",
       "  0.7722666,\n",
       "  0.38789132,\n",
       "  0.27883253,\n",
       "  0.25780028,\n",
       "  0.0490807,\n",
       "  0.19510159,\n",
       "  0.25662935,\n",
       "  -0.20048839,\n",
       "  0.026957305,\n",
       "  -0.28081632,\n",
       "  -0.25266203,\n",
       "  -0.15579233,\n",
       "  0.4060938,\n",
       "  -0.39275658,\n",
       "  0.2817154,\n",
       "  0.084627956,\n",
       "  0.34194604,\n",
       "  0.4500961,\n",
       "  -0.18840547,\n",
       "  0.35115603,\n",
       "  0.39416984,\n",
       "  -0.3111706,\n",
       "  -0.19907367,\n",
       "  -0.13184004,\n",
       "  -0.26317,\n",
       "  0.16423422,\n",
       "  0.50410837,\n",
       "  0.5198187,\n",
       "  -0.16682212,\n",
       "  -0.17778328,\n",
       "  0.16591237,\n",
       "  0.21315262,\n",
       "  0.19096468,\n",
       "  0.07263966,\n",
       "  -0.53711444,\n",
       "  -0.16055785,\n",
       "  0.350752,\n",
       "  0.19792016,\n",
       "  -0.504618,\n",
       "  0.45245877,\n",
       "  -0.24803692,\n",
       "  -0.47381648,\n",
       "  -0.044716984,\n",
       "  0.30545416,\n",
       "  0.002688443,\n",
       "  0.16664594,\n",
       "  -0.25030664,\n",
       "  0.32292488,\n",
       "  0.04174974,\n",
       "  -0.1235721,\n",
       "  -0.07111825,\n",
       "  0.12207416,\n",
       "  -0.20302293,\n",
       "  0.46230918,\n",
       "  0.298392,\n",
       "  -0.12088381,\n",
       "  0.6078273,\n",
       "  -0.036973506,\n",
       "  0.116748184,\n",
       "  0.15846623,\n",
       "  -0.1411425,\n",
       "  0.450208,\n",
       "  -0.15034424,\n",
       "  -0.049378473,\n",
       "  0.86875933,\n",
       "  0.25862968,\n",
       "  0.040680762,\n",
       "  -0.45444262,\n",
       "  0.1188366,\n",
       "  -0.026668869],\n",
       " [-0.24612407,\n",
       "  0.25049898,\n",
       "  0.06001121,\n",
       "  0.15313911,\n",
       "  -0.011551915,\n",
       "  -0.101750016,\n",
       "  0.19681999,\n",
       "  0.47224072,\n",
       "  0.3245519,\n",
       "  -0.28205374,\n",
       "  -0.095116004,\n",
       "  -0.2084715,\n",
       "  -0.12774076,\n",
       "  -0.071829654,\n",
       "  0.031957414,\n",
       "  -0.22114885,\n",
       "  0.28724167,\n",
       "  -0.28880468,\n",
       "  0.0060103666,\n",
       "  -0.24647002,\n",
       "  -0.10400151,\n",
       "  -0.024206825,\n",
       "  0.2668847,\n",
       "  -0.07777187,\n",
       "  -0.06611594,\n",
       "  0.043602116,\n",
       "  -0.3642535,\n",
       "  -0.25801787,\n",
       "  0.056495145,\n",
       "  0.12082583,\n",
       "  0.619727,\n",
       "  0.093863636,\n",
       "  -0.030175751,\n",
       "  0.35679868,\n",
       "  0.045407325,\n",
       "  0.091577,\n",
       "  0.1801123,\n",
       "  -0.35143805,\n",
       "  -0.3567853,\n",
       "  -0.35240862,\n",
       "  -0.18006779,\n",
       "  -0.11604754,\n",
       "  0.3388412,\n",
       "  -0.35802412,\n",
       "  0.29936945,\n",
       "  0.038156003,\n",
       "  0.15621834,\n",
       "  0.29697064,\n",
       "  -0.079427265,\n",
       "  0.2974346,\n",
       "  0.24024639,\n",
       "  -0.3718714,\n",
       "  -0.10214214,\n",
       "  -0.09299053,\n",
       "  -0.33219996,\n",
       "  0.115529515,\n",
       "  0.26999688,\n",
       "  0.18961108,\n",
       "  -0.16856474,\n",
       "  -0.13402586,\n",
       "  0.034027122,\n",
       "  -0.03590938,\n",
       "  0.125459,\n",
       "  0.048011653,\n",
       "  -0.31427136,\n",
       "  0.03977742,\n",
       "  -0.042478777,\n",
       "  0.16356155,\n",
       "  -0.4122651,\n",
       "  0.27825016,\n",
       "  -0.26693112,\n",
       "  -0.21649759,\n",
       "  0.010497715,\n",
       "  0.057659794,\n",
       "  0.16163605,\n",
       "  -0.058745068,\n",
       "  -0.20799819,\n",
       "  0.1866354,\n",
       "  -0.21997565,\n",
       "  0.01179437,\n",
       "  0.0722685,\n",
       "  0.12188261,\n",
       "  -0.34369436,\n",
       "  0.38592002,\n",
       "  0.23723368,\n",
       "  -0.024504634,\n",
       "  0.45891696,\n",
       "  0.050428286,\n",
       "  0.15368058,\n",
       "  0.20833668,\n",
       "  -0.044145647,\n",
       "  0.013149866,\n",
       "  -0.17924985,\n",
       "  0.1751414,\n",
       "  0.6599789,\n",
       "  0.1945899,\n",
       "  0.07517969,\n",
       "  -0.30248073,\n",
       "  0.23277283,\n",
       "  -0.025725221],\n",
       " [-0.10357099,\n",
       "  0.15210916,\n",
       "  0.059948638,\n",
       "  0.16418974,\n",
       "  -0.041815113,\n",
       "  -0.16485268,\n",
       "  0.10835006,\n",
       "  0.30609542,\n",
       "  0.12317309,\n",
       "  -0.14437011,\n",
       "  -0.07432908,\n",
       "  -0.14751026,\n",
       "  -0.058391154,\n",
       "  0.07057884,\n",
       "  0.03714602,\n",
       "  -0.07664958,\n",
       "  0.074166045,\n",
       "  -0.08795672,\n",
       "  0.034649197,\n",
       "  -0.21042661,\n",
       "  0.00451625,\n",
       "  -0.008136936,\n",
       "  0.08537914,\n",
       "  -0.035011124,\n",
       "  0.07516025,\n",
       "  -0.03737732,\n",
       "  -0.1943705,\n",
       "  -0.18806699,\n",
       "  0.00465434,\n",
       "  0.11893419,\n",
       "  0.33000025,\n",
       "  0.14297105,\n",
       "  -0.0007023972,\n",
       "  0.051968247,\n",
       "  -0.023124224,\n",
       "  0.13331032,\n",
       "  0.070936285,\n",
       "  -0.17816521,\n",
       "  -0.052083094,\n",
       "  -0.20697734,\n",
       "  -0.020468546,\n",
       "  -0.19729806,\n",
       "  0.059021562,\n",
       "  -0.17341234,\n",
       "  0.14943478,\n",
       "  0.017832855,\n",
       "  -0.032022137,\n",
       "  0.0851475,\n",
       "  0.08481521,\n",
       "  0.18910156,\n",
       "  0.23146278,\n",
       "  -0.14017689,\n",
       "  -0.0922738,\n",
       "  0.018727966,\n",
       "  -0.1316021,\n",
       "  0.09056454,\n",
       "  0.2371004,\n",
       "  0.01566557,\n",
       "  -0.12722333,\n",
       "  -0.065002754,\n",
       "  0.1385917,\n",
       "  0.027333358,\n",
       "  -0.057905953,\n",
       "  0.082157254,\n",
       "  -0.13957565,\n",
       "  -0.06493263,\n",
       "  0.041424677,\n",
       "  0.08565314,\n",
       "  -0.19193514,\n",
       "  0.3251524,\n",
       "  -0.058852274,\n",
       "  -0.13877451,\n",
       "  0.045482673,\n",
       "  0.015653957,\n",
       "  0.060053904,\n",
       "  0.10298375,\n",
       "  -0.08118484,\n",
       "  0.011256396,\n",
       "  0.012766639,\n",
       "  -0.028231565,\n",
       "  -0.056172177,\n",
       "  -0.009638233,\n",
       "  -0.12413235,\n",
       "  0.2247496,\n",
       "  0.068313345,\n",
       "  -0.028034452,\n",
       "  0.03839137,\n",
       "  0.02484323,\n",
       "  0.2005503,\n",
       "  0.137921,\n",
       "  -0.0012285454,\n",
       "  0.02583888,\n",
       "  -0.11575987,\n",
       "  0.11132976,\n",
       "  0.24437043,\n",
       "  0.17855701,\n",
       "  -0.007321634,\n",
       "  -0.25292838,\n",
       "  0.07761713,\n",
       "  0.06252238],\n",
       " [0.19096175,\n",
       "  -0.0074349316,\n",
       "  0.10487396,\n",
       "  0.1803143,\n",
       "  -0.03954107,\n",
       "  -0.4629732,\n",
       "  -0.07308477,\n",
       "  0.5999525,\n",
       "  0.22368991,\n",
       "  -0.10656139,\n",
       "  -0.06000866,\n",
       "  -0.36043864,\n",
       "  -0.012571908,\n",
       "  0.2490944,\n",
       "  -0.074599914,\n",
       "  -0.04823956,\n",
       "  0.06066112,\n",
       "  -0.51903373,\n",
       "  0.08483017,\n",
       "  -0.43776333,\n",
       "  0.30012864,\n",
       "  0.17867203,\n",
       "  0.38747808,\n",
       "  -0.13490377,\n",
       "  -0.34766427,\n",
       "  0.08750383,\n",
       "  -0.5041838,\n",
       "  -0.34126237,\n",
       "  0.043298647,\n",
       "  0.1410464,\n",
       "  0.16439983,\n",
       "  0.25145766,\n",
       "  0.032788277,\n",
       "  0.14128512,\n",
       "  0.07789796,\n",
       "  0.2369438,\n",
       "  -0.38596153,\n",
       "  -0.24689999,\n",
       "  -0.57171017,\n",
       "  -0.5039644,\n",
       "  -0.023106813,\n",
       "  -0.109216295,\n",
       "  0.18918566,\n",
       "  -0.026233967,\n",
       "  0.2889315,\n",
       "  -0.26991552,\n",
       "  -0.38811067,\n",
       "  -0.07960721,\n",
       "  0.40497983,\n",
       "  0.18380226,\n",
       "  0.0018188838,\n",
       "  -0.28114137,\n",
       "  -0.018544566,\n",
       "  -0.14511232,\n",
       "  -0.25813448,\n",
       "  0.3115078,\n",
       "  0.033540696,\n",
       "  0.12114898,\n",
       "  -0.22225249,\n",
       "  0.37476572,\n",
       "  -0.35180607,\n",
       "  0.1061368,\n",
       "  0.15792756,\n",
       "  0.46591094,\n",
       "  -0.5696483,\n",
       "  0.17625603,\n",
       "  -0.285277,\n",
       "  0.23024747,\n",
       "  -0.5918082,\n",
       "  0.17824693,\n",
       "  -0.07240332,\n",
       "  -0.101641014,\n",
       "  0.17177135,\n",
       "  0.01699744,\n",
       "  0.21148916,\n",
       "  -0.30429626,\n",
       "  0.19703543,\n",
       "  -0.17281017,\n",
       "  -0.31494567,\n",
       "  0.39043882,\n",
       "  -0.24402985,\n",
       "  0.39434722,\n",
       "  -0.20039275,\n",
       "  0.21583988,\n",
       "  0.07396246,\n",
       "  -0.049280375,\n",
       "  -0.04349329,\n",
       "  0.44622678,\n",
       "  0.8427794,\n",
       "  0.27820265,\n",
       "  0.38595513,\n",
       "  0.02866076,\n",
       "  -0.15856068,\n",
       "  0.14872333,\n",
       "  0.13018787,\n",
       "  0.4126811,\n",
       "  0.031411935,\n",
       "  -0.23544693,\n",
       "  0.18753886,\n",
       "  0.31005237],\n",
       " [-0.3145165,\n",
       "  0.0555834,\n",
       "  0.0029192646,\n",
       "  0.21016152,\n",
       "  -0.014106647,\n",
       "  -0.13397872,\n",
       "  0.081382565,\n",
       "  0.5302402,\n",
       "  0.26972464,\n",
       "  -0.16553985,\n",
       "  -0.17391585,\n",
       "  -0.11888199,\n",
       "  -0.15853,\n",
       "  0.030628633,\n",
       "  -0.05735523,\n",
       "  -0.42875418,\n",
       "  0.32856518,\n",
       "  -0.20739754,\n",
       "  0.20974296,\n",
       "  -0.28443253,\n",
       "  -0.019437533,\n",
       "  -0.21576452,\n",
       "  0.35062996,\n",
       "  -0.0785099,\n",
       "  0.0021521193,\n",
       "  -0.018388832,\n",
       "  -0.1516077,\n",
       "  -0.23207334,\n",
       "  -0.034057178,\n",
       "  0.02497988,\n",
       "  0.59641165,\n",
       "  0.19715288,\n",
       "  -0.11071742,\n",
       "  0.52294415,\n",
       "  0.059624117,\n",
       "  0.061955243,\n",
       "  0.1392313,\n",
       "  -0.14415371,\n",
       "  -0.41680077,\n",
       "  -0.38072833,\n",
       "  -0.09166329,\n",
       "  0.013742806,\n",
       "  0.41468495,\n",
       "  -0.51068145,\n",
       "  0.21873623,\n",
       "  0.05090759,\n",
       "  0.09383732,\n",
       "  0.32720342,\n",
       "  -0.05527997,\n",
       "  0.22291619,\n",
       "  0.31008878,\n",
       "  -0.39384255,\n",
       "  -0.20481692,\n",
       "  0.044476457,\n",
       "  -0.38865358,\n",
       "  0.07049955,\n",
       "  0.13322015,\n",
       "  0.21479271,\n",
       "  -0.055158358,\n",
       "  -0.14329681,\n",
       "  0.2142806,\n",
       "  0.00051956915,\n",
       "  -0.07354247,\n",
       "  0.04217095,\n",
       "  -0.27834198,\n",
       "  -0.06011361,\n",
       "  0.0019750567,\n",
       "  0.06426919,\n",
       "  -0.3166778,\n",
       "  0.407441,\n",
       "  -0.20673576,\n",
       "  -0.15155785,\n",
       "  0.052144628,\n",
       "  0.07128368,\n",
       "  0.024371877,\n",
       "  -0.13295393,\n",
       "  -0.15977854,\n",
       "  0.10661283,\n",
       "  -0.21538612,\n",
       "  0.09799014,\n",
       "  0.22784434,\n",
       "  0.15805124,\n",
       "  -0.43458068,\n",
       "  0.33629122,\n",
       "  0.30823025,\n",
       "  0.055042803,\n",
       "  0.3381973,\n",
       "  0.084264755,\n",
       "  0.31423697,\n",
       "  0.088470004,\n",
       "  -0.22360893,\n",
       "  -0.048505493,\n",
       "  -0.30480877,\n",
       "  0.13651735,\n",
       "  0.8432937,\n",
       "  0.19742517,\n",
       "  -0.012326612,\n",
       "  -0.44663313,\n",
       "  0.08082726,\n",
       "  0.101340674],\n",
       " [-0.057816174,\n",
       "  0.0893937,\n",
       "  0.020222718,\n",
       "  0.11036532,\n",
       "  -0.0142956525,\n",
       "  -0.119254574,\n",
       "  0.060778238,\n",
       "  0.2453677,\n",
       "  0.06350328,\n",
       "  -0.04176551,\n",
       "  -0.104687564,\n",
       "  -0.08526146,\n",
       "  -0.06455849,\n",
       "  0.024253843,\n",
       "  -0.021626731,\n",
       "  -0.07689494,\n",
       "  0.024730736,\n",
       "  -0.096832834,\n",
       "  0.05381521,\n",
       "  -0.10731102,\n",
       "  0.0069994386,\n",
       "  -0.014189425,\n",
       "  0.055044252,\n",
       "  -0.034998577,\n",
       "  0.005002127,\n",
       "  -0.017465279,\n",
       "  -0.10935911,\n",
       "  -0.13590527,\n",
       "  -0.040132083,\n",
       "  0.048063636,\n",
       "  0.20748048,\n",
       "  0.03916986,\n",
       "  -0.022029288,\n",
       "  -0.017858308,\n",
       "  0.0044192174,\n",
       "  0.05883994,\n",
       "  0.06392448,\n",
       "  -0.086664595,\n",
       "  -0.043584734,\n",
       "  -0.1476613,\n",
       "  0.007410841,\n",
       "  -0.14729777,\n",
       "  0.013937519,\n",
       "  -0.05255771,\n",
       "  0.06906945,\n",
       "  -0.028339114,\n",
       "  -0.025962967,\n",
       "  0.020473821,\n",
       "  0.042385194,\n",
       "  0.09489458,\n",
       "  0.16025463,\n",
       "  -0.14086393,\n",
       "  -0.01174667,\n",
       "  -0.0110459635,\n",
       "  -0.0849399,\n",
       "  0.08404527,\n",
       "  0.11513505,\n",
       "  -0.009600197,\n",
       "  -0.09336452,\n",
       "  -0.055199686,\n",
       "  0.056172263,\n",
       "  0.003947297,\n",
       "  -0.03737995,\n",
       "  0.052344654,\n",
       "  -0.0899873,\n",
       "  0.0001509235,\n",
       "  0.036010496,\n",
       "  0.07787199,\n",
       "  -0.13419694,\n",
       "  0.19130771,\n",
       "  -0.06978531,\n",
       "  -0.057589695,\n",
       "  0.033188038,\n",
       "  0.04456251,\n",
       "  0.038549706,\n",
       "  0.06040752,\n",
       "  -0.07432554,\n",
       "  -0.0022238954,\n",
       "  -0.011839454,\n",
       "  -0.012713622,\n",
       "  -0.026851475,\n",
       "  -0.033224836,\n",
       "  -0.09117428,\n",
       "  0.12561308,\n",
       "  0.031601213,\n",
       "  -0.009785578,\n",
       "  0.007835013,\n",
       "  0.06268541,\n",
       "  0.15539569,\n",
       "  0.07146643,\n",
       "  0.039013598,\n",
       "  -0.011219667,\n",
       "  -0.052115496,\n",
       "  0.02959911,\n",
       "  0.16687556,\n",
       "  0.13183258,\n",
       "  -0.0037715533,\n",
       "  -0.13390926,\n",
       "  0.049345803,\n",
       "  0.025325054],\n",
       " [-0.3950659,\n",
       "  0.26473647,\n",
       "  -0.12991624,\n",
       "  0.24469887,\n",
       "  0.016281556,\n",
       "  -0.17786734,\n",
       "  0.30331755,\n",
       "  0.77424836,\n",
       "  0.37128082,\n",
       "  -0.066780366,\n",
       "  -0.32182828,\n",
       "  -0.13035452,\n",
       "  -0.18451929,\n",
       "  -0.14776982,\n",
       "  0.007296284,\n",
       "  -0.3170034,\n",
       "  -0.0067853387,\n",
       "  -0.10681802,\n",
       "  0.27684087,\n",
       "  -0.19063614,\n",
       "  0.12093881,\n",
       "  -0.28975105,\n",
       "  0.15065661,\n",
       "  -0.06766244,\n",
       "  0.03901961,\n",
       "  -0.19133234,\n",
       "  -0.26076168,\n",
       "  -0.41305417,\n",
       "  -0.2681841,\n",
       "  0.24203685,\n",
       "  0.639228,\n",
       "  0.09740921,\n",
       "  -0.109210424,\n",
       "  -0.18596174,\n",
       "  0.008613017,\n",
       "  0.042150512,\n",
       "  0.12812956,\n",
       "  -0.24344803,\n",
       "  -0.12831819,\n",
       "  -0.24298288,\n",
       "  -0.051983926,\n",
       "  -0.38337055,\n",
       "  -0.09938472,\n",
       "  -0.06609154,\n",
       "  0.1426734,\n",
       "  -0.18869226,\n",
       "  0.23049684,\n",
       "  -0.04091787,\n",
       "  -0.061472986,\n",
       "  0.19435269,\n",
       "  0.57612514,\n",
       "  -0.45929283,\n",
       "  -0.10635366,\n",
       "  -0.22049108,\n",
       "  -0.13597456,\n",
       "  0.18540622,\n",
       "  0.07710866,\n",
       "  -0.12026707,\n",
       "  -0.3011363,\n",
       "  -0.22959545,\n",
       "  -0.14912625,\n",
       "  -0.081492655,\n",
       "  0.00037429293,\n",
       "  -0.23138282,\n",
       "  -0.19358487,\n",
       "  0.10817404,\n",
       "  0.16203563,\n",
       "  0.49037784,\n",
       "  -0.37154043,\n",
       "  0.42883438,\n",
       "  -0.2512218,\n",
       "  -0.080178514,\n",
       "  -0.044225946,\n",
       "  0.40582675,\n",
       "  0.029306464,\n",
       "  0.23326324,\n",
       "  -0.39077452,\n",
       "  0.035893273,\n",
       "  -0.18705888,\n",
       "  -0.24984187,\n",
       "  -0.025178596,\n",
       "  -0.05777521,\n",
       "  -0.08257014,\n",
       "  0.26401845,\n",
       "  0.21204269,\n",
       "  -0.25264475,\n",
       "  0.15679656,\n",
       "  0.14070205,\n",
       "  0.25341174,\n",
       "  0.21641389,\n",
       "  0.12342549,\n",
       "  -0.046142977,\n",
       "  -0.09236488,\n",
       "  0.027304819,\n",
       "  0.71520513,\n",
       "  0.21793167,\n",
       "  0.021848826,\n",
       "  -0.16601261,\n",
       "  0.056942582,\n",
       "  -0.29383412],\n",
       " [0.0025144892,\n",
       "  0.17010896,\n",
       "  -0.012988966,\n",
       "  0.30166242,\n",
       "  -0.2445242,\n",
       "  -0.18032439,\n",
       "  0.23943968,\n",
       "  0.5075605,\n",
       "  0.31853098,\n",
       "  -0.031005176,\n",
       "  -0.19282524,\n",
       "  -0.025506377,\n",
       "  -0.21654403,\n",
       "  -0.018882435,\n",
       "  0.0046253745,\n",
       "  -0.023773165,\n",
       "  -0.2454468,\n",
       "  -0.14850059,\n",
       "  0.323117,\n",
       "  -0.052894935,\n",
       "  0.24261104,\n",
       "  -0.124426916,\n",
       "  0.26702034,\n",
       "  0.019610027,\n",
       "  0.02411679,\n",
       "  -0.2905032,\n",
       "  -0.3434901,\n",
       "  -0.5573888,\n",
       "  0.23215258,\n",
       "  0.30993086,\n",
       "  0.33453286,\n",
       "  0.19019935,\n",
       "  0.20593277,\n",
       "  -0.29721367,\n",
       "  0.060981877,\n",
       "  0.022171209,\n",
       "  0.12746844,\n",
       "  0.027148396,\n",
       "  -0.059412036,\n",
       "  -0.0354424,\n",
       "  0.10671129,\n",
       "  -0.47528106,\n",
       "  -0.153804,\n",
       "  -0.09122163,\n",
       "  0.36119708,\n",
       "  -0.23476592,\n",
       "  0.008970493,\n",
       "  -0.10960507,\n",
       "  0.48643884,\n",
       "  0.21584545,\n",
       "  0.5990886,\n",
       "  -0.37271953,\n",
       "  0.14780965,\n",
       "  -0.25886557,\n",
       "  0.013625323,\n",
       "  0.3961216,\n",
       "  0.17774029,\n",
       "  -0.085436665,\n",
       "  -0.55078906,\n",
       "  -0.09881549,\n",
       "  0.0749325,\n",
       "  -0.32746866,\n",
       "  -0.090646684,\n",
       "  0.05059965,\n",
       "  -0.1802885,\n",
       "  -0.0035928397,\n",
       "  0.23291382,\n",
       "  0.4564487,\n",
       "  -0.46489903,\n",
       "  0.64151037,\n",
       "  0.0988523,\n",
       "  -0.2750162,\n",
       "  -0.17621297,\n",
       "  0.30387706,\n",
       "  -0.1529589,\n",
       "  0.20835038,\n",
       "  -0.19951962,\n",
       "  -0.0470362,\n",
       "  0.006224567,\n",
       "  -0.09940926,\n",
       "  -0.3069597,\n",
       "  -0.17936061,\n",
       "  -0.12932575,\n",
       "  0.12411738,\n",
       "  0.10352217,\n",
       "  -0.22446397,\n",
       "  0.24480136,\n",
       "  0.22101247,\n",
       "  0.26267758,\n",
       "  0.13395019,\n",
       "  0.23999552,\n",
       "  -0.28290108,\n",
       "  -0.3808287,\n",
       "  0.17470545,\n",
       "  0.33812413,\n",
       "  0.45010433,\n",
       "  -0.06652445,\n",
       "  -0.19341415,\n",
       "  0.17830412,\n",
       "  0.06452403],\n",
       " [-0.11701471,\n",
       "  0.24865921,\n",
       "  -0.074133724,\n",
       "  0.27946177,\n",
       "  -0.0052522635,\n",
       "  -0.2280702,\n",
       "  0.03834604,\n",
       "  0.5186581,\n",
       "  0.13245477,\n",
       "  0.05103575,\n",
       "  -0.340804,\n",
       "  -0.2381355,\n",
       "  -0.23965427,\n",
       "  -0.07319352,\n",
       "  -0.2749441,\n",
       "  -0.36826465,\n",
       "  -0.26874158,\n",
       "  -0.3519172,\n",
       "  0.37878716,\n",
       "  -0.1733036,\n",
       "  0.02305778,\n",
       "  -0.25669432,\n",
       "  0.22091202,\n",
       "  0.06425137,\n",
       "  -0.15468349,\n",
       "  -0.18021058,\n",
       "  -0.13994838,\n",
       "  -0.4853129,\n",
       "  -0.20206365,\n",
       "  0.20444356,\n",
       "  0.3165982,\n",
       "  -0.020259239,\n",
       "  0.21372521,\n",
       "  -0.27576375,\n",
       "  0.11508134,\n",
       "  -0.17644878,\n",
       "  0.086020425,\n",
       "  0.026717072,\n",
       "  -0.09347053,\n",
       "  -0.31123525,\n",
       "  0.31773594,\n",
       "  -0.5275935,\n",
       "  -0.23966466,\n",
       "  0.13398783,\n",
       "  0.08559675,\n",
       "  -0.28662053,\n",
       "  -0.26578537,\n",
       "  -0.17030784,\n",
       "  0.34030315,\n",
       "  0.08642181,\n",
       "  0.52018833,\n",
       "  -0.39504474,\n",
       "  0.21253337,\n",
       "  -0.17290193,\n",
       "  -0.22107264,\n",
       "  0.36852083,\n",
       "  0.21552086,\n",
       "  -0.17801224,\n",
       "  -0.27921757,\n",
       "  -0.12706636,\n",
       "  0.031713795,\n",
       "  -0.1101336,\n",
       "  -0.23539634,\n",
       "  0.018615017,\n",
       "  -0.16364866,\n",
       "  0.13590929,\n",
       "  0.3096843,\n",
       "  0.3552402,\n",
       "  -0.5935762,\n",
       "  0.40561113,\n",
       "  -0.20831297,\n",
       "  -0.025538199,\n",
       "  -0.017161323,\n",
       "  0.1802545,\n",
       "  -0.13468342,\n",
       "  0.15369837,\n",
       "  -0.25821415,\n",
       "  -0.0046389312,\n",
       "  -0.007821404,\n",
       "  0.0045347274,\n",
       "  -0.17907833,\n",
       "  -0.30050516,\n",
       "  -0.044108637,\n",
       "  0.1856531,\n",
       "  -0.26628834,\n",
       "  -0.10707867,\n",
       "  -0.16665365,\n",
       "  0.30048475,\n",
       "  0.43781674,\n",
       "  0.07087819,\n",
       "  0.29176423,\n",
       "  -0.22502118,\n",
       "  -0.3734109,\n",
       "  0.02606173,\n",
       "  0.02617042,\n",
       "  0.3316943,\n",
       "  -0.037435237,\n",
       "  -0.20978333,\n",
       "  0.027125834,\n",
       "  0.33974108],\n",
       " [-0.1645538,\n",
       "  0.3934366,\n",
       "  -0.1515699,\n",
       "  -0.19031705,\n",
       "  0.31103343,\n",
       "  -0.09721299,\n",
       "  0.42901978,\n",
       "  0.7046471,\n",
       "  -0.08190624,\n",
       "  0.054981865,\n",
       "  -0.3444732,\n",
       "  -0.37296087,\n",
       "  -0.109158754,\n",
       "  -0.07973992,\n",
       "  0.2785256,\n",
       "  0.11431924,\n",
       "  0.74434394,\n",
       "  -0.40703455,\n",
       "  0.14693287,\n",
       "  -0.18349971,\n",
       "  0.049408298,\n",
       "  -0.22343077,\n",
       "  0.29519603,\n",
       "  -0.12597618,\n",
       "  0.20162883,\n",
       "  0.03453917,\n",
       "  -0.24911788,\n",
       "  -0.26402143,\n",
       "  -0.24046479,\n",
       "  0.099328235,\n",
       "  0.5760734,\n",
       "  0.08017532,\n",
       "  -0.33614856,\n",
       "  -0.14666963,\n",
       "  -0.20561,\n",
       "  0.06717178,\n",
       "  -0.0027480002,\n",
       "  -0.12237815,\n",
       "  -0.22549418,\n",
       "  -0.34292907,\n",
       "  -0.33744812,\n",
       "  -0.40722987,\n",
       "  0.0561419,\n",
       "  -0.10900205,\n",
       "  0.4982992,\n",
       "  -0.013466931,\n",
       "  -0.25065145,\n",
       "  0.21873124,\n",
       "  -0.16583963,\n",
       "  0.2898173,\n",
       "  0.14897515,\n",
       "  -0.47160062,\n",
       "  0.04239216,\n",
       "  -0.2991205,\n",
       "  -0.24860263,\n",
       "  0.06735378,\n",
       "  -0.018480472,\n",
       "  0.17676006,\n",
       "  -0.33865196,\n",
       "  -0.44255963,\n",
       "  0.06589133,\n",
       "  -0.4356552,\n",
       "  -0.3081974,\n",
       "  0.028821748,\n",
       "  -0.3074807,\n",
       "  0.18827593,\n",
       "  0.31862357,\n",
       "  0.37958953,\n",
       "  -0.1131989,\n",
       "  0.68919647,\n",
       "  -0.32231498,\n",
       "  -0.107319854,\n",
       "  0.0071351263,\n",
       "  0.24978822,\n",
       "  0.1331616,\n",
       "  0.22855756,\n",
       "  -0.23496437,\n",
       "  0.17262314,\n",
       "  -0.14127935,\n",
       "  0.094678715,\n",
       "  0.29068056,\n",
       "  0.36035478,\n",
       "  -0.10003139,\n",
       "  0.3521072,\n",
       "  0.64790094,\n",
       "  -0.05489313,\n",
       "  0.4122864,\n",
       "  0.038408086,\n",
       "  0.23842561,\n",
       "  0.33914676,\n",
       "  0.14800194,\n",
       "  -0.438307,\n",
       "  0.15585642,\n",
       "  0.017835796,\n",
       "  0.7114292,\n",
       "  0.07627068,\n",
       "  0.4569652,\n",
       "  -0.0064484677,\n",
       "  0.13244866,\n",
       "  -0.4648037]]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[51]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "43a1efdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = [np.array(x) for x in X]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ac8b9929",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "793"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_len = max([sentence.shape[0] for sentence in X])\n",
    "max_len"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2be35ed",
   "metadata": {},
   "source": [
    "Geralmente o valor 0 é utilizado no padding de word embeddings, pois ele representa a ausência de valor para aquele elemento. O padding é usado para que todas as amostras tenham o mesmo tamanho, por exemplo, para que todas as frases tenham o mesmo número de palavras. Ao usar o valor 0 para o padding, estamos representando que aquela posição é uma palavra \"fictícia\" que não possui significado. Dessa forma, a rede neural não dará importância a essas palavras fictícias durante o processo de treinamento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "eef9d76d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = tf.keras.preprocessing.sequence.pad_sequences(X, value = 0, padding = 'post', maxlen = max_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "99131d13",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = dataset.iloc[:, 5].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "09bb144c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 2, 3], dtype=int64)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = np.array(y)\n",
    "np.unique(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5399c97c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1441, 793, 100), (1441,))"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape, y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8d13a75",
   "metadata": {},
   "source": [
    "O TensorFlow não suporta tensores com formas variadas, então todas as listas precisam ter o mesmo tamanho. Para resolver este problema, pode-se usar uma biblioteca de processamento de dados para garantir que todas as listas tenham o mesmo tamanho, ou pode-se remover as listas que têm tamanhos diferentes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b15b4f8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_tensor = tf.convert_to_tensor(X, dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9d02c4fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([1441, 793, 100])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_tensor.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc878b21",
   "metadata": {},
   "source": [
    " ## treinamento de uma rede neural convolucional"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "558cf9a6",
   "metadata": {},
   "source": [
    "### Camada de convolução\n",
    "\n",
    "A **camada de convolução** é uma das camadas fundamentais de uma rede neural convolucional (CNN) para classificação de texto. Essa camada é responsável por extrair as características dos dados de entrada, que podem ser, por exemplo, palavras ou frases de um texto. A convolução é uma operação matemática que envolve a multiplicação da entrada com um pequeno filtro (também chamado de kernel ou janela), que se desloca pela entrada em uma determinada direção. A cada posição, o resultado da multiplicação é somado e a saída é produzida.\n",
    "\n",
    "A camada de convolução pode ter vários filtros diferentes, cada um aprendendo uma característica diferente dos dados. Isso permite que a CNN capture uma variedade de informações importantes do texto, como a presença de palavras-chave, a estrutura gramatical e o contexto em que as palavras são usadas.\n",
    "\n",
    "O número de filtros recomendados para a camada de convolução em uma rede neural convolucional pode variar dependendo da complexidade do problema e da arquitetura da rede. Não há um número fixo que seja considerado ideal ou padrão, mas é comum utilizar potências de 2, como 32, 64, 128, 256, etc. para o número de filtros em cada camada. O número de filtros também pode ser aumentado à medida que se avança nas camadas da rede, com o objetivo de aprender características mais complexas e abstratas\n",
    "\n",
    "Além disso, é comum usar outras camadas, como camadas de pooling e camadas de dropout, para aumentar a eficiência e evitar overfitting, que é um problema comum em redes neurais.\n",
    "\n",
    "Em resumo, a camada de convolução é uma peça fundamental na arquitetura de uma rede neural convolucional para classificação de texto, permitindo a extração de características relevantes dos dados de entrada.\n",
    "\n",
    "Na arquitetura de uma Rede Neural Convolucional (CNN), a camada de pooling é uma das camadas fundamentais. Essa camada é responsável por reduzir a dimensionalidade espacial do mapa de características gerado pela camada de convolução anterior.\n",
    "\n",
    "Não há um valor recomendado fixo de kernel_size para todos os casos, pois ele depende do tamanho da sequência, da natureza dos dados e dos objetivos do modelo. Em geral, valores comuns de kernel_size para sequências de texto variam de 2 a 5. No entanto, pode ser necessário testar diferentes valores para encontrar o melhor desempenho para o seu conjunto de dados específico. Além disso, a escolha do kernel_size também pode ser influenciada pelo tamanho da dimensão embutida (word embedding), pelo número de camadas na rede e pelo número de filtros. É importante experimentar diferentes configurações e avaliar o desempenho para encontrar o melhor modelo.\n",
    "\n",
    "Se a rede neural convolucional não converge com 1000 épocas, significa que o modelo ainda não atingiu a performance desejada após 1000 iterações de treinamento. Neste caso, aumentar o número de **filtros** pode ser uma possível solução, mas existem outros fatores que precisam ser considerados, como o tipo de otimizador, taxa de aprendizado, regularização, e se o conjunto de dados de treinamento é suficientemente grande e representativo. Além disso, é importante verificar se o modelo não está sofrendo de overfitting, ou seja, se ele está generalizando bem para dados não vistos durante o treinamento. Não há uma única resposta para essa questão, e a solução pode envolver uma combinação de diferentes ajustes e experimentos.\n",
    "\n",
    "### Camada de pooling\n",
    "\n",
    "A ideia básica da **camada de pooling** é reduzir a resolução espacial da representação do mapa de características, a fim de reduzir a quantidade de parâmetros e poder generalizar melhor o modelo para novos dados. Ela funciona selecionando um valor de um conjunto de valores de características próximos, agrupando-os e reduzindo-os a um único valor representativo. Essa operação é realizada em cada \"sub-região\" do mapa de características, onde cada sub-região é definida por um filtro.\n",
    "\n",
    "Existem vários tipos de pooling, sendo os mais comuns o max pooling e o average pooling. No max pooling, é selecionado o valor máximo dentro da sub-região para ser o valor representativo. Já no average pooling, é calculada a média dos valores da sub-região para ser o valor representativo.\n",
    "\n",
    "A camada de pooling é uma forma de regularização, já que ela reduz a dimensionalidade da representação do mapa de características e, consequentemente, o número de parâmetros a serem treinados. Isso reduz o risco de overfitting, tornando o modelo.\n",
    "\n",
    "### Camada totalmente conectada\n",
    "\n",
    "A **camada totalmente conectada** é uma camada de rede neural que recebe as características extraídas pela camada de convolução e/ou de pooling e as usa para realizar a classificação final. Essa camada é composta por neurônios que estão totalmente conectados com os neurônios da camada anterior.\n",
    "\n",
    "Na tarefa de classificação de texto, a camada totalmente conectada pode ser usada para gerar a pontuação da classe correspondente a cada possível categoria. Por exemplo, em uma tarefa de classificação de texto em que há duas categorias, \"positivo\" e \"negativo\", a camada totalmente conectada pode gerar uma pontuação para cada uma dessas categorias. Em seguida, a classe final é escolhida com base na pontuação mais alta.\n",
    "\n",
    "Uma das desvantagens da camada totalmente conectada é que ela pode causar overfitting (sobreajuste) aos dados de treinamento. Para lidar com esse problema, é comum o uso de técnicas como **dropout** ou **regularização L2** na camada totalmente conectada para reduzir a complexidade do modelo e evitar overfitting.\n",
    "\n",
    "Não existe um número recomendado exato de **camadas e neurônios** para uma camada densa em uma rede neural, pois isso depende de vários fatores, como o tamanho do conjunto de dados, a complexidade do modelo, a precisão desejada, entre outros. Algumas boas práticas incluem começar com uma camada densa com uma pequena quantidade de neurônios, como 32 ou 64, e aumentar gradativamente até atingir uma boa precisão. É importante também usar **regularização** para evitar **overfitting**. Uma boa prática é experimentar com diferentes configurações e comparar os resultados para escolher a melhor opção.\n",
    "\n",
    "Aumentar o número de camadas em uma rede neural convolucional pode ser considerado como uma técnica para melhorar a performance do modelo em uma **tarefa de classificação de texto**, mas isso depende de vários fatores, tais como a quantidade de dados disponíveis, a complexidade do modelo e a quantidade de recursos computacionais disponíveis.\n",
    "\n",
    "A adição de camadas pode permitir que o modelo capture **padrões mais complexos nas sequências de texto**, o que pode levar a uma melhora na acurácia. _No entanto, também é importante ter em mente que a adição de muitas camadas pode tornar o modelo propenso a overfitting, especialmente se a quantidade de dados disponíveis for limitada_.\n",
    "\n",
    "Além disso, o número de camadas também pode impactar a velocidade de treinamento do modelo e a complexidade computacional. É importante encontrar um equilíbrio entre a capacidade do modelo de aprender padrões importantes e a capacidade de manter uma performance eficiente.\n",
    "\n",
    "Em geral, é recomendado experimentar diferentes configurações, incluindo diferentes números de camadas, para encontrar a melhor configuração para o problema específico de classificação de texto em questão.\n",
    "\n",
    "### Dropout\n",
    "\n",
    "A **técnica de \"dropout\"** é um método de regularização que é frequentemente utilizado em redes neurais, incluindo as camadas totalmente conectadas. O objetivo do dropout é evitar o overfitting, que é quando a rede se ajusta demais aos dados de treinamento, e não generaliza bem para novos dados.\n",
    "\n",
    "O dropout funciona desativando aleatoriamente um conjunto de neurônios da camada em cada passagem de treinamento. Isso significa que a camada tem que aprender a confiar em diferentes combinações de neurônios em cada passagem de treinamento, em vez de depender sempre dos mesmos neurônios. Isso faz com que a rede se torne mais robusta, pois não pode confiar em um subconjunto específico de neurônios para a classificação de uma entrada.\n",
    "\n",
    "Durante o processo de teste, todos os neurônios são ativados, pois não há necessidade de regularização neste momento. Em resumo, o dropout é uma técnica simples e eficaz para reduzir o overfitting em redes neurais, tornando as camadas totalmente conectadas mais robustas e generalizáveis.\n",
    "\n",
    "O valor recomendado para o dropout_rate varia dependendo da aplicação e dos dados. Em geral, o dropout_rate varia entre 0.2 e 0.5. O dropout_rate de 0.5 significa que 50% dos neurônios serão \"desligados\" durante o treinamento para evitar overfitting, enquanto o dropout_rate de 0.2 significa que 20% dos neurônios serão desligados. O valor ótimo par'a o dropout_rate deve ser determinado experimentando com diferentes valores e avaliando o desempenho do modelo.\n",
    "\n",
    "### Regularização L2\n",
    "\n",
    "Em redes neurais, a **regularização L2** é uma técnica usada para evitar o overfitting, ou seja, o modelo aprender demais o conjunto de treinamento, e não generalizar bem para novos dados. A regularização L2 adiciona um termo à função de custo da rede neural, que penaliza pesos grandes. Especificamente, a função de custo adiciona a soma dos quadrados dos pesos multiplicada por um parâmetro de regularização lambda. Essa penalização faz com que a rede favoreça pesos menores, o que pode ajudar a evitar o overfitting.\n",
    "\n",
    "Na camada totalmente conectada, onde cada neurônio está conectado a todos os neurônios da camada anterior, a regularização L2 é aplicada aos pesos da camada. Isso ajuda a controlar a complexidade do modelo, evitando que os pesos da rede se tornem muito grandes. Além disso, a regularização L2 pode melhorar o desempenho da rede em conjuntos de dados de teste, onde o modelo não foi treinado, ajudando a rede a generalizar melhor para novos dados.\n",
    "\n",
    "A recomendação geral é aplicar a regularização L2 em camadas densas ou camadas totalmente conectadas, em vez de nas camadas de convolução. Isso se deve ao fato de que a regularização L2 é mais eficaz na prevenção do overfitting em camadas densas, já que as camadas densas tendem a ter muitos parâmetros e a possibilidade de aprender padrões redundantes.\n",
    "\n",
    "O parâmetro \"kernel_regularizer=keras.regularizers.l2(0.01)\" é um argumento que pode ser passado em uma camada de rede neural no Keras para aplicar regularização L2 aos pesos (kernels) dessa camada. O valor 0,01 passado como argumento representa a força da regularização L2, onde valores maiores levarão a uma penalidade mais forte e pesos mais próximos de zero.\n",
    "\n",
    "No entanto, é importante lembrar que a implementação da regularização L2 depende do problema específico e dos dados de treinamento. É possível que a aplicação da regularização L2 nas camadas de convolução seja benéfica em algumas situações específicas. Portanto, é sempre recomendável experimentar diferentes abordagens e verificar qual funciona melhor para o problema em questão.\n",
    "\n",
    "A saída de uma rede neural convolucional de classificação de texto com 4 classes é uma matriz de probabilidade com 4 colunas, onde cada coluna representa a probabilidade de uma determinada classe. O valor da saída é o índice da coluna que apresenta o maior valor. Por exemplo, se o maior valor da saída for na primeira coluna, então o modelo preveu a classe 0. Se o maior valor da saída for na segunda coluna, então o modelo preveu a classe 1 e assim por diante.\n",
    "\n",
    "O número de épocas recomendado para uma rede neural convolucional varia dependendo do tamanho do seu conjunto de dados e da complexidade do modelo. Em geral, um número de épocas entre 10 e 100 é considerado um bom ponto de partida. Se o treinamento da rede não estiver levando a uma boa precisão, você pode aumentar o número de épocas. De maneira geral, é importante observar o comportamento do modelo em relação à precisão e loss ao longo do treinamento para determinar o melhor número de épocas. Além disso, é importante utilizar uma técnica de validação cruzada para evitar o overfitting do modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c9cd04d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# o vetor de word embbeding é de tamanho 100-\n",
    "tamanho_word_embbeding = 100\n",
    "# o número de filtros de convolução é 32\n",
    "qtd_filtros = 32\n",
    "# quantidade de neuronios na camada densa é 64\n",
    "qtd_neuronios_camada_densa = 64\n",
    "# o tamanho do bath é 256\n",
    "tamanho_batch = 100\n",
    "# a quantidade de classes é quatro\n",
    "qtd_classes = len(set(y))\n",
    "# taxa de dropout é a taxa de neurônios que serão desligados no treinamento\n",
    "#o valor 0.2 é um valor que empiricamente evita overffiting\n",
    "taxa_dropout = 0.2\n",
    "#é a quantidade de épocas de treinamento\n",
    "qtd_epocas = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0e73a9c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "classe que representa a rede neural convolucional  para classificação de textos\n",
    "'''\n",
    "class DCNN(tf.keras.Model):\n",
    "    \n",
    "    '''\n",
    "        tamanho_word_embbeding: tamanho do vetor de números representando a palavra;\n",
    "        qtd_filtros: número de filtros para cada dimensão;\n",
    "        qtd_neuronios_camada_densa: número de neurônios da rede neural densa;\n",
    "        qtd_classes: número de classes para classificação;\n",
    "        taxa_dropout: porcentagem de desativação de neurônios;\n",
    "    '''\n",
    "    def __init__(self,  \n",
    "                 tamanho_word_embbeding = 1, \n",
    "                 qtd_filtros = 8, \n",
    "                 qtd_neuronios_camada_densa = 64, \n",
    "                 qtd_classes = 2,\n",
    "                 taxa_dropout = 0.2, \n",
    "                 training = False, \n",
    "                 name = 'dcnn'):\n",
    "        super(DCNN, self).__init__(name=name)\n",
    "        #gera a matriz de embedding do vocabulário ou a representação vetorial de cada palavra\n",
    "        #camadas de convolução\n",
    "        #define os filtros\n",
    "        #same: retorna os mesmos dados no mesmo formato\n",
    "        # para cada sentença, extrai as fetures e realiza o treinamento das feature vector\n",
    "        self.bigram = layers.Conv1D(filters=qtd_filtros, kernel_size=2, padding='same', activation = 'relu', kernel_regularizer=keras.regularizers.l2(0.01))\n",
    "        self.trigram = layers.Conv1D(filters=qtd_filtros, kernel_size=3, padding='same', activation = 'relu')\n",
    "        self.fourgram = layers.Conv1D(filters=qtd_filtros, kernel_size=4, padding='same', activation = 'relu')\n",
    "        self.fivegram = layers.Conv1D(filters=qtd_filtros, kernel_size=5, padding='same', activation = 'relu')\n",
    "        #camada max pooling\n",
    "        self.pool = layers.GlobalMaxPool1D()\n",
    "        #camada densa\n",
    "        self.dense_1 = layers.Dense(units = qtd_neuronios_camada_densa, activation = 'relu')\n",
    "        self.dense_2 = layers.Dense(units = qtd_neuronios_camada_densa, activation = 'relu')\n",
    "        self.dense_3 = layers.Dense(units = qtd_neuronios_camada_densa, activation = 'relu')\n",
    "        self.dropout = layers.Dropout(rate = taxa_dropout)\n",
    "        if qtd_classes == 2:\n",
    "            self.last_dense = layers.Dense(units = 1, activation = 'sigmoid')\n",
    "        else:\n",
    "            #problemas de classificação com mais de 2 classes utilizar a softmax\n",
    "            self.last_dense = layers.Dense(units = qtd_classes, activation = 'softmax', kernel_regularizer=keras.regularizers.l2(0.01))\n",
    "            \n",
    "    def call(self, inputs, training):\n",
    "        x = inputs\n",
    "        x_1 = self.bigram(x)\n",
    "        x_1 = self.pool(x_1)\n",
    "        x_2 = self.trigram(x)\n",
    "        x_2 = self.pool(x_2)\n",
    "        x_3 = self.fourgram(x)\n",
    "        x_3 = self.pool(x_3)\n",
    "        x_4 = self.fivegram(x)\n",
    "        x_4 = self.pool(x_4)\n",
    "        \n",
    "        merged = tf.concat([x_1, x_2, x_3,x_4], axis = -1) # (batch_size, 3*qtd_filtros)\n",
    "        print(merged.shape)\n",
    "        merged = self.dense_1(merged)\n",
    "        merged = self.dropout(merged, training)\n",
    "        merged = self.dense_2(merged)\n",
    "        merged = self.dropout(merged, training)\n",
    "        merged = self.dense_3(merged)\n",
    "        merged = self.dropout(merged, training)\n",
    "        output = self.last_dense(merged)\n",
    "        \n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d36b9e2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#criar a instância da rede neural especificada\n",
    "Dcnn = DCNN(tamanho_word_embbeding=tamanho_word_embbeding, qtd_filtros=qtd_filtros, qtd_neuronios_camada_densa=qtd_neuronios_camada_densa, qtd_classes=qtd_classes, taxa_dropout=taxa_dropout)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abca85a0",
   "metadata": {},
   "source": [
    "### Função de perda e otimizador\n",
    "\n",
    "As linhas a seguir definem a **função de perda** e o **otimizador** que serão usados durante o treinamento da rede neural. Especificamente, essas linhas determinam se a rede neural será usada para classificação binária ou multiclasse. Se nb_classes for igual a 2, a rede neural será usada para classificação binária e a função de perda será **binary_crossentropy**. Neste caso, o otimizador será **adam**. Se nb_classes for diferente de 2, a rede neural será usada para classificação multiclasse e a função de perda será **sparse_categorical_crossentropy**. Neste caso, o otimizador também será adam. Além disso, o desempenho será avaliado usando a métrica de acurácia.\n",
    "\n",
    "A **binary_crossentropy** é uma função de perda utilizada em problemas de classificação binária. Ela mede a diferença entre a previsão do modelo e o valor alvo (verdadeiro). Isso é feito calculando a **entropia cruzada** (cross-entropy) entre a distribuição de probabilidade predita pelo modelo e a distribuição de probabilidade real.\n",
    "\n",
    "A **sparse_categorical_crossentropy**, por outro lado, é uma função de perda utilizada em problemas de classificação multiclasse. Nestes problemas, cada exemplo de treinamento pode ser classificado como uma das várias categorias possíveis. Esta função de perda compara a previsão do modelo com o valor alvo e calcula a **entropia cruzada (cross-entropy)** entre a distribuição de probabilidade predita e a distribuição de probabilidade verdadeira.\n",
    "\n",
    "A diferença entre binary_crossentropy e sparse_categorical_crossentropy é que a última é mais eficiente para problemas com muitas categorias, pois permite que os valores-alvo sejam especificados como inteiros (índices) em vez de vetores one-hot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5544e284",
   "metadata": {},
   "outputs": [],
   "source": [
    "if qtd_classes == 2:\n",
    "    Dcnn.compile(loss = 'binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "else:\n",
    "    Dcnn.compile(loss = 'sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65145b2f",
   "metadata": {},
   "source": [
    "### Objeto de verificação de ponto\n",
    "\n",
    "As linhas a seguir são uma implementação de salvar e restaurar os pesos de uma rede neural no TensorFlow.\n",
    "\n",
    "O código cria um **objeto de verificação de ponto (ckpt)** que é associado à rede neural (Dcnn). Em seguida, cria um gerenciador de ponto de verificação (ckpt_manager) que controla o local onde os checkpoints são salvos e quantos checkpoints são mantidos.\n",
    "\n",
    "A linha seguinte verifica se existe um checkpoint mais recente. Se houver, o checkpoint é restaurado, o que significa que os pesos salvos da última vez em que o modelo foi treinado são carregados na rede neural. Finalmente, a mensagem \"Latest checkpoint restored\" é impressa na tela para indicar que o checkpoint foi restaurado com sucesso."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "36adc501",
   "metadata": {},
   "outputs": [],
   "source": [
    "ckpt = tf.train.Checkpoint(Dcnn=Dcnn)\n",
    "ckpt_manager = tf.train.CheckpointManager(ckpt, '', max_to_keep=5)\n",
    "if ckpt_manager.latest_checkpoint:\n",
    "    ckpt.restore(ckpt_manager.latest_checkpoint)\n",
    "    print('Latest checkpoint restored')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db37f635",
   "metadata": {},
   "source": [
    "### Parâmetros do método fit\n",
    "\n",
    "A função fit da classe tf.keras.Model tem os seguintes tipos de parâmetros:\n",
    "\n",
    "**x**: array Numpy ou tensor, ou seja, dados de treinamento para o modelo.\n",
    "\n",
    "**y**: array Numpy ou tensor, ou seja, etiquetas de treinamento para o modelo.\n",
    "\n",
    "**batch_size**: inteiro, ou seja, o número de amostras de treinamento por atualização de peso.\n",
    "\n",
    "**epochs**: inteiro, ou seja, o número de épocas (ciclos) a serem executados sobre os dados de treinamento.\n",
    "\n",
    "**verbose**: inteiro, ou seja, o nível de verbosidade da função. 0 significa que não há saída, 1 significa que a saída de progresso é exibida em forma de barra de progresso, 2 significa que o progresso é exibido como uma única linha.\n",
    "\n",
    "**callbacks**: lista, ou seja, lista de instâncias de Callback, que são funções de retorno de chamada a serem executadas durante o treinamento.\n",
    "\n",
    "**validation_data**: tupla (x_val, y_val), ou seja, conjunto de dados de validação, onde x_val é um array Numpy ou tensor e y_val é uma lista ou array Numpy ou tensor.\n",
    "\n",
    "**shuffle**: booleano, ou seja, se os dados de treinamento devem ser embaralhados antes de cada época.\n",
    "\n",
    "**class_weight**: dicionário, ou seja, pesos das classes, usados para lidar com desequilíbrios de classes em dados de treinamento.\n",
    "\n",
    "**sample_weight**: array Numpy ou tensor, ou seja, pesos amostrais, usados para lidar com desequilíbrios de amostras em dados de treinamento.\n",
    "\n",
    "**initial_epoch**: inteiro, ou seja, época inicial para iniciar a contagem de épocas. Útil quando você quer retomar o treinamento de um modelo interrompido.\n",
    "\n",
    "**steps_per_epoch**: inteiro, ou seja, o número de etapas (batches) por época. Se for fornecido, sobrescreve o cálculo automático baseado na quantidade de amostras de treinamento.\n",
    "\n",
    "**validation_steps**: inteiro, ou seja, o número de etapas (batches) de validação por época. Se for fornecido, sobrescreve o cálculo automático baseado na quantidade de amostras de validação.\n",
    "\n",
    "A vantagem de usar o **parâmetro shuffle** no método fit é que ele embaralha os dados de treinamento a cada época, o que pode melhorar a generalização do modelo e prevenir overfitting. Isso acontece porque o modelo não é treinado com um conjunto de dados sempre na mesma ordem, o que pode evitar que ele memorize as informações e não generalize corretamente.\n",
    "\n",
    "No entanto, há também uma desvantagem ao usar shuffle. Embaralhar os dados a cada época pode tornar o treinamento mais lento, especialmente se o conjunto de dados for grande. Além disso, o embaralhamento pode ser inadequado para algumas aplicações em que a ordem dos dados é importante, como previsão de séries temporais.\n",
    "\n",
    "Em geral, usar shuffle é uma boa prática para muitos tipos de modelos, mas é importante avaliar se o uso é adequado para o problema em questão.\n",
    "\n",
    "### Valores de accuracy e val_accuracy durante o treinamento\n",
    "\n",
    "Durante o treinamento de uma rede neural convolucional, é ideal que a **\"accuracy\"** (acurácia do treinamento) e **\"val_accuracy\"** (acurácia da validação) aumentem ao longo das épocas. A acurácia de treinamento deve aumentar até alcançar um valor próximo de 100% e a acurácia de validação deve aumentar até alcançar um valor próximo do valor da acurácia de treinamento. _Se a acurácia de validação estiver ficando muito abaixo da acurácia de treinamento, pode ser um sinal de overfitting_.\n",
    "\n",
    "O overfitting ocorre quando a rede neural é muito complexa para o conjunto de dados de treinamento e aprende características específicas dos dados de treinamento que não são genéricas e não se aplicam a novos dados. Isso pode ser solucionado usando técnicas de regularização, diminuindo o número de camadas ou de neurônios, ou aumentando o número de exemplos de treinamento.\n",
    "\n",
    "Uma acurácia de treinamento alta e uma acurácia de validação baixa em uma rede neural convolucional (CNN) ao longo das épocas geralmente significa que a rede está sofrendo de overfitting, ou seja, ela está memorizando os dados de treinamento em vez de generalizar e aprender padrões mais amplos que possam ser aplicados a novos dados. Isso pode ser indicado pelo fato de que a rede é capaz de classificar corretamente a maioria dos dados de treinamento, mas não é capaz de classificar corretamente uma quantidade significativa de dados de validação.\n",
    "\n",
    "Uma abordagem para lidar com esse problema é adicionar regularização à rede, como dropout, L1 ou L2 regularization, ou usar data augmentation para aumentar o tamanho do conjunto de treinamento. Também pode ser útil ajustar os hiperparâmetros da rede, como a taxa de aprendizado, tamanho do lote, número de camadas, tamanho dos filtros convolucionais e tamanho dos mapas de características."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0acca61b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "(None, 128)\n",
      "(None, 128)\n",
      "12/12 [==============================] - ETA: 0s - loss: 1.9071 - accuracy: 0.2465(None, 128)\n",
      "12/12 [==============================] - 6s 134ms/step - loss: 1.9071 - accuracy: 0.2465 - val_loss: 1.8436 - val_accuracy: 0.2284\n",
      "Epoch 2/200\n",
      "12/12 [==============================] - 1s 105ms/step - loss: 1.7995 - accuracy: 0.2509 - val_loss: 1.7534 - val_accuracy: 0.2042\n",
      "Epoch 3/200\n",
      "12/12 [==============================] - 1s 105ms/step - loss: 1.7104 - accuracy: 0.2821 - val_loss: 1.6799 - val_accuracy: 0.2076\n",
      "Epoch 4/200\n",
      "12/12 [==============================] - 1s 106ms/step - loss: 1.6446 - accuracy: 0.2630 - val_loss: 1.6211 - val_accuracy: 0.2388\n",
      "Epoch 5/200\n",
      "12/12 [==============================] - 1s 108ms/step - loss: 1.5887 - accuracy: 0.2925 - val_loss: 1.5756 - val_accuracy: 0.2353\n",
      "Epoch 6/200\n",
      "12/12 [==============================] - 1s 107ms/step - loss: 1.5410 - accuracy: 0.2951 - val_loss: 1.5429 - val_accuracy: 0.2388\n",
      "Epoch 7/200\n",
      "12/12 [==============================] - 1s 110ms/step - loss: 1.4995 - accuracy: 0.3316 - val_loss: 1.5174 - val_accuracy: 0.2457\n",
      "Epoch 8/200\n",
      "12/12 [==============================] - 1s 111ms/step - loss: 1.4736 - accuracy: 0.3212 - val_loss: 1.5003 - val_accuracy: 0.2180\n",
      "Epoch 9/200\n",
      "12/12 [==============================] - 1s 109ms/step - loss: 1.4480 - accuracy: 0.3186 - val_loss: 1.4844 - val_accuracy: 0.2042\n",
      "Epoch 10/200\n",
      "12/12 [==============================] - 1s 117ms/step - loss: 1.4195 - accuracy: 0.3411 - val_loss: 1.4752 - val_accuracy: 0.1938\n",
      "Epoch 11/200\n",
      "12/12 [==============================] - 1s 119ms/step - loss: 1.3913 - accuracy: 0.3681 - val_loss: 1.4711 - val_accuracy: 0.2284\n",
      "Epoch 12/200\n",
      "12/12 [==============================] - 1s 117ms/step - loss: 1.3796 - accuracy: 0.3637 - val_loss: 1.4747 - val_accuracy: 0.2422\n",
      "Epoch 13/200\n",
      "12/12 [==============================] - 1s 112ms/step - loss: 1.3482 - accuracy: 0.3958 - val_loss: 1.4805 - val_accuracy: 0.2318\n",
      "Epoch 14/200\n",
      "12/12 [==============================] - 1s 112ms/step - loss: 1.3120 - accuracy: 0.4262 - val_loss: 1.4906 - val_accuracy: 0.2561\n",
      "Epoch 15/200\n",
      "12/12 [==============================] - 1s 110ms/step - loss: 1.2775 - accuracy: 0.4566 - val_loss: 1.5211 - val_accuracy: 0.2249\n",
      "Epoch 16/200\n",
      "12/12 [==============================] - 1s 106ms/step - loss: 1.2325 - accuracy: 0.4609 - val_loss: 1.5943 - val_accuracy: 0.2284\n",
      "Epoch 17/200\n",
      "12/12 [==============================] - 1s 111ms/step - loss: 1.2053 - accuracy: 0.4861 - val_loss: 1.5767 - val_accuracy: 0.2388\n",
      "Epoch 18/200\n",
      "12/12 [==============================] - 1s 110ms/step - loss: 1.1657 - accuracy: 0.5069 - val_loss: 1.5908 - val_accuracy: 0.2284\n",
      "Epoch 19/200\n",
      "12/12 [==============================] - 1s 108ms/step - loss: 1.1053 - accuracy: 0.5651 - val_loss: 1.6658 - val_accuracy: 0.2249\n",
      "Epoch 20/200\n",
      "12/12 [==============================] - 1s 108ms/step - loss: 1.0806 - accuracy: 0.5668 - val_loss: 1.6641 - val_accuracy: 0.2249\n",
      "Epoch 21/200\n",
      "12/12 [==============================] - 1s 105ms/step - loss: 1.0400 - accuracy: 0.5825 - val_loss: 1.7340 - val_accuracy: 0.2422\n",
      "Epoch 22/200\n",
      "12/12 [==============================] - 1s 108ms/step - loss: 1.0038 - accuracy: 0.6094 - val_loss: 1.7944 - val_accuracy: 0.2249\n",
      "Epoch 23/200\n",
      "12/12 [==============================] - 1s 107ms/step - loss: 0.9476 - accuracy: 0.6450 - val_loss: 1.8009 - val_accuracy: 0.2111\n",
      "Epoch 24/200\n",
      "12/12 [==============================] - 1s 107ms/step - loss: 0.8884 - accuracy: 0.6658 - val_loss: 1.8753 - val_accuracy: 0.2215\n",
      "Epoch 25/200\n",
      "12/12 [==============================] - 1s 108ms/step - loss: 0.8753 - accuracy: 0.6545 - val_loss: 2.0117 - val_accuracy: 0.2284\n",
      "Epoch 26/200\n",
      "12/12 [==============================] - 1s 107ms/step - loss: 0.8537 - accuracy: 0.6762 - val_loss: 2.0038 - val_accuracy: 0.2215\n",
      "Epoch 27/200\n",
      "12/12 [==============================] - 1s 116ms/step - loss: 0.8188 - accuracy: 0.7057 - val_loss: 2.0372 - val_accuracy: 0.2180\n",
      "Epoch 28/200\n",
      "12/12 [==============================] - 1s 114ms/step - loss: 0.8342 - accuracy: 0.6736 - val_loss: 2.0385 - val_accuracy: 0.2145\n",
      "Epoch 29/200\n",
      "12/12 [==============================] - 1s 109ms/step - loss: 0.7544 - accuracy: 0.7318 - val_loss: 2.1330 - val_accuracy: 0.2249\n",
      "Epoch 30/200\n",
      "12/12 [==============================] - 1s 107ms/step - loss: 0.7078 - accuracy: 0.7448 - val_loss: 2.2812 - val_accuracy: 0.1972\n",
      "Epoch 31/200\n",
      "12/12 [==============================] - 1s 109ms/step - loss: 0.6483 - accuracy: 0.7804 - val_loss: 2.2812 - val_accuracy: 0.2422\n",
      "Epoch 32/200\n",
      "12/12 [==============================] - 1s 107ms/step - loss: 0.6398 - accuracy: 0.7795 - val_loss: 2.3144 - val_accuracy: 0.2284\n",
      "Epoch 33/200\n",
      "12/12 [==============================] - 1s 106ms/step - loss: 0.6429 - accuracy: 0.7917 - val_loss: 2.3581 - val_accuracy: 0.2076\n",
      "Epoch 34/200\n",
      "12/12 [==============================] - 1s 105ms/step - loss: 0.6153 - accuracy: 0.7795 - val_loss: 2.4512 - val_accuracy: 0.2180\n",
      "Epoch 35/200\n",
      "12/12 [==============================] - 1s 103ms/step - loss: 0.5544 - accuracy: 0.8351 - val_loss: 2.5186 - val_accuracy: 0.2076\n",
      "Epoch 36/200\n",
      "12/12 [==============================] - 1s 104ms/step - loss: 0.5324 - accuracy: 0.8273 - val_loss: 2.6086 - val_accuracy: 0.2076\n",
      "Epoch 37/200\n",
      "12/12 [==============================] - 1s 102ms/step - loss: 0.5519 - accuracy: 0.8229 - val_loss: 2.7676 - val_accuracy: 0.2249\n",
      "Epoch 38/200\n",
      "12/12 [==============================] - 1s 105ms/step - loss: 0.4901 - accuracy: 0.8290 - val_loss: 2.7081 - val_accuracy: 0.2111\n",
      "Epoch 39/200\n",
      "12/12 [==============================] - 1s 104ms/step - loss: 0.4746 - accuracy: 0.8490 - val_loss: 2.9833 - val_accuracy: 0.2007\n",
      "Epoch 40/200\n",
      "12/12 [==============================] - 1s 104ms/step - loss: 0.4864 - accuracy: 0.8420 - val_loss: 2.7816 - val_accuracy: 0.2180\n",
      "Epoch 41/200\n",
      "12/12 [==============================] - 1s 103ms/step - loss: 0.4873 - accuracy: 0.8420 - val_loss: 2.7721 - val_accuracy: 0.2249\n",
      "Epoch 42/200\n",
      "12/12 [==============================] - 1s 102ms/step - loss: 0.4465 - accuracy: 0.8689 - val_loss: 2.9853 - val_accuracy: 0.1938\n",
      "Epoch 43/200\n",
      "12/12 [==============================] - 1s 103ms/step - loss: 0.4293 - accuracy: 0.8707 - val_loss: 3.0351 - val_accuracy: 0.2180\n",
      "Epoch 44/200\n",
      "12/12 [==============================] - 1s 108ms/step - loss: 0.4761 - accuracy: 0.8420 - val_loss: 3.1012 - val_accuracy: 0.2180\n",
      "Epoch 45/200\n",
      "12/12 [==============================] - 1s 104ms/step - loss: 0.4511 - accuracy: 0.8481 - val_loss: 2.9991 - val_accuracy: 0.2145\n",
      "Epoch 46/200\n",
      "12/12 [==============================] - 1s 104ms/step - loss: 0.4347 - accuracy: 0.8681 - val_loss: 2.9826 - val_accuracy: 0.1869\n",
      "Epoch 47/200\n",
      "12/12 [==============================] - 1s 104ms/step - loss: 0.4247 - accuracy: 0.8724 - val_loss: 3.2595 - val_accuracy: 0.2076\n",
      "Epoch 48/200\n",
      "12/12 [==============================] - 1s 102ms/step - loss: 0.3911 - accuracy: 0.8802 - val_loss: 3.2208 - val_accuracy: 0.1938\n",
      "Epoch 49/200\n",
      "12/12 [==============================] - 1s 103ms/step - loss: 0.3718 - accuracy: 0.8889 - val_loss: 3.2877 - val_accuracy: 0.2180\n",
      "Epoch 50/200\n",
      "12/12 [==============================] - 1s 104ms/step - loss: 0.3719 - accuracy: 0.8872 - val_loss: 3.2546 - val_accuracy: 0.2111\n",
      "Epoch 51/200\n",
      "12/12 [==============================] - 1s 106ms/step - loss: 0.3705 - accuracy: 0.8880 - val_loss: 3.3936 - val_accuracy: 0.2318\n",
      "Epoch 52/200\n",
      "12/12 [==============================] - 1s 110ms/step - loss: 0.3571 - accuracy: 0.8958 - val_loss: 3.2917 - val_accuracy: 0.2215\n",
      "Epoch 53/200\n",
      "12/12 [==============================] - 1s 109ms/step - loss: 0.3574 - accuracy: 0.8845 - val_loss: 3.5739 - val_accuracy: 0.2007\n",
      "Epoch 54/200\n",
      "12/12 [==============================] - 1s 109ms/step - loss: 0.3764 - accuracy: 0.8898 - val_loss: 3.3841 - val_accuracy: 0.2457\n",
      "Epoch 55/200\n",
      "12/12 [==============================] - 1s 104ms/step - loss: 0.3457 - accuracy: 0.8958 - val_loss: 3.5238 - val_accuracy: 0.2180\n",
      "Epoch 56/200\n",
      "12/12 [==============================] - 1s 103ms/step - loss: 0.3294 - accuracy: 0.9123 - val_loss: 3.4574 - val_accuracy: 0.2526\n",
      "Epoch 57/200\n",
      "12/12 [==============================] - 1s 101ms/step - loss: 0.3149 - accuracy: 0.9115 - val_loss: 3.6250 - val_accuracy: 0.2007\n",
      "Epoch 58/200\n",
      "12/12 [==============================] - 1s 108ms/step - loss: 0.3121 - accuracy: 0.9141 - val_loss: 3.5372 - val_accuracy: 0.2215\n",
      "Epoch 59/200\n",
      "12/12 [==============================] - 1s 105ms/step - loss: 0.2630 - accuracy: 0.9340 - val_loss: 3.7173 - val_accuracy: 0.2215\n",
      "Epoch 60/200\n",
      "12/12 [==============================] - 1s 107ms/step - loss: 0.2681 - accuracy: 0.9323 - val_loss: 3.9075 - val_accuracy: 0.2180\n",
      "Epoch 61/200\n",
      "12/12 [==============================] - 1s 105ms/step - loss: 0.2676 - accuracy: 0.9323 - val_loss: 3.7867 - val_accuracy: 0.2215\n",
      "Epoch 62/200\n",
      "12/12 [==============================] - 1s 106ms/step - loss: 0.2696 - accuracy: 0.9306 - val_loss: 3.8217 - val_accuracy: 0.2215\n",
      "Epoch 63/200\n",
      "12/12 [==============================] - 1s 103ms/step - loss: 0.2382 - accuracy: 0.9427 - val_loss: 4.1122 - val_accuracy: 0.2180\n",
      "Epoch 64/200\n",
      "12/12 [==============================] - 1s 110ms/step - loss: 0.2394 - accuracy: 0.9427 - val_loss: 4.1393 - val_accuracy: 0.2215\n",
      "Epoch 65/200\n",
      "12/12 [==============================] - 1s 115ms/step - loss: 0.2942 - accuracy: 0.9184 - val_loss: 3.8429 - val_accuracy: 0.2111\n",
      "Epoch 66/200\n",
      "12/12 [==============================] - 1s 111ms/step - loss: 0.2751 - accuracy: 0.9288 - val_loss: 3.9149 - val_accuracy: 0.2111\n",
      "Epoch 67/200\n",
      "12/12 [==============================] - 1s 108ms/step - loss: 0.2699 - accuracy: 0.9323 - val_loss: 4.0243 - val_accuracy: 0.2318\n",
      "Epoch 68/200\n",
      "12/12 [==============================] - 1s 108ms/step - loss: 0.2614 - accuracy: 0.9280 - val_loss: 4.0364 - val_accuracy: 0.1972\n",
      "Epoch 69/200\n",
      "12/12 [==============================] - 1s 108ms/step - loss: 0.2463 - accuracy: 0.9401 - val_loss: 4.0852 - val_accuracy: 0.2076\n",
      "Epoch 70/200\n",
      "12/12 [==============================] - 1s 106ms/step - loss: 0.2168 - accuracy: 0.9470 - val_loss: 4.2397 - val_accuracy: 0.2180\n",
      "Epoch 71/200\n",
      "12/12 [==============================] - 1s 106ms/step - loss: 0.2190 - accuracy: 0.9479 - val_loss: 4.3843 - val_accuracy: 0.2180\n",
      "Epoch 72/200\n",
      "12/12 [==============================] - 1s 107ms/step - loss: 0.2292 - accuracy: 0.9427 - val_loss: 4.1640 - val_accuracy: 0.1972\n",
      "Epoch 73/200\n",
      "12/12 [==============================] - 1s 102ms/step - loss: 0.2150 - accuracy: 0.9418 - val_loss: 4.1387 - val_accuracy: 0.2284\n",
      "Epoch 74/200\n",
      "12/12 [==============================] - 1s 102ms/step - loss: 0.2248 - accuracy: 0.9358 - val_loss: 4.2958 - val_accuracy: 0.2215\n",
      "Epoch 75/200\n",
      "12/12 [==============================] - 1s 111ms/step - loss: 0.2294 - accuracy: 0.9349 - val_loss: 4.3222 - val_accuracy: 0.2111\n",
      "Epoch 76/200\n",
      "12/12 [==============================] - 1s 106ms/step - loss: 0.2391 - accuracy: 0.9418 - val_loss: 4.2420 - val_accuracy: 0.2007\n",
      "Epoch 77/200\n",
      "12/12 [==============================] - 1s 105ms/step - loss: 0.1922 - accuracy: 0.9566 - val_loss: 4.4725 - val_accuracy: 0.2249\n",
      "Epoch 78/200\n",
      "12/12 [==============================] - 1s 109ms/step - loss: 0.1949 - accuracy: 0.9549 - val_loss: 4.5637 - val_accuracy: 0.2111\n",
      "Epoch 79/200\n",
      "12/12 [==============================] - 1s 112ms/step - loss: 0.2040 - accuracy: 0.9479 - val_loss: 4.3880 - val_accuracy: 0.2215\n",
      "Epoch 80/200\n",
      "12/12 [==============================] - 1s 105ms/step - loss: 0.2193 - accuracy: 0.9427 - val_loss: 4.2668 - val_accuracy: 0.2111\n",
      "Epoch 81/200\n",
      "12/12 [==============================] - 1s 106ms/step - loss: 0.2207 - accuracy: 0.9462 - val_loss: 4.3707 - val_accuracy: 0.2145\n",
      "Epoch 82/200\n",
      "12/12 [==============================] - 1s 108ms/step - loss: 0.2275 - accuracy: 0.9444 - val_loss: 4.4022 - val_accuracy: 0.2353\n",
      "Epoch 83/200\n",
      "12/12 [==============================] - 1s 109ms/step - loss: 0.2235 - accuracy: 0.9488 - val_loss: 4.3992 - val_accuracy: 0.2076\n",
      "Epoch 84/200\n",
      "12/12 [==============================] - 1s 103ms/step - loss: 0.2049 - accuracy: 0.9453 - val_loss: 4.4043 - val_accuracy: 0.2180\n",
      "Epoch 85/200\n",
      "12/12 [==============================] - 1s 105ms/step - loss: 0.2020 - accuracy: 0.9505 - val_loss: 4.3529 - val_accuracy: 0.2284\n",
      "Epoch 86/200\n",
      "12/12 [==============================] - 1s 107ms/step - loss: 0.1803 - accuracy: 0.9523 - val_loss: 4.5720 - val_accuracy: 0.2042\n",
      "Epoch 87/200\n",
      "12/12 [==============================] - 1s 110ms/step - loss: 0.2032 - accuracy: 0.9462 - val_loss: 4.6561 - val_accuracy: 0.2007\n",
      "Epoch 88/200\n",
      "12/12 [==============================] - 1s 105ms/step - loss: 0.2353 - accuracy: 0.9314 - val_loss: 4.3053 - val_accuracy: 0.2249\n",
      "Epoch 89/200\n",
      "12/12 [==============================] - 1s 105ms/step - loss: 0.2214 - accuracy: 0.9375 - val_loss: 4.1836 - val_accuracy: 0.2284\n",
      "Epoch 90/200\n",
      "12/12 [==============================] - 1s 105ms/step - loss: 0.2061 - accuracy: 0.9444 - val_loss: 4.5675 - val_accuracy: 0.2145\n",
      "Epoch 91/200\n",
      "12/12 [==============================] - 1s 107ms/step - loss: 0.1964 - accuracy: 0.9505 - val_loss: 4.6666 - val_accuracy: 0.1938\n",
      "Epoch 92/200\n",
      "12/12 [==============================] - 1s 107ms/step - loss: 0.1819 - accuracy: 0.9540 - val_loss: 4.6618 - val_accuracy: 0.2215\n",
      "Epoch 93/200\n",
      "12/12 [==============================] - 1s 103ms/step - loss: 0.1775 - accuracy: 0.9618 - val_loss: 4.5862 - val_accuracy: 0.2042\n",
      "Epoch 94/200\n",
      "12/12 [==============================] - 1s 107ms/step - loss: 0.1796 - accuracy: 0.9601 - val_loss: 4.5396 - val_accuracy: 0.1972\n",
      "Epoch 95/200\n",
      "12/12 [==============================] - 1s 108ms/step - loss: 0.1713 - accuracy: 0.9531 - val_loss: 4.5410 - val_accuracy: 0.2111\n",
      "Epoch 96/200\n",
      "12/12 [==============================] - 1s 110ms/step - loss: 0.1708 - accuracy: 0.9618 - val_loss: 4.5381 - val_accuracy: 0.2111\n",
      "Epoch 97/200\n",
      "12/12 [==============================] - 1s 108ms/step - loss: 0.1782 - accuracy: 0.9609 - val_loss: 4.6726 - val_accuracy: 0.2111\n",
      "Epoch 98/200\n",
      "12/12 [==============================] - 1s 109ms/step - loss: 0.1907 - accuracy: 0.9488 - val_loss: 4.5161 - val_accuracy: 0.1869\n",
      "Epoch 99/200\n",
      "12/12 [==============================] - 1s 108ms/step - loss: 0.1548 - accuracy: 0.9670 - val_loss: 4.8395 - val_accuracy: 0.2111\n",
      "Epoch 100/200\n",
      "12/12 [==============================] - 1s 108ms/step - loss: 0.1841 - accuracy: 0.9566 - val_loss: 4.7180 - val_accuracy: 0.2180\n",
      "Epoch 101/200\n",
      "12/12 [==============================] - 1s 110ms/step - loss: 0.1828 - accuracy: 0.9557 - val_loss: 4.7575 - val_accuracy: 0.2076\n",
      "Epoch 102/200\n",
      "12/12 [==============================] - 1s 110ms/step - loss: 0.1923 - accuracy: 0.9470 - val_loss: 4.5194 - val_accuracy: 0.2111\n",
      "Epoch 103/200\n",
      "12/12 [==============================] - 1s 112ms/step - loss: 0.1696 - accuracy: 0.9549 - val_loss: 4.4885 - val_accuracy: 0.2042\n",
      "Epoch 104/200\n",
      "12/12 [==============================] - 1s 111ms/step - loss: 0.1752 - accuracy: 0.9609 - val_loss: 4.5054 - val_accuracy: 0.2318\n",
      "Epoch 105/200\n",
      "12/12 [==============================] - 1s 114ms/step - loss: 0.1658 - accuracy: 0.9575 - val_loss: 4.5694 - val_accuracy: 0.2076\n",
      "Epoch 106/200\n",
      "12/12 [==============================] - 1s 108ms/step - loss: 0.1509 - accuracy: 0.9661 - val_loss: 4.6460 - val_accuracy: 0.2076\n",
      "Epoch 107/200\n",
      "12/12 [==============================] - 1s 110ms/step - loss: 0.1421 - accuracy: 0.9696 - val_loss: 4.8322 - val_accuracy: 0.2180\n",
      "Epoch 108/200\n",
      "12/12 [==============================] - 1s 109ms/step - loss: 0.1470 - accuracy: 0.9661 - val_loss: 4.9372 - val_accuracy: 0.2249\n",
      "Epoch 109/200\n",
      "12/12 [==============================] - 1s 112ms/step - loss: 0.1536 - accuracy: 0.9609 - val_loss: 4.5140 - val_accuracy: 0.2076\n",
      "Epoch 110/200\n",
      "12/12 [==============================] - 1s 110ms/step - loss: 0.1379 - accuracy: 0.9748 - val_loss: 4.8192 - val_accuracy: 0.2145\n",
      "Epoch 111/200\n",
      "12/12 [==============================] - 1s 112ms/step - loss: 0.1524 - accuracy: 0.9635 - val_loss: 4.6363 - val_accuracy: 0.2318\n",
      "Epoch 112/200\n",
      "12/12 [==============================] - 1s 108ms/step - loss: 0.1515 - accuracy: 0.9601 - val_loss: 4.8721 - val_accuracy: 0.2215\n",
      "Epoch 113/200\n",
      "12/12 [==============================] - 1s 111ms/step - loss: 0.1497 - accuracy: 0.9635 - val_loss: 5.0276 - val_accuracy: 0.2145\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 114/200\n",
      "12/12 [==============================] - 1s 114ms/step - loss: 0.1760 - accuracy: 0.9505 - val_loss: 4.7994 - val_accuracy: 0.2215\n",
      "Epoch 115/200\n",
      "12/12 [==============================] - 1s 109ms/step - loss: 0.1489 - accuracy: 0.9635 - val_loss: 4.5871 - val_accuracy: 0.2215\n",
      "Epoch 116/200\n",
      "12/12 [==============================] - 1s 110ms/step - loss: 0.1732 - accuracy: 0.9557 - val_loss: 4.8459 - val_accuracy: 0.2284\n",
      "Epoch 117/200\n",
      "12/12 [==============================] - 1s 117ms/step - loss: 0.1761 - accuracy: 0.9514 - val_loss: 4.9119 - val_accuracy: 0.2007\n",
      "Epoch 118/200\n",
      "12/12 [==============================] - 1s 113ms/step - loss: 0.1754 - accuracy: 0.9557 - val_loss: 4.7469 - val_accuracy: 0.2111\n",
      "Epoch 119/200\n",
      "12/12 [==============================] - 1s 109ms/step - loss: 0.1610 - accuracy: 0.9601 - val_loss: 4.5995 - val_accuracy: 0.2111\n",
      "Epoch 120/200\n",
      "12/12 [==============================] - 1s 115ms/step - loss: 0.1436 - accuracy: 0.9644 - val_loss: 4.9647 - val_accuracy: 0.2145\n",
      "Epoch 121/200\n",
      "12/12 [==============================] - 1s 120ms/step - loss: 0.1337 - accuracy: 0.9688 - val_loss: 4.8573 - val_accuracy: 0.2111\n",
      "Epoch 122/200\n",
      "12/12 [==============================] - 1s 114ms/step - loss: 0.1298 - accuracy: 0.9670 - val_loss: 4.8448 - val_accuracy: 0.2249\n",
      "Epoch 123/200\n",
      "12/12 [==============================] - 1s 107ms/step - loss: 0.1488 - accuracy: 0.9627 - val_loss: 4.9836 - val_accuracy: 0.2180\n",
      "Epoch 124/200\n",
      "12/12 [==============================] - 1s 110ms/step - loss: 0.1434 - accuracy: 0.9618 - val_loss: 5.0554 - val_accuracy: 0.1834\n",
      "Epoch 125/200\n",
      "12/12 [==============================] - 1s 110ms/step - loss: 0.1740 - accuracy: 0.9488 - val_loss: 4.6061 - val_accuracy: 0.2215\n",
      "Epoch 126/200\n",
      "12/12 [==============================] - 1s 107ms/step - loss: 0.1695 - accuracy: 0.9523 - val_loss: 4.8584 - val_accuracy: 0.2215\n",
      "Epoch 127/200\n",
      "12/12 [==============================] - 1s 113ms/step - loss: 0.1681 - accuracy: 0.9479 - val_loss: 4.8468 - val_accuracy: 0.2076\n",
      "Epoch 128/200\n",
      "12/12 [==============================] - 1s 105ms/step - loss: 0.1440 - accuracy: 0.9653 - val_loss: 4.8827 - val_accuracy: 0.2111\n",
      "Epoch 129/200\n",
      "12/12 [==============================] - 1s 105ms/step - loss: 0.1243 - accuracy: 0.9740 - val_loss: 4.8764 - val_accuracy: 0.2145\n",
      "Epoch 130/200\n",
      "12/12 [==============================] - 1s 111ms/step - loss: 0.1377 - accuracy: 0.9670 - val_loss: 5.0903 - val_accuracy: 0.2111\n",
      "Epoch 131/200\n",
      "12/12 [==============================] - 1s 113ms/step - loss: 0.1328 - accuracy: 0.9670 - val_loss: 4.8339 - val_accuracy: 0.2180\n",
      "Epoch 132/200\n",
      "12/12 [==============================] - 1s 113ms/step - loss: 0.1080 - accuracy: 0.9774 - val_loss: 4.9499 - val_accuracy: 0.2111\n",
      "Epoch 133/200\n",
      "12/12 [==============================] - 1s 110ms/step - loss: 0.1230 - accuracy: 0.9670 - val_loss: 5.2192 - val_accuracy: 0.2042\n",
      "Epoch 134/200\n",
      "12/12 [==============================] - 1s 107ms/step - loss: 0.1277 - accuracy: 0.9661 - val_loss: 5.0708 - val_accuracy: 0.2042\n",
      "Epoch 135/200\n",
      "12/12 [==============================] - 1s 109ms/step - loss: 0.1413 - accuracy: 0.9635 - val_loss: 4.9512 - val_accuracy: 0.2318\n",
      "Epoch 136/200\n",
      "12/12 [==============================] - 1s 108ms/step - loss: 0.1500 - accuracy: 0.9627 - val_loss: 4.9180 - val_accuracy: 0.2145\n",
      "Epoch 137/200\n",
      "12/12 [==============================] - 1s 109ms/step - loss: 0.1583 - accuracy: 0.9609 - val_loss: 4.9346 - val_accuracy: 0.2145\n",
      "Epoch 138/200\n",
      "12/12 [==============================] - 1s 109ms/step - loss: 0.1260 - accuracy: 0.9688 - val_loss: 4.9841 - val_accuracy: 0.2249\n",
      "Epoch 139/200\n",
      "12/12 [==============================] - 1s 109ms/step - loss: 0.1189 - accuracy: 0.9757 - val_loss: 5.1031 - val_accuracy: 0.2318\n",
      "Epoch 140/200\n",
      "12/12 [==============================] - 1s 105ms/step - loss: 0.1086 - accuracy: 0.9731 - val_loss: 5.1507 - val_accuracy: 0.2388\n",
      "Epoch 141/200\n",
      "12/12 [==============================] - 1s 109ms/step - loss: 0.1174 - accuracy: 0.9705 - val_loss: 5.0751 - val_accuracy: 0.2111\n",
      "Epoch 142/200\n",
      "12/12 [==============================] - 1s 110ms/step - loss: 0.1228 - accuracy: 0.9714 - val_loss: 5.0007 - val_accuracy: 0.1972\n",
      "Epoch 143/200\n",
      "12/12 [==============================] - 1s 108ms/step - loss: 0.1152 - accuracy: 0.9696 - val_loss: 5.0807 - val_accuracy: 0.2284\n",
      "Epoch 144/200\n",
      "12/12 [==============================] - 1s 109ms/step - loss: 0.1152 - accuracy: 0.9748 - val_loss: 5.0660 - val_accuracy: 0.2180\n",
      "Epoch 145/200\n",
      "12/12 [==============================] - 1s 111ms/step - loss: 0.1126 - accuracy: 0.9748 - val_loss: 5.0234 - val_accuracy: 0.2042\n",
      "Epoch 146/200\n",
      "12/12 [==============================] - 1s 102ms/step - loss: 0.1198 - accuracy: 0.9748 - val_loss: 5.1148 - val_accuracy: 0.2180\n",
      "Epoch 147/200\n",
      "12/12 [==============================] - 1s 108ms/step - loss: 0.1299 - accuracy: 0.9688 - val_loss: 5.0444 - val_accuracy: 0.2180\n",
      "Epoch 148/200\n",
      "12/12 [==============================] - 1s 105ms/step - loss: 0.1260 - accuracy: 0.9679 - val_loss: 5.2954 - val_accuracy: 0.2007\n",
      "Epoch 149/200\n",
      "12/12 [==============================] - 1s 109ms/step - loss: 0.1264 - accuracy: 0.9696 - val_loss: 4.8586 - val_accuracy: 0.2145\n",
      "Epoch 150/200\n",
      "12/12 [==============================] - 1s 110ms/step - loss: 0.1101 - accuracy: 0.9722 - val_loss: 5.2832 - val_accuracy: 0.2215\n",
      "Epoch 151/200\n",
      "12/12 [==============================] - 1s 109ms/step - loss: 0.1068 - accuracy: 0.9748 - val_loss: 5.5192 - val_accuracy: 0.2215\n",
      "Epoch 152/200\n",
      "12/12 [==============================] - 1s 108ms/step - loss: 0.1064 - accuracy: 0.9722 - val_loss: 5.4926 - val_accuracy: 0.1972\n",
      "Epoch 153/200\n",
      "12/12 [==============================] - 1s 111ms/step - loss: 0.1075 - accuracy: 0.9748 - val_loss: 5.2481 - val_accuracy: 0.2145\n",
      "Epoch 154/200\n",
      "12/12 [==============================] - 1s 109ms/step - loss: 0.1137 - accuracy: 0.9731 - val_loss: 5.1943 - val_accuracy: 0.2145\n",
      "Epoch 155/200\n",
      "12/12 [==============================] - 1s 110ms/step - loss: 0.1163 - accuracy: 0.9670 - val_loss: 5.2872 - val_accuracy: 0.2042\n",
      "Epoch 156/200\n",
      "12/12 [==============================] - 1s 111ms/step - loss: 0.1099 - accuracy: 0.9705 - val_loss: 5.1280 - val_accuracy: 0.2318\n",
      "Epoch 157/200\n",
      "12/12 [==============================] - 1s 113ms/step - loss: 0.1003 - accuracy: 0.9731 - val_loss: 5.4059 - val_accuracy: 0.2145\n",
      "Epoch 158/200\n",
      "12/12 [==============================] - 1s 112ms/step - loss: 0.0957 - accuracy: 0.9757 - val_loss: 5.2834 - val_accuracy: 0.2249\n",
      "Epoch 159/200\n",
      "12/12 [==============================] - 1s 111ms/step - loss: 0.1079 - accuracy: 0.9731 - val_loss: 5.2378 - val_accuracy: 0.2353\n",
      "Epoch 160/200\n",
      "12/12 [==============================] - 1s 108ms/step - loss: 0.1027 - accuracy: 0.9748 - val_loss: 5.2048 - val_accuracy: 0.2318\n",
      "Epoch 161/200\n",
      "12/12 [==============================] - 1s 106ms/step - loss: 0.1085 - accuracy: 0.9757 - val_loss: 5.2399 - val_accuracy: 0.2284\n",
      "Epoch 162/200\n",
      "12/12 [==============================] - 1s 122ms/step - loss: 0.1246 - accuracy: 0.9679 - val_loss: 4.9167 - val_accuracy: 0.2284\n",
      "Epoch 163/200\n",
      "12/12 [==============================] - 1s 122ms/step - loss: 0.1114 - accuracy: 0.9714 - val_loss: 5.0124 - val_accuracy: 0.2215\n",
      "Epoch 164/200\n",
      "12/12 [==============================] - 1s 115ms/step - loss: 0.1138 - accuracy: 0.9757 - val_loss: 5.1752 - val_accuracy: 0.2318\n",
      "Epoch 165/200\n",
      "12/12 [==============================] - 1s 109ms/step - loss: 0.0994 - accuracy: 0.9757 - val_loss: 5.3523 - val_accuracy: 0.2388\n",
      "Epoch 166/200\n",
      "12/12 [==============================] - 1s 119ms/step - loss: 0.1000 - accuracy: 0.9731 - val_loss: 5.5247 - val_accuracy: 0.2318\n",
      "Epoch 167/200\n",
      "12/12 [==============================] - 1s 118ms/step - loss: 0.1034 - accuracy: 0.9731 - val_loss: 5.1579 - val_accuracy: 0.2145\n",
      "Epoch 168/200\n",
      "12/12 [==============================] - 1s 110ms/step - loss: 0.1117 - accuracy: 0.9757 - val_loss: 5.0880 - val_accuracy: 0.2284\n",
      "Epoch 169/200\n",
      "12/12 [==============================] - 1s 109ms/step - loss: 0.1330 - accuracy: 0.9644 - val_loss: 5.0684 - val_accuracy: 0.2111\n",
      "Epoch 170/200\n",
      "12/12 [==============================] - 1s 113ms/step - loss: 0.1489 - accuracy: 0.9540 - val_loss: 5.5607 - val_accuracy: 0.2388\n",
      "Epoch 171/200\n",
      "12/12 [==============================] - 1s 114ms/step - loss: 0.1610 - accuracy: 0.9470 - val_loss: 5.0336 - val_accuracy: 0.2111\n",
      "Epoch 172/200\n",
      "12/12 [==============================] - 1s 115ms/step - loss: 0.1786 - accuracy: 0.9444 - val_loss: 4.7141 - val_accuracy: 0.2180\n",
      "Epoch 173/200\n",
      "12/12 [==============================] - 1s 117ms/step - loss: 0.1421 - accuracy: 0.9557 - val_loss: 5.0584 - val_accuracy: 0.2042\n",
      "Epoch 174/200\n",
      "12/12 [==============================] - 1s 115ms/step - loss: 0.1375 - accuracy: 0.9618 - val_loss: 5.2938 - val_accuracy: 0.2215\n",
      "Epoch 175/200\n",
      "12/12 [==============================] - 1s 112ms/step - loss: 0.1480 - accuracy: 0.9540 - val_loss: 5.3249 - val_accuracy: 0.2215\n",
      "Epoch 176/200\n",
      "12/12 [==============================] - 1s 119ms/step - loss: 0.1722 - accuracy: 0.9401 - val_loss: 4.9617 - val_accuracy: 0.2388\n",
      "Epoch 177/200\n",
      "12/12 [==============================] - 1s 117ms/step - loss: 0.1881 - accuracy: 0.9392 - val_loss: 4.7922 - val_accuracy: 0.2422\n",
      "Epoch 178/200\n",
      "12/12 [==============================] - 1s 108ms/step - loss: 0.2089 - accuracy: 0.9280 - val_loss: 5.0099 - val_accuracy: 0.2042\n",
      "Epoch 179/200\n",
      "12/12 [==============================] - 1s 109ms/step - loss: 0.1634 - accuracy: 0.9514 - val_loss: 5.2927 - val_accuracy: 0.2215\n",
      "Epoch 180/200\n",
      "12/12 [==============================] - 1s 115ms/step - loss: 0.1394 - accuracy: 0.9566 - val_loss: 5.4034 - val_accuracy: 0.2249\n",
      "Epoch 181/200\n",
      "12/12 [==============================] - 1s 108ms/step - loss: 0.1363 - accuracy: 0.9627 - val_loss: 5.1473 - val_accuracy: 0.2318\n",
      "Epoch 182/200\n",
      "12/12 [==============================] - 1s 112ms/step - loss: 0.1100 - accuracy: 0.9705 - val_loss: 5.0993 - val_accuracy: 0.2284\n",
      "Epoch 183/200\n",
      "12/12 [==============================] - 1s 110ms/step - loss: 0.1153 - accuracy: 0.9679 - val_loss: 5.3316 - val_accuracy: 0.2249\n",
      "Epoch 184/200\n",
      "12/12 [==============================] - 1s 112ms/step - loss: 0.0955 - accuracy: 0.9757 - val_loss: 5.5244 - val_accuracy: 0.2180\n",
      "Epoch 185/200\n",
      "12/12 [==============================] - 1s 117ms/step - loss: 0.0987 - accuracy: 0.9714 - val_loss: 5.3692 - val_accuracy: 0.2215\n",
      "Epoch 186/200\n",
      "12/12 [==============================] - 1s 113ms/step - loss: 0.0986 - accuracy: 0.9757 - val_loss: 5.3931 - val_accuracy: 0.2249\n",
      "Epoch 187/200\n",
      "12/12 [==============================] - 1s 110ms/step - loss: 0.1058 - accuracy: 0.9766 - val_loss: 5.3485 - val_accuracy: 0.2249\n",
      "Epoch 188/200\n",
      "12/12 [==============================] - 1s 110ms/step - loss: 0.1000 - accuracy: 0.9740 - val_loss: 5.3494 - val_accuracy: 0.2111\n",
      "Epoch 189/200\n",
      "12/12 [==============================] - 1s 109ms/step - loss: 0.0855 - accuracy: 0.9792 - val_loss: 5.5400 - val_accuracy: 0.2145\n",
      "Epoch 190/200\n",
      "12/12 [==============================] - 1s 110ms/step - loss: 0.0884 - accuracy: 0.9774 - val_loss: 5.6098 - val_accuracy: 0.2111\n",
      "Epoch 191/200\n",
      "12/12 [==============================] - 1s 110ms/step - loss: 0.0723 - accuracy: 0.9826 - val_loss: 5.8856 - val_accuracy: 0.2215\n",
      "Epoch 192/200\n",
      "12/12 [==============================] - 1s 114ms/step - loss: 0.0909 - accuracy: 0.9783 - val_loss: 5.9842 - val_accuracy: 0.2111\n",
      "Epoch 193/200\n",
      "12/12 [==============================] - 1s 108ms/step - loss: 0.0896 - accuracy: 0.9757 - val_loss: 5.5729 - val_accuracy: 0.2007\n",
      "Epoch 194/200\n",
      "12/12 [==============================] - 1s 110ms/step - loss: 0.0895 - accuracy: 0.9774 - val_loss: 5.5507 - val_accuracy: 0.2076\n",
      "Epoch 195/200\n",
      "12/12 [==============================] - 1s 109ms/step - loss: 0.0908 - accuracy: 0.9800 - val_loss: 5.6465 - val_accuracy: 0.2249\n",
      "Epoch 196/200\n",
      "12/12 [==============================] - 1s 110ms/step - loss: 0.0843 - accuracy: 0.9809 - val_loss: 5.7380 - val_accuracy: 0.2215\n",
      "Epoch 197/200\n",
      "12/12 [==============================] - 1s 110ms/step - loss: 0.0879 - accuracy: 0.9757 - val_loss: 5.7694 - val_accuracy: 0.1903\n",
      "Epoch 198/200\n",
      "12/12 [==============================] - 1s 109ms/step - loss: 0.0940 - accuracy: 0.9731 - val_loss: 5.8128 - val_accuracy: 0.2076\n",
      "Epoch 199/200\n",
      "12/12 [==============================] - 1s 116ms/step - loss: 0.0920 - accuracy: 0.9783 - val_loss: 5.7346 - val_accuracy: 0.2042\n",
      "Epoch 200/200\n",
      "12/12 [==============================] - 1s 106ms/step - loss: 0.1015 - accuracy: 0.9731 - val_loss: 5.5828 - val_accuracy: 0.2076\n"
     ]
    }
   ],
   "source": [
    "#treinar a rede neural convolucional\n",
    "history = Dcnn.fit(X_tensor, y, batch_size = tamanho_batch, epochs = qtd_epocas, verbose = 1, validation_split = 0.2, shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f55b97a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"dcnn\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv1d (Conv1D)             multiple                  6432      \n",
      "                                                                 \n",
      " conv1d_1 (Conv1D)           multiple                  9632      \n",
      "                                                                 \n",
      " conv1d_2 (Conv1D)           multiple                  12832     \n",
      "                                                                 \n",
      " conv1d_3 (Conv1D)           multiple                  16032     \n",
      "                                                                 \n",
      " global_max_pooling1d (Globa  multiple                 0         \n",
      " lMaxPooling1D)                                                  \n",
      "                                                                 \n",
      " dense (Dense)               multiple                  8256      \n",
      "                                                                 \n",
      " dense_1 (Dense)             multiple                  4160      \n",
      "                                                                 \n",
      " dense_2 (Dense)             multiple                  4160      \n",
      "                                                                 \n",
      " dropout (Dropout)           multiple                  0         \n",
      "                                                                 \n",
      " dense_3 (Dense)             multiple                  260       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 61,764\n",
      "Trainable params: 61,764\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "Dcnn.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "564e3903",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ckpt-1'"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# salvar o checkpoint\n",
    "ckpt_manager.save()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1eebdd41",
   "metadata": {},
   "source": [
    "## avaliação do modelo de rede neural convolucional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1c91397d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# carregar os dados de teste\n",
    "with open(os.path.join('data', 'dataset_param_c_test.pkl'), 'rb') as f:\n",
    "    df_test = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "523b2163",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['tf_idf', 'wes', 'wes_own', 'classes_param_a_1', 'classes_param_b_1',\n",
       "       'classes_param_c_1'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "deab1847",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(481, 793, 100)\n",
      "(481,)\n"
     ]
    }
   ],
   "source": [
    "#obtém os dados do conjunto de teste\n",
    "X_test = df_test.iloc[:, 2].values\n",
    "X_test = tf.keras.preprocessing.sequence.pad_sequences(X_test, value = 0, padding = 'post', maxlen = max_len)\n",
    "X_test = tf.convert_to_tensor(X_test, dtype=tf.float32)\n",
    "print(X_test.shape)\n",
    "y_test = np.array(df_test.iloc[:, 3].values)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5bf7130",
   "metadata": {},
   "source": [
    "O trecho results = Dcnn.evaluate(X_test, y_test, batch_size=tamanho_batch) é utilizado para avaliar o desempenho de um modelo de rede neural convolucional (CNN) chamado Dcnn em um conjunto de dados de teste X_test e rótulos de teste y_test. A função evaluate do objeto Dcnn calcula a perda (loss) e a acurácia (accuracy) do modelo no conjunto de teste, e armazena essas métricas na variável results. O parâmetro batch_size é usado para definir o tamanho do lote (batch size) a ser usado para a avaliação do modelo. Geralmente, quanto maior o tamanho do lote, mais rápido o processo de avaliação, mas isso pode levar a um aumento do uso de memória e possíveis limitações computacionais."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "8a815644",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 24ms/step - loss: 5.6324 - accuracy: 0.2536\n",
      "[5.632358551025391, 0.25363826751708984]\n"
     ]
    }
   ],
   "source": [
    "#avalia o modelo com o conjunto de teste\n",
    "results = Dcnn.evaluate(X_test, y_test, batch_size=tamanho_batch)\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "fbc11eea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(None, 128)\n",
      "16/16 [==============================] - 0s 11ms/step\n"
     ]
    }
   ],
   "source": [
    "y_pred_test = Dcnn.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "9102ecd6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[9.9993408e-01, 5.2484056e-06, 3.4010472e-12, 6.0627604e-05],\n",
       "       [8.3996002e-03, 7.7451282e-04, 4.6955998e-04, 9.9035639e-01],\n",
       "       [4.0452811e-03, 8.1068832e-01, 1.8019745e-01, 5.0689117e-03],\n",
       "       ...,\n",
       "       [8.8118322e-05, 4.6900147e-01, 5.2859682e-01, 2.3136870e-03],\n",
       "       [1.6711246e-03, 6.5242930e-04, 5.5280915e-03, 9.9214840e-01],\n",
       "       [4.7134326e-05, 3.9771998e-01, 5.9674531e-01, 5.4875072e-03]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "edbe2ee4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 3, 1, 2, 2, 1, 1, 2, 0, 1, 1, 3, 0, 3, 2, 3, 1, 3, 0, 2, 1, 3,\n",
       "       3, 2, 3, 0, 3, 0, 1, 1, 3, 0, 0, 1, 3, 3, 0, 2, 3, 1, 2, 1, 1, 3,\n",
       "       0, 1, 1, 2, 1, 3, 2, 1, 1, 3, 3, 3, 1, 3, 0, 1, 3, 1, 3, 3, 0, 2,\n",
       "       2, 0, 0, 3, 0, 1, 1, 0, 0, 0, 0, 1, 3, 2, 2, 2, 0, 0, 2, 0, 2, 3,\n",
       "       2, 1, 0, 3, 2, 0, 1, 1, 0, 1, 1, 1, 1, 1, 2, 3, 3, 3, 2, 1, 0, 2,\n",
       "       3, 2, 1, 3, 3, 1, 3, 3, 1, 2, 1, 0, 1, 2, 1, 1, 0, 2, 1, 3, 2, 2,\n",
       "       0, 3, 3, 1, 2, 2, 3, 1, 3, 3, 0, 3, 2, 2, 3, 1, 2, 1, 3, 3, 2, 0,\n",
       "       2, 2, 1, 2, 2, 2, 3, 3, 0, 0, 3, 0, 2, 1, 1, 2, 3, 0, 3, 3, 0, 3,\n",
       "       0, 3, 3, 1, 1, 0, 3, 1, 2, 1, 1, 0, 1, 1, 2, 2, 2, 2, 1, 0, 0, 0,\n",
       "       0, 1, 3, 3, 2, 0, 1, 2, 3, 0, 0, 3, 2, 1, 1, 1, 1, 1, 2, 0, 2, 0,\n",
       "       3, 1, 0, 1, 2, 1, 0, 1, 3, 1, 2, 3, 3, 1, 2, 2, 0, 1, 0, 1, 3, 3,\n",
       "       1, 3, 3, 2, 0, 2, 3, 0, 0, 3, 3, 0, 2, 1, 1, 2, 1, 3, 1, 2, 2, 1,\n",
       "       0, 2, 2, 1, 2, 1, 1, 2, 0, 0, 3, 3, 3, 3, 3, 1, 0, 3, 2, 2, 1, 1,\n",
       "       0, 0, 0, 3, 0, 2, 2, 1, 1, 3, 0, 2, 1, 2, 0, 1, 3, 3, 0, 0, 2, 3,\n",
       "       1, 2, 2, 2, 0, 2, 2, 3, 2, 2, 1, 0, 1, 1, 1, 2, 0, 0, 2, 3, 2, 0,\n",
       "       1, 3, 3, 1, 3, 0, 3, 0, 1, 2, 2, 0, 1, 2, 3, 1, 3, 3, 3, 0, 2, 3,\n",
       "       2, 1, 3, 3, 1, 0, 3, 3, 1, 2, 1, 3, 3, 0, 0, 3, 1, 2, 2, 3, 3, 3,\n",
       "       3, 2, 2, 1, 3, 1, 2, 2, 1, 1, 0, 2, 1, 3, 3, 1, 0, 0, 3, 3, 2, 0,\n",
       "       2, 3, 3, 2, 3, 1, 3, 2, 1, 3, 3, 3, 3, 3, 2, 0, 0, 3, 0, 3, 0, 3,\n",
       "       3, 3, 2, 1, 0, 2, 3, 2, 2, 3, 0, 1, 2, 3, 0, 2, 3, 2, 3, 0, 3, 2,\n",
       "       1, 3, 0, 3, 0, 1, 3, 1, 1, 1, 1, 3, 1, 2, 3, 1, 3, 1, 2, 3, 1, 1,\n",
       "       3, 1, 0, 0, 0, 1, 2, 0, 3, 3, 3, 1, 3, 0, 1, 1, 2, 3, 2],\n",
       "      dtype=int64)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#valores previstos\n",
    "y_pred_test_values = []\n",
    "for y_ in y_pred_test:\n",
    "    #obtem o valor máximo do array de probabilidades\n",
    "    y_pred_test_values.append(np.argmax(y_))\n",
    "\n",
    "y_pred_test_values = np.array(y_pred_test_values)\n",
    "y_pred_test_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "21cf5e74",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[24, 30, 33, 33],\n",
       "       [27, 32, 23, 33],\n",
       "       [19, 34, 29, 38],\n",
       "       [29, 32, 28, 37]], dtype=int64)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cm = confusion_matrix(y_test, y_pred_test_values)\n",
    "cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "a8f2c3ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "parâmetro de discriminação\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "print('parâmetro de acerto ao acaso')\n",
    "xlabels = ['<=0.12487', '>0.12487 e <=0.165', '>0.165 e <=0.203', '>0.203']\n",
    "ylabels = ['predito <=0.12487', 'predito >0.12487 e <=0.165', 'predito >0.165 e <=0.203', 'predito >0.203']\n",
    "sns.heatmap(cm, annot=True, fmt = 'g', xticklabels = xlabels, yticklabels = ylabels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "c0562236",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.24      0.20      0.22       120\n",
      "           1       0.25      0.28      0.26       115\n",
      "           2       0.26      0.24      0.25       120\n",
      "           3       0.26      0.29      0.28       126\n",
      "\n",
      "    accuracy                           0.25       481\n",
      "   macro avg       0.25      0.25      0.25       481\n",
      "weighted avg       0.25      0.25      0.25       481\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_pred_test_values))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0422943b",
   "metadata": {},
   "source": [
    "Esses são resultados de métricas de avaliação de um modelo de classificação. \"Precision\" representa a proporção de exemplos positivos que o modelo classificou corretamente. \"Recall\" representa a proporção de exemplos positivos que o modelo conseguiu identificar. \"F1-score\" é a média harmônica entre precisão e recall, fornecendo uma métrica equilibrada que reflete tanto a precisão quanto a capacidade de identificação do modelo. \"Support\" representa o número de exemplos na classe.\n",
    "\n",
    "Com base nas métricas fornecidas, podemos ver que o modelo tem baixa precisão, baixo recall e baixo f1-score, o que indica que ele está tendo dificuldade em classificar corretamente os exemplos positivos e ainda não está conseguindo identificar a maioria deles, sendo que ele foi testado em 120 exemplos da classe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "2e09d1e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history.history.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "865e52ac",
   "metadata": {},
   "source": [
    "Ao comparar o erro de treinamento e o erro de validação em um gráfico, é possível realizar várias análises importantes. Algumas delas são:\n",
    "\n",
    "- Overfitting: Se o erro de treinamento estiver caindo enquanto o erro de validação estiver aumentando, é provável que o modelo esteja sofrendo de overfitting. Isso significa que o modelo está se ajustando muito bem aos dados de treinamento, mas não está generalizando bem para os dados de validação.\n",
    "\n",
    "- Underfitting: Se ambos os erros estiverem aumentando, é possível que o modelo esteja underfitting, ou seja, não está se ajustando suficientemente aos dados de treinamento e validação.\n",
    "\n",
    "- Ideal fit: Se o erro de treinamento estiver diminuindo enquanto o erro de validação estiver diminuindo, é provável que o modelo esteja se ajustando de maneira adequada aos dados de treinamento e validação, ou seja, o modelo está aprendendo e generalizando corretamente.\n",
    "\n",
    "Além disso, também é importante observar a velocidade de aprendizado, ou seja, quanto o erro está diminuindo com cada época. Uma diminuição muito lenta pode indicar que o modelo precisa de mais épocas ou que o tamanho do batch precisa ser ajustado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "c0c9f84c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x294107d5d30>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('Progresso de erro do modelo durante o treinamento e validação')\n",
    "plt.xlabel('Época')\n",
    "plt.ylabel('Erro')\n",
    "plt.legend(['Erro de treinamento', 'Erro de validação'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cac990c1",
   "metadata": {},
   "source": [
    "A análise dos gráficos de comparação da acurácia de treinamento e acurácia de validação pode fornecer informações importantes sobre o modelo e o seu desempenho. Aqui estão algumas das possíveis análises que se pode fazer:\n",
    "\n",
    "- Overfitting: Se o gráfico de treinamento mostra uma acurácia muito alta e o gráfico de validação mostra uma acurácia muito baixa, isso pode indicar overfitting, ou seja, o modelo está memorizando o conjunto de treinamento, mas não é geral o suficiente para prever corretamente dados desconhecidos.\n",
    "\n",
    "- Underfitting: Se ambos os gráficos de treinamento e validação mostram baixa acurácia, isso pode indicar sub-ajuste, ou seja, o modelo é muito simples e não está capturando a complexidade da relação entre as características e as classes.\n",
    "\n",
    "- Convergência: Se o gráfico de treinamento mostra uma tendência crescente na acurácia e o gráfico de validação mostra uma tendência estacionária, isso pode indicar que o modelo está convergindo e que mais épocas de treinamento não seriam úteis.\n",
    "\n",
    "- Viés: Se o gráfico de treinamento mostra uma acurácia muito alta, mas o gráfico de validação mostra uma acurácia muito baixa, isso pode indicar viés, ou seja, o modelo está otimizando a métrica de avaliação de forma inadequada e não está levando em conta todas as características do conjunto de dados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "ebd0e4cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x2940e3c7c10>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('Progresso da acurácia do modelo durante o treinamento e validação')\n",
    "plt.xlabel('Época')\n",
    "plt.ylabel('Acurácia')\n",
    "plt.legend(['Acurácia de treino', 'Acurácia de validação'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0acf5bc0",
   "metadata": {},
   "source": [
    "O **método de bootstrap** é uma técnica para estimar a **incerteza** em métricas com base em **amostragem com reposição**. A idéia é que, ao realizarmos várias amostragens de nosso conjunto de dados com reposição, podemos obter diferentes valores para nossa métrica. Então, podemos estimar a variabilidade da nossa métrica e, portanto, seu desvio padrão.\n",
    "\n",
    "O método de bootstrap é frequentemente usado em métricas de modelos de machine learning, como precisão, recall e F1-score, para estimar o erro padrão. Isso pode ser útil para entender a incerteza em nossas métricas e para determinar se o desempenho de nossos modelos é estatisticamente significativo.\n",
    "\n",
    "O método de bootstrap é uma técnica estatística usada para estimar o **desvio padrão** de uma métrica de desempenho da rede neural. Ele pode ser comparado ao ato de tirar amostras aleatórias de uma população para entender a variação da população. Da mesma forma, o método de bootstrap tira amostras aleatórias do conjunto de dados usado para treinar a rede e, em seguida, avalia o desempenho da rede usando a métrica escolhida. Isso é feito várias vezes, e a variação na métrica é usada para estimar o desvio padrão da métrica. É uma maneira de avaliar a incerteza associada às métricas de desempenho da rede e ajuda a entender se a rede está realmente tendo desempenho melhor ou pior do que o esperado.\n",
    "\n",
    "O parâmetro \"B\" representa o número de vezes que o método bootstrap será aplicado para estimar o desvio padrão das métricas usadas para medir o desempenho da rede. Esse valor é usado para determinar o número de amostras aleatórias que serão selecionadas da base de dados de teste para realizar a avaliação do modelo. Quanto maior for o valor de \"B\", maior será a precisão da estimativa do desvio padrão, mas também aumentará o tempo de processamento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "bff3f486",
   "metadata": {},
   "outputs": [],
   "source": [
    "#função que realiza o método bootstrap\n",
    "def bootstrap(X_test, y_test, model, nn=False, B=250):\n",
    "    #Creating dictionary to store results\n",
    "    out={}\n",
    "    out['accuracy']=[]\n",
    "    out['macro avg']={}\n",
    "    out['macro avg']['f1-score']=[]\n",
    "    out['macro avg']['recall']=[]\n",
    "    out['macro avg']['precision']=[]\n",
    "    out['weighted avg']={}\n",
    "    out['weighted avg']['f1-score']=[]\n",
    "    out['weighted avg']['recall']=[]\n",
    "    out['weighted avg']['precision']=[]\n",
    "\n",
    "    #Running Bootstrap on the test set\n",
    "    for b in tqdm(range(B)):\n",
    "        ind = np.random.choice(range(y_test.shape[0]),y_test.shape[0])\n",
    "        X_test_boot, y_test_boot = X_test[ind,:], y_test[ind]\n",
    "\n",
    "        y_pred=model.predict(X_test_boot)\n",
    "        \n",
    "        if nn:\n",
    "            y_pred=np.argmax(y_pred,axis=1)\n",
    "            report=classification_report(y_test_boot, y_pred, labels=[0, 1, 2, 3], output_dict=True)\n",
    "        else:\n",
    "            report=classification_report(y_test_boot, y_pred, labels=[0, 1, 2, 3], output_dict=True)\n",
    "\n",
    "        out['accuracy'].append(report['accuracy'])\n",
    "        out['macro avg']['f1-score'].append(report['macro avg']['f1-score'])\n",
    "        out['macro avg']['recall'].append(report['macro avg']['recall'])\n",
    "        out['macro avg']['precision'].append(report['macro avg']['precision'])\n",
    "        out['weighted avg']['f1-score'].append(report['weighted avg']['f1-score'])\n",
    "        out['weighted avg']['recall'].append(report['weighted avg']['recall'])\n",
    "        out['weighted avg']['precision'].append(report['weighted avg']['precision'])\n",
    "\n",
    "    #Preparing output\n",
    "    y_pred=model.predict(X_test)\n",
    "    \n",
    "    if nn:\n",
    "        y_pred=np.argmax(y_pred,axis=1)\n",
    "        report=classification_report(y_test, y_pred, labels=[0, 1, 2, 3], output_dict=True)\n",
    "    else:\n",
    "        report=classification_report(y_test, y_pred, labels=[0, 1, 2, 3], output_dict=True)\n",
    "\n",
    "    out['accuracy'] = [report['accuracy'], np.std(out['accuracy'])]\n",
    "    out['macro avg']['f1-score'] = [report['macro avg']['f1-score'], np.std(out['macro avg']['f1-score'])] \n",
    "    out['macro avg']['recall'] = [report['macro avg']['recall'], np.std(out['macro avg']['recall'])] \n",
    "    out['macro avg']['precision'] = [report['macro avg']['precision'], np.std(out['macro avg']['precision'])] \n",
    "    out['weighted avg']['f1-score'] = [report['weighted avg']['f1-score'], np.std(out['weighted avg']['f1-score'])] \n",
    "    out['weighted avg']['recall'] = [report['weighted avg']['recall'], np.std(out['weighted avg']['recall'])] \n",
    "    out['weighted avg']['precision'] = [report['weighted avg']['precision'], np.std(out['weighted avg']['precision'])]\n",
    "    \n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "cfb4b93c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                                                          | 0/250 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 11ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|▎                                                                                 | 1/250 [00:00<01:22,  3.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 11ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  1%|▋                                                                                 | 2/250 [00:00<01:21,  3.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 12ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  1%|▉                                                                                 | 3/250 [00:01<01:26,  2.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 11ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  2%|█▎                                                                                | 4/250 [00:01<01:24,  2.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 11ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  2%|█▋                                                                                | 5/250 [00:01<01:23,  2.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 11ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  2%|█▉                                                                                | 6/250 [00:02<01:26,  2.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 11ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  3%|██▎                                                                               | 7/250 [00:02<01:23,  2.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 11ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  3%|██▌                                                                               | 8/250 [00:02<01:21,  2.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 11ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  4%|██▉                                                                               | 9/250 [00:03<01:24,  2.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 11ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  4%|███▏                                                                             | 10/250 [00:03<01:22,  2.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 11ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  4%|███▌                                                                             | 11/250 [00:03<01:22,  2.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 11ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  5%|███▉                                                                             | 12/250 [00:04<01:22,  2.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 10ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  5%|████▏                                                                            | 13/250 [00:04<01:20,  2.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 11ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  6%|████▌                                                                            | 14/250 [00:04<01:18,  2.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 11ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  6%|████▊                                                                            | 15/250 [00:07<04:12,  1.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 12ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  6%|█████▏                                                                           | 16/250 [00:07<03:19,  1.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 11ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  7%|█████▌                                                                           | 17/250 [00:08<02:42,  1.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 10ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  7%|█████▊                                                                           | 18/250 [00:08<02:16,  1.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 11ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  8%|██████▏                                                                          | 19/250 [00:08<01:57,  1.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 11ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  8%|██████▍                                                                          | 20/250 [00:09<01:43,  2.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 10ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  8%|██████▊                                                                          | 21/250 [00:09<01:35,  2.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 13ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  9%|███████▏                                                                         | 22/250 [00:09<01:30,  2.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 11ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  9%|███████▍                                                                         | 23/250 [00:10<01:25,  2.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 10ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 10%|███████▊                                                                         | 24/250 [00:10<01:22,  2.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 13ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 10%|████████                                                                         | 25/250 [00:10<01:22,  2.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 11ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 10%|████████▍                                                                        | 26/250 [00:11<01:18,  2.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 11ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 11%|████████▋                                                                        | 27/250 [00:11<01:17,  2.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 13ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 11%|█████████                                                                        | 28/250 [00:11<01:17,  2.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 11ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 12%|█████████▍                                                                       | 29/250 [00:12<01:15,  2.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 11ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 12%|█████████▋                                                                       | 30/250 [00:12<01:14,  2.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 12ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 12%|██████████                                                                       | 31/250 [00:12<01:15,  2.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 11ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 13%|██████████▎                                                                      | 32/250 [00:13<01:13,  2.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 11ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 13%|██████████▋                                                                      | 33/250 [00:13<01:13,  2.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 12ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 14%|███████████                                                                      | 34/250 [00:13<01:13,  2.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 11ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 14%|███████████▎                                                                     | 35/250 [00:14<01:12,  2.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 11ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 14%|███████████▋                                                                     | 36/250 [00:14<01:12,  2.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 12ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 15%|███████████▉                                                                     | 37/250 [00:15<01:12,  2.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 10ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 15%|████████████▎                                                                    | 38/250 [00:15<01:10,  2.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 11ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 16%|████████████▋                                                                    | 39/250 [00:15<01:11,  2.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 12ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 16%|████████████▉                                                                    | 40/250 [00:16<01:12,  2.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 11ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 16%|█████████████▎                                                                   | 41/250 [00:16<01:10,  2.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 11ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 17%|█████████████▌                                                                   | 42/250 [00:16<01:11,  2.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 11ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 17%|█████████████▉                                                                   | 43/250 [00:17<01:11,  2.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 11ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 18%|██████████████▎                                                                  | 44/250 [00:17<01:09,  2.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 11ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 18%|██████████████▌                                                                  | 45/250 [00:17<01:09,  2.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 11ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 18%|██████████████▉                                                                  | 46/250 [00:18<01:09,  2.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 11ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 19%|███████████████▏                                                                 | 47/250 [00:18<01:08,  2.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 11ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 19%|███████████████▌                                                                 | 48/250 [00:18<01:08,  2.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 11ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 20%|███████████████▉                                                                 | 49/250 [00:19<01:07,  2.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 10ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 20%|████████████████▏                                                                | 50/250 [00:19<01:06,  3.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 12ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 20%|████████████████▌                                                                | 51/250 [00:19<01:07,  2.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 11ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 21%|████████████████▊                                                                | 52/250 [00:20<01:07,  2.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 11ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 21%|█████████████████▏                                                               | 53/250 [00:20<01:06,  2.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 11ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 22%|█████████████████▍                                                               | 54/250 [00:20<01:06,  2.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 11ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 22%|█████████████████▊                                                               | 55/250 [00:21<01:05,  2.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 11ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 22%|██████████████████▏                                                              | 56/250 [00:21<01:04,  3.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 11ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 23%|██████████████████▍                                                              | 57/250 [00:21<01:05,  2.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 11ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 23%|██████████████████▊                                                              | 58/250 [00:22<01:06,  2.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 11ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 24%|███████████████████                                                              | 59/250 [00:22<01:04,  2.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 11ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 24%|███████████████████▍                                                             | 60/250 [00:22<01:05,  2.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 11ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 24%|███████████████████▊                                                             | 61/250 [00:23<01:04,  2.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 11ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 25%|████████████████████                                                             | 62/250 [00:23<01:03,  2.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 12ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 25%|████████████████████▍                                                            | 63/250 [00:23<01:05,  2.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 11ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 26%|████████████████████▋                                                            | 64/250 [00:24<01:04,  2.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 11ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 26%|█████████████████████                                                            | 65/250 [00:24<01:04,  2.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 11ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 26%|█████████████████████▍                                                           | 66/250 [00:24<01:05,  2.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 11ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 27%|█████████████████████▋                                                           | 67/250 [00:25<01:03,  2.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 11ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 27%|██████████████████████                                                           | 68/250 [00:25<01:02,  2.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 12ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 28%|██████████████████████▎                                                          | 69/250 [00:25<01:04,  2.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 11ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 28%|██████████████████████▋                                                          | 70/250 [00:26<01:02,  2.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 11ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 28%|███████████████████████                                                          | 71/250 [00:26<01:01,  2.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 12ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 29%|███████████████████████▎                                                         | 72/250 [00:26<01:01,  2.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 11ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 29%|███████████████████████▋                                                         | 73/250 [00:27<01:00,  2.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 11ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 30%|███████████████████████▉                                                         | 74/250 [00:27<00:59,  2.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 13ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 30%|████████████████████████▎                                                        | 75/250 [00:28<01:01,  2.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 11ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 30%|████████████████████████▌                                                        | 76/250 [00:28<01:00,  2.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 11ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 31%|████████████████████████▉                                                        | 77/250 [00:28<00:58,  2.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 11ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 31%|█████████████████████████▎                                                       | 78/250 [00:29<00:59,  2.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 10ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 32%|█████████████████████████▌                                                       | 79/250 [00:29<00:57,  2.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 11ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 32%|█████████████████████████▉                                                       | 80/250 [00:29<00:57,  2.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 11ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 32%|██████████████████████████▏                                                      | 81/250 [00:30<00:58,  2.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 11ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 33%|██████████████████████████▌                                                      | 82/250 [00:30<00:58,  2.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 11ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 33%|██████████████████████████▉                                                      | 83/250 [00:30<00:58,  2.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 11ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 34%|███████████████████████████▏                                                     | 84/250 [00:31<00:59,  2.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 11ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 34%|███████████████████████████▌                                                     | 85/250 [00:31<00:57,  2.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 11ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 34%|███████████████████████████▊                                                     | 86/250 [00:31<00:56,  2.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 11ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 35%|████████████████████████████▏                                                    | 87/250 [00:32<00:57,  2.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 11ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 35%|████████████████████████████▌                                                    | 88/250 [00:32<00:55,  2.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 12ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 36%|████████████████████████████▊                                                    | 89/250 [00:32<00:55,  2.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 11ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 36%|█████████████████████████████▏                                                   | 90/250 [00:33<00:55,  2.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 11ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 36%|█████████████████████████████▍                                                   | 91/250 [00:33<00:55,  2.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 12ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 37%|█████████████████████████████▊                                                   | 92/250 [00:33<00:55,  2.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 11ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 37%|██████████████████████████████▏                                                  | 93/250 [00:34<00:54,  2.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 11ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 38%|██████████████████████████████▍                                                  | 94/250 [00:34<00:53,  2.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 14ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 38%|██████████████████████████████▊                                                  | 95/250 [00:35<00:55,  2.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 11ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 38%|███████████████████████████████                                                  | 96/250 [00:35<00:55,  2.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 11ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 39%|███████████████████████████████▍                                                 | 97/250 [00:35<00:53,  2.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 12ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 39%|███████████████████████████████▊                                                 | 98/250 [00:36<00:52,  2.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 11ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 40%|████████████████████████████████                                                 | 99/250 [00:36<00:52,  2.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 11ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 40%|████████████████████████████████                                                | 100/250 [00:36<00:52,  2.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 11ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 40%|████████████████████████████████▎                                               | 101/250 [00:37<00:51,  2.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 11ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 41%|████████████████████████████████▋                                               | 102/250 [00:37<00:51,  2.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 11ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 41%|████████████████████████████████▉                                               | 103/250 [00:37<00:50,  2.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 11ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 42%|█████████████████████████████████▎                                              | 104/250 [00:38<00:50,  2.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 12ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 42%|█████████████████████████████████▌                                              | 105/250 [00:38<00:51,  2.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 12ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 42%|█████████████████████████████████▉                                              | 106/250 [00:38<00:50,  2.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 11ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 43%|██████████████████████████████████▏                                             | 107/250 [00:39<00:49,  2.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 11ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 43%|██████████████████████████████████▌                                             | 108/250 [00:39<00:49,  2.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 12ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 44%|██████████████████████████████████▉                                             | 109/250 [00:39<00:49,  2.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 11ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 44%|███████████████████████████████████▏                                            | 110/250 [00:40<00:48,  2.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 11ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 44%|███████████████████████████████████▌                                            | 111/250 [00:40<00:48,  2.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 12ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 45%|███████████████████████████████████▊                                            | 112/250 [00:40<00:48,  2.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 12ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 45%|████████████████████████████████████▏                                           | 113/250 [00:41<00:47,  2.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 11ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 46%|████████████████████████████████████▍                                           | 114/250 [00:41<00:47,  2.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 12ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 46%|████████████████████████████████████▊                                           | 115/250 [00:41<00:46,  2.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 10ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 46%|█████████████████████████████████████                                           | 116/250 [00:42<00:45,  2.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 11ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 47%|█████████████████████████████████████▍                                          | 117/250 [00:42<00:45,  2.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 12ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 47%|█████████████████████████████████████▊                                          | 118/250 [00:42<00:44,  2.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 11ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 48%|██████████████████████████████████████                                          | 119/250 [00:43<00:44,  2.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 11ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 48%|██████████████████████████████████████▍                                         | 120/250 [00:43<00:44,  2.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 12ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 48%|██████████████████████████████████████▋                                         | 121/250 [00:43<00:44,  2.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 11ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 49%|███████████████████████████████████████                                         | 122/250 [00:44<00:43,  2.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 11ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 49%|███████████████████████████████████████▎                                        | 123/250 [00:44<00:42,  2.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 12ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 50%|███████████████████████████████████████▋                                        | 124/250 [00:44<00:43,  2.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 11ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 50%|████████████████████████████████████████                                        | 125/250 [00:45<00:42,  2.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 11ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 50%|████████████████████████████████████████▎                                       | 126/250 [00:45<00:43,  2.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 11ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 51%|████████████████████████████████████████▋                                       | 127/250 [00:46<00:42,  2.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 11ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 51%|████████████████████████████████████████▉                                       | 128/250 [00:46<00:42,  2.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 11ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 52%|█████████████████████████████████████████▎                                      | 129/250 [00:46<00:41,  2.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 11ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 52%|█████████████████████████████████████████▌                                      | 130/250 [00:47<00:41,  2.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 12ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 52%|█████████████████████████████████████████▉                                      | 131/250 [00:47<00:41,  2.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 11ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 53%|██████████████████████████████████████████▏                                     | 132/250 [00:47<00:40,  2.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 11ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 53%|██████████████████████████████████████████▌                                     | 133/250 [00:48<00:40,  2.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 11ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 54%|██████████████████████████████████████████▉                                     | 134/250 [00:48<00:40,  2.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 11ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 54%|███████████████████████████████████████████▏                                    | 135/250 [00:48<00:40,  2.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 10ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 54%|███████████████████████████████████████████▌                                    | 136/250 [00:49<00:39,  2.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 11ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 55%|███████████████████████████████████████████▊                                    | 137/250 [00:49<00:38,  2.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 11ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 55%|████████████████████████████████████████████▏                                   | 138/250 [00:49<00:38,  2.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 11ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 56%|████████████████████████████████████████████▍                                   | 139/250 [00:50<00:38,  2.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 11ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 56%|████████████████████████████████████████████▊                                   | 140/250 [00:50<00:37,  2.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 12ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 56%|█████████████████████████████████████████████                                   | 141/250 [00:50<00:38,  2.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 11ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 57%|█████████████████████████████████████████████▍                                  | 142/250 [00:51<00:37,  2.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 11ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 57%|█████████████████████████████████████████████▊                                  | 143/250 [00:51<00:36,  2.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 12ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 58%|██████████████████████████████████████████████                                  | 144/250 [00:51<00:37,  2.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 11ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 58%|██████████████████████████████████████████████▍                                 | 145/250 [00:52<00:36,  2.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 11ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 58%|██████████████████████████████████████████████▋                                 | 146/250 [00:52<00:35,  2.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 12ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 59%|███████████████████████████████████████████████                                 | 147/250 [00:53<00:36,  2.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 11ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 59%|███████████████████████████████████████████████▎                                | 148/250 [00:53<00:35,  2.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 11ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 60%|███████████████████████████████████████████████▋                                | 149/250 [00:53<00:34,  2.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 11ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 60%|████████████████████████████████████████████████                                | 150/250 [00:54<00:35,  2.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 11ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 60%|████████████████████████████████████████████████▎                               | 151/250 [00:54<00:34,  2.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 11ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 61%|████████████████████████████████████████████████▋                               | 152/250 [00:54<00:33,  2.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 11ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 61%|████████████████████████████████████████████████▉                               | 153/250 [00:55<00:34,  2.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 11ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 62%|█████████████████████████████████████████████████▎                              | 154/250 [00:55<00:33,  2.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 11ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 62%|█████████████████████████████████████████████████▌                              | 155/250 [00:55<00:32,  2.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 11ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 62%|█████████████████████████████████████████████████▉                              | 156/250 [00:56<00:32,  2.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 11ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 63%|██████████████████████████████████████████████████▏                             | 157/250 [00:56<00:32,  2.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 11ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 63%|██████████████████████████████████████████████████▌                             | 158/250 [00:56<00:31,  2.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 11ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 64%|██████████████████████████████████████████████████▉                             | 159/250 [00:57<00:31,  2.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 11ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 64%|███████████████████████████████████████████████████▏                            | 160/250 [00:57<00:30,  2.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 11ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 64%|███████████████████████████████████████████████████▌                            | 161/250 [00:57<00:30,  2.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 11ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 65%|███████████████████████████████████████████████████▊                            | 162/250 [00:58<00:30,  2.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 11ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 65%|████████████████████████████████████████████████████▏                           | 163/250 [00:58<00:29,  2.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 13ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 66%|████████████████████████████████████████████████████▍                           | 164/250 [00:58<00:29,  2.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 11ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 66%|████████████████████████████████████████████████████▊                           | 165/250 [00:59<00:29,  2.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 11ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 66%|█████████████████████████████████████████████████████                           | 166/250 [00:59<00:28,  2.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 12ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 67%|█████████████████████████████████████████████████████▍                          | 167/250 [00:59<00:28,  2.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 11ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 67%|█████████████████████████████████████████████████████▊                          | 168/250 [01:00<00:28,  2.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 11ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 68%|██████████████████████████████████████████████████████                          | 169/250 [01:00<00:27,  2.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 13ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 68%|██████████████████████████████████████████████████████▍                         | 170/250 [01:00<00:27,  2.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 12ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 68%|██████████████████████████████████████████████████████▋                         | 171/250 [01:01<00:28,  2.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 11ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 69%|███████████████████████████████████████████████████████                         | 172/250 [01:01<00:27,  2.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 13ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 69%|███████████████████████████████████████████████████████▎                        | 173/250 [01:02<00:27,  2.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 11ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 70%|███████████████████████████████████████████████████████▋                        | 174/250 [01:02<00:26,  2.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 11ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 70%|████████████████████████████████████████████████████████                        | 175/250 [01:02<00:25,  2.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 12ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 70%|████████████████████████████████████████████████████████▎                       | 176/250 [01:03<00:25,  2.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 11ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 71%|████████████████████████████████████████████████████████▋                       | 177/250 [01:03<00:25,  2.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 12ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 71%|████████████████████████████████████████████████████████▉                       | 178/250 [01:03<00:25,  2.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 11ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 72%|█████████████████████████████████████████████████████████▎                      | 179/250 [01:04<00:24,  2.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 11ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 72%|█████████████████████████████████████████████████████████▌                      | 180/250 [01:04<00:24,  2.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 11ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 72%|█████████████████████████████████████████████████████████▉                      | 181/250 [01:04<00:23,  2.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 12ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 73%|██████████████████████████████████████████████████████████▏                     | 182/250 [01:05<00:23,  2.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 11ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 73%|██████████████████████████████████████████████████████████▌                     | 183/250 [01:05<00:23,  2.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 11ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 74%|██████████████████████████████████████████████████████████▉                     | 184/250 [01:05<00:23,  2.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 12ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 74%|███████████████████████████████████████████████████████████▏                    | 185/250 [01:06<00:22,  2.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 11ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 74%|███████████████████████████████████████████████████████████▌                    | 186/250 [01:06<00:22,  2.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 12ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 75%|███████████████████████████████████████████████████████████▊                    | 187/250 [01:06<00:22,  2.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 11ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 75%|████████████████████████████████████████████████████████████▏                   | 188/250 [01:07<00:21,  2.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 11ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 76%|████████████████████████████████████████████████████████████▍                   | 189/250 [01:07<00:21,  2.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 12ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 76%|████████████████████████████████████████████████████████████▊                   | 190/250 [01:07<00:21,  2.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 10ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 76%|█████████████████████████████████████████████████████████████                   | 191/250 [01:08<00:20,  2.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 11ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 77%|█████████████████████████████████████████████████████████████▍                  | 192/250 [01:08<00:20,  2.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 12ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 77%|█████████████████████████████████████████████████████████████▊                  | 193/250 [01:09<00:19,  2.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 11ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 78%|██████████████████████████████████████████████████████████████                  | 194/250 [01:09<00:19,  2.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 11ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 78%|██████████████████████████████████████████████████████████████▍                 | 195/250 [01:09<00:19,  2.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 12ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 78%|██████████████████████████████████████████████████████████████▋                 | 196/250 [01:10<00:18,  2.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 11ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 79%|███████████████████████████████████████████████████████████████                 | 197/250 [01:10<00:18,  2.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 11ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 79%|███████████████████████████████████████████████████████████████▎                | 198/250 [01:10<00:18,  2.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 12ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 80%|███████████████████████████████████████████████████████████████▋                | 199/250 [01:11<00:17,  2.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 11ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 80%|████████████████████████████████████████████████████████████████                | 200/250 [01:11<00:17,  2.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 11ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 80%|████████████████████████████████████████████████████████████████▎               | 201/250 [01:11<00:16,  2.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 11ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 81%|████████████████████████████████████████████████████████████████▋               | 202/250 [01:12<00:16,  2.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 11ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 81%|████████████████████████████████████████████████████████████████▉               | 203/250 [01:12<00:15,  2.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 11ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 82%|█████████████████████████████████████████████████████████████████▎              | 204/250 [01:12<00:15,  2.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 11ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 82%|█████████████████████████████████████████████████████████████████▌              | 205/250 [01:13<00:15,  2.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 11ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 82%|█████████████████████████████████████████████████████████████████▉              | 206/250 [01:13<00:14,  2.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 11ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 83%|██████████████████████████████████████████████████████████████████▏             | 207/250 [01:13<00:14,  2.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 11ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 83%|██████████████████████████████████████████████████████████████████▌             | 208/250 [01:14<00:14,  2.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 11ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 84%|██████████████████████████████████████████████████████████████████▉             | 209/250 [01:14<00:13,  2.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 11ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 84%|███████████████████████████████████████████████████████████████████▏            | 210/250 [01:14<00:13,  2.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 11ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 84%|███████████████████████████████████████████████████████████████████▌            | 211/250 [01:15<00:13,  2.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 11ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 85%|███████████████████████████████████████████████████████████████████▊            | 212/250 [01:15<00:12,  2.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 12ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 85%|████████████████████████████████████████████████████████████████████▏           | 213/250 [01:15<00:12,  2.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 11ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 86%|████████████████████████████████████████████████████████████████████▍           | 214/250 [01:16<00:12,  2.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 11ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 86%|████████████████████████████████████████████████████████████████████▊           | 215/250 [01:16<00:11,  2.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 13ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 86%|█████████████████████████████████████████████████████████████████████           | 216/250 [01:16<00:12,  2.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 11ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 87%|█████████████████████████████████████████████████████████████████████▍          | 217/250 [01:17<00:11,  2.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 11ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 87%|█████████████████████████████████████████████████████████████████████▊          | 218/250 [01:17<00:10,  2.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 12ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 88%|██████████████████████████████████████████████████████████████████████          | 219/250 [01:17<00:10,  2.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 11ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 88%|██████████████████████████████████████████████████████████████████████▍         | 220/250 [01:18<00:10,  2.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 11ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 88%|██████████████████████████████████████████████████████████████████████▋         | 221/250 [01:18<00:09,  2.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 12ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 89%|███████████████████████████████████████████████████████████████████████         | 222/250 [01:18<00:09,  2.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 11ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 89%|███████████████████████████████████████████████████████████████████████▎        | 223/250 [01:19<00:09,  2.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 11ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 90%|███████████████████████████████████████████████████████████████████████▋        | 224/250 [01:19<00:08,  2.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 14ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 90%|████████████████████████████████████████████████████████████████████████        | 225/250 [01:20<00:09,  2.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 11ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 90%|████████████████████████████████████████████████████████████████████████▎       | 226/250 [01:20<00:08,  2.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 11ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 91%|████████████████████████████████████████████████████████████████████████▋       | 227/250 [01:20<00:08,  2.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 12ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 91%|████████████████████████████████████████████████████████████████████████▉       | 228/250 [01:21<00:07,  2.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 11ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 92%|█████████████████████████████████████████████████████████████████████████▎      | 229/250 [01:21<00:07,  2.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 11ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 92%|█████████████████████████████████████████████████████████████████████████▌      | 230/250 [01:21<00:06,  2.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 11ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 92%|█████████████████████████████████████████████████████████████████████████▉      | 231/250 [01:22<00:06,  2.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 11ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 93%|██████████████████████████████████████████████████████████████████████████▏     | 232/250 [01:22<00:06,  2.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 12ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 93%|██████████████████████████████████████████████████████████████████████████▌     | 233/250 [01:22<00:05,  2.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 11ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 94%|██████████████████████████████████████████████████████████████████████████▉     | 234/250 [01:23<00:05,  2.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 11ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 94%|███████████████████████████████████████████████████████████████████████████▏    | 235/250 [01:23<00:05,  2.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 12ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 94%|███████████████████████████████████████████████████████████████████████████▌    | 236/250 [01:23<00:04,  2.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 11ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 95%|███████████████████████████████████████████████████████████████████████████▊    | 237/250 [01:24<00:04,  2.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 11ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 95%|████████████████████████████████████████████████████████████████████████████▏   | 238/250 [01:24<00:04,  2.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 12ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 96%|████████████████████████████████████████████████████████████████████████████▍   | 239/250 [01:24<00:03,  2.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 11ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 96%|████████████████████████████████████████████████████████████████████████████▊   | 240/250 [01:25<00:03,  2.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 11ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 96%|█████████████████████████████████████████████████████████████████████████████   | 241/250 [01:25<00:03,  2.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 15ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 97%|█████████████████████████████████████████████████████████████████████████████▍  | 242/250 [01:26<00:02,  2.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 11ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 97%|█████████████████████████████████████████████████████████████████████████████▊  | 243/250 [01:26<00:02,  2.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 11ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 98%|██████████████████████████████████████████████████████████████████████████████  | 244/250 [01:26<00:02,  2.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 12ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 98%|██████████████████████████████████████████████████████████████████████████████▍ | 245/250 [01:27<00:01,  2.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 11ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 98%|██████████████████████████████████████████████████████████████████████████████▋ | 246/250 [01:27<00:01,  2.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 11ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 99%|███████████████████████████████████████████████████████████████████████████████ | 247/250 [01:27<00:01,  2.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 12ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 99%|███████████████████████████████████████████████████████████████████████████████▎| 248/250 [01:28<00:00,  2.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 11ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "100%|███████████████████████████████████████████████████████████████████████████████▋| 249/250 [01:28<00:00,  2.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 11ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 250/250 [01:28<00:00,  2.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 5/16 [========>.....................] - ETA: 0s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 12ms/step\n",
      "\n",
      "\n",
      "accuracy                   : 0.25 ± 0.02\n",
      "macro avg        f1-score  : 0.25 ± 0.02\n",
      "macro avg        recall    : 0.25 ± 0.02\n",
      "macro avg        precision : 0.25 ± 0.02\n",
      "weighted avg     f1-score  : 0.25 ± 0.02\n",
      "weighted avg     recall    : 0.25 ± 0.02\n",
      "weighted avg     precision : 0.25 ± 0.02\n"
     ]
    }
   ],
   "source": [
    "report_boot=bootstrap(np.array(X_test), np.array(y_test), Dcnn, nn = True)\n",
    "\n",
    "for i in ['accuracy', 'macro avg', 'weighted avg']:\n",
    "    if i == 'accuracy':\n",
    "        print(\"\\n\\n{:27}: {:.2f} ± {:.2f}\".format(i, report_boot[i][0], report_boot[i][1]))\n",
    "    for j in ['f1-score', 'recall', 'precision']:\n",
    "        if i != 'accuracy':\n",
    "            print(\"{:15}  {:10}: {:.2f} ± {:.2f}\".format(i, j, report_boot[i][j][0], report_boot[i][j][1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28279b5e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
