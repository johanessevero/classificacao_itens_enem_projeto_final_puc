{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "04f67161",
   "metadata": {},
   "outputs": [],
   "source": [
    "# importação das bilbiotecas\n",
    "#data\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "#plot\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#ml\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import tensorflow_datasets as tfds\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "#aux\n",
    "from IPython.display import clear_output\n",
    "import os\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "637a3568",
   "metadata": {},
   "source": [
    "## carregar dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db347796",
   "metadata": {},
   "source": [
    "### treinamento o word embbeding próprio treinado com skip-gram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fbda41d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the dataframe object from the pickle file\n",
    "with open(os.path.join('data', 'data_set_param_b_train.pkl'), 'rb') as f:\n",
    "    dataset = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4e05283b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tf_idf</th>\n",
       "      <th>wes</th>\n",
       "      <th>wes_own</th>\n",
       "      <th>classes_param_a_1</th>\n",
       "      <th>classes_param_b_1</th>\n",
       "      <th>classes_param_c_1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1757</th>\n",
       "      <td>[0.1520375028210196, 0.17699962659034899, 0.11...</td>\n",
       "      <td>[[-0.0024, -0.033, 0.0099, 0.0034, -0.1078, -0...</td>\n",
       "      <td>[[-0.15383221, 0.17914692, -0.010291061, 0.344...</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>573</th>\n",
       "      <td>[0.17117729139134427, 0.12149402947247992, 0.1...</td>\n",
       "      <td>[[-0.0312, -0.0228, 0.0538, 0.2069, -0.0707, -...</td>\n",
       "      <td>[[0.124431126, 0.1792577, 0.22388884, 0.179398...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>357</th>\n",
       "      <td>[0.056354022158337326, 0.0900773086241686, 0.0...</td>\n",
       "      <td>[[0.0087, -0.015, 0.073, 0.0244, -0.0139, -0.0...</td>\n",
       "      <td>[[-0.2735036, -0.19421376, 0.26711008, 0.26224...</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1874</th>\n",
       "      <td>[0.06280307748585236, 0.5022780351753088, 0.05...</td>\n",
       "      <td>[[0.0033, 0.0033, 0.0621, -0.0199, -0.0136, -0...</td>\n",
       "      <td>[[0.39825365, 0.03401856, -0.08328956, 0.15628...</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>952</th>\n",
       "      <td>[0.2162069029386577, 0.17003122409083568, 0.21...</td>\n",
       "      <td>[[0.0426, 0.0016, -0.0254, 0.0166, 0.0386, -0....</td>\n",
       "      <td>[[-0.1674651, -0.041456904, 0.089936934, 0.109...</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>469</th>\n",
       "      <td>[0.03344511075801128, 0.03344511075801128, 0.0...</td>\n",
       "      <td>[[-0.022, 0.0315, 0.0752, -0.0268, 0.0625, -0....</td>\n",
       "      <td>[[-0.20457007, 0.2068289, -0.22812223, 0.41948...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1523</th>\n",
       "      <td>[0.1444444525285251, 0.14320885524210786, 0.11...</td>\n",
       "      <td>[[-0.0176, 0.0149, 0.029, -0.018, 0.0394, -0.0...</td>\n",
       "      <td>[[0.15224683, -0.04294147, 0.23700559, 0.45965...</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>184</th>\n",
       "      <td>[0.07487472267235452, 0.08646331108472735, 0.0...</td>\n",
       "      <td>[[0.0392, 0.0332, 0.011, -0.0712, 0.1688, 0.10...</td>\n",
       "      <td>[[-0.613815, 0.052886456, 0.1884509, 0.3149106...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1623</th>\n",
       "      <td>[0.24468841743329098, 0.07221445715635107, 0.0...</td>\n",
       "      <td>[[0.0442, -0.087, 0.0251, 0.015, 0.0006, -0.09...</td>\n",
       "      <td>[[-0.18899466, 0.050661664, 0.13411203, 0.0431...</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1442</th>\n",
       "      <td>[0.11702273888350695, 0.09765272329520391, 0.0...</td>\n",
       "      <td>[[0.0286, 0.0005, -0.0008, 0.0068, 0.0196, -0....</td>\n",
       "      <td>[[-0.2550963, 0.29668498, 0.01296361, 0.290734...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1441 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 tf_idf  \\\n",
       "1757  [0.1520375028210196, 0.17699962659034899, 0.11...   \n",
       "573   [0.17117729139134427, 0.12149402947247992, 0.1...   \n",
       "357   [0.056354022158337326, 0.0900773086241686, 0.0...   \n",
       "1874  [0.06280307748585236, 0.5022780351753088, 0.05...   \n",
       "952   [0.2162069029386577, 0.17003122409083568, 0.21...   \n",
       "...                                                 ...   \n",
       "469   [0.03344511075801128, 0.03344511075801128, 0.0...   \n",
       "1523  [0.1444444525285251, 0.14320885524210786, 0.11...   \n",
       "184   [0.07487472267235452, 0.08646331108472735, 0.0...   \n",
       "1623  [0.24468841743329098, 0.07221445715635107, 0.0...   \n",
       "1442  [0.11702273888350695, 0.09765272329520391, 0.0...   \n",
       "\n",
       "                                                    wes  \\\n",
       "1757  [[-0.0024, -0.033, 0.0099, 0.0034, -0.1078, -0...   \n",
       "573   [[-0.0312, -0.0228, 0.0538, 0.2069, -0.0707, -...   \n",
       "357   [[0.0087, -0.015, 0.073, 0.0244, -0.0139, -0.0...   \n",
       "1874  [[0.0033, 0.0033, 0.0621, -0.0199, -0.0136, -0...   \n",
       "952   [[0.0426, 0.0016, -0.0254, 0.0166, 0.0386, -0....   \n",
       "...                                                 ...   \n",
       "469   [[-0.022, 0.0315, 0.0752, -0.0268, 0.0625, -0....   \n",
       "1523  [[-0.0176, 0.0149, 0.029, -0.018, 0.0394, -0.0...   \n",
       "184   [[0.0392, 0.0332, 0.011, -0.0712, 0.1688, 0.10...   \n",
       "1623  [[0.0442, -0.087, 0.0251, 0.015, 0.0006, -0.09...   \n",
       "1442  [[0.0286, 0.0005, -0.0008, 0.0068, 0.0196, -0....   \n",
       "\n",
       "                                                wes_own classes_param_a_1  \\\n",
       "1757  [[-0.15383221, 0.17914692, -0.010291061, 0.344...                 1   \n",
       "573   [[0.124431126, 0.1792577, 0.22388884, 0.179398...                 0   \n",
       "357   [[-0.2735036, -0.19421376, 0.26711008, 0.26224...                 2   \n",
       "1874  [[0.39825365, 0.03401856, -0.08328956, 0.15628...                 3   \n",
       "952   [[-0.1674651, -0.041456904, 0.089936934, 0.109...                 2   \n",
       "...                                                 ...               ...   \n",
       "469   [[-0.20457007, 0.2068289, -0.22812223, 0.41948...                 0   \n",
       "1523  [[0.15224683, -0.04294147, 0.23700559, 0.45965...                 2   \n",
       "184   [[-0.613815, 0.052886456, 0.1884509, 0.3149106...                 1   \n",
       "1623  [[-0.18899466, 0.050661664, 0.13411203, 0.0431...                 0   \n",
       "1442  [[-0.2550963, 0.29668498, 0.01296361, 0.290734...                 1   \n",
       "\n",
       "     classes_param_b_1 classes_param_c_1  \n",
       "1757                 2                 0  \n",
       "573                  1                 2  \n",
       "357                  0                 0  \n",
       "1874                 1                 3  \n",
       "952                  0                 3  \n",
       "...                ...               ...  \n",
       "469                  0                 0  \n",
       "1523                 3                 3  \n",
       "184                  0                 1  \n",
       "1623                 2                 2  \n",
       "1442                 1                 2  \n",
       "\n",
       "[1441 rows x 6 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "721b4ae4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#X = np.array([x.reshape(x.shape[0], -1, 300) for x in df.iloc[:, 0].values])\n",
    "X = dataset.iloc[:, 2].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cb42485b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(64, 100)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(X[51]).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2bcccf33",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[-0.015052611,\n",
       "  0.026005073,\n",
       "  0.08162173,\n",
       "  0.11108343,\n",
       "  -0.053565945,\n",
       "  -0.26356855,\n",
       "  0.05125048,\n",
       "  0.8140289,\n",
       "  0.34408334,\n",
       "  -0.18467052,\n",
       "  -0.06613437,\n",
       "  -0.18222493,\n",
       "  -0.12252722,\n",
       "  0.46490398,\n",
       "  -0.018289424,\n",
       "  -0.2921946,\n",
       "  0.26809135,\n",
       "  -0.041981168,\n",
       "  -0.07799694,\n",
       "  -0.5931647,\n",
       "  -0.022973813,\n",
       "  0.1528141,\n",
       "  -0.08289891,\n",
       "  -0.0029902053,\n",
       "  -0.3373523,\n",
       "  -0.08016596,\n",
       "  -0.25400162,\n",
       "  -0.5280474,\n",
       "  0.15532994,\n",
       "  -0.057525177,\n",
       "  0.09554777,\n",
       "  0.17367886,\n",
       "  0.07257081,\n",
       "  0.15022135,\n",
       "  -0.14133129,\n",
       "  0.3088258,\n",
       "  -0.21448472,\n",
       "  -0.39636645,\n",
       "  -0.18647645,\n",
       "  -0.6097174,\n",
       "  -0.047418516,\n",
       "  -0.12529854,\n",
       "  0.16262873,\n",
       "  -0.108832076,\n",
       "  0.12227581,\n",
       "  -0.1459426,\n",
       "  0.2121711,\n",
       "  -0.20516989,\n",
       "  0.083030574,\n",
       "  0.14703692,\n",
       "  0.13879547,\n",
       "  -0.4346314,\n",
       "  -0.23240884,\n",
       "  0.16148514,\n",
       "  -0.098046385,\n",
       "  0.122823745,\n",
       "  0.13832667,\n",
       "  -0.102091245,\n",
       "  0.270468,\n",
       "  0.12359094,\n",
       "  -0.034647964,\n",
       "  0.16906162,\n",
       "  0.26446798,\n",
       "  -0.10466301,\n",
       "  -0.44654068,\n",
       "  0.40565512,\n",
       "  -0.32945958,\n",
       "  0.10150338,\n",
       "  -0.3314024,\n",
       "  0.07007218,\n",
       "  -0.050751593,\n",
       "  0.10953683,\n",
       "  -0.002081462,\n",
       "  0.035312723,\n",
       "  0.1277536,\n",
       "  -0.106951654,\n",
       "  0.02124393,\n",
       "  -0.14475907,\n",
       "  -0.21347657,\n",
       "  0.24440214,\n",
       "  0.21594265,\n",
       "  0.27353245,\n",
       "  -0.17915593,\n",
       "  0.4522888,\n",
       "  -0.08831617,\n",
       "  0.11223477,\n",
       "  0.055302925,\n",
       "  0.13140434,\n",
       "  0.6344121,\n",
       "  0.55650055,\n",
       "  0.09806448,\n",
       "  -0.16629557,\n",
       "  0.10731517,\n",
       "  0.24067405,\n",
       "  0.4765172,\n",
       "  0.29773143,\n",
       "  0.17780834,\n",
       "  -0.107357055,\n",
       "  -0.06450597,\n",
       "  -0.033593368],\n",
       " [-0.60265213,\n",
       "  -0.020975737,\n",
       "  0.039546248,\n",
       "  0.05865323,\n",
       "  -0.42571923,\n",
       "  -0.64075655,\n",
       "  -0.19836816,\n",
       "  0.6324955,\n",
       "  0.21202327,\n",
       "  0.048182935,\n",
       "  -0.24337904,\n",
       "  -0.3342365,\n",
       "  0.28853783,\n",
       "  0.045862414,\n",
       "  -0.12108438,\n",
       "  0.12811014,\n",
       "  0.30562764,\n",
       "  -0.07090481,\n",
       "  -0.008301646,\n",
       "  -0.65115803,\n",
       "  0.17747897,\n",
       "  0.2992708,\n",
       "  -0.02960176,\n",
       "  -0.21757777,\n",
       "  -0.27235055,\n",
       "  -0.32339388,\n",
       "  -0.20129046,\n",
       "  -0.7251358,\n",
       "  -0.11133838,\n",
       "  -0.33450362,\n",
       "  0.028226025,\n",
       "  0.22796826,\n",
       "  0.8244923,\n",
       "  0.70316404,\n",
       "  0.21162473,\n",
       "  0.42310625,\n",
       "  -0.2907032,\n",
       "  -0.49897328,\n",
       "  -0.7322511,\n",
       "  -0.5724706,\n",
       "  0.09864091,\n",
       "  0.11979855,\n",
       "  -0.119768836,\n",
       "  -0.5351112,\n",
       "  0.27886316,\n",
       "  0.06809668,\n",
       "  0.031874698,\n",
       "  -0.06135889,\n",
       "  0.11287575,\n",
       "  -0.14213483,\n",
       "  0.35983527,\n",
       "  -0.70250565,\n",
       "  -0.53376687,\n",
       "  0.15249932,\n",
       "  -0.21159895,\n",
       "  0.34510913,\n",
       "  -0.052368857,\n",
       "  -0.44777295,\n",
       "  0.037917018,\n",
       "  0.49633622,\n",
       "  -0.40669137,\n",
       "  0.43991846,\n",
       "  -0.085871145,\n",
       "  0.09949213,\n",
       "  0.06953947,\n",
       "  0.109021276,\n",
       "  -0.60370135,\n",
       "  0.6557729,\n",
       "  -0.03182373,\n",
       "  0.21542387,\n",
       "  -0.28822702,\n",
       "  -0.022449872,\n",
       "  0.5461073,\n",
       "  -0.15775385,\n",
       "  0.2722089,\n",
       "  -0.43863547,\n",
       "  0.18564464,\n",
       "  -0.6528918,\n",
       "  -0.57427937,\n",
       "  0.20947203,\n",
       "  -0.16479689,\n",
       "  0.37019712,\n",
       "  -0.43574795,\n",
       "  0.76650983,\n",
       "  0.102181256,\n",
       "  0.3278265,\n",
       "  -0.34922433,\n",
       "  0.008152592,\n",
       "  0.64311457,\n",
       "  0.67613184,\n",
       "  0.53345895,\n",
       "  -0.010494821,\n",
       "  0.18938819,\n",
       "  0.011527376,\n",
       "  0.9564037,\n",
       "  -0.010991298,\n",
       "  0.034799423,\n",
       "  -0.66840744,\n",
       "  0.008625622,\n",
       "  0.5606001],\n",
       " [0.05219439,\n",
       "  0.08904299,\n",
       "  0.024534278,\n",
       "  0.39919177,\n",
       "  0.003061448,\n",
       "  -0.14717144,\n",
       "  0.019484548,\n",
       "  0.78371817,\n",
       "  0.20738073,\n",
       "  0.0018150177,\n",
       "  -0.26468056,\n",
       "  -0.31289735,\n",
       "  -0.19812703,\n",
       "  -0.03298616,\n",
       "  -0.14114715,\n",
       "  -0.3008829,\n",
       "  0.25466326,\n",
       "  -0.28716898,\n",
       "  0.43881217,\n",
       "  -0.17250077,\n",
       "  -0.16810845,\n",
       "  -0.25009108,\n",
       "  0.19075938,\n",
       "  -0.3599603,\n",
       "  -0.2756535,\n",
       "  -0.018778559,\n",
       "  -0.29174873,\n",
       "  -0.5353752,\n",
       "  -0.13034876,\n",
       "  0.11179379,\n",
       "  0.55567735,\n",
       "  0.083312325,\n",
       "  0.23302111,\n",
       "  0.33571598,\n",
       "  -0.04586931,\n",
       "  0.13913818,\n",
       "  0.10841325,\n",
       "  -0.07056405,\n",
       "  -0.32887992,\n",
       "  -0.4218882,\n",
       "  -0.04705423,\n",
       "  0.18865402,\n",
       "  0.44961458,\n",
       "  -0.3298707,\n",
       "  0.24541672,\n",
       "  -0.064053394,\n",
       "  0.17018381,\n",
       "  0.03834788,\n",
       "  0.06826896,\n",
       "  0.21588236,\n",
       "  0.15767288,\n",
       "  -0.4547127,\n",
       "  -0.16340268,\n",
       "  -0.15214379,\n",
       "  -0.13952084,\n",
       "  0.09927807,\n",
       "  0.047309354,\n",
       "  0.18964583,\n",
       "  -0.13860968,\n",
       "  -0.09837405,\n",
       "  -0.024321493,\n",
       "  0.14582175,\n",
       "  -0.012788662,\n",
       "  0.06987392,\n",
       "  -0.35494292,\n",
       "  -0.18807882,\n",
       "  -0.009957253,\n",
       "  0.1519025,\n",
       "  -0.26450413,\n",
       "  0.18163949,\n",
       "  0.00290832,\n",
       "  -0.22854182,\n",
       "  0.011052312,\n",
       "  0.27160648,\n",
       "  0.23002988,\n",
       "  -0.24354003,\n",
       "  -0.025833031,\n",
       "  0.0023825432,\n",
       "  -0.3402862,\n",
       "  -0.0012433702,\n",
       "  0.18852745,\n",
       "  -0.065011956,\n",
       "  -0.3468975,\n",
       "  0.24534546,\n",
       "  0.37464002,\n",
       "  -0.039504007,\n",
       "  0.2517889,\n",
       "  0.26989007,\n",
       "  0.2361294,\n",
       "  -0.080983214,\n",
       "  0.10174904,\n",
       "  -0.19171399,\n",
       "  -0.21985959,\n",
       "  0.17247866,\n",
       "  0.62263817,\n",
       "  0.2528405,\n",
       "  -0.026456587,\n",
       "  -0.35607708,\n",
       "  0.31440765,\n",
       "  0.0595029],\n",
       " [0.058137182,\n",
       "  0.6528325,\n",
       "  0.014911489,\n",
       "  0.08269347,\n",
       "  0.22170472,\n",
       "  -0.66479385,\n",
       "  0.2171203,\n",
       "  0.7120093,\n",
       "  -0.34397054,\n",
       "  -0.25977904,\n",
       "  -0.36702085,\n",
       "  -0.6001586,\n",
       "  0.24410394,\n",
       "  0.3545561,\n",
       "  0.21776861,\n",
       "  -0.51859164,\n",
       "  0.52156836,\n",
       "  -0.36034667,\n",
       "  -0.12001224,\n",
       "  -0.55809563,\n",
       "  -0.026141727,\n",
       "  0.10755857,\n",
       "  0.43571523,\n",
       "  -0.33488068,\n",
       "  -0.35522732,\n",
       "  0.635017,\n",
       "  -0.64744616,\n",
       "  -0.7881391,\n",
       "  0.043753512,\n",
       "  0.08180271,\n",
       "  0.32747918,\n",
       "  0.0021335257,\n",
       "  -0.03488568,\n",
       "  0.6619955,\n",
       "  -0.20822084,\n",
       "  0.30918887,\n",
       "  0.12162098,\n",
       "  0.31030306,\n",
       "  -0.23648961,\n",
       "  -0.918844,\n",
       "  0.2204519,\n",
       "  0.5402764,\n",
       "  0.57222474,\n",
       "  -0.36604744,\n",
       "  0.019634385,\n",
       "  -0.26268417,\n",
       "  0.30456054,\n",
       "  0.18475662,\n",
       "  0.25062707,\n",
       "  -0.22326817,\n",
       "  -0.31390864,\n",
       "  -0.3751336,\n",
       "  0.40089893,\n",
       "  -0.3330659,\n",
       "  -0.20959346,\n",
       "  -0.15416436,\n",
       "  0.3104093,\n",
       "  0.26782006,\n",
       "  -0.073448315,\n",
       "  0.34975848,\n",
       "  0.36897945,\n",
       "  -0.05148795,\n",
       "  0.0053605107,\n",
       "  0.48326614,\n",
       "  -0.3022022,\n",
       "  0.15574004,\n",
       "  0.00065832783,\n",
       "  0.009136707,\n",
       "  -0.41113934,\n",
       "  0.11232988,\n",
       "  0.05252545,\n",
       "  -0.009783746,\n",
       "  0.82165265,\n",
       "  0.064471684,\n",
       "  0.5105516,\n",
       "  0.06042225,\n",
       "  0.4202967,\n",
       "  0.024277125,\n",
       "  -0.09829487,\n",
       "  0.15431355,\n",
       "  0.22760879,\n",
       "  0.50099033,\n",
       "  -0.36302316,\n",
       "  0.15294793,\n",
       "  0.28430873,\n",
       "  -0.22259969,\n",
       "  0.14789894,\n",
       "  0.35368818,\n",
       "  0.12427015,\n",
       "  -0.006551659,\n",
       "  0.8813509,\n",
       "  0.24039301,\n",
       "  -0.0937061,\n",
       "  -0.4421767,\n",
       "  0.87205684,\n",
       "  0.013413445,\n",
       "  -0.00019059617,\n",
       "  -0.4810587,\n",
       "  0.25769794,\n",
       "  -0.25352025],\n",
       " [0.33006182,\n",
       "  0.08265074,\n",
       "  0.0863686,\n",
       "  0.14234176,\n",
       "  0.31877095,\n",
       "  -0.21460524,\n",
       "  0.29050046,\n",
       "  0.49230006,\n",
       "  0.0025720045,\n",
       "  -0.0430632,\n",
       "  -0.03962667,\n",
       "  -0.5079768,\n",
       "  -0.008197279,\n",
       "  0.17207448,\n",
       "  -0.0199641,\n",
       "  -0.08083754,\n",
       "  0.19357297,\n",
       "  -0.3801919,\n",
       "  0.048830867,\n",
       "  -0.31608704,\n",
       "  0.32637972,\n",
       "  0.026995854,\n",
       "  0.25707015,\n",
       "  -0.13334243,\n",
       "  -0.4668482,\n",
       "  0.07554069,\n",
       "  -0.32696378,\n",
       "  -0.28900546,\n",
       "  -0.36086324,\n",
       "  0.044613257,\n",
       "  0.28393734,\n",
       "  -0.17424093,\n",
       "  0.15653905,\n",
       "  0.0555608,\n",
       "  -0.019946728,\n",
       "  0.14860038,\n",
       "  -0.11164215,\n",
       "  -0.09303895,\n",
       "  -0.36605278,\n",
       "  -0.44988352,\n",
       "  -0.07914528,\n",
       "  -0.15914589,\n",
       "  -0.10318647,\n",
       "  0.19220904,\n",
       "  0.28798553,\n",
       "  0.0261109,\n",
       "  -0.13676369,\n",
       "  -0.25560114,\n",
       "  0.49164206,\n",
       "  0.21988137,\n",
       "  -0.032583926,\n",
       "  -0.06357531,\n",
       "  0.23444654,\n",
       "  -0.054364484,\n",
       "  -0.40305713,\n",
       "  -0.14384124,\n",
       "  0.19352408,\n",
       "  -0.11728626,\n",
       "  -0.18153268,\n",
       "  0.051932056,\n",
       "  0.023288695,\n",
       "  -0.11347665,\n",
       "  -0.05941905,\n",
       "  0.1179349,\n",
       "  -0.4703739,\n",
       "  0.2841548,\n",
       "  0.13047569,\n",
       "  0.33952853,\n",
       "  -0.34588775,\n",
       "  0.45666856,\n",
       "  -0.0144825475,\n",
       "  -0.046649445,\n",
       "  0.3586345,\n",
       "  0.30580917,\n",
       "  0.20014727,\n",
       "  -0.011253601,\n",
       "  0.1339791,\n",
       "  -0.13068289,\n",
       "  -0.14098449,\n",
       "  0.10612557,\n",
       "  0.037362207,\n",
       "  0.0049557816,\n",
       "  -0.2681392,\n",
       "  0.24928991,\n",
       "  0.14063002,\n",
       "  -0.2558681,\n",
       "  0.11136184,\n",
       "  0.30682746,\n",
       "  0.3578065,\n",
       "  0.0013702248,\n",
       "  0.47075504,\n",
       "  0.0698329,\n",
       "  0.1324005,\n",
       "  0.1371857,\n",
       "  0.43861392,\n",
       "  0.39986846,\n",
       "  -0.043656822,\n",
       "  -0.061585832,\n",
       "  0.09309915,\n",
       "  -0.20065594],\n",
       " [0.022928026,\n",
       "  0.03557612,\n",
       "  0.20414266,\n",
       "  0.1752098,\n",
       "  0.014518613,\n",
       "  -0.35887656,\n",
       "  0.19565359,\n",
       "  0.5188583,\n",
       "  -0.063977495,\n",
       "  -0.17197703,\n",
       "  -0.09207029,\n",
       "  -0.2958509,\n",
       "  -0.039690163,\n",
       "  0.21914887,\n",
       "  0.05907546,\n",
       "  -0.016328787,\n",
       "  0.23266846,\n",
       "  -0.24516232,\n",
       "  -0.19313456,\n",
       "  -0.5021864,\n",
       "  0.13863966,\n",
       "  0.34887546,\n",
       "  0.14431715,\n",
       "  -0.20434807,\n",
       "  -0.18903604,\n",
       "  0.14183521,\n",
       "  -0.3530866,\n",
       "  -0.1927377,\n",
       "  0.023782138,\n",
       "  0.124993205,\n",
       "  0.30165273,\n",
       "  0.13127261,\n",
       "  0.1094013,\n",
       "  -0.023657523,\n",
       "  -0.040720757,\n",
       "  0.29471785,\n",
       "  -0.21972333,\n",
       "  -0.2457936,\n",
       "  -0.34112728,\n",
       "  -0.5934362,\n",
       "  -0.023933148,\n",
       "  -0.100041814,\n",
       "  0.039746646,\n",
       "  -0.09930764,\n",
       "  0.22989596,\n",
       "  -0.24667157,\n",
       "  -0.2600234,\n",
       "  0.037193455,\n",
       "  0.35185516,\n",
       "  0.07634618,\n",
       "  0.050328303,\n",
       "  -0.22026604,\n",
       "  0.031947132,\n",
       "  0.03957528,\n",
       "  -0.20979032,\n",
       "  0.28249848,\n",
       "  0.16840033,\n",
       "  0.02617394,\n",
       "  -0.1856135,\n",
       "  0.26376867,\n",
       "  -0.094239146,\n",
       "  0.09417564,\n",
       "  0.033493135,\n",
       "  0.24713443,\n",
       "  -0.41295022,\n",
       "  0.2937478,\n",
       "  -0.268785,\n",
       "  0.015202322,\n",
       "  -0.331948,\n",
       "  0.06316648,\n",
       "  0.02758094,\n",
       "  0.043166008,\n",
       "  0.22460441,\n",
       "  -0.042554785,\n",
       "  0.31302625,\n",
       "  -0.07689582,\n",
       "  0.162268,\n",
       "  -0.20790301,\n",
       "  -0.17991905,\n",
       "  0.12768404,\n",
       "  -0.036856886,\n",
       "  0.15436874,\n",
       "  -0.14800529,\n",
       "  0.24463463,\n",
       "  0.068288274,\n",
       "  0.16441883,\n",
       "  0.009702263,\n",
       "  0.20206322,\n",
       "  0.6943125,\n",
       "  0.20991628,\n",
       "  0.35332164,\n",
       "  0.05881753,\n",
       "  0.057087384,\n",
       "  0.16287047,\n",
       "  0.27502206,\n",
       "  0.228284,\n",
       "  -0.00059682305,\n",
       "  -0.35054007,\n",
       "  0.21081786,\n",
       "  0.22901253],\n",
       " [0.089945875,\n",
       "  0.17338319,\n",
       "  0.012071338,\n",
       "  0.2336196,\n",
       "  0.089270554,\n",
       "  -0.30636644,\n",
       "  0.09158262,\n",
       "  0.6462983,\n",
       "  0.13841583,\n",
       "  0.0706868,\n",
       "  -0.30639794,\n",
       "  -0.211332,\n",
       "  -0.14370142,\n",
       "  -0.03779349,\n",
       "  -0.12914388,\n",
       "  -0.22619824,\n",
       "  -0.11180636,\n",
       "  -0.3742187,\n",
       "  0.17277662,\n",
       "  -0.23600449,\n",
       "  0.23968032,\n",
       "  -0.053945098,\n",
       "  0.13794637,\n",
       "  -0.17292088,\n",
       "  -0.3059929,\n",
       "  -0.019304989,\n",
       "  -0.22623162,\n",
       "  -0.5265648,\n",
       "  -0.18536596,\n",
       "  0.17724547,\n",
       "  0.3011692,\n",
       "  -0.07222239,\n",
       "  0.095888495,\n",
       "  -0.21582559,\n",
       "  0.0620218,\n",
       "  -0.010253123,\n",
       "  -0.08504406,\n",
       "  0.020904517,\n",
       "  -0.09041323,\n",
       "  -0.3811237,\n",
       "  0.16828951,\n",
       "  -0.23342742,\n",
       "  -0.1016894,\n",
       "  0.17469141,\n",
       "  0.057373576,\n",
       "  -0.3012167,\n",
       "  -0.16806999,\n",
       "  -0.19021298,\n",
       "  0.3616781,\n",
       "  0.1404712,\n",
       "  0.21961087,\n",
       "  -0.32498354,\n",
       "  0.14650074,\n",
       "  -0.09659515,\n",
       "  -0.24497743,\n",
       "  0.31006855,\n",
       "  0.1302968,\n",
       "  -0.013120756,\n",
       "  -0.18675849,\n",
       "  0.07590991,\n",
       "  0.011611605,\n",
       "  0.14323664,\n",
       "  -0.13719432,\n",
       "  0.13256924,\n",
       "  -0.25617528,\n",
       "  0.22542885,\n",
       "  0.07734113,\n",
       "  0.16860911,\n",
       "  -0.5024433,\n",
       "  0.2111374,\n",
       "  -0.07533855,\n",
       "  -0.036666602,\n",
       "  0.085764036,\n",
       "  0.18676192,\n",
       "  0.09452866,\n",
       "  0.041470785,\n",
       "  -0.026881395,\n",
       "  -0.15816927,\n",
       "  -0.1562666,\n",
       "  -0.015412177,\n",
       "  -0.06271404,\n",
       "  -0.15255862,\n",
       "  -0.07726222,\n",
       "  0.14142819,\n",
       "  -0.031600967,\n",
       "  -0.043942995,\n",
       "  -0.16297175,\n",
       "  0.29015833,\n",
       "  0.55281645,\n",
       "  0.015225428,\n",
       "  0.3356114,\n",
       "  -0.09395363,\n",
       "  -0.090729676,\n",
       "  -0.0602512,\n",
       "  0.10119928,\n",
       "  0.3273477,\n",
       "  -0.055516154,\n",
       "  -0.30161765,\n",
       "  0.1556201,\n",
       "  0.08013692],\n",
       " [-0.52921665,\n",
       "  0.42257765,\n",
       "  0.12753987,\n",
       "  0.012122203,\n",
       "  0.004380224,\n",
       "  -0.15083499,\n",
       "  -0.123021014,\n",
       "  0.2284533,\n",
       "  -0.16439061,\n",
       "  -0.22729495,\n",
       "  0.0036093218,\n",
       "  -0.48620802,\n",
       "  -0.17307395,\n",
       "  0.12789781,\n",
       "  0.08560395,\n",
       "  -0.33251366,\n",
       "  0.62550026,\n",
       "  -0.078210935,\n",
       "  -0.039413143,\n",
       "  -0.334918,\n",
       "  0.0056057675,\n",
       "  -0.118353054,\n",
       "  0.33063117,\n",
       "  0.009904495,\n",
       "  -0.42764527,\n",
       "  -0.031576756,\n",
       "  -0.41950947,\n",
       "  -0.20243838,\n",
       "  -0.12148061,\n",
       "  -0.13441773,\n",
       "  0.35880762,\n",
       "  0.0021006174,\n",
       "  0.025347194,\n",
       "  0.2590557,\n",
       "  0.10837722,\n",
       "  0.28486896,\n",
       "  0.111339,\n",
       "  -0.16965167,\n",
       "  -0.36278814,\n",
       "  -0.3679535,\n",
       "  -0.13483974,\n",
       "  0.0485764,\n",
       "  0.112000205,\n",
       "  -0.14428665,\n",
       "  0.06645057,\n",
       "  -0.0469771,\n",
       "  -0.05804466,\n",
       "  0.033991173,\n",
       "  0.19206949,\n",
       "  0.060797546,\n",
       "  0.15707767,\n",
       "  -0.3391115,\n",
       "  0.13138814,\n",
       "  0.087342545,\n",
       "  -0.44856486,\n",
       "  0.32661742,\n",
       "  0.04523314,\n",
       "  -0.18136209,\n",
       "  -0.22229226,\n",
       "  0.17378421,\n",
       "  0.038503643,\n",
       "  0.031036556,\n",
       "  0.08037329,\n",
       "  0.07715193,\n",
       "  -0.22305831,\n",
       "  0.5353195,\n",
       "  -0.36049291,\n",
       "  0.20230721,\n",
       "  -0.3361808,\n",
       "  0.31177184,\n",
       "  -0.1728437,\n",
       "  0.06343153,\n",
       "  0.22765265,\n",
       "  0.20439559,\n",
       "  0.15055747,\n",
       "  0.09940543,\n",
       "  -0.16433781,\n",
       "  0.025956571,\n",
       "  -0.021388888,\n",
       "  -0.15756942,\n",
       "  -0.037494924,\n",
       "  -0.21396653,\n",
       "  -0.22727184,\n",
       "  0.06864244,\n",
       "  0.21973833,\n",
       "  0.19391748,\n",
       "  0.11996964,\n",
       "  0.008162012,\n",
       "  0.4181182,\n",
       "  0.15089008,\n",
       "  0.068227984,\n",
       "  0.06441254,\n",
       "  0.03259793,\n",
       "  0.19629847,\n",
       "  0.69207674,\n",
       "  0.058373395,\n",
       "  -0.072616555,\n",
       "  -0.33007267,\n",
       "  -0.008593038,\n",
       "  0.08949718],\n",
       " [-0.05074387,\n",
       "  0.11291335,\n",
       "  0.038319625,\n",
       "  0.12939799,\n",
       "  0.017672133,\n",
       "  -0.15591723,\n",
       "  0.06166457,\n",
       "  0.2665779,\n",
       "  0.027113631,\n",
       "  -0.059127826,\n",
       "  -0.10623134,\n",
       "  -0.12913288,\n",
       "  -0.03914214,\n",
       "  0.06645686,\n",
       "  -0.012719826,\n",
       "  -0.07665111,\n",
       "  0.04232754,\n",
       "  -0.09550997,\n",
       "  0.013195176,\n",
       "  -0.16849586,\n",
       "  0.024545873,\n",
       "  0.023002416,\n",
       "  0.048621845,\n",
       "  -0.04643546,\n",
       "  -0.033646632,\n",
       "  -0.0014833835,\n",
       "  -0.14478073,\n",
       "  -0.14407307,\n",
       "  -0.045060106,\n",
       "  0.03442708,\n",
       "  0.20439821,\n",
       "  0.039600223,\n",
       "  -0.0034393622,\n",
       "  -0.038804796,\n",
       "  0.006570417,\n",
       "  0.0862719,\n",
       "  0.019080494,\n",
       "  -0.09583716,\n",
       "  -0.063011646,\n",
       "  -0.1893541,\n",
       "  0.018424561,\n",
       "  -0.13986674,\n",
       "  -0.009890677,\n",
       "  -0.05063114,\n",
       "  0.084878765,\n",
       "  -0.041078802,\n",
       "  -0.06806249,\n",
       "  0.03406617,\n",
       "  0.079405434,\n",
       "  0.07507253,\n",
       "  0.12930083,\n",
       "  -0.117186286,\n",
       "  -0.0070624235,\n",
       "  0.016225591,\n",
       "  -0.10155426,\n",
       "  0.085023195,\n",
       "  0.11538105,\n",
       "  -0.047831025,\n",
       "  -0.08747243,\n",
       "  -0.019936822,\n",
       "  0.07941203,\n",
       "  0.02096544,\n",
       "  -0.050099276,\n",
       "  0.067445524,\n",
       "  -0.13123678,\n",
       "  0.032699052,\n",
       "  -9.204519e-05,\n",
       "  0.06801021,\n",
       "  -0.13177948,\n",
       "  0.19037656,\n",
       "  -0.045605287,\n",
       "  -0.022796845,\n",
       "  0.087135516,\n",
       "  0.033816174,\n",
       "  0.07905093,\n",
       "  0.053380754,\n",
       "  -0.027779978,\n",
       "  -0.019739347,\n",
       "  0.00038100348,\n",
       "  -0.014490799,\n",
       "  -0.02258859,\n",
       "  -0.030474255,\n",
       "  -0.074506395,\n",
       "  0.14084084,\n",
       "  0.0032063676,\n",
       "  0.011888088,\n",
       "  -0.031726684,\n",
       "  0.065942824,\n",
       "  0.20666005,\n",
       "  0.08464287,\n",
       "  0.08132763,\n",
       "  0.022847245,\n",
       "  -0.013435133,\n",
       "  0.044108767,\n",
       "  0.14750786,\n",
       "  0.13133937,\n",
       "  -0.013450841,\n",
       "  -0.17478968,\n",
       "  0.02670203,\n",
       "  0.031199273],\n",
       " [-0.027697476,\n",
       "  0.21988499,\n",
       "  0.044734363,\n",
       "  0.23895398,\n",
       "  0.04949587,\n",
       "  -0.26717278,\n",
       "  0.13633758,\n",
       "  0.4943387,\n",
       "  0.13022009,\n",
       "  0.010748303,\n",
       "  -0.29695898,\n",
       "  -0.17459196,\n",
       "  -0.09237035,\n",
       "  -0.010841796,\n",
       "  -0.035161465,\n",
       "  -0.18494578,\n",
       "  -0.020165322,\n",
       "  -0.25144118,\n",
       "  0.060797587,\n",
       "  -0.21672614,\n",
       "  0.10520067,\n",
       "  0.0014087142,\n",
       "  0.034915984,\n",
       "  -0.13180883,\n",
       "  -0.084636234,\n",
       "  -0.026320988,\n",
       "  -0.23119779,\n",
       "  -0.31806514,\n",
       "  -0.15424633,\n",
       "  0.123807065,\n",
       "  0.36507747,\n",
       "  0.0080011515,\n",
       "  -0.03166216,\n",
       "  -0.15550514,\n",
       "  0.028096147,\n",
       "  0.047681622,\n",
       "  0.06214238,\n",
       "  -0.10037656,\n",
       "  -0.046729784,\n",
       "  -0.33782637,\n",
       "  0.06467094,\n",
       "  -0.25460842,\n",
       "  -0.109917,\n",
       "  0.060204633,\n",
       "  0.077553265,\n",
       "  -0.164729,\n",
       "  -0.10007998,\n",
       "  -0.0010404647,\n",
       "  0.16672161,\n",
       "  0.15897311,\n",
       "  0.25320762,\n",
       "  -0.24521986,\n",
       "  0.059091117,\n",
       "  -0.065928385,\n",
       "  -0.17969693,\n",
       "  0.21078439,\n",
       "  0.20142823,\n",
       "  -0.0076962803,\n",
       "  -0.17119214,\n",
       "  -0.016252447,\n",
       "  0.058563218,\n",
       "  0.0329145,\n",
       "  -0.13144557,\n",
       "  0.092526786,\n",
       "  -0.20974347,\n",
       "  0.11059526,\n",
       "  0.113725916,\n",
       "  0.12271969,\n",
       "  -0.30221465,\n",
       "  0.31432793,\n",
       "  -0.10999759,\n",
       "  -0.050978012,\n",
       "  0.117461786,\n",
       "  0.09752909,\n",
       "  0.10401191,\n",
       "  0.14828451,\n",
       "  -0.09449157,\n",
       "  -0.0715471,\n",
       "  -0.05490225,\n",
       "  -0.09070656,\n",
       "  -0.06632921,\n",
       "  -0.09695676,\n",
       "  -0.05918037,\n",
       "  0.18297662,\n",
       "  -0.0066298186,\n",
       "  -0.066320896,\n",
       "  -0.09415866,\n",
       "  0.13209349,\n",
       "  0.34684053,\n",
       "  0.09294041,\n",
       "  0.18611003,\n",
       "  -0.042134847,\n",
       "  -0.06305967,\n",
       "  -0.014693754,\n",
       "  0.20152433,\n",
       "  0.24572684,\n",
       "  -0.03375009,\n",
       "  -0.24282855,\n",
       "  0.051257383,\n",
       "  0.01862036],\n",
       " [-0.42689174,\n",
       "  0.3942135,\n",
       "  -0.10448852,\n",
       "  0.06735074,\n",
       "  0.100495145,\n",
       "  0.012741374,\n",
       "  0.06429539,\n",
       "  0.3869658,\n",
       "  0.30572197,\n",
       "  -0.51326466,\n",
       "  0.24533242,\n",
       "  -0.374345,\n",
       "  -0.18997514,\n",
       "  -0.023294814,\n",
       "  -0.15513779,\n",
       "  -0.54140127,\n",
       "  -0.105778374,\n",
       "  -0.09106345,\n",
       "  0.16697107,\n",
       "  -0.28292194,\n",
       "  0.05125628,\n",
       "  -0.34171882,\n",
       "  0.209564,\n",
       "  0.38184884,\n",
       "  -0.18959501,\n",
       "  -0.10260736,\n",
       "  -0.2555319,\n",
       "  -0.24474838,\n",
       "  -0.14003824,\n",
       "  -0.11338945,\n",
       "  0.14649738,\n",
       "  -0.072223976,\n",
       "  0.104480535,\n",
       "  -0.1088232,\n",
       "  0.073115215,\n",
       "  0.12972745,\n",
       "  0.00020468827,\n",
       "  -0.43967223,\n",
       "  -0.16219258,\n",
       "  -0.28299156,\n",
       "  -0.077400796,\n",
       "  -0.62029076,\n",
       "  0.22840631,\n",
       "  0.13239324,\n",
       "  0.41127324,\n",
       "  0.27876067,\n",
       "  0.11206631,\n",
       "  0.09550634,\n",
       "  -0.041362125,\n",
       "  0.018239353,\n",
       "  0.3972159,\n",
       "  -0.21677229,\n",
       "  -0.20225422,\n",
       "  0.17460652,\n",
       "  -0.30158898,\n",
       "  0.13144086,\n",
       "  0.49877444,\n",
       "  -0.50963116,\n",
       "  0.15059139,\n",
       "  -0.5448115,\n",
       "  0.19998704,\n",
       "  0.12488014,\n",
       "  -0.11733059,\n",
       "  -0.20729868,\n",
       "  -0.39931,\n",
       "  0.1270542,\n",
       "  0.017702855,\n",
       "  0.17024021,\n",
       "  -0.5668566,\n",
       "  0.71663296,\n",
       "  -0.4298546,\n",
       "  0.016674805,\n",
       "  0.085163645,\n",
       "  0.3697978,\n",
       "  0.16999955,\n",
       "  0.61326927,\n",
       "  -0.5327887,\n",
       "  0.27765855,\n",
       "  -0.049724597,\n",
       "  -0.008336783,\n",
       "  0.1077896,\n",
       "  -0.038905133,\n",
       "  -0.38392958,\n",
       "  0.24337445,\n",
       "  0.15800858,\n",
       "  0.2501877,\n",
       "  0.12312266,\n",
       "  0.20538224,\n",
       "  0.47573638,\n",
       "  0.38717115,\n",
       "  -0.3834111,\n",
       "  0.2034437,\n",
       "  -0.33338687,\n",
       "  0.3251314,\n",
       "  0.58106005,\n",
       "  0.2472197,\n",
       "  -0.1904773,\n",
       "  0.087318964,\n",
       "  -0.32427755,\n",
       "  0.008358457],\n",
       " [-0.10184931,\n",
       "  0.15921463,\n",
       "  0.055266358,\n",
       "  0.18287359,\n",
       "  0.04075872,\n",
       "  -0.21280293,\n",
       "  0.05874612,\n",
       "  0.40235275,\n",
       "  0.08406835,\n",
       "  -0.11308103,\n",
       "  -0.10724286,\n",
       "  -0.22738534,\n",
       "  -0.097868346,\n",
       "  0.08564199,\n",
       "  0.019518808,\n",
       "  -0.12652266,\n",
       "  0.14918302,\n",
       "  -0.15386885,\n",
       "  0.029816197,\n",
       "  -0.23660737,\n",
       "  0.041178133,\n",
       "  -0.0015984986,\n",
       "  0.08408637,\n",
       "  -0.023685269,\n",
       "  -0.055629276,\n",
       "  -0.014996525,\n",
       "  -0.24059378,\n",
       "  -0.19755594,\n",
       "  -0.05637302,\n",
       "  0.039213367,\n",
       "  0.3066712,\n",
       "  0.057502434,\n",
       "  -0.02304128,\n",
       "  0.013296092,\n",
       "  -0.018625038,\n",
       "  0.13069758,\n",
       "  0.028310217,\n",
       "  -0.21719973,\n",
       "  -0.113201834,\n",
       "  -0.2758184,\n",
       "  0.016651276,\n",
       "  -0.19355369,\n",
       "  0.113033466,\n",
       "  -0.09712891,\n",
       "  0.14689118,\n",
       "  0.01350908,\n",
       "  -0.056297883,\n",
       "  0.0870093,\n",
       "  0.060457237,\n",
       "  0.12108589,\n",
       "  0.2084903,\n",
       "  -0.20824993,\n",
       "  -0.056824815,\n",
       "  0.022098111,\n",
       "  -0.19269368,\n",
       "  0.09698888,\n",
       "  0.1969695,\n",
       "  -0.052976612,\n",
       "  -0.08302353,\n",
       "  -0.06149473,\n",
       "  0.06767528,\n",
       "  0.0872391,\n",
       "  -0.044159003,\n",
       "  0.0678102,\n",
       "  -0.21514042,\n",
       "  0.056767777,\n",
       "  0.0005216043,\n",
       "  0.10111504,\n",
       "  -0.21112925,\n",
       "  0.26969138,\n",
       "  -0.114022635,\n",
       "  -0.03419273,\n",
       "  0.110978216,\n",
       "  0.046527144,\n",
       "  0.15803725,\n",
       "  0.06155638,\n",
       "  -0.09044034,\n",
       "  -0.03370027,\n",
       "  -0.021763742,\n",
       "  -0.009172507,\n",
       "  -0.009411796,\n",
       "  -0.05824882,\n",
       "  -0.17508747,\n",
       "  0.2288705,\n",
       "  0.0646149,\n",
       "  0.08187,\n",
       "  -0.024728611,\n",
       "  0.11613122,\n",
       "  0.33119777,\n",
       "  0.15674172,\n",
       "  0.06622395,\n",
       "  0.03515985,\n",
       "  -0.018072136,\n",
       "  0.10040283,\n",
       "  0.30436274,\n",
       "  0.20787463,\n",
       "  -0.006408958,\n",
       "  -0.23179288,\n",
       "  0.08482385,\n",
       "  0.033728085],\n",
       " [-0.07801837,\n",
       "  0.09658209,\n",
       "  0.035402924,\n",
       "  0.105066195,\n",
       "  0.0012267116,\n",
       "  -0.1249354,\n",
       "  0.053000752,\n",
       "  0.24744259,\n",
       "  0.06364161,\n",
       "  -0.068954214,\n",
       "  -0.08894651,\n",
       "  -0.09938409,\n",
       "  -0.06577249,\n",
       "  0.043129604,\n",
       "  -0.0043578027,\n",
       "  -0.08747775,\n",
       "  0.038972426,\n",
       "  -0.096698955,\n",
       "  0.026879271,\n",
       "  -0.13204157,\n",
       "  0.0008860738,\n",
       "  -0.013263276,\n",
       "  0.043812614,\n",
       "  -0.028466193,\n",
       "  0.0050153313,\n",
       "  -0.011304162,\n",
       "  -0.111271694,\n",
       "  -0.13154173,\n",
       "  -0.057549294,\n",
       "  0.030134732,\n",
       "  0.20706737,\n",
       "  0.036636926,\n",
       "  -0.020120751,\n",
       "  -0.022178425,\n",
       "  0.011629613,\n",
       "  0.060762156,\n",
       "  0.040349413,\n",
       "  -0.11129184,\n",
       "  -0.05812773,\n",
       "  -0.17432822,\n",
       "  -0.0008486038,\n",
       "  -0.13482387,\n",
       "  0.0192384,\n",
       "  -0.07449014,\n",
       "  0.086267926,\n",
       "  -0.009106197,\n",
       "  -0.03373386,\n",
       "  0.043657776,\n",
       "  0.047199924,\n",
       "  0.08130121,\n",
       "  0.14397968,\n",
       "  -0.12489019,\n",
       "  -0.028160727,\n",
       "  0.0075829346,\n",
       "  -0.10829127,\n",
       "  0.079888776,\n",
       "  0.112834364,\n",
       "  -0.033570055,\n",
       "  -0.08827743,\n",
       "  -0.054240778,\n",
       "  0.068739265,\n",
       "  0.037338395,\n",
       "  -0.050883833,\n",
       "  0.04116618,\n",
       "  -0.1022368,\n",
       "  0.020602114,\n",
       "  0.005644519,\n",
       "  0.06606928,\n",
       "  -0.13678603,\n",
       "  0.18129116,\n",
       "  -0.057071637,\n",
       "  -0.033892184,\n",
       "  0.046031043,\n",
       "  0.043364096,\n",
       "  0.058444843,\n",
       "  0.048612088,\n",
       "  -0.074892156,\n",
       "  -0.015595411,\n",
       "  -0.00031586207,\n",
       "  -0.016060628,\n",
       "  -0.009868142,\n",
       "  -0.041562434,\n",
       "  -0.08609038,\n",
       "  0.14382559,\n",
       "  0.015014561,\n",
       "  0.0016729842,\n",
       "  -0.010596148,\n",
       "  0.055968817,\n",
       "  0.16758564,\n",
       "  0.0758862,\n",
       "  0.048530653,\n",
       "  0.0011511389,\n",
       "  -0.03273251,\n",
       "  0.051252097,\n",
       "  0.16226692,\n",
       "  0.11414942,\n",
       "  -0.015500012,\n",
       "  -0.14981551,\n",
       "  0.033924863,\n",
       "  0.033508833],\n",
       " [0.022928026,\n",
       "  0.03557612,\n",
       "  0.20414266,\n",
       "  0.1752098,\n",
       "  0.014518613,\n",
       "  -0.35887656,\n",
       "  0.19565359,\n",
       "  0.5188583,\n",
       "  -0.063977495,\n",
       "  -0.17197703,\n",
       "  -0.09207029,\n",
       "  -0.2958509,\n",
       "  -0.039690163,\n",
       "  0.21914887,\n",
       "  0.05907546,\n",
       "  -0.016328787,\n",
       "  0.23266846,\n",
       "  -0.24516232,\n",
       "  -0.19313456,\n",
       "  -0.5021864,\n",
       "  0.13863966,\n",
       "  0.34887546,\n",
       "  0.14431715,\n",
       "  -0.20434807,\n",
       "  -0.18903604,\n",
       "  0.14183521,\n",
       "  -0.3530866,\n",
       "  -0.1927377,\n",
       "  0.023782138,\n",
       "  0.124993205,\n",
       "  0.30165273,\n",
       "  0.13127261,\n",
       "  0.1094013,\n",
       "  -0.023657523,\n",
       "  -0.040720757,\n",
       "  0.29471785,\n",
       "  -0.21972333,\n",
       "  -0.2457936,\n",
       "  -0.34112728,\n",
       "  -0.5934362,\n",
       "  -0.023933148,\n",
       "  -0.100041814,\n",
       "  0.039746646,\n",
       "  -0.09930764,\n",
       "  0.22989596,\n",
       "  -0.24667157,\n",
       "  -0.2600234,\n",
       "  0.037193455,\n",
       "  0.35185516,\n",
       "  0.07634618,\n",
       "  0.050328303,\n",
       "  -0.22026604,\n",
       "  0.031947132,\n",
       "  0.03957528,\n",
       "  -0.20979032,\n",
       "  0.28249848,\n",
       "  0.16840033,\n",
       "  0.02617394,\n",
       "  -0.1856135,\n",
       "  0.26376867,\n",
       "  -0.094239146,\n",
       "  0.09417564,\n",
       "  0.033493135,\n",
       "  0.24713443,\n",
       "  -0.41295022,\n",
       "  0.2937478,\n",
       "  -0.268785,\n",
       "  0.015202322,\n",
       "  -0.331948,\n",
       "  0.06316648,\n",
       "  0.02758094,\n",
       "  0.043166008,\n",
       "  0.22460441,\n",
       "  -0.042554785,\n",
       "  0.31302625,\n",
       "  -0.07689582,\n",
       "  0.162268,\n",
       "  -0.20790301,\n",
       "  -0.17991905,\n",
       "  0.12768404,\n",
       "  -0.036856886,\n",
       "  0.15436874,\n",
       "  -0.14800529,\n",
       "  0.24463463,\n",
       "  0.068288274,\n",
       "  0.16441883,\n",
       "  0.009702263,\n",
       "  0.20206322,\n",
       "  0.6943125,\n",
       "  0.20991628,\n",
       "  0.35332164,\n",
       "  0.05881753,\n",
       "  0.057087384,\n",
       "  0.16287047,\n",
       "  0.27502206,\n",
       "  0.228284,\n",
       "  -0.00059682305,\n",
       "  -0.35054007,\n",
       "  0.21081786,\n",
       "  0.22901253],\n",
       " [-0.07738264,\n",
       "  0.10534935,\n",
       "  0.029960634,\n",
       "  0.126602,\n",
       "  -0.008686871,\n",
       "  -0.13257644,\n",
       "  0.06944054,\n",
       "  0.21962896,\n",
       "  0.031819668,\n",
       "  -0.05433757,\n",
       "  -0.08113021,\n",
       "  -0.10684115,\n",
       "  -0.0501426,\n",
       "  0.063374706,\n",
       "  -0.003013817,\n",
       "  -0.05835349,\n",
       "  0.06381096,\n",
       "  -0.07191144,\n",
       "  0.013455875,\n",
       "  -0.13794704,\n",
       "  0.013373677,\n",
       "  0.0012897461,\n",
       "  0.03815024,\n",
       "  -0.026089806,\n",
       "  -0.0054932907,\n",
       "  0.007858747,\n",
       "  -0.12953565,\n",
       "  -0.10691128,\n",
       "  -0.028402196,\n",
       "  0.032811854,\n",
       "  0.19063756,\n",
       "  0.066203974,\n",
       "  -0.021425173,\n",
       "  -0.027397288,\n",
       "  -0.0125973765,\n",
       "  0.0832063,\n",
       "  0.03870479,\n",
       "  -0.115762345,\n",
       "  -0.045325726,\n",
       "  -0.15345293,\n",
       "  0.014907106,\n",
       "  -0.13668682,\n",
       "  0.015198165,\n",
       "  -0.07484797,\n",
       "  0.07474985,\n",
       "  -0.011128302,\n",
       "  -0.061176885,\n",
       "  0.06076868,\n",
       "  0.04224862,\n",
       "  0.084675625,\n",
       "  0.14366549,\n",
       "  -0.09863008,\n",
       "  -0.017946567,\n",
       "  0.017781952,\n",
       "  -0.090494506,\n",
       "  0.07336192,\n",
       "  0.12500201,\n",
       "  -0.035041068,\n",
       "  -0.08432116,\n",
       "  -0.04488684,\n",
       "  0.0799209,\n",
       "  0.020595293,\n",
       "  -0.04540194,\n",
       "  0.06614507,\n",
       "  -0.10332763,\n",
       "  0.014177688,\n",
       "  0.00073611137,\n",
       "  0.058333382,\n",
       "  -0.121466495,\n",
       "  0.16645955,\n",
       "  -0.047711503,\n",
       "  -0.023888059,\n",
       "  0.05849939,\n",
       "  0.015185787,\n",
       "  0.06701703,\n",
       "  0.059279893,\n",
       "  -0.04938019,\n",
       "  -0.0154195195,\n",
       "  0.0151774,\n",
       "  -0.015493017,\n",
       "  -0.0357247,\n",
       "  -0.031761058,\n",
       "  -0.06797394,\n",
       "  0.1257123,\n",
       "  0.0020896748,\n",
       "  0.013089633,\n",
       "  -0.019240653,\n",
       "  0.037151434,\n",
       "  0.16886999,\n",
       "  0.07073952,\n",
       "  0.04483561,\n",
       "  0.023982938,\n",
       "  -0.020558132,\n",
       "  0.06910228,\n",
       "  0.14837117,\n",
       "  0.11667828,\n",
       "  0.0038943072,\n",
       "  -0.1418326,\n",
       "  0.04025871,\n",
       "  0.051022723],\n",
       " [-0.52921665,\n",
       "  0.42257765,\n",
       "  0.12753987,\n",
       "  0.012122203,\n",
       "  0.004380224,\n",
       "  -0.15083499,\n",
       "  -0.123021014,\n",
       "  0.2284533,\n",
       "  -0.16439061,\n",
       "  -0.22729495,\n",
       "  0.0036093218,\n",
       "  -0.48620802,\n",
       "  -0.17307395,\n",
       "  0.12789781,\n",
       "  0.08560395,\n",
       "  -0.33251366,\n",
       "  0.62550026,\n",
       "  -0.078210935,\n",
       "  -0.039413143,\n",
       "  -0.334918,\n",
       "  0.0056057675,\n",
       "  -0.118353054,\n",
       "  0.33063117,\n",
       "  0.009904495,\n",
       "  -0.42764527,\n",
       "  -0.031576756,\n",
       "  -0.41950947,\n",
       "  -0.20243838,\n",
       "  -0.12148061,\n",
       "  -0.13441773,\n",
       "  0.35880762,\n",
       "  0.0021006174,\n",
       "  0.025347194,\n",
       "  0.2590557,\n",
       "  0.10837722,\n",
       "  0.28486896,\n",
       "  0.111339,\n",
       "  -0.16965167,\n",
       "  -0.36278814,\n",
       "  -0.3679535,\n",
       "  -0.13483974,\n",
       "  0.0485764,\n",
       "  0.112000205,\n",
       "  -0.14428665,\n",
       "  0.06645057,\n",
       "  -0.0469771,\n",
       "  -0.05804466,\n",
       "  0.033991173,\n",
       "  0.19206949,\n",
       "  0.060797546,\n",
       "  0.15707767,\n",
       "  -0.3391115,\n",
       "  0.13138814,\n",
       "  0.087342545,\n",
       "  -0.44856486,\n",
       "  0.32661742,\n",
       "  0.04523314,\n",
       "  -0.18136209,\n",
       "  -0.22229226,\n",
       "  0.17378421,\n",
       "  0.038503643,\n",
       "  0.031036556,\n",
       "  0.08037329,\n",
       "  0.07715193,\n",
       "  -0.22305831,\n",
       "  0.5353195,\n",
       "  -0.36049291,\n",
       "  0.20230721,\n",
       "  -0.3361808,\n",
       "  0.31177184,\n",
       "  -0.1728437,\n",
       "  0.06343153,\n",
       "  0.22765265,\n",
       "  0.20439559,\n",
       "  0.15055747,\n",
       "  0.09940543,\n",
       "  -0.16433781,\n",
       "  0.025956571,\n",
       "  -0.021388888,\n",
       "  -0.15756942,\n",
       "  -0.037494924,\n",
       "  -0.21396653,\n",
       "  -0.22727184,\n",
       "  0.06864244,\n",
       "  0.21973833,\n",
       "  0.19391748,\n",
       "  0.11996964,\n",
       "  0.008162012,\n",
       "  0.4181182,\n",
       "  0.15089008,\n",
       "  0.068227984,\n",
       "  0.06441254,\n",
       "  0.03259793,\n",
       "  0.19629847,\n",
       "  0.69207674,\n",
       "  0.058373395,\n",
       "  -0.072616555,\n",
       "  -0.33007267,\n",
       "  -0.008593038,\n",
       "  0.08949718],\n",
       " [-0.48809963,\n",
       "  0.24487567,\n",
       "  -0.07333145,\n",
       "  0.23535351,\n",
       "  0.10701795,\n",
       "  0.018248042,\n",
       "  0.3276229,\n",
       "  0.6822056,\n",
       "  0.14495587,\n",
       "  -0.19250861,\n",
       "  -0.2534087,\n",
       "  -0.21623532,\n",
       "  -0.25850743,\n",
       "  -0.092209175,\n",
       "  -0.034373492,\n",
       "  -0.30495206,\n",
       "  0.18261884,\n",
       "  -0.13471222,\n",
       "  0.10114746,\n",
       "  -0.39384952,\n",
       "  -0.2296359,\n",
       "  -0.045111284,\n",
       "  0.30860126,\n",
       "  0.02682665,\n",
       "  -0.21620215,\n",
       "  -0.014735174,\n",
       "  -0.27733424,\n",
       "  -0.3756065,\n",
       "  -0.19123927,\n",
       "  0.13763328,\n",
       "  0.69583,\n",
       "  -0.029281469,\n",
       "  -0.061920024,\n",
       "  -0.16340443,\n",
       "  0.007019148,\n",
       "  0.08845964,\n",
       "  0.13990277,\n",
       "  -0.32529518,\n",
       "  -0.10732031,\n",
       "  -0.26571882,\n",
       "  -0.0042285044,\n",
       "  -0.41025025,\n",
       "  -0.14123376,\n",
       "  -0.10294241,\n",
       "  0.29338795,\n",
       "  -0.09839414,\n",
       "  0.17606583,\n",
       "  0.19503152,\n",
       "  -0.019812828,\n",
       "  0.1000288,\n",
       "  0.26958334,\n",
       "  -0.47061422,\n",
       "  0.15636781,\n",
       "  -0.08199863,\n",
       "  -0.40338784,\n",
       "  -0.049609542,\n",
       "  0.14563231,\n",
       "  -0.22247465,\n",
       "  -0.3462555,\n",
       "  -0.44252616,\n",
       "  0.19327834,\n",
       "  -0.26038224,\n",
       "  0.20841147,\n",
       "  -0.20209445,\n",
       "  -0.47484806,\n",
       "  0.13561125,\n",
       "  -0.05263517,\n",
       "  0.37669685,\n",
       "  -0.37823176,\n",
       "  0.22050856,\n",
       "  -0.22671154,\n",
       "  0.10589673,\n",
       "  0.02926867,\n",
       "  0.26559526,\n",
       "  0.2608785,\n",
       "  0.2316823,\n",
       "  -0.36585906,\n",
       "  0.20434277,\n",
       "  -0.17325132,\n",
       "  -0.21193752,\n",
       "  0.101614,\n",
       "  -0.35476968,\n",
       "  -0.07538663,\n",
       "  0.17988525,\n",
       "  0.012083036,\n",
       "  -0.35872775,\n",
       "  0.28203696,\n",
       "  0.23970251,\n",
       "  0.09096228,\n",
       "  0.2892826,\n",
       "  0.053294048,\n",
       "  0.15411146,\n",
       "  0.02999582,\n",
       "  0.2615427,\n",
       "  0.8215991,\n",
       "  0.33042136,\n",
       "  0.02149891,\n",
       "  -0.16105033,\n",
       "  0.15559304,\n",
       "  -0.17823091],\n",
       " [-0.088261195,\n",
       "  0.17143376,\n",
       "  0.11132118,\n",
       "  0.2157198,\n",
       "  -0.06003869,\n",
       "  -0.19643863,\n",
       "  0.095919795,\n",
       "  0.41526112,\n",
       "  0.20311062,\n",
       "  -0.13373168,\n",
       "  -0.11072974,\n",
       "  -0.1871601,\n",
       "  -0.09227505,\n",
       "  0.014215502,\n",
       "  0.046774734,\n",
       "  -0.028924286,\n",
       "  0.17044762,\n",
       "  -0.12840122,\n",
       "  0.03927658,\n",
       "  -0.17473331,\n",
       "  -0.040456224,\n",
       "  -0.045177255,\n",
       "  0.07827362,\n",
       "  -0.13064952,\n",
       "  0.09780766,\n",
       "  -0.029636474,\n",
       "  -0.24793087,\n",
       "  -0.30262914,\n",
       "  -0.06930433,\n",
       "  0.14508353,\n",
       "  0.43155333,\n",
       "  0.13624787,\n",
       "  -0.022472316,\n",
       "  0.0437531,\n",
       "  -0.022218645,\n",
       "  0.11255413,\n",
       "  0.08073211,\n",
       "  -0.21561508,\n",
       "  -0.08762741,\n",
       "  -0.31975505,\n",
       "  -0.17797635,\n",
       "  -0.18552433,\n",
       "  0.13233954,\n",
       "  -0.2271742,\n",
       "  0.14789182,\n",
       "  0.006052901,\n",
       "  0.031311218,\n",
       "  0.14900322,\n",
       "  0.023517499,\n",
       "  0.29697514,\n",
       "  0.27366632,\n",
       "  -0.22220434,\n",
       "  -0.12200082,\n",
       "  -0.06441747,\n",
       "  -0.12341263,\n",
       "  0.15989977,\n",
       "  0.23394708,\n",
       "  0.05588846,\n",
       "  -0.20961814,\n",
       "  -0.05964068,\n",
       "  0.07835062,\n",
       "  0.14117207,\n",
       "  -0.10726416,\n",
       "  0.10890729,\n",
       "  -0.1865981,\n",
       "  -0.062150277,\n",
       "  0.028518116,\n",
       "  0.13371375,\n",
       "  -0.17808212,\n",
       "  0.36628133,\n",
       "  -0.035592362,\n",
       "  -0.18307817,\n",
       "  0.10089461,\n",
       "  0.046455737,\n",
       "  0.09336527,\n",
       "  0.09845675,\n",
       "  -0.06441261,\n",
       "  -0.031977475,\n",
       "  -0.020751486,\n",
       "  -0.06030487,\n",
       "  -0.02547767,\n",
       "  0.0030986313,\n",
       "  -0.1857324,\n",
       "  0.25355616,\n",
       "  0.1694228,\n",
       "  0.032031134,\n",
       "  0.11849351,\n",
       "  0.013703538,\n",
       "  0.21953839,\n",
       "  0.18914899,\n",
       "  0.027539773,\n",
       "  0.002566184,\n",
       "  -0.0029977474,\n",
       "  0.12829913,\n",
       "  0.3067904,\n",
       "  0.28016222,\n",
       "  -0.0017161731,\n",
       "  -0.3433934,\n",
       "  0.09186365,\n",
       "  -0.07849409],\n",
       " [-0.41327792,\n",
       "  0.14435562,\n",
       "  -0.08771378,\n",
       "  0.27055353,\n",
       "  -0.050468724,\n",
       "  -0.14048551,\n",
       "  0.20585547,\n",
       "  0.45021704,\n",
       "  0.25724158,\n",
       "  -0.24930982,\n",
       "  -0.12916476,\n",
       "  -0.19667274,\n",
       "  -0.10567697,\n",
       "  0.17853826,\n",
       "  0.040511563,\n",
       "  -0.17912906,\n",
       "  0.13140212,\n",
       "  0.06417417,\n",
       "  0.12620609,\n",
       "  -0.31041256,\n",
       "  -0.0933988,\n",
       "  -0.16382492,\n",
       "  0.078369945,\n",
       "  0.1213216,\n",
       "  0.252211,\n",
       "  -0.14726844,\n",
       "  -0.15822819,\n",
       "  -0.22287834,\n",
       "  -0.073049925,\n",
       "  0.12000552,\n",
       "  0.51890624,\n",
       "  0.21061166,\n",
       "  -0.1742894,\n",
       "  0.038177352,\n",
       "  -0.069535404,\n",
       "  0.23576754,\n",
       "  0.14224827,\n",
       "  -0.28740457,\n",
       "  -0.05913467,\n",
       "  -0.32202744,\n",
       "  -0.026533477,\n",
       "  -0.39020824,\n",
       "  0.06705125,\n",
       "  -0.37818363,\n",
       "  0.27577603,\n",
       "  0.177062,\n",
       "  0.08803798,\n",
       "  0.18285485,\n",
       "  -0.07915787,\n",
       "  0.16301745,\n",
       "  0.44952595,\n",
       "  -0.2756356,\n",
       "  -0.16839078,\n",
       "  0.10885558,\n",
       "  -0.20504323,\n",
       "  -0.024180926,\n",
       "  0.18145794,\n",
       "  -0.27639922,\n",
       "  -0.16909407,\n",
       "  -0.28524977,\n",
       "  0.31850496,\n",
       "  -0.071459666,\n",
       "  -0.036408585,\n",
       "  -0.0989212,\n",
       "  -0.1638049,\n",
       "  -0.15676229,\n",
       "  0.0540986,\n",
       "  0.2546497,\n",
       "  -0.1712359,\n",
       "  0.4337312,\n",
       "  -0.058589473,\n",
       "  -0.0009095941,\n",
       "  0.06712651,\n",
       "  0.1827693,\n",
       "  0.08154931,\n",
       "  0.15431015,\n",
       "  -0.22406162,\n",
       "  -0.019621225,\n",
       "  0.110448815,\n",
       "  -0.14011267,\n",
       "  -0.016382439,\n",
       "  -0.11649511,\n",
       "  -0.12393344,\n",
       "  0.3010324,\n",
       "  0.14858574,\n",
       "  -0.10986526,\n",
       "  0.11798009,\n",
       "  0.0077625057,\n",
       "  0.23963015,\n",
       "  0.22575875,\n",
       "  -0.10476161,\n",
       "  0.08053322,\n",
       "  -0.13179693,\n",
       "  0.25803924,\n",
       "  0.62313974,\n",
       "  0.22455946,\n",
       "  0.0043174597,\n",
       "  -0.34107634,\n",
       "  -0.0007905987,\n",
       "  -0.02511162],\n",
       " [-0.13088861,\n",
       "  0.14790957,\n",
       "  0.017753033,\n",
       "  0.26891345,\n",
       "  -0.09708157,\n",
       "  -0.19285354,\n",
       "  0.09952323,\n",
       "  0.41390377,\n",
       "  0.11754151,\n",
       "  -0.08725679,\n",
       "  -0.2125126,\n",
       "  -0.20571207,\n",
       "  -0.1113883,\n",
       "  0.116430946,\n",
       "  -0.05856324,\n",
       "  -0.1378871,\n",
       "  0.03775175,\n",
       "  -0.091160886,\n",
       "  0.1519243,\n",
       "  -0.17835262,\n",
       "  0.008757327,\n",
       "  -0.07070921,\n",
       "  0.016476298,\n",
       "  0.005320257,\n",
       "  0.084119305,\n",
       "  -0.0762715,\n",
       "  -0.2520237,\n",
       "  -0.26066363,\n",
       "  0.041794416,\n",
       "  0.07217147,\n",
       "  0.3637414,\n",
       "  0.15816121,\n",
       "  -0.09810323,\n",
       "  0.04562188,\n",
       "  -0.04531447,\n",
       "  0.1168465,\n",
       "  0.1368929,\n",
       "  -0.21204475,\n",
       "  -0.037201352,\n",
       "  -0.2211409,\n",
       "  0.08170467,\n",
       "  -0.28867638,\n",
       "  0.12766972,\n",
       "  -0.1943754,\n",
       "  0.14115779,\n",
       "  0.10042726,\n",
       "  -0.11720268,\n",
       "  0.08635568,\n",
       "  0.016108898,\n",
       "  0.10279079,\n",
       "  0.30328274,\n",
       "  -0.19805434,\n",
       "  -0.05099473,\n",
       "  0.038506746,\n",
       "  -0.19063757,\n",
       "  0.061403368,\n",
       "  0.2534966,\n",
       "  -0.04607923,\n",
       "  -0.094889455,\n",
       "  -0.17758836,\n",
       "  0.17275487,\n",
       "  -0.0311093,\n",
       "  -0.032215476,\n",
       "  0.09341902,\n",
       "  -0.13599648,\n",
       "  -0.086870566,\n",
       "  0.08117646,\n",
       "  0.14378135,\n",
       "  -0.20773488,\n",
       "  0.41453072,\n",
       "  -0.1084579,\n",
       "  -0.06256023,\n",
       "  -0.008309748,\n",
       "  0.019802377,\n",
       "  0.04543276,\n",
       "  0.068482354,\n",
       "  -0.12838477,\n",
       "  0.014390324,\n",
       "  0.040447626,\n",
       "  0.00077102793,\n",
       "  -0.09029399,\n",
       "  -0.14382952,\n",
       "  -0.16746305,\n",
       "  0.29554984,\n",
       "  0.02243096,\n",
       "  -0.001167835,\n",
       "  -0.050545983,\n",
       "  0.13667259,\n",
       "  0.23856091,\n",
       "  0.16994001,\n",
       "  -0.03551789,\n",
       "  -0.017614283,\n",
       "  -0.15911035,\n",
       "  0.0912045,\n",
       "  0.31736815,\n",
       "  0.22982074,\n",
       "  -0.038467757,\n",
       "  -0.17445934,\n",
       "  0.10988204,\n",
       "  0.07925518],\n",
       " [-0.33702216,\n",
       "  -0.014859279,\n",
       "  0.39293537,\n",
       "  0.23399897,\n",
       "  -0.0417059,\n",
       "  0.029612092,\n",
       "  -0.15781748,\n",
       "  0.58872604,\n",
       "  0.23756576,\n",
       "  -0.091683246,\n",
       "  0.04451762,\n",
       "  -0.72052693,\n",
       "  -0.049144946,\n",
       "  0.085655086,\n",
       "  0.2806835,\n",
       "  -0.26233295,\n",
       "  0.61308086,\n",
       "  0.06918111,\n",
       "  0.086874425,\n",
       "  -0.44916844,\n",
       "  0.16450812,\n",
       "  0.14793551,\n",
       "  -0.16946545,\n",
       "  -0.0009929136,\n",
       "  -0.08526532,\n",
       "  -0.28203517,\n",
       "  -0.37332132,\n",
       "  0.039177,\n",
       "  0.08357552,\n",
       "  0.017229587,\n",
       "  0.08860381,\n",
       "  -0.017740134,\n",
       "  -0.08451125,\n",
       "  0.24766064,\n",
       "  -0.3486164,\n",
       "  0.2472262,\n",
       "  -0.38426587,\n",
       "  -0.6277789,\n",
       "  -0.3397015,\n",
       "  -0.5582456,\n",
       "  -0.17678523,\n",
       "  -0.041143678,\n",
       "  0.8953245,\n",
       "  -0.021127347,\n",
       "  0.51721156,\n",
       "  0.44668776,\n",
       "  0.22809811,\n",
       "  0.021862749,\n",
       "  -0.23014383,\n",
       "  0.12890549,\n",
       "  0.35678318,\n",
       "  -0.29207006,\n",
       "  -0.21178952,\n",
       "  -0.1216914,\n",
       "  -0.4207328,\n",
       "  -0.09482595,\n",
       "  0.30906677,\n",
       "  -0.32987,\n",
       "  -0.16303253,\n",
       "  0.18823212,\n",
       "  -0.3717903,\n",
       "  0.5121956,\n",
       "  0.23574819,\n",
       "  -0.06054059,\n",
       "  -0.43293712,\n",
       "  0.25826776,\n",
       "  0.11614,\n",
       "  0.34554252,\n",
       "  -0.5512834,\n",
       "  -0.049377184,\n",
       "  0.12450306,\n",
       "  -0.034459792,\n",
       "  0.20385182,\n",
       "  -0.05598203,\n",
       "  0.4802354,\n",
       "  -0.42071787,\n",
       "  0.007998187,\n",
       "  -0.030885695,\n",
       "  -0.04369034,\n",
       "  0.15235576,\n",
       "  0.0031122996,\n",
       "  -0.007275816,\n",
       "  -0.27498108,\n",
       "  0.29530138,\n",
       "  0.24239624,\n",
       "  0.7317903,\n",
       "  0.18855551,\n",
       "  -0.028237142,\n",
       "  0.82422376,\n",
       "  0.6023928,\n",
       "  0.06866496,\n",
       "  0.24663244,\n",
       "  0.25743157,\n",
       "  0.48411655,\n",
       "  0.6448736,\n",
       "  0.3136171,\n",
       "  -0.09273969,\n",
       "  -0.23645878,\n",
       "  0.45469698,\n",
       "  0.2879584],\n",
       " [-0.10184931,\n",
       "  0.15921463,\n",
       "  0.055266358,\n",
       "  0.18287359,\n",
       "  0.04075872,\n",
       "  -0.21280293,\n",
       "  0.05874612,\n",
       "  0.40235275,\n",
       "  0.08406835,\n",
       "  -0.11308103,\n",
       "  -0.10724286,\n",
       "  -0.22738534,\n",
       "  -0.097868346,\n",
       "  0.08564199,\n",
       "  0.019518808,\n",
       "  -0.12652266,\n",
       "  0.14918302,\n",
       "  -0.15386885,\n",
       "  0.029816197,\n",
       "  -0.23660737,\n",
       "  0.041178133,\n",
       "  -0.0015984986,\n",
       "  0.08408637,\n",
       "  -0.023685269,\n",
       "  -0.055629276,\n",
       "  -0.014996525,\n",
       "  -0.24059378,\n",
       "  -0.19755594,\n",
       "  -0.05637302,\n",
       "  0.039213367,\n",
       "  0.3066712,\n",
       "  0.057502434,\n",
       "  -0.02304128,\n",
       "  0.013296092,\n",
       "  -0.018625038,\n",
       "  0.13069758,\n",
       "  0.028310217,\n",
       "  -0.21719973,\n",
       "  -0.113201834,\n",
       "  -0.2758184,\n",
       "  0.016651276,\n",
       "  -0.19355369,\n",
       "  0.113033466,\n",
       "  -0.09712891,\n",
       "  0.14689118,\n",
       "  0.01350908,\n",
       "  -0.056297883,\n",
       "  0.0870093,\n",
       "  0.060457237,\n",
       "  0.12108589,\n",
       "  0.2084903,\n",
       "  -0.20824993,\n",
       "  -0.056824815,\n",
       "  0.022098111,\n",
       "  -0.19269368,\n",
       "  0.09698888,\n",
       "  0.1969695,\n",
       "  -0.052976612,\n",
       "  -0.08302353,\n",
       "  -0.06149473,\n",
       "  0.06767528,\n",
       "  0.0872391,\n",
       "  -0.044159003,\n",
       "  0.0678102,\n",
       "  -0.21514042,\n",
       "  0.056767777,\n",
       "  0.0005216043,\n",
       "  0.10111504,\n",
       "  -0.21112925,\n",
       "  0.26969138,\n",
       "  -0.114022635,\n",
       "  -0.03419273,\n",
       "  0.110978216,\n",
       "  0.046527144,\n",
       "  0.15803725,\n",
       "  0.06155638,\n",
       "  -0.09044034,\n",
       "  -0.03370027,\n",
       "  -0.021763742,\n",
       "  -0.009172507,\n",
       "  -0.009411796,\n",
       "  -0.05824882,\n",
       "  -0.17508747,\n",
       "  0.2288705,\n",
       "  0.0646149,\n",
       "  0.08187,\n",
       "  -0.024728611,\n",
       "  0.11613122,\n",
       "  0.33119777,\n",
       "  0.15674172,\n",
       "  0.06622395,\n",
       "  0.03515985,\n",
       "  -0.018072136,\n",
       "  0.10040283,\n",
       "  0.30436274,\n",
       "  0.20787463,\n",
       "  -0.006408958,\n",
       "  -0.23179288,\n",
       "  0.08482385,\n",
       "  0.033728085],\n",
       " [-0.24196184,\n",
       "  0.18586831,\n",
       "  0.09136424,\n",
       "  0.24215074,\n",
       "  0.37968498,\n",
       "  -0.16734906,\n",
       "  0.43901289,\n",
       "  0.7471399,\n",
       "  0.47207278,\n",
       "  -0.26474115,\n",
       "  -0.23290269,\n",
       "  -0.40117642,\n",
       "  -0.1241609,\n",
       "  -0.071423315,\n",
       "  0.34676582,\n",
       "  -0.3101096,\n",
       "  0.25402507,\n",
       "  -0.33028525,\n",
       "  0.20522082,\n",
       "  -0.3965698,\n",
       "  0.17147045,\n",
       "  0.09179015,\n",
       "  0.24009013,\n",
       "  0.03875874,\n",
       "  -0.039622877,\n",
       "  0.021985438,\n",
       "  -0.3475519,\n",
       "  -0.5213529,\n",
       "  0.077225424,\n",
       "  -0.012906568,\n",
       "  0.4698989,\n",
       "  -0.14941634,\n",
       "  -0.33524892,\n",
       "  -0.22605224,\n",
       "  -0.1192205,\n",
       "  0.24243972,\n",
       "  0.14247061,\n",
       "  -0.49793717,\n",
       "  -0.4732876,\n",
       "  -0.33643442,\n",
       "  -0.11682608,\n",
       "  -0.30064362,\n",
       "  0.19728856,\n",
       "  0.13171415,\n",
       "  0.4340739,\n",
       "  0.1793758,\n",
       "  0.43862966,\n",
       "  0.0939235,\n",
       "  -0.0042022117,\n",
       "  0.1275419,\n",
       "  0.11915698,\n",
       "  -0.4486969,\n",
       "  0.23897776,\n",
       "  -0.32801256,\n",
       "  -0.2848159,\n",
       "  -0.3359801,\n",
       "  0.10885583,\n",
       "  -0.36756742,\n",
       "  -0.11670302,\n",
       "  -0.3690798,\n",
       "  0.15504666,\n",
       "  -0.19294615,\n",
       "  0.15667227,\n",
       "  -0.27023783,\n",
       "  -0.534177,\n",
       "  0.029402757,\n",
       "  -0.020408532,\n",
       "  0.33201095,\n",
       "  -0.2931662,\n",
       "  0.3121254,\n",
       "  -0.15600692,\n",
       "  0.09270359,\n",
       "  -0.18403563,\n",
       "  0.45626926,\n",
       "  0.60024273,\n",
       "  -0.17537054,\n",
       "  -0.5334349,\n",
       "  0.19274785,\n",
       "  -0.34547958,\n",
       "  -0.24739882,\n",
       "  0.108380176,\n",
       "  -0.16359842,\n",
       "  -0.19985935,\n",
       "  0.26263317,\n",
       "  0.4082434,\n",
       "  -0.16434872,\n",
       "  0.20433891,\n",
       "  0.20503356,\n",
       "  0.2975374,\n",
       "  0.17034163,\n",
       "  -0.085921556,\n",
       "  0.072862156,\n",
       "  0.045066692,\n",
       "  0.27200916,\n",
       "  0.8069931,\n",
       "  0.44930896,\n",
       "  0.18113494,\n",
       "  -0.10197418,\n",
       "  0.24712978,\n",
       "  -0.35972455],\n",
       " [0.04991289,\n",
       "  0.17586784,\n",
       "  0.07576322,\n",
       "  -0.11368299,\n",
       "  -0.1534773,\n",
       "  -0.12317985,\n",
       "  0.17981802,\n",
       "  0.32449183,\n",
       "  0.37311122,\n",
       "  -0.15441854,\n",
       "  -0.26051998,\n",
       "  -0.5409627,\n",
       "  -0.0791081,\n",
       "  0.07616084,\n",
       "  -0.16366097,\n",
       "  -0.017727198,\n",
       "  -0.17160417,\n",
       "  -0.16694272,\n",
       "  0.46379936,\n",
       "  -0.10455036,\n",
       "  0.39038044,\n",
       "  -0.04191394,\n",
       "  0.34934565,\n",
       "  0.02436672,\n",
       "  -0.17611217,\n",
       "  -0.21487318,\n",
       "  -0.51110554,\n",
       "  -0.37707856,\n",
       "  0.24259408,\n",
       "  -0.00918874,\n",
       "  0.26238284,\n",
       "  -0.0025777745,\n",
       "  -0.17814471,\n",
       "  -0.07840555,\n",
       "  0.076024264,\n",
       "  -0.014697187,\n",
       "  0.19735548,\n",
       "  -0.1424194,\n",
       "  -0.042886253,\n",
       "  -0.32101366,\n",
       "  0.1260805,\n",
       "  -0.51324326,\n",
       "  -0.056640826,\n",
       "  0.18984103,\n",
       "  0.33997023,\n",
       "  0.21951054,\n",
       "  -0.10396266,\n",
       "  -0.0030926226,\n",
       "  0.34118584,\n",
       "  0.10591873,\n",
       "  0.3090215,\n",
       "  -0.47937027,\n",
       "  0.47076744,\n",
       "  -0.3598995,\n",
       "  -0.038231295,\n",
       "  -0.061031356,\n",
       "  0.3519619,\n",
       "  -0.1583931,\n",
       "  -0.39354315,\n",
       "  -0.2766728,\n",
       "  0.12962759,\n",
       "  -0.28269428,\n",
       "  0.23580784,\n",
       "  0.14430355,\n",
       "  -0.30713424,\n",
       "  0.0749346,\n",
       "  0.118781425,\n",
       "  0.2856076,\n",
       "  -0.7101574,\n",
       "  0.57431316,\n",
       "  -0.28467736,\n",
       "  -0.31389245,\n",
       "  -0.19176053,\n",
       "  0.35401577,\n",
       "  0.031319957,\n",
       "  0.075737305,\n",
       "  -0.041641947,\n",
       "  0.28586787,\n",
       "  6.150306e-05,\n",
       "  -0.09361963,\n",
       "  -0.47628102,\n",
       "  0.048278436,\n",
       "  -0.1978399,\n",
       "  0.32360452,\n",
       "  0.27624053,\n",
       "  -0.25803852,\n",
       "  0.45506877,\n",
       "  0.27434185,\n",
       "  0.06654007,\n",
       "  0.3877848,\n",
       "  0.3451669,\n",
       "  -0.10616697,\n",
       "  -0.24849738,\n",
       "  -0.119478196,\n",
       "  0.43834764,\n",
       "  0.45347023,\n",
       "  0.0021514704,\n",
       "  -0.19140685,\n",
       "  0.25296646,\n",
       "  -0.16105206],\n",
       " [-0.33702216,\n",
       "  -0.014859279,\n",
       "  0.39293537,\n",
       "  0.23399897,\n",
       "  -0.0417059,\n",
       "  0.029612092,\n",
       "  -0.15781748,\n",
       "  0.58872604,\n",
       "  0.23756576,\n",
       "  -0.091683246,\n",
       "  0.04451762,\n",
       "  -0.72052693,\n",
       "  -0.049144946,\n",
       "  0.085655086,\n",
       "  0.2806835,\n",
       "  -0.26233295,\n",
       "  0.61308086,\n",
       "  0.06918111,\n",
       "  0.086874425,\n",
       "  -0.44916844,\n",
       "  0.16450812,\n",
       "  0.14793551,\n",
       "  -0.16946545,\n",
       "  -0.0009929136,\n",
       "  -0.08526532,\n",
       "  -0.28203517,\n",
       "  -0.37332132,\n",
       "  0.039177,\n",
       "  0.08357552,\n",
       "  0.017229587,\n",
       "  0.08860381,\n",
       "  -0.017740134,\n",
       "  -0.08451125,\n",
       "  0.24766064,\n",
       "  -0.3486164,\n",
       "  0.2472262,\n",
       "  -0.38426587,\n",
       "  -0.6277789,\n",
       "  -0.3397015,\n",
       "  -0.5582456,\n",
       "  -0.17678523,\n",
       "  -0.041143678,\n",
       "  0.8953245,\n",
       "  -0.021127347,\n",
       "  0.51721156,\n",
       "  0.44668776,\n",
       "  0.22809811,\n",
       "  0.021862749,\n",
       "  -0.23014383,\n",
       "  0.12890549,\n",
       "  0.35678318,\n",
       "  -0.29207006,\n",
       "  -0.21178952,\n",
       "  -0.1216914,\n",
       "  -0.4207328,\n",
       "  -0.09482595,\n",
       "  0.30906677,\n",
       "  -0.32987,\n",
       "  -0.16303253,\n",
       "  0.18823212,\n",
       "  -0.3717903,\n",
       "  0.5121956,\n",
       "  0.23574819,\n",
       "  -0.06054059,\n",
       "  -0.43293712,\n",
       "  0.25826776,\n",
       "  0.11614,\n",
       "  0.34554252,\n",
       "  -0.5512834,\n",
       "  -0.049377184,\n",
       "  0.12450306,\n",
       "  -0.034459792,\n",
       "  0.20385182,\n",
       "  -0.05598203,\n",
       "  0.4802354,\n",
       "  -0.42071787,\n",
       "  0.007998187,\n",
       "  -0.030885695,\n",
       "  -0.04369034,\n",
       "  0.15235576,\n",
       "  0.0031122996,\n",
       "  -0.007275816,\n",
       "  -0.27498108,\n",
       "  0.29530138,\n",
       "  0.24239624,\n",
       "  0.7317903,\n",
       "  0.18855551,\n",
       "  -0.028237142,\n",
       "  0.82422376,\n",
       "  0.6023928,\n",
       "  0.06866496,\n",
       "  0.24663244,\n",
       "  0.25743157,\n",
       "  0.48411655,\n",
       "  0.6448736,\n",
       "  0.3136171,\n",
       "  -0.09273969,\n",
       "  -0.23645878,\n",
       "  0.45469698,\n",
       "  0.2879584],\n",
       " [-0.07103177,\n",
       "  0.14560671,\n",
       "  0.034253463,\n",
       "  0.15445586,\n",
       "  0.0062890174,\n",
       "  -0.1967129,\n",
       "  0.07474024,\n",
       "  0.38446975,\n",
       "  0.11477178,\n",
       "  -0.039536167,\n",
       "  -0.17283913,\n",
       "  -0.18004438,\n",
       "  -0.09842498,\n",
       "  0.0014684265,\n",
       "  -0.013697174,\n",
       "  -0.08673763,\n",
       "  0.07863172,\n",
       "  -0.17874153,\n",
       "  0.03127932,\n",
       "  -0.18611307,\n",
       "  0.042946406,\n",
       "  -0.022204844,\n",
       "  0.073686965,\n",
       "  -0.09440942,\n",
       "  -0.021649595,\n",
       "  -0.039701443,\n",
       "  -0.24539535,\n",
       "  -0.23824929,\n",
       "  -0.06424645,\n",
       "  0.057213396,\n",
       "  0.34069398,\n",
       "  0.06860549,\n",
       "  -0.01911376,\n",
       "  -0.037271384,\n",
       "  0.006955397,\n",
       "  0.07075038,\n",
       "  0.09459014,\n",
       "  -0.16174425,\n",
       "  -0.095201716,\n",
       "  -0.21984904,\n",
       "  0.007000325,\n",
       "  -0.16211475,\n",
       "  0.044651404,\n",
       "  -0.08170241,\n",
       "  0.12229949,\n",
       "  -0.050395764,\n",
       "  -0.059823826,\n",
       "  0.078947954,\n",
       "  0.030541847,\n",
       "  0.17070025,\n",
       "  0.20491438,\n",
       "  -0.19447432,\n",
       "  -0.010067901,\n",
       "  -0.046026506,\n",
       "  -0.15401816,\n",
       "  0.14515245,\n",
       "  0.18263805,\n",
       "  -0.01516916,\n",
       "  -0.14856288,\n",
       "  -0.042435832,\n",
       "  0.013486079,\n",
       "  0.052609168,\n",
       "  -0.042525783,\n",
       "  0.091673166,\n",
       "  -0.16992748,\n",
       "  0.036084875,\n",
       "  0.04608309,\n",
       "  0.12603444,\n",
       "  -0.22052757,\n",
       "  0.26044664,\n",
       "  -0.09761979,\n",
       "  -0.05585793,\n",
       "  0.053917486,\n",
       "  0.06701616,\n",
       "  0.14000085,\n",
       "  0.039769884,\n",
       "  -0.07546944,\n",
       "  -0.021617815,\n",
       "  -0.052895375,\n",
       "  -0.018837783,\n",
       "  -0.06124693,\n",
       "  -0.05736199,\n",
       "  -0.124133065,\n",
       "  0.21270613,\n",
       "  0.06283373,\n",
       "  -0.00054156967,\n",
       "  0.021805605,\n",
       "  0.09764087,\n",
       "  0.22939892,\n",
       "  0.121150635,\n",
       "  0.086054295,\n",
       "  0.014480576,\n",
       "  -0.037735473,\n",
       "  0.053356692,\n",
       "  0.24611713,\n",
       "  0.20206971,\n",
       "  0.009017789,\n",
       "  -0.22204188,\n",
       "  0.103022225,\n",
       "  -0.003063613],\n",
       " [-0.18460254,\n",
       "  0.05009944,\n",
       "  -0.1699908,\n",
       "  0.36584198,\n",
       "  -0.10418466,\n",
       "  -0.11869923,\n",
       "  0.5068635,\n",
       "  0.70568335,\n",
       "  0.13337184,\n",
       "  0.15805261,\n",
       "  -0.33139566,\n",
       "  0.057092816,\n",
       "  -0.29017928,\n",
       "  -0.1563503,\n",
       "  -0.14968859,\n",
       "  0.14879479,\n",
       "  -0.18168537,\n",
       "  -0.24901983,\n",
       "  -0.027232397,\n",
       "  -0.25550538,\n",
       "  -0.03040612,\n",
       "  -0.009090348,\n",
       "  0.20344597,\n",
       "  -0.21354853,\n",
       "  -0.10763694,\n",
       "  -0.18975231,\n",
       "  0.028551921,\n",
       "  -0.28162733,\n",
       "  -0.14888042,\n",
       "  0.0860497,\n",
       "  0.6561365,\n",
       "  -0.06930751,\n",
       "  -0.19263688,\n",
       "  -0.2996963,\n",
       "  0.0057046204,\n",
       "  -0.2958738,\n",
       "  0.38231936,\n",
       "  -0.2500249,\n",
       "  -0.120210275,\n",
       "  -0.11896882,\n",
       "  0.20094512,\n",
       "  -0.37935033,\n",
       "  -0.04756112,\n",
       "  -0.20260783,\n",
       "  0.26224497,\n",
       "  -0.16608919,\n",
       "  0.24658892,\n",
       "  0.03404938,\n",
       "  0.20955017,\n",
       "  0.2783086,\n",
       "  0.4007036,\n",
       "  -0.19230393,\n",
       "  0.15437135,\n",
       "  0.06482937,\n",
       "  -0.3901922,\n",
       "  0.112206094,\n",
       "  0.50806624,\n",
       "  0.301277,\n",
       "  -0.38766578,\n",
       "  -0.057534035,\n",
       "  0.014348253,\n",
       "  -0.37512213,\n",
       "  0.24417785,\n",
       "  0.22927062,\n",
       "  -0.25814682,\n",
       "  0.011715558,\n",
       "  0.29841557,\n",
       "  0.2795877,\n",
       "  -0.36742517,\n",
       "  0.18030375,\n",
       "  -0.07521306,\n",
       "  -0.020928055,\n",
       "  -0.2250485,\n",
       "  0.120830536,\n",
       "  0.066937186,\n",
       "  0.03158314,\n",
       "  -0.25054824,\n",
       "  -0.010281944,\n",
       "  -0.1487384,\n",
       "  0.043930557,\n",
       "  -0.13536608,\n",
       "  -0.34292656,\n",
       "  -0.008477235,\n",
       "  0.47903067,\n",
       "  -0.032819156,\n",
       "  -0.21066932,\n",
       "  0.030658666,\n",
       "  0.30774146,\n",
       "  0.11002823,\n",
       "  0.27429184,\n",
       "  -0.018123712,\n",
       "  0.14923453,\n",
       "  -0.10021389,\n",
       "  -0.06215405,\n",
       "  0.60660255,\n",
       "  0.46060202,\n",
       "  -0.13371566,\n",
       "  -0.1335477,\n",
       "  0.26749092,\n",
       "  0.08504008],\n",
       " [0.15412015,\n",
       "  0.034696538,\n",
       "  0.05528202,\n",
       "  0.23568283,\n",
       "  0.032589752,\n",
       "  -0.30970666,\n",
       "  0.21743318,\n",
       "  0.550721,\n",
       "  0.26826498,\n",
       "  0.19482379,\n",
       "  -0.45649868,\n",
       "  -0.15752865,\n",
       "  -0.07671848,\n",
       "  -0.082910605,\n",
       "  -0.039436296,\n",
       "  -0.11979239,\n",
       "  -0.04173101,\n",
       "  -0.2806426,\n",
       "  -0.06370841,\n",
       "  -0.22703937,\n",
       "  0.15801683,\n",
       "  0.15792301,\n",
       "  0.21575828,\n",
       "  -0.2672417,\n",
       "  -0.14406922,\n",
       "  -0.13085192,\n",
       "  -0.2893036,\n",
       "  -0.47293508,\n",
       "  -0.08976227,\n",
       "  -0.04447633,\n",
       "  0.5730093,\n",
       "  -0.020854441,\n",
       "  -0.17149474,\n",
       "  0.023034558,\n",
       "  0.06604378,\n",
       "  -0.07892865,\n",
       "  -0.028636906,\n",
       "  -0.15548751,\n",
       "  -0.21486874,\n",
       "  -0.37127984,\n",
       "  0.107212625,\n",
       "  -0.09803994,\n",
       "  0.003940638,\n",
       "  0.15652779,\n",
       "  0.0652679,\n",
       "  -0.1565987,\n",
       "  0.1883992,\n",
       "  -0.07984562,\n",
       "  0.0917676,\n",
       "  0.26690963,\n",
       "  0.2009181,\n",
       "  -0.35783347,\n",
       "  0.044869225,\n",
       "  -0.12983699,\n",
       "  -0.18849978,\n",
       "  0.12821518,\n",
       "  0.18250324,\n",
       "  0.19331431,\n",
       "  -0.23259452,\n",
       "  0.0037825757,\n",
       "  -0.13127567,\n",
       "  0.020070132,\n",
       "  0.21554615,\n",
       "  0.13623743,\n",
       "  -0.44382903,\n",
       "  0.2539983,\n",
       "  0.1172578,\n",
       "  0.089201376,\n",
       "  -0.533353,\n",
       "  0.29917789,\n",
       "  -0.1600856,\n",
       "  -0.054848455,\n",
       "  0.0125328405,\n",
       "  0.112152815,\n",
       "  0.14843796,\n",
       "  -0.12689771,\n",
       "  -0.015208928,\n",
       "  -0.1229761,\n",
       "  -0.30992004,\n",
       "  0.061514463,\n",
       "  -0.102151275,\n",
       "  0.031940576,\n",
       "  -0.22372554,\n",
       "  0.38516298,\n",
       "  0.13041073,\n",
       "  0.010333054,\n",
       "  -0.038723823,\n",
       "  0.33879834,\n",
       "  0.39068323,\n",
       "  0.18306984,\n",
       "  0.15245607,\n",
       "  0.011639572,\n",
       "  -0.07526029,\n",
       "  0.0062367986,\n",
       "  0.2319787,\n",
       "  0.31699055,\n",
       "  -0.05986911,\n",
       "  -0.23404603,\n",
       "  0.074546516,\n",
       "  -0.15865372],\n",
       " [-0.015052611,\n",
       "  0.026005073,\n",
       "  0.08162173,\n",
       "  0.11108343,\n",
       "  -0.053565945,\n",
       "  -0.26356855,\n",
       "  0.05125048,\n",
       "  0.8140289,\n",
       "  0.34408334,\n",
       "  -0.18467052,\n",
       "  -0.06613437,\n",
       "  -0.18222493,\n",
       "  -0.12252722,\n",
       "  0.46490398,\n",
       "  -0.018289424,\n",
       "  -0.2921946,\n",
       "  0.26809135,\n",
       "  -0.041981168,\n",
       "  -0.07799694,\n",
       "  -0.5931647,\n",
       "  -0.022973813,\n",
       "  0.1528141,\n",
       "  -0.08289891,\n",
       "  -0.0029902053,\n",
       "  -0.3373523,\n",
       "  -0.08016596,\n",
       "  -0.25400162,\n",
       "  -0.5280474,\n",
       "  0.15532994,\n",
       "  -0.057525177,\n",
       "  0.09554777,\n",
       "  0.17367886,\n",
       "  0.07257081,\n",
       "  0.15022135,\n",
       "  -0.14133129,\n",
       "  0.3088258,\n",
       "  -0.21448472,\n",
       "  -0.39636645,\n",
       "  -0.18647645,\n",
       "  -0.6097174,\n",
       "  -0.047418516,\n",
       "  -0.12529854,\n",
       "  0.16262873,\n",
       "  -0.108832076,\n",
       "  0.12227581,\n",
       "  -0.1459426,\n",
       "  0.2121711,\n",
       "  -0.20516989,\n",
       "  0.083030574,\n",
       "  0.14703692,\n",
       "  0.13879547,\n",
       "  -0.4346314,\n",
       "  -0.23240884,\n",
       "  0.16148514,\n",
       "  -0.098046385,\n",
       "  0.122823745,\n",
       "  0.13832667,\n",
       "  -0.102091245,\n",
       "  0.270468,\n",
       "  0.12359094,\n",
       "  -0.034647964,\n",
       "  0.16906162,\n",
       "  0.26446798,\n",
       "  -0.10466301,\n",
       "  -0.44654068,\n",
       "  0.40565512,\n",
       "  -0.32945958,\n",
       "  0.10150338,\n",
       "  -0.3314024,\n",
       "  0.07007218,\n",
       "  -0.050751593,\n",
       "  0.10953683,\n",
       "  -0.002081462,\n",
       "  0.035312723,\n",
       "  0.1277536,\n",
       "  -0.106951654,\n",
       "  0.02124393,\n",
       "  -0.14475907,\n",
       "  -0.21347657,\n",
       "  0.24440214,\n",
       "  0.21594265,\n",
       "  0.27353245,\n",
       "  -0.17915593,\n",
       "  0.4522888,\n",
       "  -0.08831617,\n",
       "  0.11223477,\n",
       "  0.055302925,\n",
       "  0.13140434,\n",
       "  0.6344121,\n",
       "  0.55650055,\n",
       "  0.09806448,\n",
       "  -0.16629557,\n",
       "  0.10731517,\n",
       "  0.24067405,\n",
       "  0.4765172,\n",
       "  0.29773143,\n",
       "  0.17780834,\n",
       "  -0.107357055,\n",
       "  -0.06450597,\n",
       "  -0.033593368],\n",
       " [-0.056932498,\n",
       "  0.17576891,\n",
       "  0.063163236,\n",
       "  0.20396698,\n",
       "  0.030706534,\n",
       "  -0.24571168,\n",
       "  0.042459913,\n",
       "  0.43169418,\n",
       "  0.13936965,\n",
       "  -0.04321359,\n",
       "  -0.18502851,\n",
       "  -0.19156142,\n",
       "  -0.09828918,\n",
       "  0.049386412,\n",
       "  -0.019877478,\n",
       "  -0.11516957,\n",
       "  0.0822223,\n",
       "  -0.20875089,\n",
       "  0.044899445,\n",
       "  -0.19621249,\n",
       "  0.02786599,\n",
       "  -0.03756258,\n",
       "  0.08156544,\n",
       "  -0.08671404,\n",
       "  -0.055151906,\n",
       "  -0.0046221586,\n",
       "  -0.19762176,\n",
       "  -0.274968,\n",
       "  -0.11254187,\n",
       "  0.07587956,\n",
       "  0.33805284,\n",
       "  0.054049063,\n",
       "  -0.05039154,\n",
       "  -0.045002434,\n",
       "  0.014854534,\n",
       "  0.066167936,\n",
       "  0.06871426,\n",
       "  -0.17248575,\n",
       "  -0.10881811,\n",
       "  -0.29110464,\n",
       "  0.01313175,\n",
       "  -0.18496558,\n",
       "  0.042776737,\n",
       "  -0.08112401,\n",
       "  0.0894642,\n",
       "  -0.09034258,\n",
       "  -0.0668069,\n",
       "  0.048543505,\n",
       "  0.07061271,\n",
       "  0.17894347,\n",
       "  0.23479293,\n",
       "  -0.22220646,\n",
       "  -0.051240742,\n",
       "  -0.020456072,\n",
       "  -0.18196435,\n",
       "  0.1554465,\n",
       "  0.1948708,\n",
       "  -0.0005629657,\n",
       "  -0.13853349,\n",
       "  -0.03326294,\n",
       "  0.0606552,\n",
       "  0.11146973,\n",
       "  -0.12209327,\n",
       "  0.100057155,\n",
       "  -0.19793853,\n",
       "  0.03822328,\n",
       "  0.042786565,\n",
       "  0.09020765,\n",
       "  -0.22008744,\n",
       "  0.3014258,\n",
       "  -0.1263316,\n",
       "  -0.07010015,\n",
       "  0.095497996,\n",
       "  0.026562855,\n",
       "  0.11051579,\n",
       "  0.095893845,\n",
       "  -0.09687604,\n",
       "  -0.040004022,\n",
       "  -0.064586945,\n",
       "  -0.020072628,\n",
       "  -0.011363552,\n",
       "  -0.06283822,\n",
       "  -0.14053279,\n",
       "  0.2275678,\n",
       "  0.027400106,\n",
       "  0.02107694,\n",
       "  -0.07802875,\n",
       "  0.106556706,\n",
       "  0.29641032,\n",
       "  0.13816877,\n",
       "  0.086406134,\n",
       "  -0.02613246,\n",
       "  -0.023903744,\n",
       "  0.045942128,\n",
       "  0.24331787,\n",
       "  0.22349456,\n",
       "  -0.009433716,\n",
       "  -0.2841691,\n",
       "  0.06887853,\n",
       "  0.0319599],\n",
       " [0.12079588,\n",
       "  0.1427154,\n",
       "  0.4294778,\n",
       "  0.24642906,\n",
       "  0.32837746,\n",
       "  -0.27581033,\n",
       "  -0.0047852914,\n",
       "  0.7513396,\n",
       "  -0.07666155,\n",
       "  -0.16147132,\n",
       "  -0.43617603,\n",
       "  -0.27704698,\n",
       "  -0.1587978,\n",
       "  0.09140129,\n",
       "  -0.21228227,\n",
       "  -0.23303594,\n",
       "  0.27500555,\n",
       "  -0.52005386,\n",
       "  -0.08173547,\n",
       "  -0.20885734,\n",
       "  -0.32892337,\n",
       "  0.08516193,\n",
       "  0.29203373,\n",
       "  -0.32871467,\n",
       "  -0.39159805,\n",
       "  0.5779818,\n",
       "  -0.2511165,\n",
       "  -0.3086702,\n",
       "  -0.32549146,\n",
       "  0.24898078,\n",
       "  0.33315736,\n",
       "  0.08830341,\n",
       "  0.27224314,\n",
       "  0.0858396,\n",
       "  0.00408758,\n",
       "  0.24653998,\n",
       "  -0.009524475,\n",
       "  -0.20030019,\n",
       "  -0.30713865,\n",
       "  -0.6046832,\n",
       "  -0.3191741,\n",
       "  0.13756378,\n",
       "  0.17428909,\n",
       "  0.13555208,\n",
       "  -0.07923171,\n",
       "  -0.30967334,\n",
       "  0.31519988,\n",
       "  0.31642815,\n",
       "  0.16517833,\n",
       "  0.037289586,\n",
       "  0.06824967,\n",
       "  -0.36837217,\n",
       "  0.22797546,\n",
       "  -0.018124914,\n",
       "  -0.37530044,\n",
       "  0.18813387,\n",
       "  0.15404381,\n",
       "  0.121742755,\n",
       "  -0.29833496,\n",
       "  -0.34895027,\n",
       "  0.12137045,\n",
       "  0.28690195,\n",
       "  0.0028990975,\n",
       "  0.23989002,\n",
       "  -0.2834394,\n",
       "  0.27026433,\n",
       "  -0.32823923,\n",
       "  -0.020316703,\n",
       "  -0.3355128,\n",
       "  0.35180274,\n",
       "  -0.11453145,\n",
       "  0.19966704,\n",
       "  0.36242944,\n",
       "  0.007257474,\n",
       "  0.3302129,\n",
       "  0.13750045,\n",
       "  -0.13149443,\n",
       "  0.1281098,\n",
       "  -0.20548126,\n",
       "  -0.14894384,\n",
       "  0.3247726,\n",
       "  0.07368113,\n",
       "  -0.07502533,\n",
       "  0.054139946,\n",
       "  -0.16923863,\n",
       "  0.0049709496,\n",
       "  0.17899252,\n",
       "  0.12816387,\n",
       "  -0.06398459,\n",
       "  0.02858601,\n",
       "  0.28184557,\n",
       "  0.093215965,\n",
       "  0.40211087,\n",
       "  -0.052952442,\n",
       "  0.51212615,\n",
       "  0.30055615,\n",
       "  -0.019595686,\n",
       "  -0.2024007,\n",
       "  0.15424238,\n",
       "  -0.08649692],\n",
       " [-0.30266774,\n",
       "  0.4622473,\n",
       "  0.10289479,\n",
       "  0.117987566,\n",
       "  0.14519437,\n",
       "  -0.21200384,\n",
       "  0.08542729,\n",
       "  0.42765945,\n",
       "  0.42949176,\n",
       "  -0.2575145,\n",
       "  0.12448896,\n",
       "  -0.3072965,\n",
       "  -0.121002935,\n",
       "  0.014733391,\n",
       "  0.24625637,\n",
       "  -0.019978225,\n",
       "  0.4643002,\n",
       "  -0.1813912,\n",
       "  -0.10411296,\n",
       "  -0.12985289,\n",
       "  -0.17562836,\n",
       "  -0.05893172,\n",
       "  0.2437892,\n",
       "  -0.068124406,\n",
       "  0.12512809,\n",
       "  0.08915625,\n",
       "  -0.30378047,\n",
       "  -0.27523637,\n",
       "  -0.07554268,\n",
       "  0.08624719,\n",
       "  0.756934,\n",
       "  0.024768874,\n",
       "  0.030738793,\n",
       "  0.21769007,\n",
       "  -0.1472476,\n",
       "  0.11761656,\n",
       "  0.17373624,\n",
       "  -0.44846,\n",
       "  -0.3022282,\n",
       "  -0.45212635,\n",
       "  -0.2679828,\n",
       "  -0.07669707,\n",
       "  0.32836732,\n",
       "  -0.42037278,\n",
       "  0.37367103,\n",
       "  0.15879656,\n",
       "  0.26572227,\n",
       "  0.09680686,\n",
       "  0.006782126,\n",
       "  0.36667866,\n",
       "  0.36302912,\n",
       "  -0.23975228,\n",
       "  -0.09477909,\n",
       "  0.020045064,\n",
       "  -0.30897483,\n",
       "  0.07751058,\n",
       "  0.3206777,\n",
       "  0.12807918,\n",
       "  -0.19861117,\n",
       "  -0.19433548,\n",
       "  0.20295082,\n",
       "  0.20078887,\n",
       "  -0.2885886,\n",
       "  -0.07583705,\n",
       "  -0.25283834,\n",
       "  -0.11526496,\n",
       "  0.18493606,\n",
       "  -0.051808037,\n",
       "  -0.27988666,\n",
       "  0.4916907,\n",
       "  -0.31441435,\n",
       "  -0.38972235,\n",
       "  0.053251423,\n",
       "  0.1326645,\n",
       "  0.17514737,\n",
       "  0.18651286,\n",
       "  -0.2009043,\n",
       "  0.021821525,\n",
       "  -0.11594932,\n",
       "  -0.05610851,\n",
       "  0.22335905,\n",
       "  0.16587262,\n",
       "  -0.35806283,\n",
       "  0.3555592,\n",
       "  0.40089408,\n",
       "  0.086491,\n",
       "  0.29114208,\n",
       "  -0.20782244,\n",
       "  -0.076382264,\n",
       "  0.23299223,\n",
       "  -0.08091971,\n",
       "  -0.083352216,\n",
       "  -0.07224742,\n",
       "  0.18197471,\n",
       "  0.42838228,\n",
       "  0.24071632,\n",
       "  0.06706297,\n",
       "  -0.5099573,\n",
       "  0.085854165,\n",
       "  -0.118681],\n",
       " [-0.10184931,\n",
       "  0.15921463,\n",
       "  0.055266358,\n",
       "  0.18287359,\n",
       "  0.04075872,\n",
       "  -0.21280293,\n",
       "  0.05874612,\n",
       "  0.40235275,\n",
       "  0.08406835,\n",
       "  -0.11308103,\n",
       "  -0.10724286,\n",
       "  -0.22738534,\n",
       "  -0.097868346,\n",
       "  0.08564199,\n",
       "  0.019518808,\n",
       "  -0.12652266,\n",
       "  0.14918302,\n",
       "  -0.15386885,\n",
       "  0.029816197,\n",
       "  -0.23660737,\n",
       "  0.041178133,\n",
       "  -0.0015984986,\n",
       "  0.08408637,\n",
       "  -0.023685269,\n",
       "  -0.055629276,\n",
       "  -0.014996525,\n",
       "  -0.24059378,\n",
       "  -0.19755594,\n",
       "  -0.05637302,\n",
       "  0.039213367,\n",
       "  0.3066712,\n",
       "  0.057502434,\n",
       "  -0.02304128,\n",
       "  0.013296092,\n",
       "  -0.018625038,\n",
       "  0.13069758,\n",
       "  0.028310217,\n",
       "  -0.21719973,\n",
       "  -0.113201834,\n",
       "  -0.2758184,\n",
       "  0.016651276,\n",
       "  -0.19355369,\n",
       "  0.113033466,\n",
       "  -0.09712891,\n",
       "  0.14689118,\n",
       "  0.01350908,\n",
       "  -0.056297883,\n",
       "  0.0870093,\n",
       "  0.060457237,\n",
       "  0.12108589,\n",
       "  0.2084903,\n",
       "  -0.20824993,\n",
       "  -0.056824815,\n",
       "  0.022098111,\n",
       "  -0.19269368,\n",
       "  0.09698888,\n",
       "  0.1969695,\n",
       "  -0.052976612,\n",
       "  -0.08302353,\n",
       "  -0.06149473,\n",
       "  0.06767528,\n",
       "  0.0872391,\n",
       "  -0.044159003,\n",
       "  0.0678102,\n",
       "  -0.21514042,\n",
       "  0.056767777,\n",
       "  0.0005216043,\n",
       "  0.10111504,\n",
       "  -0.21112925,\n",
       "  0.26969138,\n",
       "  -0.114022635,\n",
       "  -0.03419273,\n",
       "  0.110978216,\n",
       "  0.046527144,\n",
       "  0.15803725,\n",
       "  0.06155638,\n",
       "  -0.09044034,\n",
       "  -0.03370027,\n",
       "  -0.021763742,\n",
       "  -0.009172507,\n",
       "  -0.009411796,\n",
       "  -0.05824882,\n",
       "  -0.17508747,\n",
       "  0.2288705,\n",
       "  0.0646149,\n",
       "  0.08187,\n",
       "  -0.024728611,\n",
       "  0.11613122,\n",
       "  0.33119777,\n",
       "  0.15674172,\n",
       "  0.06622395,\n",
       "  0.03515985,\n",
       "  -0.018072136,\n",
       "  0.10040283,\n",
       "  0.30436274,\n",
       "  0.20787463,\n",
       "  -0.006408958,\n",
       "  -0.23179288,\n",
       "  0.08482385,\n",
       "  0.033728085],\n",
       " [0.081538126,\n",
       "  0.041676674,\n",
       "  0.380213,\n",
       "  -0.17789961,\n",
       "  0.11297325,\n",
       "  -0.4387567,\n",
       "  0.14470027,\n",
       "  0.50527483,\n",
       "  -0.12920836,\n",
       "  -0.3506735,\n",
       "  0.011973527,\n",
       "  -0.5639185,\n",
       "  -0.070556164,\n",
       "  0.21527939,\n",
       "  -0.1153086,\n",
       "  -0.2547377,\n",
       "  0.30940005,\n",
       "  -0.45539507,\n",
       "  0.06737146,\n",
       "  -0.36362997,\n",
       "  -0.58165663,\n",
       "  0.008557908,\n",
       "  0.40141946,\n",
       "  -0.4347008,\n",
       "  -0.43271905,\n",
       "  0.3333492,\n",
       "  -0.33055764,\n",
       "  -0.35784388,\n",
       "  -0.24152534,\n",
       "  0.18508026,\n",
       "  0.13298768,\n",
       "  -0.13905315,\n",
       "  0.21400082,\n",
       "  0.22853023,\n",
       "  -0.13058384,\n",
       "  0.2322841,\n",
       "  -0.26271108,\n",
       "  -0.42054597,\n",
       "  -0.19115466,\n",
       "  -0.74443316,\n",
       "  -0.3309483,\n",
       "  0.22470056,\n",
       "  0.5222587,\n",
       "  0.14043024,\n",
       "  0.4418146,\n",
       "  -0.3487113,\n",
       "  0.60157377,\n",
       "  -0.17935146,\n",
       "  0.40256333,\n",
       "  0.13964137,\n",
       "  -0.34083596,\n",
       "  -0.29999438,\n",
       "  0.06614859,\n",
       "  0.0639784,\n",
       "  -0.5275825,\n",
       "  0.014265448,\n",
       "  0.28053373,\n",
       "  0.3022284,\n",
       "  0.097818784,\n",
       "  -0.058637552,\n",
       "  0.19465359,\n",
       "  0.57317066,\n",
       "  -0.3059222,\n",
       "  0.42049265,\n",
       "  -0.46535635,\n",
       "  0.21079572,\n",
       "  -0.38624918,\n",
       "  -0.14358485,\n",
       "  -0.20985107,\n",
       "  0.46670017,\n",
       "  -0.3609868,\n",
       "  -0.04848953,\n",
       "  0.5318139,\n",
       "  -0.06752972,\n",
       "  0.22708175,\n",
       "  0.54610854,\n",
       "  -0.060204487,\n",
       "  -0.045469068,\n",
       "  -0.35971162,\n",
       "  0.21937825,\n",
       "  0.29390985,\n",
       "  0.55420685,\n",
       "  -0.4986801,\n",
       "  0.18995062,\n",
       "  0.20326924,\n",
       "  0.4746336,\n",
       "  0.16309804,\n",
       "  0.18268447,\n",
       "  0.038676213,\n",
       "  0.18763292,\n",
       "  -0.05304082,\n",
       "  0.18721184,\n",
       "  0.12016942,\n",
       "  -0.04042344,\n",
       "  0.6675207,\n",
       "  0.4860301,\n",
       "  -0.07012942,\n",
       "  -0.5462708,\n",
       "  -0.07779451,\n",
       "  -0.0845969],\n",
       " [-0.22162713,\n",
       "  0.46263635,\n",
       "  0.042313375,\n",
       "  0.18638052,\n",
       "  -0.058185507,\n",
       "  -0.49343467,\n",
       "  -0.4071407,\n",
       "  0.3033321,\n",
       "  -0.31688032,\n",
       "  -0.14367197,\n",
       "  -0.18940276,\n",
       "  -0.70992124,\n",
       "  -0.18044849,\n",
       "  0.62554353,\n",
       "  -0.14815459,\n",
       "  0.042145334,\n",
       "  0.41327283,\n",
       "  -0.4384719,\n",
       "  0.104080364,\n",
       "  -0.30600774,\n",
       "  0.38280708,\n",
       "  -0.107164145,\n",
       "  0.053244557,\n",
       "  0.27253783,\n",
       "  -0.5920388,\n",
       "  0.27730182,\n",
       "  -0.72211283,\n",
       "  -0.15042584,\n",
       "  -0.008600849,\n",
       "  -0.3948369,\n",
       "  0.029254032,\n",
       "  -0.17669733,\n",
       "  0.24593276,\n",
       "  0.15277296,\n",
       "  0.36058822,\n",
       "  0.57386315,\n",
       "  -0.043321595,\n",
       "  -0.25287932,\n",
       "  -0.36845356,\n",
       "  -0.21420243,\n",
       "  0.22757435,\n",
       "  -0.13001971,\n",
       "  0.19756639,\n",
       "  -0.09286826,\n",
       "  0.37729084,\n",
       "  -0.22375296,\n",
       "  -0.8125406,\n",
       "  0.18671727,\n",
       "  0.15466814,\n",
       "  -0.22531451,\n",
       "  -0.026485218,\n",
       "  -0.6517548,\n",
       "  0.15222095,\n",
       "  0.09346693,\n",
       "  -0.40626904,\n",
       "  0.32860404,\n",
       "  0.0728489,\n",
       "  -0.28215685,\n",
       "  0.06293292,\n",
       "  0.050041687,\n",
       "  -0.20479512,\n",
       "  -0.004562398,\n",
       "  -0.22851728,\n",
       "  0.4452126,\n",
       "  0.048156574,\n",
       "  0.5305788,\n",
       "  -0.18811432,\n",
       "  0.24733488,\n",
       "  -0.26781672,\n",
       "  0.29428282,\n",
       "  -0.5423258,\n",
       "  0.23855127,\n",
       "  0.1492909,\n",
       "  -0.18698648,\n",
       "  0.2507944,\n",
       "  0.044202544,\n",
       "  -0.084321156,\n",
       "  -0.02491259,\n",
       "  0.1401989,\n",
       "  0.13785917,\n",
       "  -0.26406148,\n",
       "  -0.15125966,\n",
       "  -0.46934906,\n",
       "  0.27568567,\n",
       "  0.3511303,\n",
       "  0.708579,\n",
       "  -0.2007018,\n",
       "  0.18991137,\n",
       "  0.5628713,\n",
       "  0.104548156,\n",
       "  0.39599425,\n",
       "  -0.19183753,\n",
       "  0.07227624,\n",
       "  0.071482286,\n",
       "  0.66251945,\n",
       "  -0.1106209,\n",
       "  0.23421429,\n",
       "  -0.11377084,\n",
       "  0.6045117,\n",
       "  0.47550488],\n",
       " [-0.52921665,\n",
       "  0.42257765,\n",
       "  0.12753987,\n",
       "  0.012122203,\n",
       "  0.004380224,\n",
       "  -0.15083499,\n",
       "  -0.123021014,\n",
       "  0.2284533,\n",
       "  -0.16439061,\n",
       "  -0.22729495,\n",
       "  0.0036093218,\n",
       "  -0.48620802,\n",
       "  -0.17307395,\n",
       "  0.12789781,\n",
       "  0.08560395,\n",
       "  -0.33251366,\n",
       "  0.62550026,\n",
       "  -0.078210935,\n",
       "  -0.039413143,\n",
       "  -0.334918,\n",
       "  0.0056057675,\n",
       "  -0.118353054,\n",
       "  0.33063117,\n",
       "  0.009904495,\n",
       "  -0.42764527,\n",
       "  -0.031576756,\n",
       "  -0.41950947,\n",
       "  -0.20243838,\n",
       "  -0.12148061,\n",
       "  -0.13441773,\n",
       "  0.35880762,\n",
       "  0.0021006174,\n",
       "  0.025347194,\n",
       "  0.2590557,\n",
       "  0.10837722,\n",
       "  0.28486896,\n",
       "  0.111339,\n",
       "  -0.16965167,\n",
       "  -0.36278814,\n",
       "  -0.3679535,\n",
       "  -0.13483974,\n",
       "  0.0485764,\n",
       "  0.112000205,\n",
       "  -0.14428665,\n",
       "  0.06645057,\n",
       "  -0.0469771,\n",
       "  -0.05804466,\n",
       "  0.033991173,\n",
       "  0.19206949,\n",
       "  0.060797546,\n",
       "  0.15707767,\n",
       "  -0.3391115,\n",
       "  0.13138814,\n",
       "  0.087342545,\n",
       "  -0.44856486,\n",
       "  0.32661742,\n",
       "  0.04523314,\n",
       "  -0.18136209,\n",
       "  -0.22229226,\n",
       "  0.17378421,\n",
       "  0.038503643,\n",
       "  0.031036556,\n",
       "  0.08037329,\n",
       "  0.07715193,\n",
       "  -0.22305831,\n",
       "  0.5353195,\n",
       "  -0.36049291,\n",
       "  0.20230721,\n",
       "  -0.3361808,\n",
       "  0.31177184,\n",
       "  -0.1728437,\n",
       "  0.06343153,\n",
       "  0.22765265,\n",
       "  0.20439559,\n",
       "  0.15055747,\n",
       "  0.09940543,\n",
       "  -0.16433781,\n",
       "  0.025956571,\n",
       "  -0.021388888,\n",
       "  -0.15756942,\n",
       "  -0.037494924,\n",
       "  -0.21396653,\n",
       "  -0.22727184,\n",
       "  0.06864244,\n",
       "  0.21973833,\n",
       "  0.19391748,\n",
       "  0.11996964,\n",
       "  0.008162012,\n",
       "  0.4181182,\n",
       "  0.15089008,\n",
       "  0.068227984,\n",
       "  0.06441254,\n",
       "  0.03259793,\n",
       "  0.19629847,\n",
       "  0.69207674,\n",
       "  0.058373395,\n",
       "  -0.072616555,\n",
       "  -0.33007267,\n",
       "  -0.008593038,\n",
       "  0.08949718],\n",
       " [-0.4234018,\n",
       "  0.2936501,\n",
       "  0.10654593,\n",
       "  0.422387,\n",
       "  0.060069982,\n",
       "  -0.57130694,\n",
       "  -0.20175326,\n",
       "  0.40571308,\n",
       "  -0.6971355,\n",
       "  0.0073761865,\n",
       "  -0.36253288,\n",
       "  -0.345418,\n",
       "  -0.18535222,\n",
       "  0.24036638,\n",
       "  -0.057771664,\n",
       "  -0.0039299363,\n",
       "  0.04617503,\n",
       "  -0.37815213,\n",
       "  -0.16284434,\n",
       "  -0.7022808,\n",
       "  0.14180303,\n",
       "  0.3738264,\n",
       "  0.26523164,\n",
       "  0.035790507,\n",
       "  -0.15323123,\n",
       "  0.27977192,\n",
       "  -0.8125319,\n",
       "  0.28840217,\n",
       "  0.30672494,\n",
       "  -0.24494337,\n",
       "  0.118681215,\n",
       "  0.39982682,\n",
       "  -0.0075560478,\n",
       "  0.20756009,\n",
       "  0.11282547,\n",
       "  0.37947708,\n",
       "  -0.0104021365,\n",
       "  -0.19482954,\n",
       "  -0.17465705,\n",
       "  0.117795356,\n",
       "  0.3145107,\n",
       "  -0.4440752,\n",
       "  0.28238365,\n",
       "  -0.0514833,\n",
       "  0.2966103,\n",
       "  0.28973058,\n",
       "  -0.7361314,\n",
       "  0.574417,\n",
       "  -0.002751973,\n",
       "  -0.0583005,\n",
       "  -0.065723166,\n",
       "  -0.08641471,\n",
       "  -0.040176403,\n",
       "  0.24526076,\n",
       "  -0.42696798,\n",
       "  0.029529696,\n",
       "  0.47557175,\n",
       "  -0.020611994,\n",
       "  0.008786288,\n",
       "  0.069823585,\n",
       "  0.20063758,\n",
       "  0.060858395,\n",
       "  0.120757565,\n",
       "  0.6435156,\n",
       "  -0.45200235,\n",
       "  0.0029266877,\n",
       "  -0.018996647,\n",
       "  0.3167421,\n",
       "  -0.28797385,\n",
       "  0.464085,\n",
       "  -0.3288666,\n",
       "  0.10144624,\n",
       "  0.26160482,\n",
       "  -0.31124496,\n",
       "  0.462713,\n",
       "  -0.01500367,\n",
       "  0.09802407,\n",
       "  0.07114159,\n",
       "  0.36214888,\n",
       "  0.038888756,\n",
       "  -0.6418619,\n",
       "  -0.062119793,\n",
       "  -0.14148486,\n",
       "  0.339929,\n",
       "  -0.20026863,\n",
       "  0.49398708,\n",
       "  -0.24870211,\n",
       "  0.57165504,\n",
       "  0.93831986,\n",
       "  0.2127893,\n",
       "  0.26297417,\n",
       "  0.45930052,\n",
       "  0.06439845,\n",
       "  0.23344457,\n",
       "  0.3627595,\n",
       "  0.33504912,\n",
       "  0.12573007,\n",
       "  -0.34177706,\n",
       "  0.34789285,\n",
       "  0.54293305],\n",
       " [-0.6255731,\n",
       "  0.36214247,\n",
       "  -0.009540138,\n",
       "  0.26017454,\n",
       "  0.28664473,\n",
       "  -0.63116926,\n",
       "  -0.044651687,\n",
       "  0.8261708,\n",
       "  -0.5331271,\n",
       "  -0.18246812,\n",
       "  -0.12393199,\n",
       "  -0.41560405,\n",
       "  -0.35196108,\n",
       "  0.081162594,\n",
       "  0.1971953,\n",
       "  -0.48919106,\n",
       "  0.07651314,\n",
       "  -0.07907236,\n",
       "  -0.6230598,\n",
       "  -1.161404,\n",
       "  0.85838896,\n",
       "  0.5099749,\n",
       "  -0.382043,\n",
       "  0.19474012,\n",
       "  -0.58225334,\n",
       "  0.010385075,\n",
       "  -1.2081155,\n",
       "  0.19091372,\n",
       "  0.08915576,\n",
       "  -0.17349012,\n",
       "  -0.091603056,\n",
       "  0.37248656,\n",
       "  0.08260508,\n",
       "  -0.35353994,\n",
       "  0.18478465,\n",
       "  0.4075899,\n",
       "  -0.88943225,\n",
       "  -0.5854066,\n",
       "  0.4640359,\n",
       "  -0.54597193,\n",
       "  0.26215732,\n",
       "  -0.4874425,\n",
       "  0.42556584,\n",
       "  0.19540356,\n",
       "  0.40572232,\n",
       "  0.3423091,\n",
       "  -0.53536016,\n",
       "  0.14499867,\n",
       "  0.31877553,\n",
       "  -0.3319907,\n",
       "  0.45206594,\n",
       "  -0.20952961,\n",
       "  -0.26072618,\n",
       "  0.33758828,\n",
       "  -0.4760192,\n",
       "  0.7526837,\n",
       "  0.21451095,\n",
       "  -0.36602113,\n",
       "  0.50253767,\n",
       "  0.38305435,\n",
       "  -0.1329273,\n",
       "  0.85289586,\n",
       "  -0.09367502,\n",
       "  0.45046425,\n",
       "  -0.6895916,\n",
       "  0.69794494,\n",
       "  -0.43327367,\n",
       "  0.022635896,\n",
       "  -0.39058566,\n",
       "  0.4311476,\n",
       "  -0.4939899,\n",
       "  0.23863089,\n",
       "  0.66763,\n",
       "  0.21439275,\n",
       "  0.38910025,\n",
       "  0.36759466,\n",
       "  0.14122583,\n",
       "  -0.5080891,\n",
       "  0.20793332,\n",
       "  -0.22322807,\n",
       "  -0.31756526,\n",
       "  -0.10355748,\n",
       "  -0.43570253,\n",
       "  0.5047615,\n",
       "  0.020342551,\n",
       "  0.9187383,\n",
       "  -0.44509783,\n",
       "  0.569629,\n",
       "  1.8534553,\n",
       "  0.37600374,\n",
       "  0.24153431,\n",
       "  0.28202716,\n",
       "  0.8528289,\n",
       "  -0.040972374,\n",
       "  0.12445011,\n",
       "  0.08990892,\n",
       "  -0.17197752,\n",
       "  -0.36140746,\n",
       "  -0.056045644,\n",
       "  0.14649302],\n",
       " [-0.30151704,\n",
       "  0.17614035,\n",
       "  0.17436394,\n",
       "  0.3751836,\n",
       "  0.123352244,\n",
       "  -0.55051833,\n",
       "  0.1348981,\n",
       "  0.478169,\n",
       "  -0.5639281,\n",
       "  -0.19454712,\n",
       "  -0.18596914,\n",
       "  -0.37520838,\n",
       "  -0.11095704,\n",
       "  0.4523596,\n",
       "  0.011518512,\n",
       "  0.1475376,\n",
       "  0.3385907,\n",
       "  -0.21647377,\n",
       "  -0.43975925,\n",
       "  -0.9172251,\n",
       "  -0.119493626,\n",
       "  0.6499132,\n",
       "  0.24152128,\n",
       "  0.0037131598,\n",
       "  -0.307352,\n",
       "  0.23112282,\n",
       "  -0.74385273,\n",
       "  -0.04711682,\n",
       "  0.39349565,\n",
       "  -0.3171765,\n",
       "  0.0816807,\n",
       "  0.16478819,\n",
       "  -0.011962164,\n",
       "  0.26508924,\n",
       "  -0.12483969,\n",
       "  0.42714092,\n",
       "  -0.060206324,\n",
       "  -0.26892376,\n",
       "  -0.4030479,\n",
       "  -0.0061529703,\n",
       "  0.17531879,\n",
       "  -0.41957352,\n",
       "  0.16016315,\n",
       "  0.0032098491,\n",
       "  0.2766542,\n",
       "  0.24620804,\n",
       "  -0.6258605,\n",
       "  0.40374878,\n",
       "  0.09261906,\n",
       "  0.25185916,\n",
       "  -0.09268866,\n",
       "  -0.13267903,\n",
       "  -0.008489609,\n",
       "  0.42542562,\n",
       "  -0.33480924,\n",
       "  0.052693035,\n",
       "  0.4865048,\n",
       "  0.0580766,\n",
       "  0.022671446,\n",
       "  0.2182754,\n",
       "  -0.011320658,\n",
       "  -0.020120203,\n",
       "  0.17173782,\n",
       "  0.39488184,\n",
       "  -0.6529747,\n",
       "  0.26352218,\n",
       "  -0.17643519,\n",
       "  0.276854,\n",
       "  -0.25893617,\n",
       "  0.2811169,\n",
       "  -0.20373024,\n",
       "  0.06251508,\n",
       "  0.29187387,\n",
       "  -0.4351259,\n",
       "  0.5163287,\n",
       "  -0.08305314,\n",
       "  0.20193146,\n",
       "  0.10319835,\n",
       "  0.10675019,\n",
       "  0.2564064,\n",
       "  -0.4500556,\n",
       "  0.15971752,\n",
       "  -0.04369839,\n",
       "  0.50349,\n",
       "  -0.23450805,\n",
       "  0.4236679,\n",
       "  -0.2728893,\n",
       "  0.4774831,\n",
       "  0.9026762,\n",
       "  0.500612,\n",
       "  0.23214918,\n",
       "  0.34614438,\n",
       "  0.21219625,\n",
       "  0.3677854,\n",
       "  0.42948487,\n",
       "  0.4625298,\n",
       "  0.22052036,\n",
       "  -0.22324356,\n",
       "  0.16441086,\n",
       "  0.3952601],\n",
       " [-0.6255731,\n",
       "  0.36214247,\n",
       "  -0.009540138,\n",
       "  0.26017454,\n",
       "  0.28664473,\n",
       "  -0.63116926,\n",
       "  -0.044651687,\n",
       "  0.8261708,\n",
       "  -0.5331271,\n",
       "  -0.18246812,\n",
       "  -0.12393199,\n",
       "  -0.41560405,\n",
       "  -0.35196108,\n",
       "  0.081162594,\n",
       "  0.1971953,\n",
       "  -0.48919106,\n",
       "  0.07651314,\n",
       "  -0.07907236,\n",
       "  -0.6230598,\n",
       "  -1.161404,\n",
       "  0.85838896,\n",
       "  0.5099749,\n",
       "  -0.382043,\n",
       "  0.19474012,\n",
       "  -0.58225334,\n",
       "  0.010385075,\n",
       "  -1.2081155,\n",
       "  0.19091372,\n",
       "  0.08915576,\n",
       "  -0.17349012,\n",
       "  -0.091603056,\n",
       "  0.37248656,\n",
       "  0.08260508,\n",
       "  -0.35353994,\n",
       "  0.18478465,\n",
       "  0.4075899,\n",
       "  -0.88943225,\n",
       "  -0.5854066,\n",
       "  0.4640359,\n",
       "  -0.54597193,\n",
       "  0.26215732,\n",
       "  -0.4874425,\n",
       "  0.42556584,\n",
       "  0.19540356,\n",
       "  0.40572232,\n",
       "  0.3423091,\n",
       "  -0.53536016,\n",
       "  0.14499867,\n",
       "  0.31877553,\n",
       "  -0.3319907,\n",
       "  0.45206594,\n",
       "  -0.20952961,\n",
       "  -0.26072618,\n",
       "  0.33758828,\n",
       "  -0.4760192,\n",
       "  0.7526837,\n",
       "  0.21451095,\n",
       "  -0.36602113,\n",
       "  0.50253767,\n",
       "  0.38305435,\n",
       "  -0.1329273,\n",
       "  0.85289586,\n",
       "  -0.09367502,\n",
       "  0.45046425,\n",
       "  -0.6895916,\n",
       "  0.69794494,\n",
       "  -0.43327367,\n",
       "  0.022635896,\n",
       "  -0.39058566,\n",
       "  0.4311476,\n",
       "  -0.4939899,\n",
       "  0.23863089,\n",
       "  0.66763,\n",
       "  0.21439275,\n",
       "  0.38910025,\n",
       "  0.36759466,\n",
       "  0.14122583,\n",
       "  -0.5080891,\n",
       "  0.20793332,\n",
       "  -0.22322807,\n",
       "  -0.31756526,\n",
       "  -0.10355748,\n",
       "  -0.43570253,\n",
       "  0.5047615,\n",
       "  0.020342551,\n",
       "  0.9187383,\n",
       "  -0.44509783,\n",
       "  0.569629,\n",
       "  1.8534553,\n",
       "  0.37600374,\n",
       "  0.24153431,\n",
       "  0.28202716,\n",
       "  0.8528289,\n",
       "  -0.040972374,\n",
       "  0.12445011,\n",
       "  0.08990892,\n",
       "  -0.17197752,\n",
       "  -0.36140746,\n",
       "  -0.056045644,\n",
       "  0.14649302],\n",
       " [-0.070742376,\n",
       "  0.2639105,\n",
       "  0.06421832,\n",
       "  -0.018682206,\n",
       "  -0.024604356,\n",
       "  -0.10366982,\n",
       "  0.18068835,\n",
       "  0.45306727,\n",
       "  0.06887333,\n",
       "  0.19102167,\n",
       "  -0.2605217,\n",
       "  -0.26811585,\n",
       "  -0.19927165,\n",
       "  -0.09049199,\n",
       "  -0.12563154,\n",
       "  -0.12887068,\n",
       "  0.349089,\n",
       "  -0.42134935,\n",
       "  0.26039112,\n",
       "  -0.059575595,\n",
       "  0.011616617,\n",
       "  -0.17546573,\n",
       "  0.09057576,\n",
       "  -0.118680894,\n",
       "  -0.42605132,\n",
       "  -0.023620268,\n",
       "  -0.34370685,\n",
       "  -0.66432667,\n",
       "  -0.095578276,\n",
       "  0.116742395,\n",
       "  0.4519417,\n",
       "  -0.03478936,\n",
       "  0.08474288,\n",
       "  -0.1017213,\n",
       "  0.12583779,\n",
       "  0.0806478,\n",
       "  0.2006714,\n",
       "  0.09502611,\n",
       "  -0.15703392,\n",
       "  -0.31119773,\n",
       "  -0.14358115,\n",
       "  -0.13787931,\n",
       "  0.022426818,\n",
       "  0.013337534,\n",
       "  -0.008856883,\n",
       "  -0.22254764,\n",
       "  -0.21685481,\n",
       "  -0.07622588,\n",
       "  0.34509572,\n",
       "  0.08943676,\n",
       "  0.11463569,\n",
       "  -0.2356035,\n",
       "  0.37667122,\n",
       "  -0.105004944,\n",
       "  -0.19344394,\n",
       "  0.33641508,\n",
       "  0.19376066,\n",
       "  -0.08299983,\n",
       "  -0.51254094,\n",
       "  -0.07336042,\n",
       "  -0.115305535,\n",
       "  -0.02741611,\n",
       "  -0.16592799,\n",
       "  0.10644481,\n",
       "  -0.35310054,\n",
       "  0.08091174,\n",
       "  0.09495488,\n",
       "  0.28861544,\n",
       "  -0.43348187,\n",
       "  0.36492577,\n",
       "  -0.15537705,\n",
       "  -0.15898485,\n",
       "  0.062636055,\n",
       "  0.18279104,\n",
       "  0.1012521,\n",
       "  0.12215824,\n",
       "  -0.016571304,\n",
       "  0.047543548,\n",
       "  -0.12904178,\n",
       "  -0.060699847,\n",
       "  -0.18761322,\n",
       "  -0.2886173,\n",
       "  -0.15595204,\n",
       "  0.110982485,\n",
       "  0.11428712,\n",
       "  -0.02273543,\n",
       "  0.156592,\n",
       "  0.24734682,\n",
       "  0.18894209,\n",
       "  -0.02082608,\n",
       "  0.41217628,\n",
       "  -0.2725034,\n",
       "  -0.048950117,\n",
       "  -0.031451944,\n",
       "  0.36899963,\n",
       "  0.4239802,\n",
       "  0.082470834,\n",
       "  -0.30914724,\n",
       "  0.2041984,\n",
       "  -0.11735468],\n",
       " [0.04663509,\n",
       "  0.28573048,\n",
       "  0.05724531,\n",
       "  0.42081454,\n",
       "  0.020753738,\n",
       "  -0.088945284,\n",
       "  -0.16796665,\n",
       "  0.5110772,\n",
       "  -0.045796387,\n",
       "  0.33086726,\n",
       "  -0.6008228,\n",
       "  -0.12176116,\n",
       "  -0.30678046,\n",
       "  -0.24036434,\n",
       "  -0.29427528,\n",
       "  -0.42802575,\n",
       "  -0.14813785,\n",
       "  -0.57063496,\n",
       "  0.23087867,\n",
       "  -0.10114052,\n",
       "  0.15260862,\n",
       "  -0.10891562,\n",
       "  0.13507979,\n",
       "  -0.07698076,\n",
       "  -0.33558732,\n",
       "  0.0588551,\n",
       "  -0.44986618,\n",
       "  -0.4973684,\n",
       "  -0.027962726,\n",
       "  -0.0056617768,\n",
       "  0.28577575,\n",
       "  0.14658327,\n",
       "  -0.14458816,\n",
       "  -0.035434734,\n",
       "  0.1170328,\n",
       "  -0.12241182,\n",
       "  0.034133796,\n",
       "  0.03311692,\n",
       "  -0.04263337,\n",
       "  -0.2636612,\n",
       "  0.30809608,\n",
       "  -0.27067134,\n",
       "  0.34017357,\n",
       "  0.17113726,\n",
       "  -0.057264067,\n",
       "  -0.08236419,\n",
       "  -0.4586951,\n",
       "  0.30338046,\n",
       "  0.03689156,\n",
       "  -0.06577098,\n",
       "  0.24255694,\n",
       "  -0.28213024,\n",
       "  0.30554983,\n",
       "  -0.14545417,\n",
       "  -0.4815627,\n",
       "  0.15475659,\n",
       "  0.28268698,\n",
       "  0.029537657,\n",
       "  -0.18213087,\n",
       "  -0.2550401,\n",
       "  0.17924833,\n",
       "  0.0688556,\n",
       "  -0.09256252,\n",
       "  0.2505867,\n",
       "  -0.1717676,\n",
       "  -0.017295552,\n",
       "  0.20156994,\n",
       "  0.17481872,\n",
       "  -0.3875982,\n",
       "  0.351879,\n",
       "  -0.2955338,\n",
       "  -0.019675482,\n",
       "  0.01445346,\n",
       "  0.066487074,\n",
       "  0.16207471,\n",
       "  0.032654516,\n",
       "  -0.1329857,\n",
       "  0.15184464,\n",
       "  -0.014107808,\n",
       "  0.018469648,\n",
       "  -0.23528525,\n",
       "  -0.49828365,\n",
       "  -0.05052066,\n",
       "  0.052052844,\n",
       "  -0.33710808,\n",
       "  0.02075076,\n",
       "  -0.23479144,\n",
       "  0.55502814,\n",
       "  0.44293728,\n",
       "  0.07181028,\n",
       "  0.12817547,\n",
       "  -0.08328637,\n",
       "  -0.14282064,\n",
       "  -0.091621205,\n",
       "  0.17897937,\n",
       "  0.41017336,\n",
       "  -0.05769793,\n",
       "  -0.123569146,\n",
       "  0.18329842,\n",
       "  0.096707195],\n",
       " [0.022928026,\n",
       "  0.03557612,\n",
       "  0.20414266,\n",
       "  0.1752098,\n",
       "  0.014518613,\n",
       "  -0.35887656,\n",
       "  0.19565359,\n",
       "  0.5188583,\n",
       "  -0.063977495,\n",
       "  -0.17197703,\n",
       "  -0.09207029,\n",
       "  -0.2958509,\n",
       "  -0.039690163,\n",
       "  0.21914887,\n",
       "  0.05907546,\n",
       "  -0.016328787,\n",
       "  0.23266846,\n",
       "  -0.24516232,\n",
       "  -0.19313456,\n",
       "  -0.5021864,\n",
       "  0.13863966,\n",
       "  0.34887546,\n",
       "  0.14431715,\n",
       "  -0.20434807,\n",
       "  -0.18903604,\n",
       "  0.14183521,\n",
       "  -0.3530866,\n",
       "  -0.1927377,\n",
       "  0.023782138,\n",
       "  0.124993205,\n",
       "  0.30165273,\n",
       "  0.13127261,\n",
       "  0.1094013,\n",
       "  -0.023657523,\n",
       "  -0.040720757,\n",
       "  0.29471785,\n",
       "  -0.21972333,\n",
       "  -0.2457936,\n",
       "  -0.34112728,\n",
       "  -0.5934362,\n",
       "  -0.023933148,\n",
       "  -0.100041814,\n",
       "  0.039746646,\n",
       "  -0.09930764,\n",
       "  0.22989596,\n",
       "  -0.24667157,\n",
       "  -0.2600234,\n",
       "  0.037193455,\n",
       "  0.35185516,\n",
       "  0.07634618,\n",
       "  0.050328303,\n",
       "  -0.22026604,\n",
       "  0.031947132,\n",
       "  0.03957528,\n",
       "  -0.20979032,\n",
       "  0.28249848,\n",
       "  0.16840033,\n",
       "  0.02617394,\n",
       "  -0.1856135,\n",
       "  0.26376867,\n",
       "  -0.094239146,\n",
       "  0.09417564,\n",
       "  0.033493135,\n",
       "  0.24713443,\n",
       "  -0.41295022,\n",
       "  0.2937478,\n",
       "  -0.268785,\n",
       "  0.015202322,\n",
       "  -0.331948,\n",
       "  0.06316648,\n",
       "  0.02758094,\n",
       "  0.043166008,\n",
       "  0.22460441,\n",
       "  -0.042554785,\n",
       "  0.31302625,\n",
       "  -0.07689582,\n",
       "  0.162268,\n",
       "  -0.20790301,\n",
       "  -0.17991905,\n",
       "  0.12768404,\n",
       "  -0.036856886,\n",
       "  0.15436874,\n",
       "  -0.14800529,\n",
       "  0.24463463,\n",
       "  0.068288274,\n",
       "  0.16441883,\n",
       "  0.009702263,\n",
       "  0.20206322,\n",
       "  0.6943125,\n",
       "  0.20991628,\n",
       "  0.35332164,\n",
       "  0.05881753,\n",
       "  0.057087384,\n",
       "  0.16287047,\n",
       "  0.27502206,\n",
       "  0.228284,\n",
       "  -0.00059682305,\n",
       "  -0.35054007,\n",
       "  0.21081786,\n",
       "  0.22901253],\n",
       " [-0.22162713,\n",
       "  0.46263635,\n",
       "  0.042313375,\n",
       "  0.18638052,\n",
       "  -0.058185507,\n",
       "  -0.49343467,\n",
       "  -0.4071407,\n",
       "  0.3033321,\n",
       "  -0.31688032,\n",
       "  -0.14367197,\n",
       "  -0.18940276,\n",
       "  -0.70992124,\n",
       "  -0.18044849,\n",
       "  0.62554353,\n",
       "  -0.14815459,\n",
       "  0.042145334,\n",
       "  0.41327283,\n",
       "  -0.4384719,\n",
       "  0.104080364,\n",
       "  -0.30600774,\n",
       "  0.38280708,\n",
       "  -0.107164145,\n",
       "  0.053244557,\n",
       "  0.27253783,\n",
       "  -0.5920388,\n",
       "  0.27730182,\n",
       "  -0.72211283,\n",
       "  -0.15042584,\n",
       "  -0.008600849,\n",
       "  -0.3948369,\n",
       "  0.029254032,\n",
       "  -0.17669733,\n",
       "  0.24593276,\n",
       "  0.15277296,\n",
       "  0.36058822,\n",
       "  0.57386315,\n",
       "  -0.043321595,\n",
       "  -0.25287932,\n",
       "  -0.36845356,\n",
       "  -0.21420243,\n",
       "  0.22757435,\n",
       "  -0.13001971,\n",
       "  0.19756639,\n",
       "  -0.09286826,\n",
       "  0.37729084,\n",
       "  -0.22375296,\n",
       "  -0.8125406,\n",
       "  0.18671727,\n",
       "  0.15466814,\n",
       "  -0.22531451,\n",
       "  -0.026485218,\n",
       "  -0.6517548,\n",
       "  0.15222095,\n",
       "  0.09346693,\n",
       "  -0.40626904,\n",
       "  0.32860404,\n",
       "  0.0728489,\n",
       "  -0.28215685,\n",
       "  0.06293292,\n",
       "  0.050041687,\n",
       "  -0.20479512,\n",
       "  -0.004562398,\n",
       "  -0.22851728,\n",
       "  0.4452126,\n",
       "  0.048156574,\n",
       "  0.5305788,\n",
       "  -0.18811432,\n",
       "  0.24733488,\n",
       "  -0.26781672,\n",
       "  0.29428282,\n",
       "  -0.5423258,\n",
       "  0.23855127,\n",
       "  0.1492909,\n",
       "  -0.18698648,\n",
       "  0.2507944,\n",
       "  0.044202544,\n",
       "  -0.084321156,\n",
       "  -0.02491259,\n",
       "  0.1401989,\n",
       "  0.13785917,\n",
       "  -0.26406148,\n",
       "  -0.15125966,\n",
       "  -0.46934906,\n",
       "  0.27568567,\n",
       "  0.3511303,\n",
       "  0.708579,\n",
       "  -0.2007018,\n",
       "  0.18991137,\n",
       "  0.5628713,\n",
       "  0.104548156,\n",
       "  0.39599425,\n",
       "  -0.19183753,\n",
       "  0.07227624,\n",
       "  0.071482286,\n",
       "  0.66251945,\n",
       "  -0.1106209,\n",
       "  0.23421429,\n",
       "  -0.11377084,\n",
       "  0.6045117,\n",
       "  0.47550488],\n",
       " [-0.32046258,\n",
       "  -0.102361314,\n",
       "  0.27096745,\n",
       "  0.33284256,\n",
       "  -0.26460373,\n",
       "  -0.26447165,\n",
       "  -0.10934898,\n",
       "  0.3940659,\n",
       "  0.15650426,\n",
       "  -0.029767131,\n",
       "  -0.18825036,\n",
       "  -0.49095613,\n",
       "  0.14349857,\n",
       "  0.51983976,\n",
       "  -0.053438377,\n",
       "  -0.0586244,\n",
       "  0.5000267,\n",
       "  0.031549174,\n",
       "  -0.06524104,\n",
       "  -0.3552327,\n",
       "  0.052875496,\n",
       "  0.004403376,\n",
       "  -0.28439516,\n",
       "  -0.02913107,\n",
       "  -0.15153143,\n",
       "  -0.29626733,\n",
       "  -0.27935708,\n",
       "  -0.3365242,\n",
       "  0.0016799959,\n",
       "  -0.29712734,\n",
       "  0.3346331,\n",
       "  0.16493426,\n",
       "  0.43156165,\n",
       "  0.5067443,\n",
       "  0.05304709,\n",
       "  0.2531781,\n",
       "  -0.07129024,\n",
       "  -0.43386263,\n",
       "  -0.7287027,\n",
       "  -0.7742067,\n",
       "  -0.12076207,\n",
       "  0.25294825,\n",
       "  0.28254718,\n",
       "  -0.5432252,\n",
       "  0.30012152,\n",
       "  -0.24163686,\n",
       "  -0.09690069,\n",
       "  -0.06274841,\n",
       "  0.19818482,\n",
       "  0.25347584,\n",
       "  0.35465893,\n",
       "  -0.22533663,\n",
       "  -0.41781884,\n",
       "  0.3542716,\n",
       "  -0.13965948,\n",
       "  0.32674155,\n",
       "  0.120496266,\n",
       "  -0.2597399,\n",
       "  -0.1397471,\n",
       "  0.40222543,\n",
       "  -0.22685118,\n",
       "  0.3091001,\n",
       "  0.15203805,\n",
       "  0.12336286,\n",
       "  0.034191865,\n",
       "  0.3369217,\n",
       "  -0.25652424,\n",
       "  0.15513502,\n",
       "  -0.054159526,\n",
       "  0.004690613,\n",
       "  0.012965037,\n",
       "  -0.045205727,\n",
       "  0.35069,\n",
       "  -0.13728556,\n",
       "  0.16353005,\n",
       "  -0.3689679,\n",
       "  0.13450664,\n",
       "  -0.49595398,\n",
       "  -0.42707708,\n",
       "  0.23488997,\n",
       "  -0.124494515,\n",
       "  0.275136,\n",
       "  -0.28848213,\n",
       "  0.7424928,\n",
       "  0.034715507,\n",
       "  0.5864383,\n",
       "  -0.018067246,\n",
       "  0.10347901,\n",
       "  0.55607635,\n",
       "  0.2942023,\n",
       "  0.33190793,\n",
       "  0.08873995,\n",
       "  -0.19259219,\n",
       "  0.5015276,\n",
       "  0.8547632,\n",
       "  0.24225214,\n",
       "  0.12650484,\n",
       "  -0.5708837,\n",
       "  0.29739362,\n",
       "  0.4791695],\n",
       " [-0.60265213,\n",
       "  -0.020975737,\n",
       "  0.039546248,\n",
       "  0.05865323,\n",
       "  -0.42571923,\n",
       "  -0.64075655,\n",
       "  -0.19836816,\n",
       "  0.6324955,\n",
       "  0.21202327,\n",
       "  0.048182935,\n",
       "  -0.24337904,\n",
       "  -0.3342365,\n",
       "  0.28853783,\n",
       "  0.045862414,\n",
       "  -0.12108438,\n",
       "  0.12811014,\n",
       "  0.30562764,\n",
       "  -0.07090481,\n",
       "  -0.008301646,\n",
       "  -0.65115803,\n",
       "  0.17747897,\n",
       "  0.2992708,\n",
       "  -0.02960176,\n",
       "  -0.21757777,\n",
       "  -0.27235055,\n",
       "  -0.32339388,\n",
       "  -0.20129046,\n",
       "  -0.7251358,\n",
       "  -0.11133838,\n",
       "  -0.33450362,\n",
       "  0.028226025,\n",
       "  0.22796826,\n",
       "  0.8244923,\n",
       "  0.70316404,\n",
       "  0.21162473,\n",
       "  0.42310625,\n",
       "  -0.2907032,\n",
       "  -0.49897328,\n",
       "  -0.7322511,\n",
       "  -0.5724706,\n",
       "  0.09864091,\n",
       "  0.11979855,\n",
       "  -0.119768836,\n",
       "  -0.5351112,\n",
       "  0.27886316,\n",
       "  0.06809668,\n",
       "  0.031874698,\n",
       "  -0.06135889,\n",
       "  0.11287575,\n",
       "  -0.14213483,\n",
       "  0.35983527,\n",
       "  -0.70250565,\n",
       "  -0.53376687,\n",
       "  0.15249932,\n",
       "  -0.21159895,\n",
       "  0.34510913,\n",
       "  -0.052368857,\n",
       "  -0.44777295,\n",
       "  0.037917018,\n",
       "  0.49633622,\n",
       "  -0.40669137,\n",
       "  0.43991846,\n",
       "  -0.085871145,\n",
       "  0.09949213,\n",
       "  0.06953947,\n",
       "  0.109021276,\n",
       "  -0.60370135,\n",
       "  0.6557729,\n",
       "  -0.03182373,\n",
       "  0.21542387,\n",
       "  -0.28822702,\n",
       "  -0.022449872,\n",
       "  0.5461073,\n",
       "  -0.15775385,\n",
       "  0.2722089,\n",
       "  -0.43863547,\n",
       "  0.18564464,\n",
       "  -0.6528918,\n",
       "  -0.57427937,\n",
       "  0.20947203,\n",
       "  -0.16479689,\n",
       "  0.37019712,\n",
       "  -0.43574795,\n",
       "  0.76650983,\n",
       "  0.102181256,\n",
       "  0.3278265,\n",
       "  -0.34922433,\n",
       "  0.008152592,\n",
       "  0.64311457,\n",
       "  0.67613184,\n",
       "  0.53345895,\n",
       "  -0.010494821,\n",
       "  0.18938819,\n",
       "  0.011527376,\n",
       "  0.9564037,\n",
       "  -0.010991298,\n",
       "  0.034799423,\n",
       "  -0.66840744,\n",
       "  0.008625622,\n",
       "  0.5606001],\n",
       " [-0.04826598,\n",
       "  -0.010074791,\n",
       "  0.35336077,\n",
       "  0.24469323,\n",
       "  -0.17004882,\n",
       "  -0.28356946,\n",
       "  0.0707497,\n",
       "  0.33685672,\n",
       "  -0.053646382,\n",
       "  0.41029587,\n",
       "  -0.12371924,\n",
       "  -0.11073409,\n",
       "  0.016542612,\n",
       "  0.11362961,\n",
       "  -0.039503742,\n",
       "  0.2023981,\n",
       "  0.11578273,\n",
       "  -0.5350385,\n",
       "  -0.31902024,\n",
       "  -0.47938436,\n",
       "  0.21779071,\n",
       "  0.0033693674,\n",
       "  0.53395236,\n",
       "  -0.23081861,\n",
       "  -0.12949301,\n",
       "  0.085459225,\n",
       "  0.13369405,\n",
       "  -0.35517916,\n",
       "  0.12930007,\n",
       "  0.030911483,\n",
       "  0.38847876,\n",
       "  -0.009393529,\n",
       "  -0.25877225,\n",
       "  0.33887538,\n",
       "  0.097443394,\n",
       "  -0.21304072,\n",
       "  0.13909128,\n",
       "  0.15764423,\n",
       "  -0.5562256,\n",
       "  -0.25521576,\n",
       "  0.16554476,\n",
       "  -0.027467573,\n",
       "  0.34231448,\n",
       "  -0.07693492,\n",
       "  0.014993729,\n",
       "  -0.11157218,\n",
       "  -0.008365758,\n",
       "  -0.17384033,\n",
       "  0.4770703,\n",
       "  0.3217432,\n",
       "  0.002713856,\n",
       "  0.04384616,\n",
       "  0.020745505,\n",
       "  0.13548414,\n",
       "  -0.6391273,\n",
       "  0.07538495,\n",
       "  0.324788,\n",
       "  0.40496802,\n",
       "  -0.7252373,\n",
       "  0.431725,\n",
       "  -0.056972068,\n",
       "  0.16881128,\n",
       "  0.056170303,\n",
       "  0.57994986,\n",
       "  -0.61708486,\n",
       "  0.10231729,\n",
       "  -0.06673001,\n",
       "  0.13625461,\n",
       "  -0.44332683,\n",
       "  0.6757489,\n",
       "  0.21250656,\n",
       "  0.008265794,\n",
       "  0.39246774,\n",
       "  -0.034671724,\n",
       "  0.21602708,\n",
       "  -0.08962852,\n",
       "  0.32620108,\n",
       "  -0.15754725,\n",
       "  -0.19997148,\n",
       "  0.13620445,\n",
       "  -0.25542098,\n",
       "  -0.033814162,\n",
       "  0.02660349,\n",
       "  0.084327705,\n",
       "  -0.12350551,\n",
       "  0.18089418,\n",
       "  -0.36682618,\n",
       "  0.23813999,\n",
       "  0.6615438,\n",
       "  0.090117596,\n",
       "  -0.011298317,\n",
       "  0.049894802,\n",
       "  0.14021946,\n",
       "  0.0062810373,\n",
       "  0.19188981,\n",
       "  0.6143785,\n",
       "  -0.20025651,\n",
       "  -0.6321169,\n",
       "  0.021578444,\n",
       "  0.2441464],\n",
       " [0.20220613,\n",
       "  -0.024253637,\n",
       "  0.1251602,\n",
       "  0.15677102,\n",
       "  0.10732241,\n",
       "  -0.20411319,\n",
       "  0.20911443,\n",
       "  0.5623397,\n",
       "  0.3357019,\n",
       "  0.16695705,\n",
       "  -0.04981191,\n",
       "  -0.07345424,\n",
       "  -0.32022887,\n",
       "  0.19503944,\n",
       "  -0.039167292,\n",
       "  -0.1313395,\n",
       "  0.20148808,\n",
       "  -0.31240457,\n",
       "  0.08796418,\n",
       "  -0.35896808,\n",
       "  0.20078783,\n",
       "  0.10515468,\n",
       "  0.47678047,\n",
       "  0.08719119,\n",
       "  -0.45239678,\n",
       "  0.03486333,\n",
       "  0.040223498,\n",
       "  -0.5227161,\n",
       "  0.21893887,\n",
       "  0.24249278,\n",
       "  0.40369183,\n",
       "  0.5768491,\n",
       "  -0.4129962,\n",
       "  0.43056127,\n",
       "  -0.18148492,\n",
       "  -0.017906975,\n",
       "  -0.12395223,\n",
       "  0.09498079,\n",
       "  -0.3065451,\n",
       "  -0.31196818,\n",
       "  0.07221643,\n",
       "  -0.05035006,\n",
       "  0.5651541,\n",
       "  -0.20410201,\n",
       "  0.046268042,\n",
       "  -0.0830351,\n",
       "  -0.60961676,\n",
       "  -0.00559229,\n",
       "  0.481825,\n",
       "  0.15847859,\n",
       "  -0.08176848,\n",
       "  0.057804875,\n",
       "  0.48907837,\n",
       "  0.09127424,\n",
       "  -0.56930995,\n",
       "  -0.016141526,\n",
       "  0.2363023,\n",
       "  0.3583711,\n",
       "  -0.44568783,\n",
       "  -0.112955086,\n",
       "  0.12795188,\n",
       "  -0.29692975,\n",
       "  0.19050638,\n",
       "  0.22630073,\n",
       "  -0.52214366,\n",
       "  0.1580024,\n",
       "  -0.108592965,\n",
       "  0.070615076,\n",
       "  -0.71133876,\n",
       "  0.56543297,\n",
       "  0.08555194,\n",
       "  0.23149538,\n",
       "  0.028211404,\n",
       "  0.015410429,\n",
       "  -0.10114334,\n",
       "  -0.064048186,\n",
       "  0.29788303,\n",
       "  0.27274755,\n",
       "  0.08897285,\n",
       "  0.1355196,\n",
       "  -0.0046970714,\n",
       "  0.044282332,\n",
       "  0.06327652,\n",
       "  -0.21334597,\n",
       "  -0.0054585007,\n",
       "  -0.30836335,\n",
       "  -0.32544392,\n",
       "  0.41315073,\n",
       "  1.0166373,\n",
       "  0.32363153,\n",
       "  0.26773143,\n",
       "  -0.3182746,\n",
       "  -0.422289,\n",
       "  0.039366625,\n",
       "  0.31197906,\n",
       "  0.7302299,\n",
       "  0.065663785,\n",
       "  -0.09113632,\n",
       "  0.12254631,\n",
       "  0.052095555],\n",
       " [-0.05008601,\n",
       "  0.060409393,\n",
       "  0.048354305,\n",
       "  0.12574638,\n",
       "  -0.023971504,\n",
       "  -0.17834425,\n",
       "  0.024228457,\n",
       "  0.26955667,\n",
       "  0.031618003,\n",
       "  -0.033897202,\n",
       "  -0.08930397,\n",
       "  -0.14371514,\n",
       "  -0.030030968,\n",
       "  0.0958321,\n",
       "  0.0023605512,\n",
       "  -0.03289491,\n",
       "  0.07069399,\n",
       "  -0.11680459,\n",
       "  0.021008272,\n",
       "  -0.18358551,\n",
       "  0.04116782,\n",
       "  0.042039394,\n",
       "  0.052646644,\n",
       "  -0.025914531,\n",
       "  -0.04014446,\n",
       "  0.0035125143,\n",
       "  -0.17303851,\n",
       "  -0.14069174,\n",
       "  0.0101305125,\n",
       "  0.009025224,\n",
       "  0.17282304,\n",
       "  0.09853777,\n",
       "  -0.010868708,\n",
       "  0.028439514,\n",
       "  -0.007531256,\n",
       "  0.07968365,\n",
       "  0.011265863,\n",
       "  -0.12402664,\n",
       "  -0.10983087,\n",
       "  -0.1778826,\n",
       "  0.042969815,\n",
       "  -0.12112375,\n",
       "  0.034222525,\n",
       "  -0.080578975,\n",
       "  0.08355244,\n",
       "  -0.04234543,\n",
       "  -0.098519914,\n",
       "  0.028368372,\n",
       "  0.074945726,\n",
       "  0.08699958,\n",
       "  0.11901762,\n",
       "  -0.108296074,\n",
       "  -0.040723808,\n",
       "  0.03730117,\n",
       "  -0.12505883,\n",
       "  0.10015965,\n",
       "  0.1215194,\n",
       "  -0.011776695,\n",
       "  -0.095977396,\n",
       "  0.043560557,\n",
       "  -0.003991168,\n",
       "  0.044361293,\n",
       "  -0.027381629,\n",
       "  0.13936661,\n",
       "  -0.15333101,\n",
       "  0.036182236,\n",
       "  -0.043594424,\n",
       "  0.07845861,\n",
       "  -0.1457447,\n",
       "  0.19481596,\n",
       "  -0.04772212,\n",
       "  -0.017082943,\n",
       "  0.05431384,\n",
       "  -0.013568955,\n",
       "  0.07057855,\n",
       "  0.01854934,\n",
       "  -0.01301995,\n",
       "  -0.0529036,\n",
       "  -0.031570375,\n",
       "  0.024564251,\n",
       "  -0.060427338,\n",
       "  -0.014307972,\n",
       "  -0.09064164,\n",
       "  0.16449109,\n",
       "  0.0008482141,\n",
       "  0.05344773,\n",
       "  -0.056035176,\n",
       "  0.12230122,\n",
       "  0.2766596,\n",
       "  0.09973633,\n",
       "  0.08191254,\n",
       "  -0.000919187,\n",
       "  -0.012976045,\n",
       "  0.07085289,\n",
       "  0.14832605,\n",
       "  0.16002096,\n",
       "  0.008181645,\n",
       "  -0.18182947,\n",
       "  0.05513472,\n",
       "  0.08617117],\n",
       " [-0.0064381063,\n",
       "  0.05360492,\n",
       "  0.09547638,\n",
       "  0.2393989,\n",
       "  -0.22937717,\n",
       "  -0.2812496,\n",
       "  -0.040348817,\n",
       "  0.57303363,\n",
       "  0.26578808,\n",
       "  -0.24256025,\n",
       "  -0.013783329,\n",
       "  -0.23545147,\n",
       "  -0.12876593,\n",
       "  0.27153724,\n",
       "  0.060450215,\n",
       "  0.2771349,\n",
       "  0.1475452,\n",
       "  0.09609573,\n",
       "  -0.13705023,\n",
       "  -0.31109545,\n",
       "  -0.11128634,\n",
       "  0.20660315,\n",
       "  0.11622334,\n",
       "  -0.10960418,\n",
       "  -0.005284476,\n",
       "  0.11390384,\n",
       "  -0.64313066,\n",
       "  -0.5303631,\n",
       "  -0.023647638,\n",
       "  0.010112242,\n",
       "  0.088039525,\n",
       "  0.38645557,\n",
       "  -0.15610233,\n",
       "  0.2565565,\n",
       "  -0.02691661,\n",
       "  0.4358276,\n",
       "  -0.51959616,\n",
       "  -0.44956595,\n",
       "  -0.15583555,\n",
       "  -0.4332484,\n",
       "  -0.19844975,\n",
       "  -0.06530078,\n",
       "  0.4814142,\n",
       "  -0.36292198,\n",
       "  0.18043327,\n",
       "  0.16494182,\n",
       "  0.16688533,\n",
       "  -0.12557462,\n",
       "  0.11340571,\n",
       "  0.047374275,\n",
       "  0.39130998,\n",
       "  -0.57921517,\n",
       "  -0.36692685,\n",
       "  0.0140828695,\n",
       "  -0.041562736,\n",
       "  0.23726316,\n",
       "  0.12745422,\n",
       "  -0.06542188,\n",
       "  -0.29321364,\n",
       "  0.1917413,\n",
       "  -0.3053159,\n",
       "  0.2540388,\n",
       "  0.08959952,\n",
       "  0.34125778,\n",
       "  -0.2537111,\n",
       "  0.29241458,\n",
       "  -0.75594056,\n",
       "  0.51879066,\n",
       "  -0.10207538,\n",
       "  0.33901054,\n",
       "  0.10044301,\n",
       "  0.040458195,\n",
       "  0.26828608,\n",
       "  0.25521687,\n",
       "  -0.022158178,\n",
       "  0.07978023,\n",
       "  -0.040933438,\n",
       "  -0.4392504,\n",
       "  -0.05368803,\n",
       "  0.04147977,\n",
       "  -0.03602463,\n",
       "  -0.008181164,\n",
       "  -0.32919118,\n",
       "  0.041996036,\n",
       "  0.29028177,\n",
       "  0.4119409,\n",
       "  0.3030788,\n",
       "  0.38773715,\n",
       "  0.5521626,\n",
       "  0.74104863,\n",
       "  0.16818625,\n",
       "  -0.04541409,\n",
       "  0.60361254,\n",
       "  0.31994104,\n",
       "  0.5777031,\n",
       "  0.21891843,\n",
       "  0.1894181,\n",
       "  -0.32924336,\n",
       "  0.020055547,\n",
       "  -0.40310884],\n",
       " [-0.24595803,\n",
       "  -0.011538694,\n",
       "  0.13078907,\n",
       "  0.2640737,\n",
       "  -0.1489538,\n",
       "  -0.4997165,\n",
       "  -0.0085454825,\n",
       "  0.40729618,\n",
       "  0.2606855,\n",
       "  -0.088410385,\n",
       "  -0.062026963,\n",
       "  -0.3973436,\n",
       "  0.115173355,\n",
       "  0.37988183,\n",
       "  0.28303817,\n",
       "  0.015186982,\n",
       "  0.21657671,\n",
       "  -0.12170748,\n",
       "  0.038079556,\n",
       "  -0.41796923,\n",
       "  0.24021432,\n",
       "  0.23438857,\n",
       "  -0.06630119,\n",
       "  0.011447817,\n",
       "  0.044113293,\n",
       "  -0.14129621,\n",
       "  -0.42123568,\n",
       "  -0.38370416,\n",
       "  0.15785955,\n",
       "  0.046449397,\n",
       "  0.18780096,\n",
       "  0.32885495,\n",
       "  0.029249389,\n",
       "  0.079063274,\n",
       "  -0.031886615,\n",
       "  0.37966737,\n",
       "  -0.23014422,\n",
       "  -0.40439,\n",
       "  -0.47550833,\n",
       "  -0.405809,\n",
       "  0.038670648,\n",
       "  -0.13247344,\n",
       "  -0.14914499,\n",
       "  -0.24509498,\n",
       "  0.26940492,\n",
       "  -0.25219858,\n",
       "  0.04374382,\n",
       "  -0.119971775,\n",
       "  0.28013003,\n",
       "  -0.057307474,\n",
       "  0.45199496,\n",
       "  -0.32117575,\n",
       "  -0.14759772,\n",
       "  0.08129835,\n",
       "  0.09842667,\n",
       "  0.3858503,\n",
       "  -0.0030379496,\n",
       "  -0.13004485,\n",
       "  -0.18758407,\n",
       "  0.53708714,\n",
       "  -0.34594256,\n",
       "  -0.025002535,\n",
       "  -0.025330905,\n",
       "  0.14993165,\n",
       "  -0.16141838,\n",
       "  0.16189452,\n",
       "  -0.3542505,\n",
       "  0.3140988,\n",
       "  -0.15539557,\n",
       "  0.33221796,\n",
       "  -0.015278185,\n",
       "  -0.050757375,\n",
       "  0.08535971,\n",
       "  -0.029828127,\n",
       "  0.041053187,\n",
       "  -0.13858195,\n",
       "  -0.045192514,\n",
       "  -0.41871417,\n",
       "  -0.17770402,\n",
       "  0.13087502,\n",
       "  -0.11983451,\n",
       "  0.35994065,\n",
       "  -0.18764956,\n",
       "  0.22493479,\n",
       "  0.16178788,\n",
       "  0.093806565,\n",
       "  -0.10678976,\n",
       "  0.13172328,\n",
       "  0.79982096,\n",
       "  0.27845806,\n",
       "  0.33257884,\n",
       "  -0.02110297,\n",
       "  -0.08036776,\n",
       "  0.32804105,\n",
       "  0.45960566,\n",
       "  0.09580111,\n",
       "  0.012735833,\n",
       "  -0.34826547,\n",
       "  0.06626292,\n",
       "  0.24248506],\n",
       " [-0.12506641,\n",
       "  0.14830194,\n",
       "  0.07017288,\n",
       "  0.19638583,\n",
       "  0.05193335,\n",
       "  -0.2994235,\n",
       "  0.03322648,\n",
       "  0.3884687,\n",
       "  -0.09297776,\n",
       "  -0.09332879,\n",
       "  -0.11959536,\n",
       "  -0.23250839,\n",
       "  -0.08496463,\n",
       "  0.14759672,\n",
       "  0.0056956816,\n",
       "  -0.088911235,\n",
       "  0.07418642,\n",
       "  -0.106151626,\n",
       "  -0.1144391,\n",
       "  -0.38993248,\n",
       "  0.112639405,\n",
       "  0.13614693,\n",
       "  0.012955196,\n",
       "  -0.03179243,\n",
       "  -0.08203657,\n",
       "  0.03138288,\n",
       "  -0.35543373,\n",
       "  -0.06715488,\n",
       "  -0.0015048299,\n",
       "  -0.009635907,\n",
       "  0.13478597,\n",
       "  0.14868583,\n",
       "  -0.03851606,\n",
       "  -0.025321295,\n",
       "  0.0031695,\n",
       "  0.18028341,\n",
       "  -0.110153355,\n",
       "  -0.22851433,\n",
       "  -0.06416483,\n",
       "  -0.25995982,\n",
       "  0.049256474,\n",
       "  -0.23728286,\n",
       "  0.030857924,\n",
       "  -0.040537775,\n",
       "  0.12276297,\n",
       "  -0.0018043577,\n",
       "  -0.20589139,\n",
       "  0.07649581,\n",
       "  0.12534973,\n",
       "  0.054148607,\n",
       "  0.18702818,\n",
       "  -0.1543999,\n",
       "  -0.08959823,\n",
       "  0.098431475,\n",
       "  -0.19029687,\n",
       "  0.18522319,\n",
       "  0.19228646,\n",
       "  -0.04619425,\n",
       "  -0.04538048,\n",
       "  0.12495791,\n",
       "  0.019554755,\n",
       "  0.12215446,\n",
       "  -0.0305144,\n",
       "  0.19461294,\n",
       "  -0.25431198,\n",
       "  0.12527396,\n",
       "  -0.12789306,\n",
       "  0.12601098,\n",
       "  -0.16928267,\n",
       "  0.2672961,\n",
       "  -0.09157096,\n",
       "  0.015533209,\n",
       "  0.19420773,\n",
       "  0.017605865,\n",
       "  0.1859673,\n",
       "  0.09861885,\n",
       "  0.008099273,\n",
       "  -0.09479535,\n",
       "  0.04024579,\n",
       "  -0.014824784,\n",
       "  -0.094503485,\n",
       "  0.008168056,\n",
       "  -0.116680115,\n",
       "  0.22349344,\n",
       "  -0.01922679,\n",
       "  0.19771451,\n",
       "  -0.11994215,\n",
       "  0.18185101,\n",
       "  0.5601607,\n",
       "  0.21045011,\n",
       "  0.16733271,\n",
       "  0.087826654,\n",
       "  0.113257736,\n",
       "  0.09938201,\n",
       "  0.21589543,\n",
       "  0.17447169,\n",
       "  0.013365027,\n",
       "  -0.23357965,\n",
       "  0.043949533,\n",
       "  0.09985055],\n",
       " [-0.6255731,\n",
       "  0.36214247,\n",
       "  -0.009540138,\n",
       "  0.26017454,\n",
       "  0.28664473,\n",
       "  -0.63116926,\n",
       "  -0.044651687,\n",
       "  0.8261708,\n",
       "  -0.5331271,\n",
       "  -0.18246812,\n",
       "  -0.12393199,\n",
       "  -0.41560405,\n",
       "  -0.35196108,\n",
       "  0.081162594,\n",
       "  0.1971953,\n",
       "  -0.48919106,\n",
       "  0.07651314,\n",
       "  -0.07907236,\n",
       "  -0.6230598,\n",
       "  -1.161404,\n",
       "  0.85838896,\n",
       "  0.5099749,\n",
       "  -0.382043,\n",
       "  0.19474012,\n",
       "  -0.58225334,\n",
       "  0.010385075,\n",
       "  -1.2081155,\n",
       "  0.19091372,\n",
       "  0.08915576,\n",
       "  -0.17349012,\n",
       "  -0.091603056,\n",
       "  0.37248656,\n",
       "  0.08260508,\n",
       "  -0.35353994,\n",
       "  0.18478465,\n",
       "  0.4075899,\n",
       "  -0.88943225,\n",
       "  -0.5854066,\n",
       "  0.4640359,\n",
       "  -0.54597193,\n",
       "  0.26215732,\n",
       "  -0.4874425,\n",
       "  0.42556584,\n",
       "  0.19540356,\n",
       "  0.40572232,\n",
       "  0.3423091,\n",
       "  -0.53536016,\n",
       "  0.14499867,\n",
       "  0.31877553,\n",
       "  -0.3319907,\n",
       "  0.45206594,\n",
       "  -0.20952961,\n",
       "  -0.26072618,\n",
       "  0.33758828,\n",
       "  -0.4760192,\n",
       "  0.7526837,\n",
       "  0.21451095,\n",
       "  -0.36602113,\n",
       "  0.50253767,\n",
       "  0.38305435,\n",
       "  -0.1329273,\n",
       "  0.85289586,\n",
       "  -0.09367502,\n",
       "  0.45046425,\n",
       "  -0.6895916,\n",
       "  0.69794494,\n",
       "  -0.43327367,\n",
       "  0.022635896,\n",
       "  -0.39058566,\n",
       "  0.4311476,\n",
       "  -0.4939899,\n",
       "  0.23863089,\n",
       "  0.66763,\n",
       "  0.21439275,\n",
       "  0.38910025,\n",
       "  0.36759466,\n",
       "  0.14122583,\n",
       "  -0.5080891,\n",
       "  0.20793332,\n",
       "  -0.22322807,\n",
       "  -0.31756526,\n",
       "  -0.10355748,\n",
       "  -0.43570253,\n",
       "  0.5047615,\n",
       "  0.020342551,\n",
       "  0.9187383,\n",
       "  -0.44509783,\n",
       "  0.569629,\n",
       "  1.8534553,\n",
       "  0.37600374,\n",
       "  0.24153431,\n",
       "  0.28202716,\n",
       "  0.8528289,\n",
       "  -0.040972374,\n",
       "  0.12445011,\n",
       "  0.08990892,\n",
       "  -0.17197752,\n",
       "  -0.36140746,\n",
       "  -0.056045644,\n",
       "  0.14649302],\n",
       " [-0.6255731,\n",
       "  0.36214247,\n",
       "  -0.009540138,\n",
       "  0.26017454,\n",
       "  0.28664473,\n",
       "  -0.63116926,\n",
       "  -0.044651687,\n",
       "  0.8261708,\n",
       "  -0.5331271,\n",
       "  -0.18246812,\n",
       "  -0.12393199,\n",
       "  -0.41560405,\n",
       "  -0.35196108,\n",
       "  0.081162594,\n",
       "  0.1971953,\n",
       "  -0.48919106,\n",
       "  0.07651314,\n",
       "  -0.07907236,\n",
       "  -0.6230598,\n",
       "  -1.161404,\n",
       "  0.85838896,\n",
       "  0.5099749,\n",
       "  -0.382043,\n",
       "  0.19474012,\n",
       "  -0.58225334,\n",
       "  0.010385075,\n",
       "  -1.2081155,\n",
       "  0.19091372,\n",
       "  0.08915576,\n",
       "  -0.17349012,\n",
       "  -0.091603056,\n",
       "  0.37248656,\n",
       "  0.08260508,\n",
       "  -0.35353994,\n",
       "  0.18478465,\n",
       "  0.4075899,\n",
       "  -0.88943225,\n",
       "  -0.5854066,\n",
       "  0.4640359,\n",
       "  -0.54597193,\n",
       "  0.26215732,\n",
       "  -0.4874425,\n",
       "  0.42556584,\n",
       "  0.19540356,\n",
       "  0.40572232,\n",
       "  0.3423091,\n",
       "  -0.53536016,\n",
       "  0.14499867,\n",
       "  0.31877553,\n",
       "  -0.3319907,\n",
       "  0.45206594,\n",
       "  -0.20952961,\n",
       "  -0.26072618,\n",
       "  0.33758828,\n",
       "  -0.4760192,\n",
       "  0.7526837,\n",
       "  0.21451095,\n",
       "  -0.36602113,\n",
       "  0.50253767,\n",
       "  0.38305435,\n",
       "  -0.1329273,\n",
       "  0.85289586,\n",
       "  -0.09367502,\n",
       "  0.45046425,\n",
       "  -0.6895916,\n",
       "  0.69794494,\n",
       "  -0.43327367,\n",
       "  0.022635896,\n",
       "  -0.39058566,\n",
       "  0.4311476,\n",
       "  -0.4939899,\n",
       "  0.23863089,\n",
       "  0.66763,\n",
       "  0.21439275,\n",
       "  0.38910025,\n",
       "  0.36759466,\n",
       "  0.14122583,\n",
       "  -0.5080891,\n",
       "  0.20793332,\n",
       "  -0.22322807,\n",
       "  -0.31756526,\n",
       "  -0.10355748,\n",
       "  -0.43570253,\n",
       "  0.5047615,\n",
       "  0.020342551,\n",
       "  0.9187383,\n",
       "  -0.44509783,\n",
       "  0.569629,\n",
       "  1.8534553,\n",
       "  0.37600374,\n",
       "  0.24153431,\n",
       "  0.28202716,\n",
       "  0.8528289,\n",
       "  -0.040972374,\n",
       "  0.12445011,\n",
       "  0.08990892,\n",
       "  -0.17197752,\n",
       "  -0.36140746,\n",
       "  -0.056045644,\n",
       "  0.14649302],\n",
       " [-0.19282562,\n",
       "  0.016863732,\n",
       "  0.31074283,\n",
       "  -0.111200936,\n",
       "  -0.061514225,\n",
       "  -0.090424664,\n",
       "  0.5796476,\n",
       "  0.5426682,\n",
       "  -0.67358327,\n",
       "  -0.64635485,\n",
       "  0.29397935,\n",
       "  -0.17985596,\n",
       "  -0.47372732,\n",
       "  0.22434491,\n",
       "  0.3383462,\n",
       "  -0.5420965,\n",
       "  0.37431476,\n",
       "  0.089243345,\n",
       "  -0.29291883,\n",
       "  -1.0820862,\n",
       "  -0.059953053,\n",
       "  0.16380264,\n",
       "  0.24758643,\n",
       "  -0.1952948,\n",
       "  0.93165714,\n",
       "  -0.39801148,\n",
       "  0.052367937,\n",
       "  0.42624933,\n",
       "  -0.22355969,\n",
       "  0.2850427,\n",
       "  -0.22024462,\n",
       "  0.60792106,\n",
       "  -0.4419503,\n",
       "  -0.561508,\n",
       "  -0.33505598,\n",
       "  0.75788295,\n",
       "  0.63146454,\n",
       "  -0.33612293,\n",
       "  0.26641315,\n",
       "  -0.44116274,\n",
       "  0.11417023,\n",
       "  -0.31746614,\n",
       "  -0.30277264,\n",
       "  -0.35101485,\n",
       "  -0.13540916,\n",
       "  -0.034060292,\n",
       "  0.29550675,\n",
       "  -0.14223985,\n",
       "  0.26633886,\n",
       "  0.4665429,\n",
       "  0.2808097,\n",
       "  0.08544808,\n",
       "  -0.04942789,\n",
       "  -0.03611582,\n",
       "  0.024471255,\n",
       "  -0.050153986,\n",
       "  0.43339038,\n",
       "  0.31633976,\n",
       "  -0.43349084,\n",
       "  0.2701467,\n",
       "  -0.13280688,\n",
       "  0.3302561,\n",
       "  0.1268016,\n",
       "  -0.23267244,\n",
       "  0.028165242,\n",
       "  -0.40071115,\n",
       "  0.12280773,\n",
       "  0.26673064,\n",
       "  -0.12610854,\n",
       "  0.39307752,\n",
       "  0.16455658,\n",
       "  -0.24067342,\n",
       "  0.47825924,\n",
       "  0.3067179,\n",
       "  0.415467,\n",
       "  0.137197,\n",
       "  -0.2075218,\n",
       "  -0.16138506,\n",
       "  0.5128125,\n",
       "  -0.3371859,\n",
       "  0.06906669,\n",
       "  0.22778425,\n",
       "  0.15237458,\n",
       "  0.13962853,\n",
       "  0.22687927,\n",
       "  -0.18934925,\n",
       "  -0.37809023,\n",
       "  -0.19807552,\n",
       "  0.38835776,\n",
       "  0.2345484,\n",
       "  -0.22377698,\n",
       "  0.51061285,\n",
       "  0.17034067,\n",
       "  -0.13043009,\n",
       "  1.019577,\n",
       "  0.3927775,\n",
       "  -0.28917074,\n",
       "  -0.53399634,\n",
       "  -0.40594155,\n",
       "  0.34755495],\n",
       " [-0.30151704,\n",
       "  0.17614035,\n",
       "  0.17436394,\n",
       "  0.3751836,\n",
       "  0.123352244,\n",
       "  -0.55051833,\n",
       "  0.1348981,\n",
       "  0.478169,\n",
       "  -0.5639281,\n",
       "  -0.19454712,\n",
       "  -0.18596914,\n",
       "  -0.37520838,\n",
       "  -0.11095704,\n",
       "  0.4523596,\n",
       "  0.011518512,\n",
       "  0.1475376,\n",
       "  0.3385907,\n",
       "  -0.21647377,\n",
       "  -0.43975925,\n",
       "  -0.9172251,\n",
       "  -0.119493626,\n",
       "  0.6499132,\n",
       "  0.24152128,\n",
       "  0.0037131598,\n",
       "  -0.307352,\n",
       "  0.23112282,\n",
       "  -0.74385273,\n",
       "  -0.04711682,\n",
       "  0.39349565,\n",
       "  -0.3171765,\n",
       "  0.0816807,\n",
       "  0.16478819,\n",
       "  -0.011962164,\n",
       "  0.26508924,\n",
       "  -0.12483969,\n",
       "  0.42714092,\n",
       "  -0.060206324,\n",
       "  -0.26892376,\n",
       "  -0.4030479,\n",
       "  -0.0061529703,\n",
       "  0.17531879,\n",
       "  -0.41957352,\n",
       "  0.16016315,\n",
       "  0.0032098491,\n",
       "  0.2766542,\n",
       "  0.24620804,\n",
       "  -0.6258605,\n",
       "  0.40374878,\n",
       "  0.09261906,\n",
       "  0.25185916,\n",
       "  -0.09268866,\n",
       "  -0.13267903,\n",
       "  -0.008489609,\n",
       "  0.42542562,\n",
       "  -0.33480924,\n",
       "  0.052693035,\n",
       "  0.4865048,\n",
       "  0.0580766,\n",
       "  0.022671446,\n",
       "  0.2182754,\n",
       "  -0.011320658,\n",
       "  -0.020120203,\n",
       "  0.17173782,\n",
       "  0.39488184,\n",
       "  -0.6529747,\n",
       "  0.26352218,\n",
       "  -0.17643519,\n",
       "  0.276854,\n",
       "  -0.25893617,\n",
       "  0.2811169,\n",
       "  -0.20373024,\n",
       "  0.06251508,\n",
       "  0.29187387,\n",
       "  -0.4351259,\n",
       "  0.5163287,\n",
       "  -0.08305314,\n",
       "  0.20193146,\n",
       "  0.10319835,\n",
       "  0.10675019,\n",
       "  0.2564064,\n",
       "  -0.4500556,\n",
       "  0.15971752,\n",
       "  -0.04369839,\n",
       "  0.50349,\n",
       "  -0.23450805,\n",
       "  0.4236679,\n",
       "  -0.2728893,\n",
       "  0.4774831,\n",
       "  0.9026762,\n",
       "  0.500612,\n",
       "  0.23214918,\n",
       "  0.34614438,\n",
       "  0.21219625,\n",
       "  0.3677854,\n",
       "  0.42948487,\n",
       "  0.4625298,\n",
       "  0.22052036,\n",
       "  -0.22324356,\n",
       "  0.16441086,\n",
       "  0.3952601],\n",
       " [-0.6255731,\n",
       "  0.36214247,\n",
       "  -0.009540138,\n",
       "  0.26017454,\n",
       "  0.28664473,\n",
       "  -0.63116926,\n",
       "  -0.044651687,\n",
       "  0.8261708,\n",
       "  -0.5331271,\n",
       "  -0.18246812,\n",
       "  -0.12393199,\n",
       "  -0.41560405,\n",
       "  -0.35196108,\n",
       "  0.081162594,\n",
       "  0.1971953,\n",
       "  -0.48919106,\n",
       "  0.07651314,\n",
       "  -0.07907236,\n",
       "  -0.6230598,\n",
       "  -1.161404,\n",
       "  0.85838896,\n",
       "  0.5099749,\n",
       "  -0.382043,\n",
       "  0.19474012,\n",
       "  -0.58225334,\n",
       "  0.010385075,\n",
       "  -1.2081155,\n",
       "  0.19091372,\n",
       "  0.08915576,\n",
       "  -0.17349012,\n",
       "  -0.091603056,\n",
       "  0.37248656,\n",
       "  0.08260508,\n",
       "  -0.35353994,\n",
       "  0.18478465,\n",
       "  0.4075899,\n",
       "  -0.88943225,\n",
       "  -0.5854066,\n",
       "  0.4640359,\n",
       "  -0.54597193,\n",
       "  0.26215732,\n",
       "  -0.4874425,\n",
       "  0.42556584,\n",
       "  0.19540356,\n",
       "  0.40572232,\n",
       "  0.3423091,\n",
       "  -0.53536016,\n",
       "  0.14499867,\n",
       "  0.31877553,\n",
       "  -0.3319907,\n",
       "  0.45206594,\n",
       "  -0.20952961,\n",
       "  -0.26072618,\n",
       "  0.33758828,\n",
       "  -0.4760192,\n",
       "  0.7526837,\n",
       "  0.21451095,\n",
       "  -0.36602113,\n",
       "  0.50253767,\n",
       "  0.38305435,\n",
       "  -0.1329273,\n",
       "  0.85289586,\n",
       "  -0.09367502,\n",
       "  0.45046425,\n",
       "  -0.6895916,\n",
       "  0.69794494,\n",
       "  -0.43327367,\n",
       "  0.022635896,\n",
       "  -0.39058566,\n",
       "  0.4311476,\n",
       "  -0.4939899,\n",
       "  0.23863089,\n",
       "  0.66763,\n",
       "  0.21439275,\n",
       "  0.38910025,\n",
       "  0.36759466,\n",
       "  0.14122583,\n",
       "  -0.5080891,\n",
       "  0.20793332,\n",
       "  -0.22322807,\n",
       "  -0.31756526,\n",
       "  -0.10355748,\n",
       "  -0.43570253,\n",
       "  0.5047615,\n",
       "  0.020342551,\n",
       "  0.9187383,\n",
       "  -0.44509783,\n",
       "  0.569629,\n",
       "  1.8534553,\n",
       "  0.37600374,\n",
       "  0.24153431,\n",
       "  0.28202716,\n",
       "  0.8528289,\n",
       "  -0.040972374,\n",
       "  0.12445011,\n",
       "  0.08990892,\n",
       "  -0.17197752,\n",
       "  -0.36140746,\n",
       "  -0.056045644,\n",
       "  0.14649302],\n",
       " [-0.6255731,\n",
       "  0.36214247,\n",
       "  -0.009540138,\n",
       "  0.26017454,\n",
       "  0.28664473,\n",
       "  -0.63116926,\n",
       "  -0.044651687,\n",
       "  0.8261708,\n",
       "  -0.5331271,\n",
       "  -0.18246812,\n",
       "  -0.12393199,\n",
       "  -0.41560405,\n",
       "  -0.35196108,\n",
       "  0.081162594,\n",
       "  0.1971953,\n",
       "  -0.48919106,\n",
       "  0.07651314,\n",
       "  -0.07907236,\n",
       "  -0.6230598,\n",
       "  -1.161404,\n",
       "  0.85838896,\n",
       "  0.5099749,\n",
       "  -0.382043,\n",
       "  0.19474012,\n",
       "  -0.58225334,\n",
       "  0.010385075,\n",
       "  -1.2081155,\n",
       "  0.19091372,\n",
       "  0.08915576,\n",
       "  -0.17349012,\n",
       "  -0.091603056,\n",
       "  0.37248656,\n",
       "  0.08260508,\n",
       "  -0.35353994,\n",
       "  0.18478465,\n",
       "  0.4075899,\n",
       "  -0.88943225,\n",
       "  -0.5854066,\n",
       "  0.4640359,\n",
       "  -0.54597193,\n",
       "  0.26215732,\n",
       "  -0.4874425,\n",
       "  0.42556584,\n",
       "  0.19540356,\n",
       "  0.40572232,\n",
       "  0.3423091,\n",
       "  -0.53536016,\n",
       "  0.14499867,\n",
       "  0.31877553,\n",
       "  -0.3319907,\n",
       "  0.45206594,\n",
       "  -0.20952961,\n",
       "  -0.26072618,\n",
       "  0.33758828,\n",
       "  -0.4760192,\n",
       "  0.7526837,\n",
       "  0.21451095,\n",
       "  -0.36602113,\n",
       "  0.50253767,\n",
       "  0.38305435,\n",
       "  -0.1329273,\n",
       "  0.85289586,\n",
       "  -0.09367502,\n",
       "  0.45046425,\n",
       "  -0.6895916,\n",
       "  0.69794494,\n",
       "  -0.43327367,\n",
       "  0.022635896,\n",
       "  -0.39058566,\n",
       "  0.4311476,\n",
       "  -0.4939899,\n",
       "  0.23863089,\n",
       "  0.66763,\n",
       "  0.21439275,\n",
       "  0.38910025,\n",
       "  0.36759466,\n",
       "  0.14122583,\n",
       "  -0.5080891,\n",
       "  0.20793332,\n",
       "  -0.22322807,\n",
       "  -0.31756526,\n",
       "  -0.10355748,\n",
       "  -0.43570253,\n",
       "  0.5047615,\n",
       "  0.020342551,\n",
       "  0.9187383,\n",
       "  -0.44509783,\n",
       "  0.569629,\n",
       "  1.8534553,\n",
       "  0.37600374,\n",
       "  0.24153431,\n",
       "  0.28202716,\n",
       "  0.8528289,\n",
       "  -0.040972374,\n",
       "  0.12445011,\n",
       "  0.08990892,\n",
       "  -0.17197752,\n",
       "  -0.36140746,\n",
       "  -0.056045644,\n",
       "  0.14649302],\n",
       " [-0.6255731,\n",
       "  0.36214247,\n",
       "  -0.009540138,\n",
       "  0.26017454,\n",
       "  0.28664473,\n",
       "  -0.63116926,\n",
       "  -0.044651687,\n",
       "  0.8261708,\n",
       "  -0.5331271,\n",
       "  -0.18246812,\n",
       "  -0.12393199,\n",
       "  -0.41560405,\n",
       "  -0.35196108,\n",
       "  0.081162594,\n",
       "  0.1971953,\n",
       "  -0.48919106,\n",
       "  0.07651314,\n",
       "  -0.07907236,\n",
       "  -0.6230598,\n",
       "  -1.161404,\n",
       "  0.85838896,\n",
       "  0.5099749,\n",
       "  -0.382043,\n",
       "  0.19474012,\n",
       "  -0.58225334,\n",
       "  0.010385075,\n",
       "  -1.2081155,\n",
       "  0.19091372,\n",
       "  0.08915576,\n",
       "  -0.17349012,\n",
       "  -0.091603056,\n",
       "  0.37248656,\n",
       "  0.08260508,\n",
       "  -0.35353994,\n",
       "  0.18478465,\n",
       "  0.4075899,\n",
       "  -0.88943225,\n",
       "  -0.5854066,\n",
       "  0.4640359,\n",
       "  -0.54597193,\n",
       "  0.26215732,\n",
       "  -0.4874425,\n",
       "  0.42556584,\n",
       "  0.19540356,\n",
       "  0.40572232,\n",
       "  0.3423091,\n",
       "  -0.53536016,\n",
       "  0.14499867,\n",
       "  0.31877553,\n",
       "  -0.3319907,\n",
       "  0.45206594,\n",
       "  -0.20952961,\n",
       "  -0.26072618,\n",
       "  0.33758828,\n",
       "  -0.4760192,\n",
       "  0.7526837,\n",
       "  0.21451095,\n",
       "  -0.36602113,\n",
       "  0.50253767,\n",
       "  0.38305435,\n",
       "  -0.1329273,\n",
       "  0.85289586,\n",
       "  -0.09367502,\n",
       "  0.45046425,\n",
       "  -0.6895916,\n",
       "  0.69794494,\n",
       "  -0.43327367,\n",
       "  0.022635896,\n",
       "  -0.39058566,\n",
       "  0.4311476,\n",
       "  -0.4939899,\n",
       "  0.23863089,\n",
       "  0.66763,\n",
       "  0.21439275,\n",
       "  0.38910025,\n",
       "  0.36759466,\n",
       "  0.14122583,\n",
       "  -0.5080891,\n",
       "  0.20793332,\n",
       "  -0.22322807,\n",
       "  -0.31756526,\n",
       "  -0.10355748,\n",
       "  -0.43570253,\n",
       "  0.5047615,\n",
       "  0.020342551,\n",
       "  0.9187383,\n",
       "  -0.44509783,\n",
       "  0.569629,\n",
       "  1.8534553,\n",
       "  0.37600374,\n",
       "  0.24153431,\n",
       "  0.28202716,\n",
       "  0.8528289,\n",
       "  -0.040972374,\n",
       "  0.12445011,\n",
       "  0.08990892,\n",
       "  -0.17197752,\n",
       "  -0.36140746,\n",
       "  -0.056045644,\n",
       "  0.14649302],\n",
       " [-0.12506641,\n",
       "  0.14830194,\n",
       "  0.07017288,\n",
       "  0.19638583,\n",
       "  0.05193335,\n",
       "  -0.2994235,\n",
       "  0.03322648,\n",
       "  0.3884687,\n",
       "  -0.09297776,\n",
       "  -0.09332879,\n",
       "  -0.11959536,\n",
       "  -0.23250839,\n",
       "  -0.08496463,\n",
       "  0.14759672,\n",
       "  0.0056956816,\n",
       "  -0.088911235,\n",
       "  0.07418642,\n",
       "  -0.106151626,\n",
       "  -0.1144391,\n",
       "  -0.38993248,\n",
       "  0.112639405,\n",
       "  0.13614693,\n",
       "  0.012955196,\n",
       "  -0.03179243,\n",
       "  -0.08203657,\n",
       "  0.03138288,\n",
       "  -0.35543373,\n",
       "  -0.06715488,\n",
       "  -0.0015048299,\n",
       "  -0.009635907,\n",
       "  0.13478597,\n",
       "  0.14868583,\n",
       "  -0.03851606,\n",
       "  -0.025321295,\n",
       "  0.0031695,\n",
       "  0.18028341,\n",
       "  -0.110153355,\n",
       "  -0.22851433,\n",
       "  -0.06416483,\n",
       "  -0.25995982,\n",
       "  0.049256474,\n",
       "  -0.23728286,\n",
       "  0.030857924,\n",
       "  -0.040537775,\n",
       "  0.12276297,\n",
       "  -0.0018043577,\n",
       "  -0.20589139,\n",
       "  0.07649581,\n",
       "  0.12534973,\n",
       "  0.054148607,\n",
       "  0.18702818,\n",
       "  -0.1543999,\n",
       "  -0.08959823,\n",
       "  0.098431475,\n",
       "  -0.19029687,\n",
       "  0.18522319,\n",
       "  0.19228646,\n",
       "  -0.04619425,\n",
       "  -0.04538048,\n",
       "  0.12495791,\n",
       "  0.019554755,\n",
       "  0.12215446,\n",
       "  -0.0305144,\n",
       "  0.19461294,\n",
       "  -0.25431198,\n",
       "  0.12527396,\n",
       "  -0.12789306,\n",
       "  0.12601098,\n",
       "  -0.16928267,\n",
       "  0.2672961,\n",
       "  -0.09157096,\n",
       "  0.015533209,\n",
       "  0.19420773,\n",
       "  0.017605865,\n",
       "  0.1859673,\n",
       "  0.09861885,\n",
       "  0.008099273,\n",
       "  -0.09479535,\n",
       "  0.04024579,\n",
       "  -0.014824784,\n",
       "  -0.094503485,\n",
       "  0.008168056,\n",
       "  -0.116680115,\n",
       "  0.22349344,\n",
       "  -0.01922679,\n",
       "  0.19771451,\n",
       "  -0.11994215,\n",
       "  0.18185101,\n",
       "  0.5601607,\n",
       "  0.21045011,\n",
       "  0.16733271,\n",
       "  0.087826654,\n",
       "  0.113257736,\n",
       "  0.09938201,\n",
       "  0.21589543,\n",
       "  0.17447169,\n",
       "  0.013365027,\n",
       "  -0.23357965,\n",
       "  0.043949533,\n",
       "  0.09985055],\n",
       " [-0.13042362,\n",
       "  0.12569968,\n",
       "  0.08538387,\n",
       "  0.17105152,\n",
       "  0.031095091,\n",
       "  -0.3377625,\n",
       "  0.001646984,\n",
       "  0.40665266,\n",
       "  -0.05088093,\n",
       "  -0.0979152,\n",
       "  -0.062124442,\n",
       "  -0.2824541,\n",
       "  -0.03226235,\n",
       "  0.1592892,\n",
       "  0.0021217617,\n",
       "  -0.030624958,\n",
       "  0.11962072,\n",
       "  -0.107039385,\n",
       "  -0.08883769,\n",
       "  -0.3627573,\n",
       "  0.074187286,\n",
       "  0.1139908,\n",
       "  0.0052064895,\n",
       "  -0.04144814,\n",
       "  -0.07569119,\n",
       "  0.03428083,\n",
       "  -0.31136882,\n",
       "  -0.12973927,\n",
       "  -0.011881978,\n",
       "  -0.015652193,\n",
       "  0.14943814,\n",
       "  0.11503824,\n",
       "  0.06447793,\n",
       "  0.015744172,\n",
       "  0.014115003,\n",
       "  0.19996244,\n",
       "  -0.07278811,\n",
       "  -0.23902693,\n",
       "  -0.12885065,\n",
       "  -0.2808762,\n",
       "  0.037004918,\n",
       "  -0.20581496,\n",
       "  0.013955938,\n",
       "  -0.086975865,\n",
       "  0.08995289,\n",
       "  -0.03806056,\n",
       "  -0.17432028,\n",
       "  0.03281208,\n",
       "  0.12375764,\n",
       "  0.0712494,\n",
       "  0.19999407,\n",
       "  -0.1713063,\n",
       "  -0.13683765,\n",
       "  0.07483809,\n",
       "  -0.14807935,\n",
       "  0.20644021,\n",
       "  0.18376972,\n",
       "  -0.09177658,\n",
       "  -0.037546456,\n",
       "  0.14567952,\n",
       "  -0.06232335,\n",
       "  0.14774969,\n",
       "  -0.072593756,\n",
       "  0.18026157,\n",
       "  -0.21436335,\n",
       "  0.12963498,\n",
       "  -0.134705,\n",
       "  0.12260994,\n",
       "  -0.16085331,\n",
       "  0.25401974,\n",
       "  -0.10251515,\n",
       "  -0.0006874701,\n",
       "  0.22112226,\n",
       "  -0.009597147,\n",
       "  0.15573838,\n",
       "  0.034404792,\n",
       "  0.0202787,\n",
       "  -0.16422096,\n",
       "  -0.012727441,\n",
       "  0.02958961,\n",
       "  -0.079291515,\n",
       "  0.07741391,\n",
       "  -0.1622176,\n",
       "  0.2587968,\n",
       "  0.022430278,\n",
       "  0.24350041,\n",
       "  -0.12693469,\n",
       "  0.11315888,\n",
       "  0.5186031,\n",
       "  0.18632175,\n",
       "  0.20668036,\n",
       "  0.044936236,\n",
       "  0.1395501,\n",
       "  0.10836864,\n",
       "  0.24499768,\n",
       "  0.173703,\n",
       "  0.0063715107,\n",
       "  -0.3046825,\n",
       "  0.027845101,\n",
       "  0.114697345],\n",
       " [-0.4234018,\n",
       "  0.2936501,\n",
       "  0.10654593,\n",
       "  0.422387,\n",
       "  0.060069982,\n",
       "  -0.57130694,\n",
       "  -0.20175326,\n",
       "  0.40571308,\n",
       "  -0.6971355,\n",
       "  0.0073761865,\n",
       "  -0.36253288,\n",
       "  -0.345418,\n",
       "  -0.18535222,\n",
       "  0.24036638,\n",
       "  -0.057771664,\n",
       "  -0.0039299363,\n",
       "  0.04617503,\n",
       "  -0.37815213,\n",
       "  -0.16284434,\n",
       "  -0.7022808,\n",
       "  0.14180303,\n",
       "  0.3738264,\n",
       "  0.26523164,\n",
       "  0.035790507,\n",
       "  -0.15323123,\n",
       "  0.27977192,\n",
       "  -0.8125319,\n",
       "  0.28840217,\n",
       "  0.30672494,\n",
       "  -0.24494337,\n",
       "  0.118681215,\n",
       "  0.39982682,\n",
       "  -0.0075560478,\n",
       "  0.20756009,\n",
       "  0.11282547,\n",
       "  0.37947708,\n",
       "  -0.0104021365,\n",
       "  -0.19482954,\n",
       "  -0.17465705,\n",
       "  0.117795356,\n",
       "  0.3145107,\n",
       "  -0.4440752,\n",
       "  0.28238365,\n",
       "  -0.0514833,\n",
       "  0.2966103,\n",
       "  0.28973058,\n",
       "  -0.7361314,\n",
       "  0.574417,\n",
       "  -0.002751973,\n",
       "  -0.0583005,\n",
       "  -0.065723166,\n",
       "  -0.08641471,\n",
       "  -0.040176403,\n",
       "  0.24526076,\n",
       "  -0.42696798,\n",
       "  0.029529696,\n",
       "  0.47557175,\n",
       "  -0.020611994,\n",
       "  0.008786288,\n",
       "  0.069823585,\n",
       "  0.20063758,\n",
       "  0.060858395,\n",
       "  0.120757565,\n",
       "  0.6435156,\n",
       "  -0.45200235,\n",
       "  0.0029266877,\n",
       "  -0.018996647,\n",
       "  0.3167421,\n",
       "  -0.28797385,\n",
       "  0.464085,\n",
       "  -0.3288666,\n",
       "  0.10144624,\n",
       "  0.26160482,\n",
       "  -0.31124496,\n",
       "  0.462713,\n",
       "  -0.01500367,\n",
       "  0.09802407,\n",
       "  0.07114159,\n",
       "  0.36214888,\n",
       "  0.038888756,\n",
       "  -0.6418619,\n",
       "  -0.062119793,\n",
       "  -0.14148486,\n",
       "  0.339929,\n",
       "  -0.20026863,\n",
       "  0.49398708,\n",
       "  -0.24870211,\n",
       "  0.57165504,\n",
       "  0.93831986,\n",
       "  0.2127893,\n",
       "  0.26297417,\n",
       "  0.45930052,\n",
       "  0.06439845,\n",
       "  0.23344457,\n",
       "  0.3627595,\n",
       "  0.33504912,\n",
       "  0.12573007,\n",
       "  -0.34177706,\n",
       "  0.34789285,\n",
       "  0.54293305],\n",
       " [-0.067080215,\n",
       "  0.07442202,\n",
       "  0.038137883,\n",
       "  0.08483367,\n",
       "  0.016313314,\n",
       "  -0.13662317,\n",
       "  0.0075254953,\n",
       "  0.18101934,\n",
       "  -0.07311878,\n",
       "  -0.049324308,\n",
       "  -0.058583237,\n",
       "  -0.122940496,\n",
       "  -0.050818138,\n",
       "  0.05129907,\n",
       "  -0.0002511344,\n",
       "  -0.044097494,\n",
       "  0.04438487,\n",
       "  -0.059199315,\n",
       "  -0.040624745,\n",
       "  -0.18481205,\n",
       "  0.039140034,\n",
       "  0.06394338,\n",
       "  0.015502239,\n",
       "  -0.007857122,\n",
       "  -0.01826149,\n",
       "  0.018449415,\n",
       "  -0.15371914,\n",
       "  -0.024176206,\n",
       "  -0.008056492,\n",
       "  -0.016902007,\n",
       "  0.06747999,\n",
       "  0.062411554,\n",
       "  -0.003535101,\n",
       "  -0.00082679366,\n",
       "  -0.0037752343,\n",
       "  0.09132864,\n",
       "  -0.017417414,\n",
       "  -0.09683716,\n",
       "  -0.02249285,\n",
       "  -0.10741396,\n",
       "  0.03602095,\n",
       "  -0.11757449,\n",
       "  0.03558691,\n",
       "  -0.029718788,\n",
       "  0.05631826,\n",
       "  0.01248933,\n",
       "  -0.10133385,\n",
       "  0.04302006,\n",
       "  0.035818852,\n",
       "  0.044744253,\n",
       "  0.07694934,\n",
       "  -0.06080174,\n",
       "  -0.052110266,\n",
       "  0.039488364,\n",
       "  -0.097221635,\n",
       "  0.07089797,\n",
       "  0.11620905,\n",
       "  -0.019797396,\n",
       "  -0.011220175,\n",
       "  0.014793994,\n",
       "  0.03131907,\n",
       "  0.06301892,\n",
       "  -0.026202636,\n",
       "  0.101395644,\n",
       "  -0.11048808,\n",
       "  0.04460571,\n",
       "  -0.038337283,\n",
       "  0.04545333,\n",
       "  -0.0779065,\n",
       "  0.12594554,\n",
       "  -0.055233955,\n",
       "  0.00633659,\n",
       "  0.08311029,\n",
       "  -0.0007933466,\n",
       "  0.082733564,\n",
       "  0.030141361,\n",
       "  -0.0030792288,\n",
       "  -0.03711296,\n",
       "  0.031009745,\n",
       "  -0.009329204,\n",
       "  -0.06681024,\n",
       "  -0.0018144293,\n",
       "  -0.05921185,\n",
       "  0.120100394,\n",
       "  -0.017466135,\n",
       "  0.09104549,\n",
       "  -0.047899935,\n",
       "  0.077506185,\n",
       "  0.23577736,\n",
       "  0.07399227,\n",
       "  0.059793085,\n",
       "  0.053674046,\n",
       "  0.055512838,\n",
       "  0.042825688,\n",
       "  0.10717219,\n",
       "  0.08042679,\n",
       "  0.0016190085,\n",
       "  -0.13236772,\n",
       "  0.014236352,\n",
       "  0.0637886],\n",
       " [-0.6255731,\n",
       "  0.36214247,\n",
       "  -0.009540138,\n",
       "  0.26017454,\n",
       "  0.28664473,\n",
       "  -0.63116926,\n",
       "  -0.044651687,\n",
       "  0.8261708,\n",
       "  -0.5331271,\n",
       "  -0.18246812,\n",
       "  -0.12393199,\n",
       "  -0.41560405,\n",
       "  -0.35196108,\n",
       "  0.081162594,\n",
       "  0.1971953,\n",
       "  -0.48919106,\n",
       "  0.07651314,\n",
       "  -0.07907236,\n",
       "  -0.6230598,\n",
       "  -1.161404,\n",
       "  0.85838896,\n",
       "  0.5099749,\n",
       "  -0.382043,\n",
       "  0.19474012,\n",
       "  -0.58225334,\n",
       "  0.010385075,\n",
       "  -1.2081155,\n",
       "  0.19091372,\n",
       "  0.08915576,\n",
       "  -0.17349012,\n",
       "  -0.091603056,\n",
       "  0.37248656,\n",
       "  0.08260508,\n",
       "  -0.35353994,\n",
       "  0.18478465,\n",
       "  0.4075899,\n",
       "  -0.88943225,\n",
       "  -0.5854066,\n",
       "  0.4640359,\n",
       "  -0.54597193,\n",
       "  0.26215732,\n",
       "  -0.4874425,\n",
       "  0.42556584,\n",
       "  0.19540356,\n",
       "  0.40572232,\n",
       "  0.3423091,\n",
       "  -0.53536016,\n",
       "  0.14499867,\n",
       "  0.31877553,\n",
       "  -0.3319907,\n",
       "  0.45206594,\n",
       "  -0.20952961,\n",
       "  -0.26072618,\n",
       "  0.33758828,\n",
       "  -0.4760192,\n",
       "  0.7526837,\n",
       "  0.21451095,\n",
       "  -0.36602113,\n",
       "  0.50253767,\n",
       "  0.38305435,\n",
       "  -0.1329273,\n",
       "  0.85289586,\n",
       "  -0.09367502,\n",
       "  0.45046425,\n",
       "  -0.6895916,\n",
       "  0.69794494,\n",
       "  -0.43327367,\n",
       "  0.022635896,\n",
       "  -0.39058566,\n",
       "  0.4311476,\n",
       "  -0.4939899,\n",
       "  0.23863089,\n",
       "  0.66763,\n",
       "  0.21439275,\n",
       "  0.38910025,\n",
       "  0.36759466,\n",
       "  0.14122583,\n",
       "  -0.5080891,\n",
       "  0.20793332,\n",
       "  -0.22322807,\n",
       "  -0.31756526,\n",
       "  -0.10355748,\n",
       "  -0.43570253,\n",
       "  0.5047615,\n",
       "  0.020342551,\n",
       "  0.9187383,\n",
       "  -0.44509783,\n",
       "  0.569629,\n",
       "  1.8534553,\n",
       "  0.37600374,\n",
       "  0.24153431,\n",
       "  0.28202716,\n",
       "  0.8528289,\n",
       "  -0.040972374,\n",
       "  0.12445011,\n",
       "  0.08990892,\n",
       "  -0.17197752,\n",
       "  -0.36140746,\n",
       "  -0.056045644,\n",
       "  0.14649302]]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[51]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "43a1efdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = [np.array(x) for x in X]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ac8b9929",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "793"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_len = max([sentence.shape[0] for sentence in X])\n",
    "max_len"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2be35ed",
   "metadata": {},
   "source": [
    "Geralmente o valor 0 é utilizado no padding de word embeddings, pois ele representa a ausência de valor para aquele elemento. O padding é usado para que todas as amostras tenham o mesmo tamanho, por exemplo, para que todas as frases tenham o mesmo número de palavras. Ao usar o valor 0 para o padding, estamos representando que aquela posição é uma palavra \"fictícia\" que não possui significado. Dessa forma, a rede neural não dará importância a essas palavras fictícias durante o processo de treinamento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "eef9d76d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = tf.keras.preprocessing.sequence.pad_sequences(X, value = 0, padding = 'post', maxlen = max_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "99131d13",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = dataset.iloc[:, 4].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "09bb144c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 2, 3], dtype=int64)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = np.array(y)\n",
    "np.unique(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5399c97c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1441, 793, 100), (1441,))"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape, y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8d13a75",
   "metadata": {},
   "source": [
    "O TensorFlow não suporta tensores com formas variadas, então todas as listas precisam ter o mesmo tamanho. Para resolver este problema, pode-se usar uma biblioteca de processamento de dados para garantir que todas as listas tenham o mesmo tamanho, ou pode-se remover as listas que têm tamanhos diferentes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b15b4f8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_tensor = tf.convert_to_tensor(X, dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9d02c4fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([1441, 793, 100])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_tensor.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc878b21",
   "metadata": {},
   "source": [
    " ## treinamento de uma rede neural convolucional"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "558cf9a6",
   "metadata": {},
   "source": [
    "### Camada de convolução\n",
    "\n",
    "A **camada de convolução** é uma das camadas fundamentais de uma rede neural convolucional (CNN) para classificação de texto. Essa camada é responsável por extrair as características dos dados de entrada, que podem ser, por exemplo, palavras ou frases de um texto. A convolução é uma operação matemática que envolve a multiplicação da entrada com um pequeno filtro (também chamado de kernel ou janela), que se desloca pela entrada em uma determinada direção. A cada posição, o resultado da multiplicação é somado e a saída é produzida.\n",
    "\n",
    "A camada de convolução pode ter vários filtros diferentes, cada um aprendendo uma característica diferente dos dados. Isso permite que a CNN capture uma variedade de informações importantes do texto, como a presença de palavras-chave, a estrutura gramatical e o contexto em que as palavras são usadas.\n",
    "\n",
    "O número de filtros recomendados para a camada de convolução em uma rede neural convolucional pode variar dependendo da complexidade do problema e da arquitetura da rede. Não há um número fixo que seja considerado ideal ou padrão, mas é comum utilizar potências de 2, como 32, 64, 128, 256, etc. para o número de filtros em cada camada. O número de filtros também pode ser aumentado à medida que se avança nas camadas da rede, com o objetivo de aprender características mais complexas e abstratas\n",
    "\n",
    "Além disso, é comum usar outras camadas, como camadas de pooling e camadas de dropout, para aumentar a eficiência e evitar overfitting, que é um problema comum em redes neurais.\n",
    "\n",
    "Em resumo, a camada de convolução é uma peça fundamental na arquitetura de uma rede neural convolucional para classificação de texto, permitindo a extração de características relevantes dos dados de entrada.\n",
    "\n",
    "Na arquitetura de uma Rede Neural Convolucional (CNN), a camada de pooling é uma das camadas fundamentais. Essa camada é responsável por reduzir a dimensionalidade espacial do mapa de características gerado pela camada de convolução anterior.\n",
    "\n",
    "Não há um valor recomendado fixo de kernel_size para todos os casos, pois ele depende do tamanho da sequência, da natureza dos dados e dos objetivos do modelo. Em geral, valores comuns de kernel_size para sequências de texto variam de 2 a 5. No entanto, pode ser necessário testar diferentes valores para encontrar o melhor desempenho para o seu conjunto de dados específico. Além disso, a escolha do kernel_size também pode ser influenciada pelo tamanho da dimensão embutida (word embedding), pelo número de camadas na rede e pelo número de filtros. É importante experimentar diferentes configurações e avaliar o desempenho para encontrar o melhor modelo.\n",
    "\n",
    "Se a rede neural convolucional não converge com 1000 épocas, significa que o modelo ainda não atingiu a performance desejada após 1000 iterações de treinamento. Neste caso, aumentar o número de **filtros** pode ser uma possível solução, mas existem outros fatores que precisam ser considerados, como o tipo de otimizador, taxa de aprendizado, regularização, e se o conjunto de dados de treinamento é suficientemente grande e representativo. Além disso, é importante verificar se o modelo não está sofrendo de overfitting, ou seja, se ele está generalizando bem para dados não vistos durante o treinamento. Não há uma única resposta para essa questão, e a solução pode envolver uma combinação de diferentes ajustes e experimentos.\n",
    "\n",
    "### Camada de pooling\n",
    "\n",
    "A ideia básica da **camada de pooling** é reduzir a resolução espacial da representação do mapa de características, a fim de reduzir a quantidade de parâmetros e poder generalizar melhor o modelo para novos dados. Ela funciona selecionando um valor de um conjunto de valores de características próximos, agrupando-os e reduzindo-os a um único valor representativo. Essa operação é realizada em cada \"sub-região\" do mapa de características, onde cada sub-região é definida por um filtro.\n",
    "\n",
    "Existem vários tipos de pooling, sendo os mais comuns o max pooling e o average pooling. No max pooling, é selecionado o valor máximo dentro da sub-região para ser o valor representativo. Já no average pooling, é calculada a média dos valores da sub-região para ser o valor representativo.\n",
    "\n",
    "A camada de pooling é uma forma de regularização, já que ela reduz a dimensionalidade da representação do mapa de características e, consequentemente, o número de parâmetros a serem treinados. Isso reduz o risco de overfitting, tornando o modelo.\n",
    "\n",
    "### Camada totalmente conectada\n",
    "\n",
    "A **camada totalmente conectada** é uma camada de rede neural que recebe as características extraídas pela camada de convolução e/ou de pooling e as usa para realizar a classificação final. Essa camada é composta por neurônios que estão totalmente conectados com os neurônios da camada anterior.\n",
    "\n",
    "Na tarefa de classificação de texto, a camada totalmente conectada pode ser usada para gerar a pontuação da classe correspondente a cada possível categoria. Por exemplo, em uma tarefa de classificação de texto em que há duas categorias, \"positivo\" e \"negativo\", a camada totalmente conectada pode gerar uma pontuação para cada uma dessas categorias. Em seguida, a classe final é escolhida com base na pontuação mais alta.\n",
    "\n",
    "Uma das desvantagens da camada totalmente conectada é que ela pode causar overfitting (sobreajuste) aos dados de treinamento. Para lidar com esse problema, é comum o uso de técnicas como **dropout** ou **regularização L2** na camada totalmente conectada para reduzir a complexidade do modelo e evitar overfitting.\n",
    "\n",
    "Não existe um número recomendado exato de **camadas e neurônios** para uma camada densa em uma rede neural, pois isso depende de vários fatores, como o tamanho do conjunto de dados, a complexidade do modelo, a precisão desejada, entre outros. Algumas boas práticas incluem começar com uma camada densa com uma pequena quantidade de neurônios, como 32 ou 64, e aumentar gradativamente até atingir uma boa precisão. É importante também usar **regularização** para evitar **overfitting**. Uma boa prática é experimentar com diferentes configurações e comparar os resultados para escolher a melhor opção.\n",
    "\n",
    "Aumentar o número de camadas em uma rede neural convolucional pode ser considerado como uma técnica para melhorar a performance do modelo em uma **tarefa de classificação de texto**, mas isso depende de vários fatores, tais como a quantidade de dados disponíveis, a complexidade do modelo e a quantidade de recursos computacionais disponíveis.\n",
    "\n",
    "A adição de camadas pode permitir que o modelo capture **padrões mais complexos nas sequências de texto**, o que pode levar a uma melhora na acurácia. _No entanto, também é importante ter em mente que a adição de muitas camadas pode tornar o modelo propenso a overfitting, especialmente se a quantidade de dados disponíveis for limitada_.\n",
    "\n",
    "Além disso, o número de camadas também pode impactar a velocidade de treinamento do modelo e a complexidade computacional. É importante encontrar um equilíbrio entre a capacidade do modelo de aprender padrões importantes e a capacidade de manter uma performance eficiente.\n",
    "\n",
    "Em geral, é recomendado experimentar diferentes configurações, incluindo diferentes números de camadas, para encontrar a melhor configuração para o problema específico de classificação de texto em questão.\n",
    "\n",
    "### Dropout\n",
    "\n",
    "A **técnica de \"dropout\"** é um método de regularização que é frequentemente utilizado em redes neurais, incluindo as camadas totalmente conectadas. O objetivo do dropout é evitar o overfitting, que é quando a rede se ajusta demais aos dados de treinamento, e não generaliza bem para novos dados.\n",
    "\n",
    "O dropout funciona desativando aleatoriamente um conjunto de neurônios da camada em cada passagem de treinamento. Isso significa que a camada tem que aprender a confiar em diferentes combinações de neurônios em cada passagem de treinamento, em vez de depender sempre dos mesmos neurônios. Isso faz com que a rede se torne mais robusta, pois não pode confiar em um subconjunto específico de neurônios para a classificação de uma entrada.\n",
    "\n",
    "Durante o processo de teste, todos os neurônios são ativados, pois não há necessidade de regularização neste momento. Em resumo, o dropout é uma técnica simples e eficaz para reduzir o overfitting em redes neurais, tornando as camadas totalmente conectadas mais robustas e generalizáveis.\n",
    "\n",
    "O valor recomendado para o dropout_rate varia dependendo da aplicação e dos dados. Em geral, o dropout_rate varia entre 0.2 e 0.5. O dropout_rate de 0.5 significa que 50% dos neurônios serão \"desligados\" durante o treinamento para evitar overfitting, enquanto o dropout_rate de 0.2 significa que 20% dos neurônios serão desligados. O valor ótimo par'a o dropout_rate deve ser determinado experimentando com diferentes valores e avaliando o desempenho do modelo.\n",
    "\n",
    "### Regularização L2\n",
    "\n",
    "Em redes neurais, a **regularização L2** é uma técnica usada para evitar o overfitting, ou seja, o modelo aprender demais o conjunto de treinamento, e não generalizar bem para novos dados. A regularização L2 adiciona um termo à função de custo da rede neural, que penaliza pesos grandes. Especificamente, a função de custo adiciona a soma dos quadrados dos pesos multiplicada por um parâmetro de regularização lambda. Essa penalização faz com que a rede favoreça pesos menores, o que pode ajudar a evitar o overfitting.\n",
    "\n",
    "Na camada totalmente conectada, onde cada neurônio está conectado a todos os neurônios da camada anterior, a regularização L2 é aplicada aos pesos da camada. Isso ajuda a controlar a complexidade do modelo, evitando que os pesos da rede se tornem muito grandes. Além disso, a regularização L2 pode melhorar o desempenho da rede em conjuntos de dados de teste, onde o modelo não foi treinado, ajudando a rede a generalizar melhor para novos dados.\n",
    "\n",
    "A recomendação geral é aplicar a regularização L2 em camadas densas ou camadas totalmente conectadas, em vez de nas camadas de convolução. Isso se deve ao fato de que a regularização L2 é mais eficaz na prevenção do overfitting em camadas densas, já que as camadas densas tendem a ter muitos parâmetros e a possibilidade de aprender padrões redundantes.\n",
    "\n",
    "O parâmetro \"kernel_regularizer=keras.regularizers.l2(0.01)\" é um argumento que pode ser passado em uma camada de rede neural no Keras para aplicar regularização L2 aos pesos (kernels) dessa camada. O valor 0,01 passado como argumento representa a força da regularização L2, onde valores maiores levarão a uma penalidade mais forte e pesos mais próximos de zero.\n",
    "\n",
    "No entanto, é importante lembrar que a implementação da regularização L2 depende do problema específico e dos dados de treinamento. É possível que a aplicação da regularização L2 nas camadas de convolução seja benéfica em algumas situações específicas. Portanto, é sempre recomendável experimentar diferentes abordagens e verificar qual funciona melhor para o problema em questão.\n",
    "\n",
    "A saída de uma rede neural convolucional de classificação de texto com 4 classes é uma matriz de probabilidade com 4 colunas, onde cada coluna representa a probabilidade de uma determinada classe. O valor da saída é o índice da coluna que apresenta o maior valor. Por exemplo, se o maior valor da saída for na primeira coluna, então o modelo preveu a classe 0. Se o maior valor da saída for na segunda coluna, então o modelo preveu a classe 1 e assim por diante.\n",
    "\n",
    "O número de épocas recomendado para uma rede neural convolucional varia dependendo do tamanho do seu conjunto de dados e da complexidade do modelo. Em geral, um número de épocas entre 10 e 100 é considerado um bom ponto de partida. Se o treinamento da rede não estiver levando a uma boa precisão, você pode aumentar o número de épocas. De maneira geral, é importante observar o comportamento do modelo em relação à precisão e loss ao longo do treinamento para determinar o melhor número de épocas. Além disso, é importante utilizar uma técnica de validação cruzada para evitar o overfitting do modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c9cd04d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# o vetor de word embbeding é de tamanho 100-\n",
    "tamanho_word_embbeding = 100\n",
    "# o número de filtros de convolução é 32\n",
    "qtd_filtros = 32\n",
    "# quantidade de neuronios na camada densa é 64\n",
    "qtd_neuronios_camada_densa = 64\n",
    "# o tamanho do bath é 256\n",
    "tamanho_batch = 100\n",
    "# a quantidade de classes é quatro\n",
    "qtd_classes = len(set(y))\n",
    "# taxa de dropout é a taxa de neurônios que serão desligados no treinamento\n",
    "#o valor 0.2 é um valor que empiricamente evita overffiting\n",
    "taxa_dropout = 0.2\n",
    "#é a quantidade de épocas de treinamento\n",
    "qtd_epocas = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "0e73a9c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "classe que representa a rede neural convolucional  para classificação de textos\n",
    "'''\n",
    "class DCNN(tf.keras.Model):\n",
    "    \n",
    "    '''\n",
    "        tamanho_word_embbeding: tamanho do vetor de números representando a palavra;\n",
    "        qtd_filtros: número de filtros para cada dimensão;\n",
    "        qtd_neuronios_camada_densa: número de neurônios da rede neural densa;\n",
    "        qtd_classes: número de classes para classificação;\n",
    "        taxa_dropout: porcentagem de desativação de neurônios;\n",
    "    '''\n",
    "    def __init__(self,  \n",
    "                 tamanho_word_embbeding = 1, \n",
    "                 qtd_filtros = 8, \n",
    "                 qtd_neuronios_camada_densa = 64, \n",
    "                 qtd_classes = 2,\n",
    "                 taxa_dropout = 0.2, \n",
    "                 training = False, \n",
    "                 name = 'dcnn'):\n",
    "        super(DCNN, self).__init__(name=name)\n",
    "        #gera a matriz de embedding do vocabulário ou a representação vetorial de cada palavra\n",
    "        #camadas de convolução\n",
    "        #define os filtros\n",
    "        #same: retorna os mesmos dados no mesmo formato\n",
    "        # para cada sentença, extrai as fetures e realiza o treinamento das feature vector\n",
    "        self.bigram = layers.Conv1D(filters=qtd_filtros, kernel_size=2, padding='same', activation = 'relu', kernel_regularizer=keras.regularizers.l2(0.01))\n",
    "        self.trigram = layers.Conv1D(filters=qtd_filtros, kernel_size=3, padding='same', activation = 'relu')\n",
    "        self.fourgram = layers.Conv1D(filters=qtd_filtros, kernel_size=4, padding='same', activation = 'relu')\n",
    "        self.fivegram = layers.Conv1D(filters=qtd_filtros, kernel_size=5, padding='same', activation = 'relu')\n",
    "        #camada max pooling\n",
    "        self.pool = layers.GlobalMaxPool1D()\n",
    "        #camada densa\n",
    "        self.dense_1 = layers.Dense(units = qtd_neuronios_camada_densa, activation = 'relu')\n",
    "        self.dense_2 = layers.Dense(units = qtd_neuronios_camada_densa, activation = 'relu')\n",
    "        self.dense_3 = layers.Dense(units = qtd_neuronios_camada_densa, activation = 'relu')\n",
    "        self.dropout = layers.Dropout(rate = taxa_dropout)\n",
    "        if qtd_classes == 2:\n",
    "            self.last_dense = layers.Dense(units = 1, activation = 'sigmoid')\n",
    "        else:\n",
    "            #problemas de classificação com mais de 2 classes utilizar a softmax\n",
    "            self.last_dense = layers.Dense(units = qtd_classes, activation = 'softmax', kernel_regularizer=keras.regularizers.l2(0.01))\n",
    "            \n",
    "    def call(self, inputs, training):\n",
    "        x = inputs\n",
    "        x_1 = self.bigram(x)\n",
    "        x_1 = self.pool(x_1)\n",
    "        x_2 = self.trigram(x)\n",
    "        x_2 = self.pool(x_2)\n",
    "        x_3 = self.fourgram(x)\n",
    "        x_3 = self.pool(x_3)\n",
    "        x_4 = self.fivegram(x)\n",
    "        x_4 = self.pool(x_4)\n",
    "        \n",
    "        merged = tf.concat([x_1, x_2, x_3,x_4], axis = -1) # (batch_size, 3*qtd_filtros)\n",
    "        print(merged.shape)\n",
    "        merged = self.dense_1(merged)\n",
    "        merged = self.dropout(merged, training)\n",
    "        merged = self.dense_2(merged)\n",
    "        merged = self.dropout(merged, training)\n",
    "        merged = self.dense_3(merged)\n",
    "        merged = self.dropout(merged, training)\n",
    "        output = self.last_dense(merged)\n",
    "        \n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d36b9e2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#criar a instância da rede neural especificada\n",
    "Dcnn = DCNN(tamanho_word_embbeding=tamanho_word_embbeding, qtd_filtros=qtd_filtros, qtd_neuronios_camada_densa=qtd_neuronios_camada_densa, qtd_classes=qtd_classes, taxa_dropout=taxa_dropout)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abca85a0",
   "metadata": {},
   "source": [
    "### Função de perda e otimizador\n",
    "\n",
    "As linhas a seguir definem a **função de perda** e o **otimizador** que serão usados durante o treinamento da rede neural. Especificamente, essas linhas determinam se a rede neural será usada para classificação binária ou multiclasse. Se nb_classes for igual a 2, a rede neural será usada para classificação binária e a função de perda será **binary_crossentropy**. Neste caso, o otimizador será **adam**. Se nb_classes for diferente de 2, a rede neural será usada para classificação multiclasse e a função de perda será **sparse_categorical_crossentropy**. Neste caso, o otimizador também será adam. Além disso, o desempenho será avaliado usando a métrica de acurácia.\n",
    "\n",
    "A **binary_crossentropy** é uma função de perda utilizada em problemas de classificação binária. Ela mede a diferença entre a previsão do modelo e o valor alvo (verdadeiro). Isso é feito calculando a **entropia cruzada** (cross-entropy) entre a distribuição de probabilidade predita pelo modelo e a distribuição de probabilidade real.\n",
    "\n",
    "A **sparse_categorical_crossentropy**, por outro lado, é uma função de perda utilizada em problemas de classificação multiclasse. Nestes problemas, cada exemplo de treinamento pode ser classificado como uma das várias categorias possíveis. Esta função de perda compara a previsão do modelo com o valor alvo e calcula a **entropia cruzada (cross-entropy)** entre a distribuição de probabilidade predita e a distribuição de probabilidade verdadeira.\n",
    "\n",
    "A diferença entre binary_crossentropy e sparse_categorical_crossentropy é que a última é mais eficiente para problemas com muitas categorias, pois permite que os valores-alvo sejam especificados como inteiros (índices) em vez de vetores one-hot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "5544e284",
   "metadata": {},
   "outputs": [],
   "source": [
    "if qtd_classes == 2:\n",
    "    Dcnn.compile(loss = 'binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "else:\n",
    "    Dcnn.compile(loss = 'sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65145b2f",
   "metadata": {},
   "source": [
    "### Objeto de verificação de ponto\n",
    "\n",
    "As linhas a seguir são uma implementação de salvar e restaurar os pesos de uma rede neural no TensorFlow.\n",
    "\n",
    "O código cria um **objeto de verificação de ponto (ckpt)** que é associado à rede neural (Dcnn). Em seguida, cria um gerenciador de ponto de verificação (ckpt_manager) que controla o local onde os checkpoints são salvos e quantos checkpoints são mantidos.\n",
    "\n",
    "A linha seguinte verifica se existe um checkpoint mais recente. Se houver, o checkpoint é restaurado, o que significa que os pesos salvos da última vez em que o modelo foi treinado são carregados na rede neural. Finalmente, a mensagem \"Latest checkpoint restored\" é impressa na tela para indicar que o checkpoint foi restaurado com sucesso."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "36adc501",
   "metadata": {},
   "outputs": [],
   "source": [
    "ckpt = tf.train.Checkpoint(Dcnn=Dcnn)\n",
    "ckpt_manager = tf.train.CheckpointManager(ckpt, '', max_to_keep=5)\n",
    "if ckpt_manager.latest_checkpoint:\n",
    "    ckpt.restore(ckpt_manager.latest_checkpoint)\n",
    "    print('Latest checkpoint restored')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db37f635",
   "metadata": {},
   "source": [
    "### Parâmetros do método fit\n",
    "\n",
    "A função fit da classe tf.keras.Model tem os seguintes tipos de parâmetros:\n",
    "\n",
    "**x**: array Numpy ou tensor, ou seja, dados de treinamento para o modelo.\n",
    "\n",
    "**y**: array Numpy ou tensor, ou seja, etiquetas de treinamento para o modelo.\n",
    "\n",
    "**batch_size**: inteiro, ou seja, o número de amostras de treinamento por atualização de peso.\n",
    "\n",
    "**epochs**: inteiro, ou seja, o número de épocas (ciclos) a serem executados sobre os dados de treinamento.\n",
    "\n",
    "**verbose**: inteiro, ou seja, o nível de verbosidade da função. 0 significa que não há saída, 1 significa que a saída de progresso é exibida em forma de barra de progresso, 2 significa que o progresso é exibido como uma única linha.\n",
    "\n",
    "**callbacks**: lista, ou seja, lista de instâncias de Callback, que são funções de retorno de chamada a serem executadas durante o treinamento.\n",
    "\n",
    "**validation_data**: tupla (x_val, y_val), ou seja, conjunto de dados de validação, onde x_val é um array Numpy ou tensor e y_val é uma lista ou array Numpy ou tensor.\n",
    "\n",
    "**shuffle**: booleano, ou seja, se os dados de treinamento devem ser embaralhados antes de cada época.\n",
    "\n",
    "**class_weight**: dicionário, ou seja, pesos das classes, usados para lidar com desequilíbrios de classes em dados de treinamento.\n",
    "\n",
    "**sample_weight**: array Numpy ou tensor, ou seja, pesos amostrais, usados para lidar com desequilíbrios de amostras em dados de treinamento.\n",
    "\n",
    "**initial_epoch**: inteiro, ou seja, época inicial para iniciar a contagem de épocas. Útil quando você quer retomar o treinamento de um modelo interrompido.\n",
    "\n",
    "**steps_per_epoch**: inteiro, ou seja, o número de etapas (batches) por época. Se for fornecido, sobrescreve o cálculo automático baseado na quantidade de amostras de treinamento.\n",
    "\n",
    "**validation_steps**: inteiro, ou seja, o número de etapas (batches) de validação por época. Se for fornecido, sobrescreve o cálculo automático baseado na quantidade de amostras de validação.\n",
    "\n",
    "A vantagem de usar o **parâmetro shuffle** no método fit é que ele embaralha os dados de treinamento a cada época, o que pode melhorar a generalização do modelo e prevenir overfitting. Isso acontece porque o modelo não é treinado com um conjunto de dados sempre na mesma ordem, o que pode evitar que ele memorize as informações e não generalize corretamente.\n",
    "\n",
    "No entanto, há também uma desvantagem ao usar shuffle. Embaralhar os dados a cada época pode tornar o treinamento mais lento, especialmente se o conjunto de dados for grande. Além disso, o embaralhamento pode ser inadequado para algumas aplicações em que a ordem dos dados é importante, como previsão de séries temporais.\n",
    "\n",
    "Em geral, usar shuffle é uma boa prática para muitos tipos de modelos, mas é importante avaliar se o uso é adequado para o problema em questão.\n",
    "\n",
    "### Valores de accuracy e val_accuracy durante o treinamento\n",
    "\n",
    "Durante o treinamento de uma rede neural convolucional, é ideal que a **\"accuracy\"** (acurácia do treinamento) e **\"val_accuracy\"** (acurácia da validação) aumentem ao longo das épocas. A acurácia de treinamento deve aumentar até alcançar um valor próximo de 100% e a acurácia de validação deve aumentar até alcançar um valor próximo do valor da acurácia de treinamento. _Se a acurácia de validação estiver ficando muito abaixo da acurácia de treinamento, pode ser um sinal de overfitting_.\n",
    "\n",
    "O overfitting ocorre quando a rede neural é muito complexa para o conjunto de dados de treinamento e aprende características específicas dos dados de treinamento que não são genéricas e não se aplicam a novos dados. Isso pode ser solucionado usando técnicas de regularização, diminuindo o número de camadas ou de neurônios, ou aumentando o número de exemplos de treinamento.\n",
    "\n",
    "Uma acurácia de treinamento alta e uma acurácia de validação baixa em uma rede neural convolucional (CNN) ao longo das épocas geralmente significa que a rede está sofrendo de overfitting, ou seja, ela está memorizando os dados de treinamento em vez de generalizar e aprender padrões mais amplos que possam ser aplicados a novos dados. Isso pode ser indicado pelo fato de que a rede é capaz de classificar corretamente a maioria dos dados de treinamento, mas não é capaz de classificar corretamente uma quantidade significativa de dados de validação.\n",
    "\n",
    "Uma abordagem para lidar com esse problema é adicionar regularização à rede, como dropout, L1 ou L2 regularization, ou usar data augmentation para aumentar o tamanho do conjunto de treinamento. Também pode ser útil ajustar os hiperparâmetros da rede, como a taxa de aprendizado, tamanho do lote, número de camadas, tamanho dos filtros convolucionais e tamanho dos mapas de características."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "0acca61b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "(None, 128)\n",
      "(None, 128)\n",
      "12/12 [==============================] - ETA: 0s - loss: 1.9008 - accuracy: 0.2474(None, 128)\n",
      "12/12 [==============================] - 4s 143ms/step - loss: 1.9008 - accuracy: 0.2474 - val_loss: 1.8337 - val_accuracy: 0.2422\n",
      "Epoch 2/200\n",
      "12/12 [==============================] - 1s 110ms/step - loss: 1.7940 - accuracy: 0.2734 - val_loss: 1.7392 - val_accuracy: 0.3218\n",
      "Epoch 3/200\n",
      "12/12 [==============================] - 1s 114ms/step - loss: 1.7016 - accuracy: 0.2760 - val_loss: 1.6649 - val_accuracy: 0.2699\n",
      "Epoch 4/200\n",
      "12/12 [==============================] - 1s 119ms/step - loss: 1.6260 - accuracy: 0.3047 - val_loss: 1.5969 - val_accuracy: 0.3806\n",
      "Epoch 5/200\n",
      "12/12 [==============================] - 1s 113ms/step - loss: 1.5581 - accuracy: 0.3325 - val_loss: 1.5471 - val_accuracy: 0.3529\n",
      "Epoch 6/200\n",
      "12/12 [==============================] - 1s 109ms/step - loss: 1.5070 - accuracy: 0.3533 - val_loss: 1.4895 - val_accuracy: 0.3495\n",
      "Epoch 7/200\n",
      "12/12 [==============================] - 1s 117ms/step - loss: 1.4673 - accuracy: 0.3568 - val_loss: 1.4579 - val_accuracy: 0.3737\n",
      "Epoch 8/200\n",
      "12/12 [==============================] - 1s 121ms/step - loss: 1.4139 - accuracy: 0.3845 - val_loss: 1.4307 - val_accuracy: 0.3910\n",
      "Epoch 9/200\n",
      "12/12 [==============================] - 1s 121ms/step - loss: 1.3922 - accuracy: 0.3863 - val_loss: 1.4085 - val_accuracy: 0.3633\n",
      "Epoch 10/200\n",
      "12/12 [==============================] - 1s 115ms/step - loss: 1.3547 - accuracy: 0.4010 - val_loss: 1.3847 - val_accuracy: 0.4014\n",
      "Epoch 11/200\n",
      "12/12 [==============================] - 1s 114ms/step - loss: 1.3149 - accuracy: 0.4314 - val_loss: 1.3973 - val_accuracy: 0.3772\n",
      "Epoch 12/200\n",
      "12/12 [==============================] - 1s 122ms/step - loss: 1.2918 - accuracy: 0.4427 - val_loss: 1.3733 - val_accuracy: 0.4014\n",
      "Epoch 13/200\n",
      "12/12 [==============================] - 2s 138ms/step - loss: 1.2535 - accuracy: 0.4653 - val_loss: 1.3717 - val_accuracy: 0.4014\n",
      "Epoch 14/200\n",
      "12/12 [==============================] - 2s 130ms/step - loss: 1.2554 - accuracy: 0.4401 - val_loss: 1.3703 - val_accuracy: 0.3806\n",
      "Epoch 15/200\n",
      "12/12 [==============================] - 1s 117ms/step - loss: 1.2025 - accuracy: 0.4783 - val_loss: 1.3917 - val_accuracy: 0.3806\n",
      "Epoch 16/200\n",
      "12/12 [==============================] - 1s 118ms/step - loss: 1.1735 - accuracy: 0.4870 - val_loss: 1.4472 - val_accuracy: 0.3875\n",
      "Epoch 17/200\n",
      "12/12 [==============================] - 1s 119ms/step - loss: 1.1519 - accuracy: 0.4991 - val_loss: 1.4774 - val_accuracy: 0.3599\n",
      "Epoch 18/200\n",
      "12/12 [==============================] - 2s 127ms/step - loss: 1.1143 - accuracy: 0.5347 - val_loss: 1.4137 - val_accuracy: 0.4118\n",
      "Epoch 19/200\n",
      "12/12 [==============================] - 1s 119ms/step - loss: 1.0534 - accuracy: 0.5634 - val_loss: 1.4407 - val_accuracy: 0.3737\n",
      "Epoch 20/200\n",
      "12/12 [==============================] - 1s 120ms/step - loss: 1.0392 - accuracy: 0.5773 - val_loss: 1.4655 - val_accuracy: 0.3529\n",
      "Epoch 21/200\n",
      "12/12 [==============================] - 1s 112ms/step - loss: 1.0044 - accuracy: 0.5859 - val_loss: 1.4933 - val_accuracy: 0.4083\n",
      "Epoch 22/200\n",
      "12/12 [==============================] - 1s 113ms/step - loss: 0.9506 - accuracy: 0.6102 - val_loss: 1.5177 - val_accuracy: 0.3564\n",
      "Epoch 23/200\n",
      "12/12 [==============================] - 1s 123ms/step - loss: 0.9224 - accuracy: 0.6406 - val_loss: 1.5738 - val_accuracy: 0.3633\n",
      "Epoch 24/200\n",
      "12/12 [==============================] - 1s 124ms/step - loss: 0.8958 - accuracy: 0.6641 - val_loss: 1.7133 - val_accuracy: 0.3495\n",
      "Epoch 25/200\n",
      "12/12 [==============================] - 1s 121ms/step - loss: 0.8448 - accuracy: 0.6910 - val_loss: 1.6154 - val_accuracy: 0.3599\n",
      "Epoch 26/200\n",
      "12/12 [==============================] - 1s 114ms/step - loss: 0.7964 - accuracy: 0.7188 - val_loss: 1.7130 - val_accuracy: 0.3460\n",
      "Epoch 27/200\n",
      "12/12 [==============================] - 1s 116ms/step - loss: 0.7845 - accuracy: 0.7083 - val_loss: 1.7411 - val_accuracy: 0.3737\n",
      "Epoch 28/200\n",
      "12/12 [==============================] - 1s 112ms/step - loss: 0.7361 - accuracy: 0.7361 - val_loss: 1.7650 - val_accuracy: 0.3460\n",
      "Epoch 29/200\n",
      "12/12 [==============================] - 1s 112ms/step - loss: 0.7188 - accuracy: 0.7387 - val_loss: 1.7980 - val_accuracy: 0.3218\n",
      "Epoch 30/200\n",
      "12/12 [==============================] - 1s 108ms/step - loss: 0.6711 - accuracy: 0.7778 - val_loss: 1.8590 - val_accuracy: 0.3599\n",
      "Epoch 31/200\n",
      "12/12 [==============================] - 1s 109ms/step - loss: 0.6730 - accuracy: 0.7674 - val_loss: 1.8204 - val_accuracy: 0.3322\n",
      "Epoch 32/200\n",
      "12/12 [==============================] - 1s 108ms/step - loss: 0.5979 - accuracy: 0.8047 - val_loss: 2.0522 - val_accuracy: 0.3218\n",
      "Epoch 33/200\n",
      "12/12 [==============================] - 1s 111ms/step - loss: 0.6069 - accuracy: 0.7960 - val_loss: 2.1065 - val_accuracy: 0.3460\n",
      "Epoch 34/200\n",
      "12/12 [==============================] - 1s 111ms/step - loss: 0.6457 - accuracy: 0.7734 - val_loss: 2.0178 - val_accuracy: 0.3599\n",
      "Epoch 35/200\n",
      "12/12 [==============================] - 1s 107ms/step - loss: 0.6032 - accuracy: 0.8090 - val_loss: 2.1310 - val_accuracy: 0.3253\n",
      "Epoch 36/200\n",
      "12/12 [==============================] - 1s 108ms/step - loss: 0.5581 - accuracy: 0.8064 - val_loss: 2.1046 - val_accuracy: 0.3529\n",
      "Epoch 37/200\n",
      "12/12 [==============================] - 1s 109ms/step - loss: 0.5370 - accuracy: 0.8316 - val_loss: 2.0673 - val_accuracy: 0.3599\n",
      "Epoch 38/200\n",
      "12/12 [==============================] - 1s 109ms/step - loss: 0.4800 - accuracy: 0.8516 - val_loss: 2.2377 - val_accuracy: 0.3322\n",
      "Epoch 39/200\n",
      "12/12 [==============================] - 1s 106ms/step - loss: 0.4687 - accuracy: 0.8472 - val_loss: 2.3939 - val_accuracy: 0.3426\n",
      "Epoch 40/200\n",
      "12/12 [==============================] - 1s 105ms/step - loss: 0.4432 - accuracy: 0.8576 - val_loss: 2.2676 - val_accuracy: 0.3529\n",
      "Epoch 41/200\n",
      "12/12 [==============================] - 1s 111ms/step - loss: 0.4107 - accuracy: 0.8715 - val_loss: 2.3784 - val_accuracy: 0.3529\n",
      "Epoch 42/200\n",
      "12/12 [==============================] - 1s 109ms/step - loss: 0.4163 - accuracy: 0.8759 - val_loss: 2.3987 - val_accuracy: 0.3529\n",
      "Epoch 43/200\n",
      "12/12 [==============================] - 1s 111ms/step - loss: 0.3927 - accuracy: 0.8767 - val_loss: 2.5140 - val_accuracy: 0.3149\n",
      "Epoch 44/200\n",
      "12/12 [==============================] - 1s 115ms/step - loss: 0.4246 - accuracy: 0.8646 - val_loss: 2.5477 - val_accuracy: 0.3633\n",
      "Epoch 45/200\n",
      "12/12 [==============================] - 1s 116ms/step - loss: 0.3747 - accuracy: 0.8906 - val_loss: 2.5865 - val_accuracy: 0.3287\n",
      "Epoch 46/200\n",
      "12/12 [==============================] - 1s 113ms/step - loss: 0.3609 - accuracy: 0.8924 - val_loss: 2.6226 - val_accuracy: 0.3599\n",
      "Epoch 47/200\n",
      "12/12 [==============================] - 1s 112ms/step - loss: 0.3735 - accuracy: 0.8872 - val_loss: 2.6148 - val_accuracy: 0.3183\n",
      "Epoch 48/200\n",
      "12/12 [==============================] - 1s 111ms/step - loss: 0.3683 - accuracy: 0.8898 - val_loss: 2.7928 - val_accuracy: 0.3183\n",
      "Epoch 49/200\n",
      "12/12 [==============================] - 1s 110ms/step - loss: 0.3587 - accuracy: 0.8880 - val_loss: 2.7031 - val_accuracy: 0.3460\n",
      "Epoch 50/200\n",
      "12/12 [==============================] - 1s 115ms/step - loss: 0.3221 - accuracy: 0.9045 - val_loss: 2.7597 - val_accuracy: 0.3702\n",
      "Epoch 51/200\n",
      "12/12 [==============================] - 1s 110ms/step - loss: 0.3265 - accuracy: 0.9019 - val_loss: 2.6360 - val_accuracy: 0.3529\n",
      "Epoch 52/200\n",
      "12/12 [==============================] - 1s 109ms/step - loss: 0.3364 - accuracy: 0.8915 - val_loss: 2.7806 - val_accuracy: 0.3183\n",
      "Epoch 53/200\n",
      "12/12 [==============================] - 1s 109ms/step - loss: 0.3298 - accuracy: 0.8967 - val_loss: 2.8093 - val_accuracy: 0.3599\n",
      "Epoch 54/200\n",
      "12/12 [==============================] - 1s 107ms/step - loss: 0.2997 - accuracy: 0.9149 - val_loss: 2.8620 - val_accuracy: 0.3460\n",
      "Epoch 55/200\n",
      "12/12 [==============================] - 1s 106ms/step - loss: 0.2849 - accuracy: 0.9175 - val_loss: 2.9251 - val_accuracy: 0.3702\n",
      "Epoch 56/200\n",
      "12/12 [==============================] - 1s 107ms/step - loss: 0.2813 - accuracy: 0.9236 - val_loss: 2.8883 - val_accuracy: 0.3426\n",
      "Epoch 57/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12/12 [==============================] - 1s 118ms/step - loss: 0.2496 - accuracy: 0.9375 - val_loss: 3.0808 - val_accuracy: 0.3529\n",
      "Epoch 58/200\n",
      "12/12 [==============================] - 1s 107ms/step - loss: 0.2665 - accuracy: 0.9253 - val_loss: 3.0376 - val_accuracy: 0.3772\n",
      "Epoch 59/200\n",
      "12/12 [==============================] - 1s 111ms/step - loss: 0.2728 - accuracy: 0.9193 - val_loss: 2.8928 - val_accuracy: 0.3529\n",
      "Epoch 60/200\n",
      "12/12 [==============================] - 1s 105ms/step - loss: 0.2638 - accuracy: 0.9297 - val_loss: 2.7968 - val_accuracy: 0.3633\n",
      "Epoch 61/200\n",
      "12/12 [==============================] - 1s 106ms/step - loss: 0.2450 - accuracy: 0.9358 - val_loss: 3.0162 - val_accuracy: 0.3668\n",
      "Epoch 62/200\n",
      "12/12 [==============================] - 1s 108ms/step - loss: 0.2522 - accuracy: 0.9314 - val_loss: 3.1127 - val_accuracy: 0.3633\n",
      "Epoch 63/200\n",
      "12/12 [==============================] - 1s 101ms/step - loss: 0.2446 - accuracy: 0.9375 - val_loss: 3.2282 - val_accuracy: 0.3599\n",
      "Epoch 64/200\n",
      "12/12 [==============================] - 1s 103ms/step - loss: 0.2548 - accuracy: 0.9236 - val_loss: 3.1156 - val_accuracy: 0.3737\n",
      "Epoch 65/200\n",
      "12/12 [==============================] - 1s 102ms/step - loss: 0.2495 - accuracy: 0.9245 - val_loss: 3.0492 - val_accuracy: 0.3356\n",
      "Epoch 66/200\n",
      "12/12 [==============================] - 1s 103ms/step - loss: 0.2389 - accuracy: 0.9349 - val_loss: 3.2017 - val_accuracy: 0.3702\n",
      "Epoch 67/200\n",
      "12/12 [==============================] - 1s 103ms/step - loss: 0.2653 - accuracy: 0.9167 - val_loss: 3.1450 - val_accuracy: 0.3356\n",
      "Epoch 68/200\n",
      "12/12 [==============================] - 1s 104ms/step - loss: 0.2548 - accuracy: 0.9253 - val_loss: 3.3481 - val_accuracy: 0.3599\n",
      "Epoch 69/200\n",
      "12/12 [==============================] - 1s 100ms/step - loss: 0.2567 - accuracy: 0.9340 - val_loss: 3.2588 - val_accuracy: 0.3426\n",
      "Epoch 70/200\n",
      "12/12 [==============================] - 1s 104ms/step - loss: 0.2307 - accuracy: 0.9384 - val_loss: 3.2119 - val_accuracy: 0.3460\n",
      "Epoch 71/200\n",
      "12/12 [==============================] - 1s 104ms/step - loss: 0.2400 - accuracy: 0.9453 - val_loss: 3.2170 - val_accuracy: 0.3322\n",
      "Epoch 72/200\n",
      "12/12 [==============================] - 1s 101ms/step - loss: 0.2168 - accuracy: 0.9470 - val_loss: 3.1714 - val_accuracy: 0.3668\n",
      "Epoch 73/200\n",
      "12/12 [==============================] - 1s 107ms/step - loss: 0.1979 - accuracy: 0.9514 - val_loss: 3.2668 - val_accuracy: 0.3529\n",
      "Epoch 74/200\n",
      "12/12 [==============================] - 1s 104ms/step - loss: 0.1945 - accuracy: 0.9514 - val_loss: 3.2552 - val_accuracy: 0.3599\n",
      "Epoch 75/200\n",
      "12/12 [==============================] - 1s 110ms/step - loss: 0.2037 - accuracy: 0.9470 - val_loss: 3.3213 - val_accuracy: 0.3702\n",
      "Epoch 76/200\n",
      "12/12 [==============================] - 1s 113ms/step - loss: 0.2073 - accuracy: 0.9470 - val_loss: 3.3738 - val_accuracy: 0.3633\n",
      "Epoch 77/200\n",
      "12/12 [==============================] - 1s 106ms/step - loss: 0.2051 - accuracy: 0.9453 - val_loss: 3.3455 - val_accuracy: 0.3426\n",
      "Epoch 78/200\n",
      "12/12 [==============================] - 1s 109ms/step - loss: 0.1910 - accuracy: 0.9479 - val_loss: 3.3278 - val_accuracy: 0.3495\n",
      "Epoch 79/200\n",
      "12/12 [==============================] - 1s 108ms/step - loss: 0.1928 - accuracy: 0.9566 - val_loss: 3.4275 - val_accuracy: 0.3356\n",
      "Epoch 80/200\n",
      "12/12 [==============================] - 1s 109ms/step - loss: 0.1904 - accuracy: 0.9497 - val_loss: 3.4957 - val_accuracy: 0.3495\n",
      "Epoch 81/200\n",
      "12/12 [==============================] - 1s 109ms/step - loss: 0.1762 - accuracy: 0.9557 - val_loss: 3.3785 - val_accuracy: 0.3391\n",
      "Epoch 82/200\n",
      "12/12 [==============================] - 1s 112ms/step - loss: 0.1867 - accuracy: 0.9540 - val_loss: 3.5771 - val_accuracy: 0.3460\n",
      "Epoch 83/200\n",
      "12/12 [==============================] - 1s 112ms/step - loss: 0.1828 - accuracy: 0.9557 - val_loss: 3.4481 - val_accuracy: 0.3599\n",
      "Epoch 84/200\n",
      "12/12 [==============================] - 1s 105ms/step - loss: 0.1667 - accuracy: 0.9601 - val_loss: 3.4851 - val_accuracy: 0.3426\n",
      "Epoch 85/200\n",
      "12/12 [==============================] - 1s 112ms/step - loss: 0.1744 - accuracy: 0.9549 - val_loss: 3.6207 - val_accuracy: 0.3322\n",
      "Epoch 86/200\n",
      "12/12 [==============================] - 1s 108ms/step - loss: 0.1682 - accuracy: 0.9583 - val_loss: 3.5631 - val_accuracy: 0.3391\n",
      "Epoch 87/200\n",
      "12/12 [==============================] - 1s 107ms/step - loss: 0.1607 - accuracy: 0.9688 - val_loss: 3.5877 - val_accuracy: 0.3287\n",
      "Epoch 88/200\n",
      "12/12 [==============================] - 1s 107ms/step - loss: 0.1652 - accuracy: 0.9601 - val_loss: 3.6684 - val_accuracy: 0.3529\n",
      "Epoch 89/200\n",
      "12/12 [==============================] - 1s 106ms/step - loss: 0.1851 - accuracy: 0.9479 - val_loss: 3.5852 - val_accuracy: 0.3426\n",
      "Epoch 90/200\n",
      "12/12 [==============================] - 1s 107ms/step - loss: 0.1673 - accuracy: 0.9575 - val_loss: 3.5637 - val_accuracy: 0.3322\n",
      "Epoch 91/200\n",
      "12/12 [==============================] - 1s 105ms/step - loss: 0.1549 - accuracy: 0.9635 - val_loss: 3.5966 - val_accuracy: 0.3633\n",
      "Epoch 92/200\n",
      "12/12 [==============================] - 1s 112ms/step - loss: 0.1827 - accuracy: 0.9523 - val_loss: 3.6167 - val_accuracy: 0.3702\n",
      "Epoch 93/200\n",
      "12/12 [==============================] - 1s 109ms/step - loss: 0.1747 - accuracy: 0.9514 - val_loss: 3.4843 - val_accuracy: 0.3460\n",
      "Epoch 94/200\n",
      "12/12 [==============================] - 1s 112ms/step - loss: 0.1860 - accuracy: 0.9479 - val_loss: 3.5824 - val_accuracy: 0.3287\n",
      "Epoch 95/200\n",
      "12/12 [==============================] - 1s 105ms/step - loss: 0.1686 - accuracy: 0.9627 - val_loss: 3.7914 - val_accuracy: 0.3356\n",
      "Epoch 96/200\n",
      "12/12 [==============================] - 1s 111ms/step - loss: 0.1771 - accuracy: 0.9470 - val_loss: 3.5056 - val_accuracy: 0.3495\n",
      "Epoch 97/200\n",
      "12/12 [==============================] - 1s 110ms/step - loss: 0.1721 - accuracy: 0.9523 - val_loss: 3.6291 - val_accuracy: 0.3460\n",
      "Epoch 98/200\n",
      "12/12 [==============================] - 1s 107ms/step - loss: 0.1591 - accuracy: 0.9583 - val_loss: 3.6015 - val_accuracy: 0.3495\n",
      "Epoch 99/200\n",
      "12/12 [==============================] - 1s 108ms/step - loss: 0.1590 - accuracy: 0.9549 - val_loss: 3.5896 - val_accuracy: 0.3460\n",
      "Epoch 100/200\n",
      "12/12 [==============================] - 1s 114ms/step - loss: 0.1525 - accuracy: 0.9661 - val_loss: 3.6616 - val_accuracy: 0.3599\n",
      "Epoch 101/200\n",
      "12/12 [==============================] - 1s 109ms/step - loss: 0.1615 - accuracy: 0.9601 - val_loss: 3.5465 - val_accuracy: 0.3599\n",
      "Epoch 102/200\n",
      "12/12 [==============================] - 1s 106ms/step - loss: 0.1498 - accuracy: 0.9688 - val_loss: 3.6911 - val_accuracy: 0.3633\n",
      "Epoch 103/200\n",
      "12/12 [==============================] - 1s 107ms/step - loss: 0.1425 - accuracy: 0.9679 - val_loss: 3.7130 - val_accuracy: 0.3668\n",
      "Epoch 104/200\n",
      "12/12 [==============================] - 1s 116ms/step - loss: 0.1611 - accuracy: 0.9566 - val_loss: 3.6477 - val_accuracy: 0.3495\n",
      "Epoch 105/200\n",
      "12/12 [==============================] - 1s 105ms/step - loss: 0.1608 - accuracy: 0.9592 - val_loss: 3.6164 - val_accuracy: 0.3460\n",
      "Epoch 106/200\n",
      "12/12 [==============================] - 1s 106ms/step - loss: 0.1690 - accuracy: 0.9531 - val_loss: 3.5060 - val_accuracy: 0.3633\n",
      "Epoch 107/200\n",
      "12/12 [==============================] - 1s 101ms/step - loss: 0.1590 - accuracy: 0.9592 - val_loss: 3.5392 - val_accuracy: 0.3875\n",
      "Epoch 108/200\n",
      "12/12 [==============================] - 1s 102ms/step - loss: 0.1611 - accuracy: 0.9575 - val_loss: 3.4786 - val_accuracy: 0.3702\n",
      "Epoch 109/200\n",
      "12/12 [==============================] - 1s 107ms/step - loss: 0.1552 - accuracy: 0.9635 - val_loss: 3.5345 - val_accuracy: 0.3564\n",
      "Epoch 110/200\n",
      "12/12 [==============================] - 1s 104ms/step - loss: 0.1471 - accuracy: 0.9592 - val_loss: 3.7325 - val_accuracy: 0.3599\n",
      "Epoch 111/200\n",
      "12/12 [==============================] - 1s 108ms/step - loss: 0.1485 - accuracy: 0.9601 - val_loss: 3.7443 - val_accuracy: 0.3495\n",
      "Epoch 112/200\n",
      "12/12 [==============================] - 1s 107ms/step - loss: 0.1459 - accuracy: 0.9653 - val_loss: 3.7056 - val_accuracy: 0.3495\n",
      "Epoch 113/200\n",
      "12/12 [==============================] - 1s 109ms/step - loss: 0.1478 - accuracy: 0.9679 - val_loss: 3.7354 - val_accuracy: 0.3322\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 114/200\n",
      "12/12 [==============================] - 1s 111ms/step - loss: 0.1282 - accuracy: 0.9670 - val_loss: 3.7747 - val_accuracy: 0.3495\n",
      "Epoch 115/200\n",
      "12/12 [==============================] - 1s 112ms/step - loss: 0.1358 - accuracy: 0.9627 - val_loss: 3.7804 - val_accuracy: 0.3322\n",
      "Epoch 116/200\n",
      "12/12 [==============================] - 1s 109ms/step - loss: 0.1128 - accuracy: 0.9740 - val_loss: 3.8490 - val_accuracy: 0.3391\n",
      "Epoch 117/200\n",
      "12/12 [==============================] - 1s 109ms/step - loss: 0.1223 - accuracy: 0.9653 - val_loss: 4.0297 - val_accuracy: 0.3356\n",
      "Epoch 118/200\n",
      "12/12 [==============================] - 1s 108ms/step - loss: 0.1246 - accuracy: 0.9696 - val_loss: 4.0252 - val_accuracy: 0.3633\n",
      "Epoch 119/200\n",
      "12/12 [==============================] - 1s 102ms/step - loss: 0.1384 - accuracy: 0.9609 - val_loss: 3.7029 - val_accuracy: 0.3633\n",
      "Epoch 120/200\n",
      "12/12 [==============================] - 1s 106ms/step - loss: 0.1301 - accuracy: 0.9653 - val_loss: 3.6627 - val_accuracy: 0.3772\n",
      "Epoch 121/200\n",
      "12/12 [==============================] - 1s 106ms/step - loss: 0.1310 - accuracy: 0.9661 - val_loss: 3.8010 - val_accuracy: 0.3599\n",
      "Epoch 122/200\n",
      "12/12 [==============================] - 1s 105ms/step - loss: 0.1421 - accuracy: 0.9635 - val_loss: 3.7685 - val_accuracy: 0.3287\n",
      "Epoch 123/200\n",
      "12/12 [==============================] - 1s 103ms/step - loss: 0.1538 - accuracy: 0.9583 - val_loss: 3.7473 - val_accuracy: 0.3564\n",
      "Epoch 124/200\n",
      "12/12 [==============================] - 1s 103ms/step - loss: 0.1690 - accuracy: 0.9505 - val_loss: 3.6748 - val_accuracy: 0.3599\n",
      "Epoch 125/200\n",
      "12/12 [==============================] - 1s 103ms/step - loss: 0.1923 - accuracy: 0.9444 - val_loss: 3.6755 - val_accuracy: 0.3391\n",
      "Epoch 126/200\n",
      "12/12 [==============================] - 1s 101ms/step - loss: 0.1595 - accuracy: 0.9488 - val_loss: 3.8284 - val_accuracy: 0.3460\n",
      "Epoch 127/200\n",
      "12/12 [==============================] - 1s 103ms/step - loss: 0.1397 - accuracy: 0.9618 - val_loss: 3.8883 - val_accuracy: 0.3529\n",
      "Epoch 128/200\n",
      "12/12 [==============================] - 1s 107ms/step - loss: 0.1508 - accuracy: 0.9609 - val_loss: 3.6148 - val_accuracy: 0.3633\n",
      "Epoch 129/200\n",
      "12/12 [==============================] - 1s 109ms/step - loss: 0.1203 - accuracy: 0.9748 - val_loss: 3.9597 - val_accuracy: 0.3322\n",
      "Epoch 130/200\n",
      "12/12 [==============================] - 1s 107ms/step - loss: 0.1339 - accuracy: 0.9575 - val_loss: 3.9188 - val_accuracy: 0.3322\n",
      "Epoch 131/200\n",
      "12/12 [==============================] - 1s 108ms/step - loss: 0.1302 - accuracy: 0.9653 - val_loss: 3.9801 - val_accuracy: 0.3460\n",
      "Epoch 132/200\n",
      "12/12 [==============================] - 1s 109ms/step - loss: 0.1366 - accuracy: 0.9653 - val_loss: 3.9494 - val_accuracy: 0.3529\n",
      "Epoch 133/200\n",
      "12/12 [==============================] - 1s 104ms/step - loss: 0.1307 - accuracy: 0.9618 - val_loss: 3.8442 - val_accuracy: 0.3599\n",
      "Epoch 134/200\n",
      "12/12 [==============================] - 1s 106ms/step - loss: 0.1310 - accuracy: 0.9688 - val_loss: 3.8214 - val_accuracy: 0.3391\n",
      "Epoch 135/200\n",
      "12/12 [==============================] - 1s 105ms/step - loss: 0.1282 - accuracy: 0.9670 - val_loss: 3.9248 - val_accuracy: 0.3460\n",
      "Epoch 136/200\n",
      "12/12 [==============================] - 1s 106ms/step - loss: 0.1240 - accuracy: 0.9670 - val_loss: 3.8287 - val_accuracy: 0.3599\n",
      "Epoch 137/200\n",
      "12/12 [==============================] - 1s 105ms/step - loss: 0.1335 - accuracy: 0.9679 - val_loss: 3.8834 - val_accuracy: 0.3633\n",
      "Epoch 138/200\n",
      "12/12 [==============================] - 1s 107ms/step - loss: 0.1232 - accuracy: 0.9688 - val_loss: 3.8602 - val_accuracy: 0.3668\n",
      "Epoch 139/200\n",
      "12/12 [==============================] - 1s 107ms/step - loss: 0.1154 - accuracy: 0.9635 - val_loss: 3.8107 - val_accuracy: 0.3806\n",
      "Epoch 140/200\n",
      "12/12 [==============================] - 1s 108ms/step - loss: 0.1150 - accuracy: 0.9722 - val_loss: 3.9590 - val_accuracy: 0.3564\n",
      "Epoch 141/200\n",
      "12/12 [==============================] - 1s 107ms/step - loss: 0.1106 - accuracy: 0.9696 - val_loss: 4.0552 - val_accuracy: 0.3529\n",
      "Epoch 142/200\n",
      "12/12 [==============================] - 1s 107ms/step - loss: 0.1055 - accuracy: 0.9748 - val_loss: 4.0630 - val_accuracy: 0.3529\n",
      "Epoch 143/200\n",
      "12/12 [==============================] - 1s 112ms/step - loss: 0.1040 - accuracy: 0.9757 - val_loss: 3.9905 - val_accuracy: 0.3633\n",
      "Epoch 144/200\n",
      "12/12 [==============================] - 1s 108ms/step - loss: 0.1060 - accuracy: 0.9722 - val_loss: 4.0254 - val_accuracy: 0.3564\n",
      "Epoch 145/200\n",
      "12/12 [==============================] - 1s 108ms/step - loss: 0.1205 - accuracy: 0.9688 - val_loss: 4.0432 - val_accuracy: 0.3426\n",
      "Epoch 146/200\n",
      "12/12 [==============================] - 1s 108ms/step - loss: 0.1241 - accuracy: 0.9661 - val_loss: 4.1225 - val_accuracy: 0.3668\n",
      "Epoch 147/200\n",
      "12/12 [==============================] - 1s 104ms/step - loss: 0.1249 - accuracy: 0.9653 - val_loss: 3.8939 - val_accuracy: 0.3529\n",
      "Epoch 148/200\n",
      "12/12 [==============================] - 1s 103ms/step - loss: 0.1106 - accuracy: 0.9679 - val_loss: 3.7745 - val_accuracy: 0.3599\n",
      "Epoch 149/200\n",
      "12/12 [==============================] - 1s 104ms/step - loss: 0.1169 - accuracy: 0.9653 - val_loss: 3.9785 - val_accuracy: 0.3599\n",
      "Epoch 150/200\n",
      "12/12 [==============================] - 1s 103ms/step - loss: 0.1256 - accuracy: 0.9661 - val_loss: 4.0814 - val_accuracy: 0.3460\n",
      "Epoch 151/200\n",
      "12/12 [==============================] - 1s 112ms/step - loss: 0.1049 - accuracy: 0.9696 - val_loss: 3.8853 - val_accuracy: 0.3391\n",
      "Epoch 152/200\n",
      "12/12 [==============================] - 1s 104ms/step - loss: 0.1078 - accuracy: 0.9696 - val_loss: 3.9862 - val_accuracy: 0.3356\n",
      "Epoch 153/200\n",
      "12/12 [==============================] - 1s 104ms/step - loss: 0.1025 - accuracy: 0.9757 - val_loss: 3.9817 - val_accuracy: 0.3426\n",
      "Epoch 154/200\n",
      "12/12 [==============================] - 1s 108ms/step - loss: 0.1337 - accuracy: 0.9557 - val_loss: 3.9647 - val_accuracy: 0.3495\n",
      "Epoch 155/200\n",
      "12/12 [==============================] - 1s 105ms/step - loss: 0.1255 - accuracy: 0.9635 - val_loss: 3.7783 - val_accuracy: 0.3460\n",
      "Epoch 156/200\n",
      "12/12 [==============================] - 1s 106ms/step - loss: 0.1063 - accuracy: 0.9731 - val_loss: 3.9505 - val_accuracy: 0.3495\n",
      "Epoch 157/200\n",
      "12/12 [==============================] - 1s 103ms/step - loss: 0.1179 - accuracy: 0.9661 - val_loss: 3.9147 - val_accuracy: 0.3391\n",
      "Epoch 158/200\n",
      "12/12 [==============================] - 1s 107ms/step - loss: 0.1028 - accuracy: 0.9740 - val_loss: 3.9673 - val_accuracy: 0.3529\n",
      "Epoch 159/200\n",
      "12/12 [==============================] - 1s 102ms/step - loss: 0.0998 - accuracy: 0.9740 - val_loss: 4.0045 - val_accuracy: 0.3737\n",
      "Epoch 160/200\n",
      "12/12 [==============================] - 1s 104ms/step - loss: 0.1151 - accuracy: 0.9696 - val_loss: 4.2354 - val_accuracy: 0.3287\n",
      "Epoch 161/200\n",
      "12/12 [==============================] - 1s 107ms/step - loss: 0.1154 - accuracy: 0.9670 - val_loss: 3.9241 - val_accuracy: 0.3737\n",
      "Epoch 162/200\n",
      "12/12 [==============================] - 1s 112ms/step - loss: 0.1101 - accuracy: 0.9679 - val_loss: 3.9891 - val_accuracy: 0.3599\n",
      "Epoch 163/200\n",
      "12/12 [==============================] - 1s 110ms/step - loss: 0.0973 - accuracy: 0.9748 - val_loss: 4.1477 - val_accuracy: 0.3633\n",
      "Epoch 164/200\n",
      "12/12 [==============================] - 1s 108ms/step - loss: 0.0983 - accuracy: 0.9740 - val_loss: 4.2126 - val_accuracy: 0.3564\n",
      "Epoch 165/200\n",
      "12/12 [==============================] - 1s 107ms/step - loss: 0.1143 - accuracy: 0.9670 - val_loss: 3.9506 - val_accuracy: 0.3529\n",
      "Epoch 166/200\n",
      "12/12 [==============================] - 1s 106ms/step - loss: 0.0995 - accuracy: 0.9705 - val_loss: 4.1218 - val_accuracy: 0.3460\n",
      "Epoch 167/200\n",
      "12/12 [==============================] - 1s 107ms/step - loss: 0.1175 - accuracy: 0.9679 - val_loss: 4.0909 - val_accuracy: 0.3633\n",
      "Epoch 168/200\n",
      "12/12 [==============================] - 1s 107ms/step - loss: 0.1267 - accuracy: 0.9627 - val_loss: 3.6561 - val_accuracy: 0.3633\n",
      "Epoch 169/200\n",
      "12/12 [==============================] - 1s 105ms/step - loss: 0.1236 - accuracy: 0.9688 - val_loss: 3.8875 - val_accuracy: 0.3564\n",
      "Epoch 170/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12/12 [==============================] - 1s 107ms/step - loss: 0.1102 - accuracy: 0.9670 - val_loss: 3.9600 - val_accuracy: 0.3979\n",
      "Epoch 171/200\n",
      "12/12 [==============================] - 1s 104ms/step - loss: 0.1058 - accuracy: 0.9653 - val_loss: 3.9985 - val_accuracy: 0.3599\n",
      "Epoch 172/200\n",
      "12/12 [==============================] - 1s 108ms/step - loss: 0.1147 - accuracy: 0.9661 - val_loss: 4.0786 - val_accuracy: 0.3495\n",
      "Epoch 173/200\n",
      "12/12 [==============================] - 1s 104ms/step - loss: 0.1264 - accuracy: 0.9601 - val_loss: 3.8020 - val_accuracy: 0.4014\n",
      "Epoch 174/200\n",
      "12/12 [==============================] - 1s 106ms/step - loss: 0.1210 - accuracy: 0.9670 - val_loss: 4.1107 - val_accuracy: 0.3737\n",
      "Epoch 175/200\n",
      "12/12 [==============================] - 1s 104ms/step - loss: 0.1157 - accuracy: 0.9661 - val_loss: 4.0008 - val_accuracy: 0.3460\n",
      "Epoch 176/200\n",
      "12/12 [==============================] - 1s 113ms/step - loss: 0.1332 - accuracy: 0.9514 - val_loss: 3.8191 - val_accuracy: 0.3599\n",
      "Epoch 177/200\n",
      "12/12 [==============================] - 1s 112ms/step - loss: 0.1265 - accuracy: 0.9644 - val_loss: 3.8010 - val_accuracy: 0.3633\n",
      "Epoch 178/200\n",
      "12/12 [==============================] - 1s 106ms/step - loss: 0.1070 - accuracy: 0.9679 - val_loss: 3.6714 - val_accuracy: 0.3875\n",
      "Epoch 179/200\n",
      "12/12 [==============================] - 1s 110ms/step - loss: 0.1244 - accuracy: 0.9583 - val_loss: 4.0405 - val_accuracy: 0.3564\n",
      "Epoch 180/200\n",
      "12/12 [==============================] - 1s 105ms/step - loss: 0.1099 - accuracy: 0.9688 - val_loss: 3.9927 - val_accuracy: 0.3529\n",
      "Epoch 181/200\n",
      "12/12 [==============================] - 1s 109ms/step - loss: 0.1101 - accuracy: 0.9696 - val_loss: 4.0310 - val_accuracy: 0.3322\n",
      "Epoch 182/200\n",
      "12/12 [==============================] - 1s 109ms/step - loss: 0.1039 - accuracy: 0.9705 - val_loss: 4.1624 - val_accuracy: 0.3391\n",
      "Epoch 183/200\n",
      "12/12 [==============================] - 1s 106ms/step - loss: 0.1011 - accuracy: 0.9740 - val_loss: 4.2107 - val_accuracy: 0.3564\n",
      "Epoch 184/200\n",
      "12/12 [==============================] - 1s 107ms/step - loss: 0.0935 - accuracy: 0.9740 - val_loss: 4.1364 - val_accuracy: 0.3737\n",
      "Epoch 185/200\n",
      "12/12 [==============================] - 1s 106ms/step - loss: 0.0869 - accuracy: 0.9783 - val_loss: 4.0771 - val_accuracy: 0.3668\n",
      "Epoch 186/200\n",
      "12/12 [==============================] - 1s 107ms/step - loss: 0.0923 - accuracy: 0.9740 - val_loss: 4.0809 - val_accuracy: 0.3599\n",
      "Epoch 187/200\n",
      "12/12 [==============================] - 1s 108ms/step - loss: 0.0884 - accuracy: 0.9740 - val_loss: 4.0984 - val_accuracy: 0.3702\n",
      "Epoch 188/200\n",
      "12/12 [==============================] - 1s 107ms/step - loss: 0.0891 - accuracy: 0.9766 - val_loss: 4.1698 - val_accuracy: 0.3460\n",
      "Epoch 189/200\n",
      "12/12 [==============================] - 1s 106ms/step - loss: 0.1045 - accuracy: 0.9696 - val_loss: 4.1509 - val_accuracy: 0.3564\n",
      "Epoch 190/200\n",
      "12/12 [==============================] - 1s 105ms/step - loss: 0.0825 - accuracy: 0.9809 - val_loss: 4.1956 - val_accuracy: 0.3460\n",
      "Epoch 191/200\n",
      "12/12 [==============================] - 1s 104ms/step - loss: 0.0880 - accuracy: 0.9731 - val_loss: 4.2751 - val_accuracy: 0.3391\n",
      "Epoch 192/200\n",
      "12/12 [==============================] - 1s 105ms/step - loss: 0.0856 - accuracy: 0.9783 - val_loss: 4.3669 - val_accuracy: 0.3599\n",
      "Epoch 193/200\n",
      "12/12 [==============================] - 1s 108ms/step - loss: 0.0970 - accuracy: 0.9696 - val_loss: 4.3093 - val_accuracy: 0.3253\n",
      "Epoch 194/200\n",
      "12/12 [==============================] - 1s 109ms/step - loss: 0.0867 - accuracy: 0.9740 - val_loss: 4.2666 - val_accuracy: 0.3599\n",
      "Epoch 195/200\n",
      "12/12 [==============================] - 1s 106ms/step - loss: 0.0829 - accuracy: 0.9774 - val_loss: 4.3411 - val_accuracy: 0.3183\n",
      "Epoch 196/200\n",
      "12/12 [==============================] - 1s 105ms/step - loss: 0.0881 - accuracy: 0.9740 - val_loss: 4.3035 - val_accuracy: 0.3356\n",
      "Epoch 197/200\n",
      "12/12 [==============================] - 1s 108ms/step - loss: 0.0832 - accuracy: 0.9766 - val_loss: 4.2769 - val_accuracy: 0.3529\n",
      "Epoch 198/200\n",
      "12/12 [==============================] - 1s 112ms/step - loss: 0.1025 - accuracy: 0.9679 - val_loss: 4.1154 - val_accuracy: 0.3391\n",
      "Epoch 199/200\n",
      "12/12 [==============================] - 1s 107ms/step - loss: 0.1034 - accuracy: 0.9679 - val_loss: 4.2252 - val_accuracy: 0.3322\n",
      "Epoch 200/200\n",
      "12/12 [==============================] - 1s 108ms/step - loss: 0.1149 - accuracy: 0.9661 - val_loss: 3.9191 - val_accuracy: 0.3495\n"
     ]
    }
   ],
   "source": [
    "#treinar a rede neural convolucional\n",
    "history = Dcnn.fit(X_tensor, y, batch_size = tamanho_batch, epochs = qtd_epocas, verbose = 1, validation_split = 0.2, shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "f55b97a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"dcnn\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv1d_8 (Conv1D)           multiple                  6432      \n",
      "                                                                 \n",
      " conv1d_9 (Conv1D)           multiple                  9632      \n",
      "                                                                 \n",
      " conv1d_10 (Conv1D)          multiple                  12832     \n",
      "                                                                 \n",
      " conv1d_11 (Conv1D)          multiple                  16032     \n",
      "                                                                 \n",
      " global_max_pooling1d_2 (Glo  multiple                 0         \n",
      " balMaxPooling1D)                                                \n",
      "                                                                 \n",
      " dense_8 (Dense)             multiple                  8256      \n",
      "                                                                 \n",
      " dense_9 (Dense)             multiple                  4160      \n",
      "                                                                 \n",
      " dense_10 (Dense)            multiple                  4160      \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         multiple                  0         \n",
      "                                                                 \n",
      " dense_11 (Dense)            multiple                  260       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 61,764\n",
      "Trainable params: 61,764\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "Dcnn.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "564e3903",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ckpt-1'"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# salvar o checkpoint\n",
    "ckpt_manager.save()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1eebdd41",
   "metadata": {},
   "source": [
    "## avaliação do modelo de rede neural convolucional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "1c91397d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# carregar os dados de teste\n",
    "with open(os.path.join('data', 'data_set_param_b_test.pkl'), 'rb') as f:\n",
    "    df_test = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "523b2163",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['tf_idf', 'wes', 'wes_own', 'classes_param_a_1', 'classes_param_b_1',\n",
       "       'classes_param_c_1'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "deab1847",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(481, 793, 100)\n",
      "(481,)\n"
     ]
    }
   ],
   "source": [
    "#obtém os dados do conjunto de teste\n",
    "X_test = df_test.iloc[:, 2].values\n",
    "X_test = tf.keras.preprocessing.sequence.pad_sequences(X_test, value = 0, padding = 'post', maxlen = max_len)\n",
    "X_test = tf.convert_to_tensor(X_test, dtype=tf.float32)\n",
    "print(X_test.shape)\n",
    "y_test = np.array(df_test.iloc[:, 3].values)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5bf7130",
   "metadata": {},
   "source": [
    "O trecho results = Dcnn.evaluate(X_test, y_test, batch_size=tamanho_batch) é utilizado para avaliar o desempenho de um modelo de rede neural convolucional (CNN) chamado Dcnn em um conjunto de dados de teste X_test e rótulos de teste y_test. A função evaluate do objeto Dcnn calcula a perda (loss) e a acurácia (accuracy) do modelo no conjunto de teste, e armazena essas métricas na variável results. O parâmetro batch_size é usado para definir o tamanho do lote (batch size) a ser usado para a avaliação do modelo. Geralmente, quanto maior o tamanho do lote, mais rápido o processo de avaliação, mas isso pode levar a um aumento do uso de memória e possíveis limitações computacionais."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "8a815644",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 23ms/step - loss: 5.5340 - accuracy: 0.2328\n",
      "[5.533970355987549, 0.23284822702407837]\n"
     ]
    }
   ],
   "source": [
    "#avalia o modelo com o conjunto de teste\n",
    "results = Dcnn.evaluate(X_test, y_test, batch_size=tamanho_batch)\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "fbc11eea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(None, 128)\n",
      "16/16 [==============================] - 0s 11ms/step\n"
     ]
    }
   ],
   "source": [
    "y_pred_test = Dcnn.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "9102ecd6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[4.79986936e-01, 2.25702494e-01, 1.82703048e-01, 1.11607485e-01],\n",
       "       [7.21847638e-03, 3.49257811e-04, 2.97117624e-02, 9.62720573e-01],\n",
       "       [1.77744627e-02, 9.82220829e-01, 4.41856218e-06, 2.14018982e-07],\n",
       "       ...,\n",
       "       [5.68712458e-05, 8.93930793e-01, 1.06006213e-01, 6.19674074e-06],\n",
       "       [2.35661864e-02, 4.08303365e-03, 2.33862951e-01, 7.38487840e-01],\n",
       "       [9.23825137e-05, 2.86921859e-03, 9.96003330e-01, 1.03511079e-03]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "edbe2ee4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 3, 1, 0, 0, 0, 1, 3, 3, 1, 0, 1, 3, 0, 0, 2, 1, 1, 1, 3, 1, 0,\n",
       "       3, 0, 1, 1, 1, 1, 1, 2, 0, 2, 2, 1, 1, 1, 1, 0, 1, 1, 3, 0, 0, 1,\n",
       "       0, 1, 0, 3, 3, 3, 1, 1, 3, 0, 2, 0, 0, 3, 2, 1, 2, 2, 0, 2, 3, 1,\n",
       "       2, 1, 2, 1, 2, 1, 0, 0, 0, 2, 1, 1, 3, 1, 1, 2, 1, 1, 1, 2, 1, 1,\n",
       "       3, 2, 0, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 3, 2, 2, 1, 1, 0, 0, 1, 1,\n",
       "       3, 3, 2, 2, 3, 3, 3, 2, 2, 0, 2, 2, 3, 2, 1, 2, 0, 1, 0, 2, 3, 0,\n",
       "       3, 2, 3, 2, 0, 0, 0, 2, 2, 1, 3, 2, 2, 2, 2, 0, 2, 0, 0, 2, 3, 1,\n",
       "       1, 1, 0, 2, 1, 1, 0, 2, 0, 0, 0, 2, 0, 2, 2, 0, 1, 1, 2, 0, 1, 0,\n",
       "       3, 1, 2, 0, 1, 1, 2, 2, 2, 2, 2, 2, 1, 1, 1, 0, 1, 2, 3, 1, 2, 0,\n",
       "       3, 2, 1, 2, 3, 0, 2, 3, 2, 1, 2, 0, 0, 3, 1, 1, 2, 3, 3, 1, 3, 0,\n",
       "       2, 1, 2, 2, 0, 1, 3, 1, 1, 3, 3, 1, 3, 1, 1, 2, 3, 3, 0, 0, 2, 0,\n",
       "       1, 2, 3, 3, 0, 2, 2, 0, 3, 1, 0, 3, 1, 2, 1, 3, 3, 1, 1, 1, 3, 0,\n",
       "       1, 2, 3, 3, 1, 1, 1, 0, 2, 0, 1, 1, 0, 1, 1, 2, 1, 1, 3, 1, 0, 1,\n",
       "       0, 2, 0, 1, 0, 2, 0, 1, 3, 1, 0, 2, 3, 3, 1, 2, 1, 2, 3, 1, 0, 3,\n",
       "       1, 2, 0, 2, 1, 3, 1, 3, 1, 2, 1, 1, 1, 3, 2, 0, 0, 1, 1, 2, 0, 0,\n",
       "       0, 1, 1, 1, 2, 1, 2, 2, 2, 1, 1, 2, 0, 2, 1, 0, 3, 2, 2, 0, 1, 2,\n",
       "       1, 0, 0, 0, 0, 2, 2, 0, 1, 2, 2, 3, 1, 1, 1, 2, 1, 0, 1, 1, 3, 1,\n",
       "       1, 2, 1, 2, 1, 0, 1, 3, 1, 3, 1, 1, 2, 0, 3, 3, 0, 2, 1, 2, 0, 2,\n",
       "       3, 3, 1, 2, 1, 0, 3, 1, 2, 1, 3, 0, 3, 1, 1, 0, 1, 2, 2, 0, 0, 2,\n",
       "       0, 2, 1, 3, 3, 3, 1, 1, 1, 2, 0, 1, 2, 3, 3, 1, 3, 0, 1, 1, 2, 0,\n",
       "       1, 1, 0, 3, 3, 1, 2, 1, 1, 2, 2, 3, 1, 1, 3, 3, 2, 2, 1, 1, 1, 1,\n",
       "       0, 2, 0, 0, 1, 1, 0, 0, 3, 2, 1, 2, 2, 0, 0, 0, 1, 3, 2],\n",
       "      dtype=int64)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#valores previstos\n",
    "y_pred_test_values = []\n",
    "for y_ in y_pred_test:\n",
    "    #obtem o valor máximo do array de probabilidades\n",
    "    y_pred_test_values.append(np.argmax(y_))\n",
    "\n",
    "y_pred_test_values = np.array(y_pred_test_values)\n",
    "y_pred_test_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "21cf5e74",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[24, 39, 27, 16],\n",
       "       [18, 42, 25, 27],\n",
       "       [29, 32, 31, 27],\n",
       "       [41, 52, 36, 15]], dtype=int64)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cm = confusion_matrix(y_test, y_pred_test_values)\n",
    "cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "a8f2c3ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "parâmetro de discriminação\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "print('parâmetro de discriminação')\n",
    "xlabels = ['<=0.652', '>0.652 e <=1.224', '>1.224 e <=1.837', '>1.837']\n",
    "xlabels = ['predito <=0.652', 'predito >0.652 e <=1.224', 'predito >1.224 e <=1.837', 'predito > 1.837']\n",
    "sns.heatmap(cm, annot=True, fmt = 'g', xticklabels = xlabels, yticklabels = ylabels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "c0562236",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.21      0.23      0.22       106\n",
      "           1       0.25      0.38      0.30       112\n",
      "           2       0.26      0.26      0.26       119\n",
      "           3       0.18      0.10      0.13       144\n",
      "\n",
      "    accuracy                           0.23       481\n",
      "   macro avg       0.23      0.24      0.23       481\n",
      "weighted avg       0.22      0.23      0.22       481\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_pred_test_values))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0422943b",
   "metadata": {},
   "source": [
    "Esses são resultados de métricas de avaliação de um modelo de classificação. \"Precision\" representa a proporção de exemplos positivos que o modelo classificou corretamente. \"Recall\" representa a proporção de exemplos positivos que o modelo conseguiu identificar. \"F1-score\" é a média harmônica entre precisão e recall, fornecendo uma métrica equilibrada que reflete tanto a precisão quanto a capacidade de identificação do modelo. \"Support\" representa o número de exemplos na classe.\n",
    "\n",
    "Com base nas métricas fornecidas, podemos ver que o modelo tem baixa precisão, baixo recall e baixo f1-score, o que indica que ele está tendo dificuldade em classificar corretamente os exemplos positivos e ainda não está conseguindo identificar a maioria deles, sendo que ele foi testado em 120 exemplos da classe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "2e09d1e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history.history.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "865e52ac",
   "metadata": {},
   "source": [
    "Ao comparar o erro de treinamento e o erro de validação em um gráfico, é possível realizar várias análises importantes. Algumas delas são:\n",
    "\n",
    "- Overfitting: Se o erro de treinamento estiver caindo enquanto o erro de validação estiver aumentando, é provável que o modelo esteja sofrendo de overfitting. Isso significa que o modelo está se ajustando muito bem aos dados de treinamento, mas não está generalizando bem para os dados de validação.\n",
    "\n",
    "- Underfitting: Se ambos os erros estiverem aumentando, é possível que o modelo esteja underfitting, ou seja, não está se ajustando suficientemente aos dados de treinamento e validação.\n",
    "\n",
    "- Ideal fit: Se o erro de treinamento estiver diminuindo enquanto o erro de validação estiver diminuindo, é provável que o modelo esteja se ajustando de maneira adequada aos dados de treinamento e validação, ou seja, o modelo está aprendendo e generalizando corretamente.\n",
    "\n",
    "Além disso, também é importante observar a velocidade de aprendizado, ou seja, quanto o erro está diminuindo com cada época. Uma diminuição muito lenta pode indicar que o modelo precisa de mais épocas ou que o tamanho do batch precisa ser ajustado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "c0c9f84c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x1c24313db80>"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('Progresso de erro do modelo durante o treinamento e validação')\n",
    "plt.xlabel('Época')\n",
    "plt.ylabel('Erro')\n",
    "plt.legend(['Erro de treinamento', 'Erro de validação'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cac990c1",
   "metadata": {},
   "source": [
    "A análise dos gráficos de comparação da acurácia de treinamento e acurácia de validação pode fornecer informações importantes sobre o modelo e o seu desempenho. Aqui estão algumas das possíveis análises que se pode fazer:\n",
    "\n",
    "- Overfitting: Se o gráfico de treinamento mostra uma acurácia muito alta e o gráfico de validação mostra uma acurácia muito baixa, isso pode indicar overfitting, ou seja, o modelo está memorizando o conjunto de treinamento, mas não é geral o suficiente para prever corretamente dados desconhecidos.\n",
    "\n",
    "- Underfitting: Se ambos os gráficos de treinamento e validação mostram baixa acurácia, isso pode indicar sub-ajuste, ou seja, o modelo é muito simples e não está capturando a complexidade da relação entre as características e as classes.\n",
    "\n",
    "- Convergência: Se o gráfico de treinamento mostra uma tendência crescente na acurácia e o gráfico de validação mostra uma tendência estacionária, isso pode indicar que o modelo está convergindo e que mais épocas de treinamento não seriam úteis.\n",
    "\n",
    "- Viés: Se o gráfico de treinamento mostra uma acurácia muito alta, mas o gráfico de validação mostra uma acurácia muito baixa, isso pode indicar viés, ou seja, o modelo está otimizando a métrica de avaliação de forma inadequada e não está levando em conta todas as características do conjunto de dados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "ebd0e4cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x1c243951df0>"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('Progresso da acurácia do modelo durante o treinamento e validação')\n",
    "plt.xlabel('Época')\n",
    "plt.ylabel('Acurácia')\n",
    "plt.legend(['Acurácia de treino', 'Acurácia de validação'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0acf5bc0",
   "metadata": {},
   "source": [
    "O **método de bootstrap** é uma técnica para estimar a **incerteza** em métricas com base em **amostragem com reposição**. A idéia é que, ao realizarmos várias amostragens de nosso conjunto de dados com reposição, podemos obter diferentes valores para nossa métrica. Então, podemos estimar a variabilidade da nossa métrica e, portanto, seu desvio padrão.\n",
    "\n",
    "O método de bootstrap é frequentemente usado em métricas de modelos de machine learning, como precisão, recall e F1-score, para estimar o erro padrão. Isso pode ser útil para entender a incerteza em nossas métricas e para determinar se o desempenho de nossos modelos é estatisticamente significativo.\n",
    "\n",
    "O método de bootstrap é uma técnica estatística usada para estimar o **desvio padrão** de uma métrica de desempenho da rede neural. Ele pode ser comparado ao ato de tirar amostras aleatórias de uma população para entender a variação da população. Da mesma forma, o método de bootstrap tira amostras aleatórias do conjunto de dados usado para treinar a rede e, em seguida, avalia o desempenho da rede usando a métrica escolhida. Isso é feito várias vezes, e a variação na métrica é usada para estimar o desvio padrão da métrica. É uma maneira de avaliar a incerteza associada às métricas de desempenho da rede e ajuda a entender se a rede está realmente tendo desempenho melhor ou pior do que o esperado.\n",
    "\n",
    "O parâmetro \"B\" representa o número de vezes que o método bootstrap será aplicado para estimar o desvio padrão das métricas usadas para medir o desempenho da rede. Esse valor é usado para determinar o número de amostras aleatórias que serão selecionadas da base de dados de teste para realizar a avaliação do modelo. Quanto maior for o valor de \"B\", maior será a precisão da estimativa do desvio padrão, mas também aumentará o tempo de processamento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "bff3f486",
   "metadata": {},
   "outputs": [],
   "source": [
    "#função que realiza o método bootstrap\n",
    "def bootstrap(X_test, y_test, model, nn=False, B=250):\n",
    "    #Creating dictionary to store results\n",
    "    out={}\n",
    "    out['accuracy']=[]\n",
    "    out['macro avg']={}\n",
    "    out['macro avg']['f1-score']=[]\n",
    "    out['macro avg']['recall']=[]\n",
    "    out['macro avg']['precision']=[]\n",
    "    out['weighted avg']={}\n",
    "    out['weighted avg']['f1-score']=[]\n",
    "    out['weighted avg']['recall']=[]\n",
    "    out['weighted avg']['precision']=[]\n",
    "\n",
    "    #Running Bootstrap on the test set\n",
    "    for b in tqdm(range(B)):\n",
    "        ind = np.random.choice(range(y_test.shape[0]),y_test.shape[0])\n",
    "        X_test_boot, y_test_boot = X_test[ind,:], y_test[ind]\n",
    "\n",
    "        y_pred=model.predict(X_test_boot)\n",
    "        \n",
    "        if nn:\n",
    "            y_pred=np.argmax(y_pred,axis=1)\n",
    "            report=classification_report(y_test_boot, y_pred, labels=[0, 1, 2, 3], output_dict=True)\n",
    "        else:\n",
    "            report=classification_report(y_test_boot, y_pred, labels=[0, 1, 2, 3], output_dict=True)\n",
    "\n",
    "        out['accuracy'].append(report['accuracy'])\n",
    "        out['macro avg']['f1-score'].append(report['macro avg']['f1-score'])\n",
    "        out['macro avg']['recall'].append(report['macro avg']['recall'])\n",
    "        out['macro avg']['precision'].append(report['macro avg']['precision'])\n",
    "        out['weighted avg']['f1-score'].append(report['weighted avg']['f1-score'])\n",
    "        out['weighted avg']['recall'].append(report['weighted avg']['recall'])\n",
    "        out['weighted avg']['precision'].append(report['weighted avg']['precision'])\n",
    "\n",
    "    #Preparing output\n",
    "    y_pred=model.predict(X_test)\n",
    "    \n",
    "    if nn:\n",
    "        y_pred=np.argmax(y_pred,axis=1)\n",
    "        report=classification_report(y_test, y_pred, labels=[0, 1, 2, 3], output_dict=True)\n",
    "    else:\n",
    "        report=classification_report(y_test, y_pred, labels=[0, 1, 2, 3], output_dict=True)\n",
    "\n",
    "    out['accuracy'] = [report['accuracy'], np.std(out['accuracy'])]\n",
    "    out['macro avg']['f1-score'] = [report['macro avg']['f1-score'], np.std(out['macro avg']['f1-score'])] \n",
    "    out['macro avg']['recall'] = [report['macro avg']['recall'], np.std(out['macro avg']['recall'])] \n",
    "    out['macro avg']['precision'] = [report['macro avg']['precision'], np.std(out['macro avg']['precision'])] \n",
    "    out['weighted avg']['f1-score'] = [report['weighted avg']['f1-score'], np.std(out['weighted avg']['f1-score'])] \n",
    "    out['weighted avg']['recall'] = [report['weighted avg']['recall'], np.std(out['weighted avg']['recall'])] \n",
    "    out['weighted avg']['precision'] = [report['weighted avg']['precision'], np.std(out['weighted avg']['precision'])]\n",
    "    \n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "cfb4b93c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                                                          | 0/250 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 11ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|▎                                                                                 | 1/250 [00:00<01:22,  3.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 11ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  1%|▋                                                                                 | 2/250 [00:00<01:23,  2.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 12ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  1%|▉                                                                                 | 3/250 [00:01<01:25,  2.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 11ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  2%|█▎                                                                                | 4/250 [00:01<01:23,  2.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 11ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  2%|█▋                                                                                | 5/250 [00:01<01:21,  3.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 13ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  2%|█▉                                                                                | 6/250 [00:02<01:24,  2.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 11ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  3%|██▎                                                                               | 7/250 [00:02<01:23,  2.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 11ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  3%|██▌                                                                               | 8/250 [00:02<01:23,  2.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 11ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  4%|██▉                                                                               | 9/250 [00:05<04:29,  1.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 11ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  4%|███▏                                                                             | 10/250 [00:05<03:30,  1.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 11ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  4%|███▌                                                                             | 11/250 [00:06<02:50,  1.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 11ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  5%|███▉                                                                             | 12/250 [00:06<02:24,  1.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 11ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  5%|████▏                                                                            | 13/250 [00:06<02:03,  1.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 11ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  6%|████▌                                                                            | 14/250 [00:07<01:49,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 11ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  6%|████▊                                                                            | 15/250 [00:07<01:42,  2.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 12ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  6%|█████▏                                                                           | 16/250 [00:07<01:35,  2.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 11ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  7%|█████▌                                                                           | 17/250 [00:08<01:30,  2.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 12ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  7%|█████▊                                                                           | 18/250 [00:08<01:28,  2.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 13ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  8%|██████▏                                                                          | 19/250 [00:09<01:27,  2.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 12ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  8%|██████▍                                                                          | 20/250 [00:09<01:24,  2.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 11ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  8%|██████▊                                                                          | 21/250 [00:09<01:23,  2.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 12ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  9%|███████▏                                                                         | 22/250 [00:10<01:22,  2.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 11ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  9%|███████▍                                                                         | 23/250 [00:10<01:21,  2.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 11ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 10%|███████▊                                                                         | 24/250 [00:10<01:22,  2.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 11ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 10%|████████                                                                         | 25/250 [00:11<01:21,  2.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 11ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 10%|████████▍                                                                        | 26/250 [00:11<01:19,  2.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 11ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 11%|████████▋                                                                        | 27/250 [00:11<01:18,  2.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 11ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 11%|█████████                                                                        | 28/250 [00:12<01:17,  2.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 12ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 12%|█████████▍                                                                       | 29/250 [00:12<01:17,  2.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 12ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 12%|█████████▋                                                                       | 30/250 [00:12<01:18,  2.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 11ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 12%|██████████                                                                       | 31/250 [00:13<01:17,  2.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 11ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 13%|██████████▎                                                                      | 32/250 [00:13<01:15,  2.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 12ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 13%|██████████▋                                                                      | 33/250 [00:13<01:17,  2.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 11ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 14%|███████████                                                                      | 34/250 [00:14<01:15,  2.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 11ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 14%|███████████▎                                                                     | 35/250 [00:14<01:13,  2.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 12ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 14%|███████████▋                                                                     | 36/250 [00:15<01:15,  2.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 10ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 15%|███████████▉                                                                     | 37/250 [00:15<01:13,  2.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 11ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 15%|████████████▎                                                                    | 38/250 [00:15<01:12,  2.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 13ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 16%|████████████▋                                                                    | 39/250 [00:16<01:14,  2.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 12ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 16%|████████████▉                                                                    | 40/250 [00:16<01:13,  2.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 11ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 16%|█████████████▎                                                                   | 41/250 [00:16<01:11,  2.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 14ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 17%|█████████████▌                                                                   | 42/250 [00:17<01:16,  2.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 12ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 17%|█████████████▉                                                                   | 43/250 [00:17<01:17,  2.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 11ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 18%|██████████████▎                                                                  | 44/250 [00:17<01:14,  2.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 11ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 18%|██████████████▌                                                                  | 45/250 [00:18<01:14,  2.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 11ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 18%|██████████████▉                                                                  | 46/250 [00:18<01:12,  2.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 11ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 19%|███████████████▏                                                                 | 47/250 [00:18<01:10,  2.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 12ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 19%|███████████████▌                                                                 | 48/250 [00:19<01:12,  2.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 11ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 20%|███████████████▉                                                                 | 49/250 [00:19<01:11,  2.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 13ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 20%|████████████████▏                                                                | 50/250 [00:20<01:11,  2.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 11ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 20%|████████████████▌                                                                | 51/250 [00:20<01:11,  2.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 12ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 21%|████████████████▊                                                                | 52/250 [00:20<01:10,  2.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 13ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 21%|█████████████████▏                                                               | 53/250 [00:21<01:10,  2.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 11ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 22%|█████████████████▍                                                               | 54/250 [00:21<01:09,  2.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 11ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 22%|█████████████████▊                                                               | 55/250 [00:21<01:07,  2.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 12ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 22%|██████████████████▏                                                              | 56/250 [00:22<01:08,  2.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 11ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 23%|██████████████████▍                                                              | 57/250 [00:22<01:09,  2.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 11ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 23%|██████████████████▊                                                              | 58/250 [00:22<01:07,  2.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 12ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 24%|███████████████████                                                              | 59/250 [00:23<01:07,  2.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 11ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 24%|███████████████████▍                                                             | 60/250 [00:23<01:07,  2.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 11ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 24%|███████████████████▊                                                             | 61/250 [00:23<01:06,  2.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 11ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 25%|████████████████████                                                             | 62/250 [00:24<01:05,  2.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 11ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 25%|████████████████████▍                                                            | 63/250 [00:24<01:05,  2.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 12ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 26%|████████████████████▋                                                            | 64/250 [00:24<01:06,  2.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 11ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 26%|█████████████████████                                                            | 65/250 [00:25<01:04,  2.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 11ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 26%|█████████████████████▍                                                           | 66/250 [00:25<01:05,  2.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 12ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 27%|█████████████████████▋                                                           | 67/250 [00:26<01:04,  2.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 11ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 27%|██████████████████████                                                           | 68/250 [00:26<01:03,  2.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 11ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 28%|██████████████████████▎                                                          | 69/250 [00:26<01:03,  2.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 11ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 28%|██████████████████████▋                                                          | 70/250 [00:27<01:02,  2.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 11ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 28%|███████████████████████                                                          | 71/250 [00:27<01:02,  2.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 10ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 29%|███████████████████████▎                                                         | 72/250 [00:27<01:01,  2.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 11ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 29%|███████████████████████▋                                                         | 73/250 [00:28<01:00,  2.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 11ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 30%|███████████████████████▉                                                         | 74/250 [00:28<00:59,  2.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 11ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 30%|████████████████████████▎                                                        | 75/250 [00:28<00:59,  2.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 13ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 30%|████████████████████████▌                                                        | 76/250 [00:29<01:01,  2.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 11ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 31%|████████████████████████▉                                                        | 77/250 [00:29<00:59,  2.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 11ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 31%|█████████████████████████▎                                                       | 78/250 [00:29<01:00,  2.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 11ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 32%|█████████████████████████▌                                                       | 79/250 [00:30<00:59,  2.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 11ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 32%|█████████████████████████▉                                                       | 80/250 [00:30<00:58,  2.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 11ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 32%|██████████████████████████▏                                                      | 81/250 [00:30<00:58,  2.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 11ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 33%|██████████████████████████▌                                                      | 82/250 [00:31<00:57,  2.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 11ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 33%|██████████████████████████▉                                                      | 83/250 [00:31<00:57,  2.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 11ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 34%|███████████████████████████▏                                                     | 84/250 [00:31<00:57,  2.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 11ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 34%|███████████████████████████▌                                                     | 85/250 [00:32<00:57,  2.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 11ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 34%|███████████████████████████▊                                                     | 86/250 [00:32<00:56,  2.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 11ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 35%|████████████████████████████▏                                                    | 87/250 [00:32<00:56,  2.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 11ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 35%|████████████████████████████▌                                                    | 88/250 [00:33<00:56,  2.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 11ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 36%|████████████████████████████▊                                                    | 89/250 [00:33<00:55,  2.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 12ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 36%|█████████████████████████████▏                                                   | 90/250 [00:33<00:56,  2.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 11ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 36%|█████████████████████████████▍                                                   | 91/250 [00:34<00:55,  2.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 11ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 37%|█████████████████████████████▊                                                   | 92/250 [00:34<00:54,  2.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 13ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 37%|██████████████████████████████▏                                                  | 93/250 [00:35<00:55,  2.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 11ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 38%|██████████████████████████████▍                                                  | 94/250 [00:35<00:54,  2.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 11ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 38%|██████████████████████████████▊                                                  | 95/250 [00:35<00:53,  2.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 13ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 38%|███████████████████████████████                                                  | 96/250 [00:36<00:54,  2.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 11ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 39%|███████████████████████████████▍                                                 | 97/250 [00:36<00:53,  2.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 11ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 39%|███████████████████████████████▊                                                 | 98/250 [00:36<00:52,  2.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 13ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 40%|████████████████████████████████                                                 | 99/250 [00:37<00:54,  2.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 12ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 40%|████████████████████████████████                                                | 100/250 [00:37<00:54,  2.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 11ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 40%|████████████████████████████████▎                                               | 101/250 [00:37<00:53,  2.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 11ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 41%|████████████████████████████████▋                                               | 102/250 [00:38<00:53,  2.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 11ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 41%|████████████████████████████████▉                                               | 103/250 [00:38<00:52,  2.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 11ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 42%|█████████████████████████████████▎                                              | 104/250 [00:38<00:50,  2.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 12ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 42%|█████████████████████████████████▌                                              | 105/250 [00:39<00:52,  2.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 12ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 42%|█████████████████████████████████▉                                              | 106/250 [00:39<00:51,  2.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 13ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 43%|██████████████████████████████████▏                                             | 107/250 [00:40<00:51,  2.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 12ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 43%|██████████████████████████████████▌                                             | 108/250 [00:40<00:51,  2.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 11ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 44%|██████████████████████████████████▉                                             | 109/250 [00:40<00:49,  2.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 13ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 44%|███████████████████████████████████▏                                            | 110/250 [00:41<00:50,  2.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 11ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 44%|███████████████████████████████████▌                                            | 111/250 [00:41<00:49,  2.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 11ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 45%|███████████████████████████████████▊                                            | 112/250 [00:41<00:48,  2.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 12ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 45%|████████████████████████████████████▏                                           | 113/250 [00:42<00:48,  2.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 11ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 46%|████████████████████████████████████▍                                           | 114/250 [00:42<00:48,  2.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 11ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 46%|████████████████████████████████████▊                                           | 115/250 [00:42<00:46,  2.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 11ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 46%|█████████████████████████████████████                                           | 116/250 [00:43<00:46,  2.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 12ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 47%|█████████████████████████████████████▍                                          | 117/250 [00:43<00:46,  2.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 11ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 47%|█████████████████████████████████████▊                                          | 118/250 [00:43<00:45,  2.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 11ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 48%|██████████████████████████████████████                                          | 119/250 [00:44<00:45,  2.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 12ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 48%|██████████████████████████████████████▍                                         | 120/250 [00:44<00:46,  2.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 14ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 48%|██████████████████████████████████████▋                                         | 121/250 [00:45<00:47,  2.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 11ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 49%|███████████████████████████████████████                                         | 122/250 [00:45<00:46,  2.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 11ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 49%|███████████████████████████████████████▎                                        | 123/250 [00:45<00:45,  2.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 12ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 50%|███████████████████████████████████████▋                                        | 124/250 [00:46<00:45,  2.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 11ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 50%|████████████████████████████████████████                                        | 125/250 [00:46<00:44,  2.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 11ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 50%|████████████████████████████████████████▎                                       | 126/250 [00:46<00:44,  2.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 12ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 51%|████████████████████████████████████████▋                                       | 127/250 [00:47<00:44,  2.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 11ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 51%|████████████████████████████████████████▉                                       | 128/250 [00:47<00:43,  2.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 11ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 52%|█████████████████████████████████████████▎                                      | 129/250 [00:47<00:42,  2.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 12ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 52%|█████████████████████████████████████████▌                                      | 130/250 [00:48<00:41,  2.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 11ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 52%|█████████████████████████████████████████▉                                      | 131/250 [00:48<00:41,  2.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 13ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 53%|██████████████████████████████████████████▏                                     | 132/250 [00:48<00:42,  2.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 12ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 53%|██████████████████████████████████████████▌                                     | 133/250 [00:49<00:42,  2.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 11ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 54%|██████████████████████████████████████████▉                                     | 134/250 [00:49<00:41,  2.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 13ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 54%|███████████████████████████████████████████▏                                    | 135/250 [00:50<00:41,  2.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 12ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 54%|███████████████████████████████████████████▌                                    | 136/250 [00:50<00:41,  2.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 11ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 55%|███████████████████████████████████████████▊                                    | 137/250 [00:50<00:40,  2.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 13ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 55%|████████████████████████████████████████████▏                                   | 138/250 [00:51<00:41,  2.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 11ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 56%|████████████████████████████████████████████▍                                   | 139/250 [00:51<00:40,  2.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 11ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 56%|████████████████████████████████████████████▊                                   | 140/250 [00:51<00:39,  2.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 11ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 56%|█████████████████████████████████████████████                                   | 141/250 [00:52<00:39,  2.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 11ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 57%|█████████████████████████████████████████████▍                                  | 142/250 [00:52<00:38,  2.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 11ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 57%|█████████████████████████████████████████████▊                                  | 143/250 [00:52<00:37,  2.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 12ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 58%|██████████████████████████████████████████████                                  | 144/250 [00:53<00:38,  2.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 11ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 58%|██████████████████████████████████████████████▍                                 | 145/250 [00:53<00:37,  2.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 12ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 58%|██████████████████████████████████████████████▋                                 | 146/250 [00:53<00:37,  2.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 11ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 59%|███████████████████████████████████████████████                                 | 147/250 [00:54<00:37,  2.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 12ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 59%|███████████████████████████████████████████████▎                                | 148/250 [00:54<00:36,  2.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 15ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 60%|███████████████████████████████████████████████▋                                | 149/250 [00:55<00:38,  2.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 11ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 60%|████████████████████████████████████████████████                                | 150/250 [00:55<00:37,  2.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 11ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 60%|████████████████████████████████████████████████▎                               | 151/250 [00:55<00:35,  2.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 12ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 61%|████████████████████████████████████████████████▋                               | 152/250 [00:56<00:35,  2.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 11ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 61%|████████████████████████████████████████████████▉                               | 153/250 [00:56<00:35,  2.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 12ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 62%|█████████████████████████████████████████████████▎                              | 154/250 [00:56<00:34,  2.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 12ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 62%|█████████████████████████████████████████████████▌                              | 155/250 [00:57<00:34,  2.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 12ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 62%|█████████████████████████████████████████████████▉                              | 156/250 [00:57<00:34,  2.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 13ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 63%|██████████████████████████████████████████████████▏                             | 157/250 [00:58<00:34,  2.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 12ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 63%|██████████████████████████████████████████████████▌                             | 158/250 [00:58<00:33,  2.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 12ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 64%|██████████████████████████████████████████████████▉                             | 159/250 [00:58<00:33,  2.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 14ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 64%|███████████████████████████████████████████████████▏                            | 160/250 [00:59<00:34,  2.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 12ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 64%|███████████████████████████████████████████████████▌                            | 161/250 [00:59<00:33,  2.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 12ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 65%|███████████████████████████████████████████████████▊                            | 162/250 [00:59<00:33,  2.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 11ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 65%|████████████████████████████████████████████████████▏                           | 163/250 [01:00<00:33,  2.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 12ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 66%|████████████████████████████████████████████████████▍                           | 164/250 [01:00<00:32,  2.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 13ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 66%|████████████████████████████████████████████████████▊                           | 165/250 [01:01<00:32,  2.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 11ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 66%|█████████████████████████████████████████████████████                           | 166/250 [01:01<00:31,  2.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 12ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 67%|█████████████████████████████████████████████████████▍                          | 167/250 [01:01<00:30,  2.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 12ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 67%|█████████████████████████████████████████████████████▊                          | 168/250 [01:02<00:30,  2.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 11ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 68%|██████████████████████████████████████████████████████                          | 169/250 [01:02<00:29,  2.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 12ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 68%|██████████████████████████████████████████████████████▍                         | 170/250 [01:02<00:28,  2.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 11ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 68%|██████████████████████████████████████████████████████▋                         | 171/250 [01:03<00:28,  2.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 12ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 69%|███████████████████████████████████████████████████████                         | 172/250 [01:03<00:28,  2.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 12ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 69%|███████████████████████████████████████████████████████▎                        | 173/250 [01:03<00:28,  2.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 11ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 70%|███████████████████████████████████████████████████████▋                        | 174/250 [01:04<00:27,  2.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 12ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 70%|████████████████████████████████████████████████████████                        | 175/250 [01:04<00:27,  2.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 13ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 70%|████████████████████████████████████████████████████████▎                       | 176/250 [01:05<00:27,  2.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 11ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 71%|████████████████████████████████████████████████████████▋                       | 177/250 [01:05<00:26,  2.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 11ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 71%|████████████████████████████████████████████████████████▉                       | 178/250 [01:05<00:25,  2.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 14ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 72%|█████████████████████████████████████████████████████████▎                      | 179/250 [01:06<00:25,  2.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 11ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 72%|█████████████████████████████████████████████████████████▌                      | 180/250 [01:06<00:25,  2.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 11ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 72%|█████████████████████████████████████████████████████████▉                      | 181/250 [01:06<00:24,  2.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 12ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 73%|██████████████████████████████████████████████████████████▏                     | 182/250 [01:07<00:24,  2.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 11ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 73%|██████████████████████████████████████████████████████████▌                     | 183/250 [01:07<00:23,  2.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 11ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 74%|██████████████████████████████████████████████████████████▉                     | 184/250 [01:07<00:22,  2.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 11ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 74%|███████████████████████████████████████████████████████████▏                    | 185/250 [01:08<00:22,  2.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 11ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 74%|███████████████████████████████████████████████████████████▌                    | 186/250 [01:08<00:22,  2.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 11ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 75%|███████████████████████████████████████████████████████████▊                    | 187/250 [01:08<00:21,  2.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 12ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 75%|████████████████████████████████████████████████████████████▏                   | 188/250 [01:09<00:22,  2.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 11ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 76%|████████████████████████████████████████████████████████████▍                   | 189/250 [01:09<00:21,  2.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 13ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 76%|████████████████████████████████████████████████████████████▊                   | 190/250 [01:10<00:21,  2.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 11ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 76%|█████████████████████████████████████████████████████████████                   | 191/250 [01:10<00:21,  2.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 12ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 77%|█████████████████████████████████████████████████████████████▍                  | 192/250 [01:10<00:20,  2.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 13ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 77%|█████████████████████████████████████████████████████████████▊                  | 193/250 [01:11<00:20,  2.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 11ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 78%|██████████████████████████████████████████████████████████████                  | 194/250 [01:11<00:20,  2.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 11ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 78%|██████████████████████████████████████████████████████████████▍                 | 195/250 [01:11<00:19,  2.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 12ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 78%|██████████████████████████████████████████████████████████████▋                 | 196/250 [01:12<00:19,  2.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 12ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 79%|███████████████████████████████████████████████████████████████                 | 197/250 [01:12<00:18,  2.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 11ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 79%|███████████████████████████████████████████████████████████████▎                | 198/250 [01:12<00:18,  2.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 12ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 80%|███████████████████████████████████████████████████████████████▋                | 199/250 [01:13<00:18,  2.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 11ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 80%|████████████████████████████████████████████████████████████████                | 200/250 [01:13<00:17,  2.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 12ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 80%|████████████████████████████████████████████████████████████████▎               | 201/250 [01:13<00:17,  2.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 11ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 81%|████████████████████████████████████████████████████████████████▋               | 202/250 [01:14<00:16,  2.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 11ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 81%|████████████████████████████████████████████████████████████████▉               | 203/250 [01:14<00:16,  2.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 12ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 82%|█████████████████████████████████████████████████████████████████▎              | 204/250 [01:15<00:16,  2.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 11ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 82%|█████████████████████████████████████████████████████████████████▌              | 205/250 [01:15<00:15,  2.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 11ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 82%|█████████████████████████████████████████████████████████████████▉              | 206/250 [01:15<00:15,  2.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 13ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 83%|██████████████████████████████████████████████████████████████████▏             | 207/250 [01:16<00:15,  2.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 12ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 83%|██████████████████████████████████████████████████████████████████▌             | 208/250 [01:16<00:14,  2.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 11ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 84%|██████████████████████████████████████████████████████████████████▉             | 209/250 [01:16<00:14,  2.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 13ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 84%|███████████████████████████████████████████████████████████████████▏            | 210/250 [01:17<00:14,  2.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 12ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 84%|███████████████████████████████████████████████████████████████████▌            | 211/250 [01:17<00:14,  2.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 11ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 85%|███████████████████████████████████████████████████████████████████▊            | 212/250 [01:17<00:13,  2.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 11ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 85%|████████████████████████████████████████████████████████████████████▏           | 213/250 [01:18<00:13,  2.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 11ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 86%|████████████████████████████████████████████████████████████████████▍           | 214/250 [01:18<00:12,  2.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 11ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 86%|████████████████████████████████████████████████████████████████████▊           | 215/250 [01:18<00:11,  2.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 11ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 86%|█████████████████████████████████████████████████████████████████████           | 216/250 [01:19<00:11,  2.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 11ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 87%|█████████████████████████████████████████████████████████████████████▍          | 217/250 [01:19<00:11,  2.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 11ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 87%|█████████████████████████████████████████████████████████████████████▊          | 218/250 [01:19<00:10,  2.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 11ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 88%|██████████████████████████████████████████████████████████████████████          | 219/250 [01:20<00:10,  2.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 11ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 88%|██████████████████████████████████████████████████████████████████████▍         | 220/250 [01:20<00:10,  2.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 11ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 88%|██████████████████████████████████████████████████████████████████████▋         | 221/250 [01:20<00:09,  2.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 11ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 89%|███████████████████████████████████████████████████████████████████████         | 222/250 [01:21<00:09,  2.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 11ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 89%|███████████████████████████████████████████████████████████████████████▎        | 223/250 [01:21<00:09,  2.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 13ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 90%|███████████████████████████████████████████████████████████████████████▋        | 224/250 [01:22<00:09,  2.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 11ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 90%|████████████████████████████████████████████████████████████████████████        | 225/250 [01:22<00:08,  2.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 11ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 90%|████████████████████████████████████████████████████████████████████████▎       | 226/250 [01:22<00:08,  2.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 13ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 91%|████████████████████████████████████████████████████████████████████████▋       | 227/250 [01:23<00:08,  2.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 11ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 91%|████████████████████████████████████████████████████████████████████████▉       | 228/250 [01:23<00:07,  2.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 11ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 92%|█████████████████████████████████████████████████████████████████████████▎      | 229/250 [01:23<00:07,  2.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 13ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 92%|█████████████████████████████████████████████████████████████████████████▌      | 230/250 [01:24<00:07,  2.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 11ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 92%|█████████████████████████████████████████████████████████████████████████▉      | 231/250 [01:24<00:06,  2.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 11ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 93%|██████████████████████████████████████████████████████████████████████████▏     | 232/250 [01:24<00:06,  2.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 12ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 93%|██████████████████████████████████████████████████████████████████████████▌     | 233/250 [01:25<00:06,  2.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 11ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 94%|██████████████████████████████████████████████████████████████████████████▉     | 234/250 [01:25<00:05,  2.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 12ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 94%|███████████████████████████████████████████████████████████████████████████▏    | 235/250 [01:25<00:05,  2.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 12ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 94%|███████████████████████████████████████████████████████████████████████████▌    | 236/250 [01:26<00:05,  2.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 11ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 95%|███████████████████████████████████████████████████████████████████████████▊    | 237/250 [01:26<00:04,  2.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 11ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 95%|████████████████████████████████████████████████████████████████████████████▏   | 238/250 [01:26<00:04,  2.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 11ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 96%|████████████████████████████████████████████████████████████████████████████▍   | 239/250 [01:27<00:03,  2.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 11ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 96%|████████████████████████████████████████████████████████████████████████████▊   | 240/250 [01:27<00:03,  2.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 12ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 96%|█████████████████████████████████████████████████████████████████████████████   | 241/250 [01:27<00:03,  2.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 11ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 97%|█████████████████████████████████████████████████████████████████████████████▍  | 242/250 [01:28<00:02,  2.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 11ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 97%|█████████████████████████████████████████████████████████████████████████████▊  | 243/250 [01:28<00:02,  2.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 12ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 98%|██████████████████████████████████████████████████████████████████████████████  | 244/250 [01:29<00:02,  2.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 10ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 98%|██████████████████████████████████████████████████████████████████████████████▍ | 245/250 [01:29<00:01,  2.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 11ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 98%|██████████████████████████████████████████████████████████████████████████████▋ | 246/250 [01:29<00:01,  2.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 12ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 99%|███████████████████████████████████████████████████████████████████████████████ | 247/250 [01:30<00:01,  2.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 11ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 99%|███████████████████████████████████████████████████████████████████████████████▎| 248/250 [01:30<00:00,  2.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 11ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "100%|███████████████████████████████████████████████████████████████████████████████▋| 249/250 [01:30<00:00,  2.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 15ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 250/250 [01:31<00:00,  2.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 6/16 [==========>...................] - ETA: 0s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 11ms/step\n",
      "\n",
      "\n",
      "accuracy                   : 0.23 ± 0.02\n",
      "macro avg        f1-score  : 0.23 ± 0.02\n",
      "macro avg        recall    : 0.24 ± 0.02\n",
      "macro avg        precision : 0.23 ± 0.02\n",
      "weighted avg     f1-score  : 0.22 ± 0.02\n",
      "weighted avg     recall    : 0.23 ± 0.02\n",
      "weighted avg     precision : 0.22 ± 0.02\n"
     ]
    }
   ],
   "source": [
    "report_boot=bootstrap(np.array(X_test), np.array(y_test), Dcnn, nn = True)\n",
    "\n",
    "for i in ['accuracy', 'macro avg', 'weighted avg']:\n",
    "    if i == 'accuracy':\n",
    "        print(\"\\n\\n{:27}: {:.2f} ± {:.2f}\".format(i, report_boot[i][0], report_boot[i][1]))\n",
    "    for j in ['f1-score', 'recall', 'precision']:\n",
    "        if i != 'accuracy':\n",
    "            print(\"{:15}  {:10}: {:.2f} ± {:.2f}\".format(i, j, report_boot[i][j][0], report_boot[i][j][1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28279b5e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
