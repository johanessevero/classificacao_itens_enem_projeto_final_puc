{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "04f67161",
   "metadata": {},
   "outputs": [],
   "source": [
    "# importação das bilbiotecas\n",
    "#data\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "#plot\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#ml\n",
    "import tensorflow as tf\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import tensorflow_datasets as tfds\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "#aux\n",
    "from IPython.display import clear_output\n",
    "import os\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "637a3568",
   "metadata": {},
   "source": [
    "## carregar dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a45285df",
   "metadata": {},
   "source": [
    "### treinamento o word embbeding próprio treinado com skip-gram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "fbda41d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the dataframe object from the pickle file\n",
    "with open(os.path.join('data', 'dataset_param_a_train.pkl'), 'rb') as f:\n",
    "    dataset = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "4e05283b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tf_idf</th>\n",
       "      <th>wes</th>\n",
       "      <th>wes_own</th>\n",
       "      <th>classes_param_a_1</th>\n",
       "      <th>classes_param_b_1</th>\n",
       "      <th>classes_param_c_1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1760</th>\n",
       "      <td>[0.12456968494564394, 0.08988356079585649, 0.1...</td>\n",
       "      <td>[[-0.0073, -0.0428, -0.0087, 0.035, 0.0179, -0...</td>\n",
       "      <td>[[-0.034232993, 0.04486641, 0.00884448, 0.0722...</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>564</th>\n",
       "      <td>[0.05662525107280963, 0.10048547503414434, 0.1...</td>\n",
       "      <td>[[-0.0225, -0.0023, 0.0529, 0.0049, 0.042, -0....</td>\n",
       "      <td>[[-0.13116597, 0.21317357, 0.06456468, 0.19338...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>401</th>\n",
       "      <td>[0.026692991743747074, 0.05267474243888511, 0....</td>\n",
       "      <td>[[-0.084, 0.0216, 0.0036, -0.034, -0.0106, -0....</td>\n",
       "      <td>[[-0.13062884, 0.20189483, -0.054444484, 0.251...</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1876</th>\n",
       "      <td>[0.046029406346867315, 0.060844034470711586, 0...</td>\n",
       "      <td>[[0.03, 0.0158, 0.0584, 0.0091, 0.0409, -0.138...</td>\n",
       "      <td>[[-0.07692826, 0.095890105, 0.05258643, 0.3825...</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>956</th>\n",
       "      <td>[0.08829657106261818, 0.060500120867303185, 0....</td>\n",
       "      <td>[[-0.0086, 0.1091, 0.0922, -0.0019, 0.0524, -0...</td>\n",
       "      <td>[[0.114780754, 0.13769501, 0.01912954, 0.41985...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>456</th>\n",
       "      <td>[0.4304220081037565, 0.22943255222025502, 0.20...</td>\n",
       "      <td>[[-0.0147, -0.0014, 0.0509, 0.0234, 0.021, -0....</td>\n",
       "      <td>[[0.23310582, 0.12308032, 0.16503847, 0.254300...</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1515</th>\n",
       "      <td>[0.09869963709433056, 0.06062230642955486, 0.0...</td>\n",
       "      <td>[[0.0222, -0.0047, 0.0267, 0.0014, 0.0167, -0....</td>\n",
       "      <td>[[0.019323207, 0.36649448, 0.08162812, -0.0040...</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>216</th>\n",
       "      <td>[0.07839304093995585, 0.05048618299470653, 0.0...</td>\n",
       "      <td>[[0.0044, 0.0346, 0.0625, 0.0593, 0.0196, -0.0...</td>\n",
       "      <td>[[-0.77106756, 0.23528458, -0.21174854, 0.2718...</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1600</th>\n",
       "      <td>[0.10465107118200082, 0.11563591269664297, 0.0...</td>\n",
       "      <td>[[-0.0163, 0.0413, -0.0067, 0.0213, 0.0137, -0...</td>\n",
       "      <td>[[-0.019255916, 0.08863165, 0.014731412, 0.108...</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1417</th>\n",
       "      <td>[0.07533008177921344, 0.06787074975830051, 0.0...</td>\n",
       "      <td>[[-0.022, 0.0315, 0.0752, -0.0268, 0.0625, -0....</td>\n",
       "      <td>[[-0.20457007, 0.2068289, -0.22812223, 0.41948...</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1441 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 tf_idf  \\\n",
       "1760  [0.12456968494564394, 0.08988356079585649, 0.1...   \n",
       "564   [0.05662525107280963, 0.10048547503414434, 0.1...   \n",
       "401   [0.026692991743747074, 0.05267474243888511, 0....   \n",
       "1876  [0.046029406346867315, 0.060844034470711586, 0...   \n",
       "956   [0.08829657106261818, 0.060500120867303185, 0....   \n",
       "...                                                 ...   \n",
       "456   [0.4304220081037565, 0.22943255222025502, 0.20...   \n",
       "1515  [0.09869963709433056, 0.06062230642955486, 0.0...   \n",
       "216   [0.07839304093995585, 0.05048618299470653, 0.0...   \n",
       "1600  [0.10465107118200082, 0.11563591269664297, 0.0...   \n",
       "1417  [0.07533008177921344, 0.06787074975830051, 0.0...   \n",
       "\n",
       "                                                    wes  \\\n",
       "1760  [[-0.0073, -0.0428, -0.0087, 0.035, 0.0179, -0...   \n",
       "564   [[-0.0225, -0.0023, 0.0529, 0.0049, 0.042, -0....   \n",
       "401   [[-0.084, 0.0216, 0.0036, -0.034, -0.0106, -0....   \n",
       "1876  [[0.03, 0.0158, 0.0584, 0.0091, 0.0409, -0.138...   \n",
       "956   [[-0.0086, 0.1091, 0.0922, -0.0019, 0.0524, -0...   \n",
       "...                                                 ...   \n",
       "456   [[-0.0147, -0.0014, 0.0509, 0.0234, 0.021, -0....   \n",
       "1515  [[0.0222, -0.0047, 0.0267, 0.0014, 0.0167, -0....   \n",
       "216   [[0.0044, 0.0346, 0.0625, 0.0593, 0.0196, -0.0...   \n",
       "1600  [[-0.0163, 0.0413, -0.0067, 0.0213, 0.0137, -0...   \n",
       "1417  [[-0.022, 0.0315, 0.0752, -0.0268, 0.0625, -0....   \n",
       "\n",
       "                                                wes_own classes_param_a_1  \\\n",
       "1760  [[-0.034232993, 0.04486641, 0.00884448, 0.0722...                 2   \n",
       "564   [[-0.13116597, 0.21317357, 0.06456468, 0.19338...                 1   \n",
       "401   [[-0.13062884, 0.20189483, -0.054444484, 0.251...                 0   \n",
       "1876  [[-0.07692826, 0.095890105, 0.05258643, 0.3825...                 1   \n",
       "956   [[0.114780754, 0.13769501, 0.01912954, 0.41985...                 0   \n",
       "...                                                 ...               ...   \n",
       "456   [[0.23310582, 0.12308032, 0.16503847, 0.254300...                 0   \n",
       "1515  [[0.019323207, 0.36649448, 0.08162812, -0.0040...                 3   \n",
       "216   [[-0.77106756, 0.23528458, -0.21174854, 0.2718...                 0   \n",
       "1600  [[-0.019255916, 0.08863165, 0.014731412, 0.108...                 2   \n",
       "1417  [[-0.20457007, 0.2068289, -0.22812223, 0.41948...                 1   \n",
       "\n",
       "     classes_param_b_1 classes_param_c_1  \n",
       "1760                 0                 1  \n",
       "564                  1                 2  \n",
       "401                  2                 0  \n",
       "1876                 2                 1  \n",
       "956                  1                 3  \n",
       "...                ...               ...  \n",
       "456                  3                 2  \n",
       "1515                 0                 1  \n",
       "216                  3                 3  \n",
       "1600                 2                 3  \n",
       "1417                 2                 3  \n",
       "\n",
       "[1441 rows x 6 columns]"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "721b4ae4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#X = np.array([x.reshape(x.shape[0], -1, 300) for x in df.iloc[:, 0].values])\n",
    "X = dataset.iloc[:, 2].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "cb42485b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(47, 100)"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(X[51]).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "2bcccf33",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0.06813321,\n",
       "  0.11464058,\n",
       "  0.11486036,\n",
       "  0.17104676,\n",
       "  0.0058565335,\n",
       "  -0.2907282,\n",
       "  0.09243415,\n",
       "  0.41654432,\n",
       "  0.045927107,\n",
       "  -0.02482774,\n",
       "  -0.11498794,\n",
       "  -0.216453,\n",
       "  -0.042893834,\n",
       "  0.106376685,\n",
       "  0.0053537297,\n",
       "  -0.025612121,\n",
       "  0.093609974,\n",
       "  -0.19632964,\n",
       "  -0.06189749,\n",
       "  -0.2562701,\n",
       "  0.0815137,\n",
       "  0.14633673,\n",
       "  0.04678497,\n",
       "  -0.110196896,\n",
       "  -0.11014389,\n",
       "  0.048434433,\n",
       "  -0.32586128,\n",
       "  -0.24643783,\n",
       "  0.0049078013,\n",
       "  0.056971297,\n",
       "  0.25509757,\n",
       "  0.1319644,\n",
       "  0.017154647,\n",
       "  -0.03395471,\n",
       "  -0.020775773,\n",
       "  0.16243845,\n",
       "  -0.020497713,\n",
       "  -0.1871992,\n",
       "  -0.1352711,\n",
       "  -0.29067576,\n",
       "  0.025368359,\n",
       "  -0.15504554,\n",
       "  0.012862939,\n",
       "  -0.053347405,\n",
       "  0.090620935,\n",
       "  -0.11643119,\n",
       "  -0.16191393,\n",
       "  0.015707385,\n",
       "  0.15947081,\n",
       "  0.14733797,\n",
       "  0.15595348,\n",
       "  -0.14304256,\n",
       "  -0.047028035,\n",
       "  -0.018603109,\n",
       "  -0.11385992,\n",
       "  0.18469882,\n",
       "  0.23186606,\n",
       "  0.08829469,\n",
       "  -0.1284982,\n",
       "  0.09396078,\n",
       "  -0.04194529,\n",
       "  0.06260731,\n",
       "  -0.047221,\n",
       "  0.22355974,\n",
       "  -0.2381967,\n",
       "  0.11783152,\n",
       "  -0.043035112,\n",
       "  0.10087441,\n",
       "  -0.21277842,\n",
       "  0.2943919,\n",
       "  -0.08115728,\n",
       "  -0.05375498,\n",
       "  0.13803351,\n",
       "  -0.07565699,\n",
       "  0.12826067,\n",
       "  0.02143448,\n",
       "  0.0455942,\n",
       "  -0.0979025,\n",
       "  -0.08328249,\n",
       "  0.107447855,\n",
       "  -0.089690715,\n",
       "  0.08293331,\n",
       "  -0.1590529,\n",
       "  0.2779831,\n",
       "  0.022314686,\n",
       "  0.06176298,\n",
       "  -0.08206543,\n",
       "  0.17717795,\n",
       "  0.4077714,\n",
       "  0.16123511,\n",
       "  0.20607322,\n",
       "  0.012864157,\n",
       "  0.030864248,\n",
       "  0.08207199,\n",
       "  0.21042708,\n",
       "  0.24724928,\n",
       "  0.007054718,\n",
       "  -0.20700544,\n",
       "  0.07915176,\n",
       "  0.051845826],\n",
       " [0.27937102,\n",
       "  -0.03063896,\n",
       "  0.24253161,\n",
       "  0.05997441,\n",
       "  0.078771465,\n",
       "  -0.43238115,\n",
       "  0.05653493,\n",
       "  0.62171024,\n",
       "  0.35357553,\n",
       "  -0.05109534,\n",
       "  -0.11868131,\n",
       "  -0.21792865,\n",
       "  -0.17607854,\n",
       "  0.11838257,\n",
       "  0.10459957,\n",
       "  0.04241505,\n",
       "  0.26871336,\n",
       "  -0.116279654,\n",
       "  0.04599238,\n",
       "  -0.24957499,\n",
       "  -0.050307352,\n",
       "  0.1611978,\n",
       "  -0.13952549,\n",
       "  -0.32322797,\n",
       "  0.04900936,\n",
       "  0.05925096,\n",
       "  -0.47748068,\n",
       "  -0.4388191,\n",
       "  -0.10162117,\n",
       "  0.33162102,\n",
       "  0.37151957,\n",
       "  -0.01081185,\n",
       "  0.028507559,\n",
       "  -0.0053800386,\n",
       "  -0.13915838,\n",
       "  0.21218847,\n",
       "  -0.10951172,\n",
       "  -0.26983362,\n",
       "  -0.026866678,\n",
       "  -0.5676865,\n",
       "  -0.16508727,\n",
       "  0.004068364,\n",
       "  0.114469536,\n",
       "  -0.13014951,\n",
       "  0.13613161,\n",
       "  -0.13837785,\n",
       "  0.046308946,\n",
       "  0.018906591,\n",
       "  0.028404675,\n",
       "  0.21453063,\n",
       "  0.17334655,\n",
       "  -0.2755528,\n",
       "  -0.036298297,\n",
       "  -0.13673891,\n",
       "  0.035814308,\n",
       "  0.2672239,\n",
       "  0.28438446,\n",
       "  0.20886469,\n",
       "  -0.046533838,\n",
       "  0.27004063,\n",
       "  -0.29627907,\n",
       "  0.30486408,\n",
       "  -0.12308737,\n",
       "  0.33307028,\n",
       "  -0.3119436,\n",
       "  0.026829747,\n",
       "  -0.095388874,\n",
       "  0.07332781,\n",
       "  -0.1102991,\n",
       "  0.30187178,\n",
       "  0.027732724,\n",
       "  -0.22394393,\n",
       "  0.14310384,\n",
       "  0.024437366,\n",
       "  0.22951259,\n",
       "  0.039571714,\n",
       "  0.10527034,\n",
       "  -0.29470435,\n",
       "  -0.33433712,\n",
       "  0.11799103,\n",
       "  -0.02007929,\n",
       "  0.23245478,\n",
       "  -0.36464548,\n",
       "  0.44634596,\n",
       "  0.41501254,\n",
       "  0.067127325,\n",
       "  -0.018419944,\n",
       "  0.19282784,\n",
       "  0.27677995,\n",
       "  0.32685223,\n",
       "  0.2614721,\n",
       "  0.040306203,\n",
       "  -0.02042782,\n",
       "  -0.11503282,\n",
       "  0.27839044,\n",
       "  0.3615582,\n",
       "  0.106601745,\n",
       "  -0.24788836,\n",
       "  0.23902634,\n",
       "  -0.21253388],\n",
       " [-0.9518239,\n",
       "  0.21094996,\n",
       "  0.19613226,\n",
       "  0.48512492,\n",
       "  0.019271553,\n",
       "  -0.57215625,\n",
       "  -0.54139704,\n",
       "  0.75987643,\n",
       "  -0.66305125,\n",
       "  0.72314435,\n",
       "  -0.25104925,\n",
       "  -0.6743273,\n",
       "  -0.65252334,\n",
       "  -0.02804297,\n",
       "  -0.34960806,\n",
       "  -0.23430991,\n",
       "  -0.15202063,\n",
       "  -0.29049978,\n",
       "  0.6091131,\n",
       "  -0.13836332,\n",
       "  0.009111469,\n",
       "  0.48113793,\n",
       "  -0.84212357,\n",
       "  -0.92517406,\n",
       "  0.122023806,\n",
       "  0.15921058,\n",
       "  -0.66805804,\n",
       "  0.4001377,\n",
       "  -0.20532224,\n",
       "  -0.40508646,\n",
       "  0.61675453,\n",
       "  0.24577437,\n",
       "  0.427053,\n",
       "  0.9868237,\n",
       "  -0.5635983,\n",
       "  0.4301711,\n",
       "  0.9875045,\n",
       "  -0.69643867,\n",
       "  -0.20024705,\n",
       "  1.0786817,\n",
       "  0.47784844,\n",
       "  -0.4795707,\n",
       "  -0.19012609,\n",
       "  0.14885792,\n",
       "  0.03726548,\n",
       "  0.61702484,\n",
       "  -0.49259,\n",
       "  -0.035397045,\n",
       "  0.2316064,\n",
       "  -0.049699564,\n",
       "  0.1774415,\n",
       "  -0.60531276,\n",
       "  0.020140462,\n",
       "  0.6283035,\n",
       "  -0.22390895,\n",
       "  0.41099966,\n",
       "  0.9179781,\n",
       "  0.47028938,\n",
       "  0.6488693,\n",
       "  0.46025747,\n",
       "  -0.59177214,\n",
       "  0.34442735,\n",
       "  0.0074230433,\n",
       "  -0.107847854,\n",
       "  0.46084452,\n",
       "  -0.6610602,\n",
       "  -0.016051369,\n",
       "  0.93456954,\n",
       "  -0.25787145,\n",
       "  1.2487946,\n",
       "  -0.9184602,\n",
       "  -0.4337807,\n",
       "  -0.036407806,\n",
       "  -0.76863456,\n",
       "  0.54104215,\n",
       "  0.53405774,\n",
       "  -0.016266288,\n",
       "  0.24042603,\n",
       "  0.023456821,\n",
       "  -0.15600602,\n",
       "  -0.7177951,\n",
       "  -0.15020408,\n",
       "  -0.83857906,\n",
       "  0.16493689,\n",
       "  0.3256892,\n",
       "  0.62505454,\n",
       "  -0.17541279,\n",
       "  0.009748332,\n",
       "  0.71088517,\n",
       "  0.7368464,\n",
       "  -0.11177436,\n",
       "  0.64620316,\n",
       "  -0.026805587,\n",
       "  -0.28671506,\n",
       "  0.33424968,\n",
       "  0.44802952,\n",
       "  0.18894818,\n",
       "  0.26655495,\n",
       "  0.8103387,\n",
       "  0.29194734],\n",
       " [0.15997711,\n",
       "  0.21961804,\n",
       "  0.29440984,\n",
       "  0.3377802,\n",
       "  0.12924829,\n",
       "  -0.67814136,\n",
       "  0.13640729,\n",
       "  0.67326856,\n",
       "  -0.3187338,\n",
       "  -0.18650809,\n",
       "  -0.20539825,\n",
       "  -0.43021464,\n",
       "  0.04372197,\n",
       "  0.4209023,\n",
       "  0.10653826,\n",
       "  0.08888318,\n",
       "  0.20738636,\n",
       "  -0.09892699,\n",
       "  -0.5588771,\n",
       "  -0.8476655,\n",
       "  0.16593294,\n",
       "  0.696777,\n",
       "  -0.020333167,\n",
       "  -0.23471001,\n",
       "  -0.28094974,\n",
       "  0.27892223,\n",
       "  -0.7115055,\n",
       "  0.022817051,\n",
       "  0.19046986,\n",
       "  -0.14055015,\n",
       "  0.10135864,\n",
       "  0.3604967,\n",
       "  0.090147346,\n",
       "  -0.015843036,\n",
       "  -0.0626636,\n",
       "  0.50454974,\n",
       "  -0.24747658,\n",
       "  -0.47019193,\n",
       "  -0.18953916,\n",
       "  -0.4709153,\n",
       "  0.0639167,\n",
       "  -0.36418453,\n",
       "  -0.05415,\n",
       "  0.080291644,\n",
       "  0.20860893,\n",
       "  0.010381823,\n",
       "  -0.43682823,\n",
       "  0.1215331,\n",
       "  0.31895253,\n",
       "  0.2806253,\n",
       "  0.08390575,\n",
       "  -0.07850944,\n",
       "  -0.2095683,\n",
       "  0.28454268,\n",
       "  -0.116904385,\n",
       "  0.23367338,\n",
       "  0.50611085,\n",
       "  0.015842201,\n",
       "  -0.012075869,\n",
       "  0.4189614,\n",
       "  0.08149663,\n",
       "  0.122684486,\n",
       "  -0.02155266,\n",
       "  0.5025309,\n",
       "  -0.55731434,\n",
       "  0.26573396,\n",
       "  -0.276973,\n",
       "  -0.0018754117,\n",
       "  -0.1363788,\n",
       "  0.26464686,\n",
       "  -0.06840451,\n",
       "  -0.034870245,\n",
       "  0.43222603,\n",
       "  -0.34006652,\n",
       "  0.51194274,\n",
       "  0.06025397,\n",
       "  0.37390032,\n",
       "  -0.2434987,\n",
       "  0.088733524,\n",
       "  0.18646279,\n",
       "  -0.25686556,\n",
       "  0.26978198,\n",
       "  -0.09249144,\n",
       "  0.60150963,\n",
       "  -0.28478354,\n",
       "  0.35005182,\n",
       "  -0.29019254,\n",
       "  0.2962737,\n",
       "  0.98979884,\n",
       "  0.37658393,\n",
       "  0.48961523,\n",
       "  0.16347586,\n",
       "  0.31058943,\n",
       "  0.19554135,\n",
       "  -0.0055363965,\n",
       "  0.36096314,\n",
       "  0.14312442,\n",
       "  -0.3949896,\n",
       "  -0.058278978,\n",
       "  0.33224118],\n",
       " [0.27458096,\n",
       "  0.26965153,\n",
       "  0.26796705,\n",
       "  0.15170242,\n",
       "  0.19374427,\n",
       "  -0.38889596,\n",
       "  0.02918923,\n",
       "  0.57469815,\n",
       "  0.16548595,\n",
       "  -0.038266793,\n",
       "  -0.22495979,\n",
       "  -0.27818227,\n",
       "  -0.22320567,\n",
       "  -0.009256049,\n",
       "  0.023956463,\n",
       "  0.0006753419,\n",
       "  0.12466836,\n",
       "  -0.42417362,\n",
       "  -0.14173985,\n",
       "  -0.33970186,\n",
       "  0.028464248,\n",
       "  0.15380934,\n",
       "  0.15672341,\n",
       "  -0.2451663,\n",
       "  -0.18179588,\n",
       "  0.26349753,\n",
       "  -0.48584884,\n",
       "  -0.276908,\n",
       "  -0.24360467,\n",
       "  0.10898264,\n",
       "  0.33348843,\n",
       "  0.075710945,\n",
       "  -0.14615284,\n",
       "  0.004961621,\n",
       "  0.16813597,\n",
       "  0.051693592,\n",
       "  -0.10650742,\n",
       "  -0.364261,\n",
       "  -0.26131585,\n",
       "  -0.3922751,\n",
       "  -0.37529898,\n",
       "  0.024804747,\n",
       "  0.16813846,\n",
       "  -0.100630425,\n",
       "  -0.028012916,\n",
       "  -0.24926089,\n",
       "  -0.14442943,\n",
       "  0.19504543,\n",
       "  -0.07772985,\n",
       "  0.4676423,\n",
       "  0.006259304,\n",
       "  -0.30597633,\n",
       "  -0.054758146,\n",
       "  -0.21257983,\n",
       "  -0.18077332,\n",
       "  0.29763803,\n",
       "  0.32008627,\n",
       "  0.29205513,\n",
       "  -0.29678947,\n",
       "  0.088145405,\n",
       "  -0.406807,\n",
       "  0.34814852,\n",
       "  -0.03172315,\n",
       "  0.3767015,\n",
       "  -0.5193743,\n",
       "  0.27123016,\n",
       "  -0.3387044,\n",
       "  0.22052741,\n",
       "  -0.13006008,\n",
       "  0.15994728,\n",
       "  -0.12582178,\n",
       "  -0.22067456,\n",
       "  0.11655301,\n",
       "  -0.12694766,\n",
       "  0.21267517,\n",
       "  0.04165474,\n",
       "  -0.017383244,\n",
       "  -0.032151997,\n",
       "  -0.27620462,\n",
       "  0.09607001,\n",
       "  0.010683797,\n",
       "  0.15056661,\n",
       "  -0.4104985,\n",
       "  0.2598609,\n",
       "  0.083585404,\n",
       "  0.019224988,\n",
       "  0.09015758,\n",
       "  0.37805235,\n",
       "  0.2556452,\n",
       "  0.32243213,\n",
       "  0.1656871,\n",
       "  -0.022584194,\n",
       "  0.22405845,\n",
       "  0.048452545,\n",
       "  0.28032732,\n",
       "  0.40460777,\n",
       "  0.15404107,\n",
       "  -0.24880032,\n",
       "  0.14296192,\n",
       "  -0.12776525],\n",
       " [0.01257966,\n",
       "  0.13137905,\n",
       "  0.07753095,\n",
       "  0.2152748,\n",
       "  -0.055345282,\n",
       "  -0.11477532,\n",
       "  0.23535937,\n",
       "  0.47093847,\n",
       "  0.10987475,\n",
       "  -0.09809537,\n",
       "  -0.18349218,\n",
       "  -0.17833534,\n",
       "  -0.09335275,\n",
       "  0.031199772,\n",
       "  0.053026598,\n",
       "  -0.10057107,\n",
       "  0.17123973,\n",
       "  -0.14918382,\n",
       "  -0.085633494,\n",
       "  -0.3312493,\n",
       "  0.01634838,\n",
       "  0.10794918,\n",
       "  0.05515447,\n",
       "  -0.10955072,\n",
       "  -0.048329778,\n",
       "  0.0039744023,\n",
       "  -0.38687783,\n",
       "  -0.30605343,\n",
       "  0.026873447,\n",
       "  0.17274745,\n",
       "  0.42643267,\n",
       "  0.14656478,\n",
       "  -0.05436795,\n",
       "  -0.014541403,\n",
       "  -0.056947313,\n",
       "  0.19210966,\n",
       "  0.035297405,\n",
       "  -0.28429177,\n",
       "  -0.13702641,\n",
       "  -0.29926655,\n",
       "  -0.058574986,\n",
       "  -0.14576821,\n",
       "  0.078009784,\n",
       "  -0.16087952,\n",
       "  0.1702847,\n",
       "  -0.09973698,\n",
       "  -0.01170406,\n",
       "  0.09001899,\n",
       "  0.0032579193,\n",
       "  0.17351715,\n",
       "  0.15833709,\n",
       "  -0.15615813,\n",
       "  -0.08264321,\n",
       "  -0.061767895,\n",
       "  -0.12431615,\n",
       "  0.06032646,\n",
       "  0.29260853,\n",
       "  0.08862768,\n",
       "  -0.2206057,\n",
       "  -0.08507847,\n",
       "  -0.026283382,\n",
       "  -0.08522731,\n",
       "  0.13342819,\n",
       "  0.1203158,\n",
       "  -0.29433113,\n",
       "  0.07442401,\n",
       "  -0.03238987,\n",
       "  0.12777817,\n",
       "  -0.23102728,\n",
       "  0.2920884,\n",
       "  -0.05071246,\n",
       "  -0.07671289,\n",
       "  0.023917114,\n",
       "  -0.092312954,\n",
       "  0.13847277,\n",
       "  -0.009833459,\n",
       "  -0.058108687,\n",
       "  -0.02000337,\n",
       "  -0.16880035,\n",
       "  0.042517923,\n",
       "  -0.13531214,\n",
       "  0.027866881,\n",
       "  -0.19283786,\n",
       "  0.38994163,\n",
       "  0.09488981,\n",
       "  -0.114197105,\n",
       "  0.052754745,\n",
       "  0.22266515,\n",
       "  0.28496695,\n",
       "  0.18584932,\n",
       "  0.06368572,\n",
       "  0.080791615,\n",
       "  -0.03151504,\n",
       "  0.17192309,\n",
       "  0.51905423,\n",
       "  0.31757212,\n",
       "  0.0076671946,\n",
       "  -0.08536945,\n",
       "  0.13086179,\n",
       "  -0.0014297222],\n",
       " [0.63325953,\n",
       "  0.07702482,\n",
       "  0.19029099,\n",
       "  0.45067367,\n",
       "  0.005134413,\n",
       "  -0.36164528,\n",
       "  0.28856906,\n",
       "  1.050663,\n",
       "  0.08407817,\n",
       "  -0.08039928,\n",
       "  -0.43491548,\n",
       "  -0.23581605,\n",
       "  0.08146117,\n",
       "  -0.07360629,\n",
       "  0.010053525,\n",
       "  -0.1570465,\n",
       "  0.05893636,\n",
       "  -0.43347406,\n",
       "  -0.29988816,\n",
       "  -0.38750643,\n",
       "  0.11630442,\n",
       "  0.4076006,\n",
       "  -0.11116496,\n",
       "  -0.5895107,\n",
       "  -0.30112645,\n",
       "  0.12607984,\n",
       "  -0.50542897,\n",
       "  -0.50621367,\n",
       "  -0.05257991,\n",
       "  0.36381614,\n",
       "  0.48359028,\n",
       "  0.009068068,\n",
       "  -0.1037226,\n",
       "  -0.14019264,\n",
       "  -0.22712122,\n",
       "  0.22238414,\n",
       "  -0.23673415,\n",
       "  -0.52858406,\n",
       "  -0.082520664,\n",
       "  -0.64328784,\n",
       "  0.07511582,\n",
       "  0.025704032,\n",
       "  0.087670155,\n",
       "  0.24780649,\n",
       "  -0.016279507,\n",
       "  -0.3590073,\n",
       "  -0.10131879,\n",
       "  -0.18361373,\n",
       "  0.0076240837,\n",
       "  0.27633038,\n",
       "  -0.0457913,\n",
       "  -0.26547748,\n",
       "  -0.19359991,\n",
       "  -0.29667586,\n",
       "  -0.011849223,\n",
       "  0.24089475,\n",
       "  0.5367334,\n",
       "  0.49896395,\n",
       "  -0.1778388,\n",
       "  0.104832396,\n",
       "  -0.33011267,\n",
       "  0.023899216,\n",
       "  0.274117,\n",
       "  0.26732928,\n",
       "  -0.5667617,\n",
       "  0.22249904,\n",
       "  -0.04913922,\n",
       "  -0.08443253,\n",
       "  -0.41231185,\n",
       "  0.13548003,\n",
       "  -0.07725579,\n",
       "  0.04686722,\n",
       "  0.06639817,\n",
       "  -0.33215326,\n",
       "  0.30169103,\n",
       "  -0.07272943,\n",
       "  0.1863901,\n",
       "  -0.07663547,\n",
       "  -0.5121092,\n",
       "  0.19826397,\n",
       "  -0.11375352,\n",
       "  0.27143338,\n",
       "  -0.17112884,\n",
       "  0.5819404,\n",
       "  0.124582894,\n",
       "  0.010330212,\n",
       "  -0.35957506,\n",
       "  0.4807346,\n",
       "  0.5482508,\n",
       "  0.35470283,\n",
       "  0.26135433,\n",
       "  0.13992369,\n",
       "  0.080581106,\n",
       "  -0.035511628,\n",
       "  0.09636408,\n",
       "  0.3618881,\n",
       "  -0.12423327,\n",
       "  0.059601746,\n",
       "  0.20198628,\n",
       "  0.016974501],\n",
       " [0.34593743,\n",
       "  0.21537195,\n",
       "  0.15739398,\n",
       "  0.31333935,\n",
       "  0.059928536,\n",
       "  -0.3041606,\n",
       "  0.1271869,\n",
       "  0.6154905,\n",
       "  0.19516993,\n",
       "  -0.20141184,\n",
       "  -0.109520406,\n",
       "  -0.33669552,\n",
       "  -0.027278863,\n",
       "  0.14981516,\n",
       "  0.021332711,\n",
       "  -0.19578695,\n",
       "  0.023714421,\n",
       "  -0.40249196,\n",
       "  -0.13654901,\n",
       "  -0.23023622,\n",
       "  0.058145765,\n",
       "  0.30387622,\n",
       "  -0.062231947,\n",
       "  -0.25337324,\n",
       "  -0.24817634,\n",
       "  0.03346909,\n",
       "  -0.44411805,\n",
       "  -0.34508133,\n",
       "  -0.11900492,\n",
       "  0.14044908,\n",
       "  0.24673344,\n",
       "  0.0056615802,\n",
       "  -0.082545295,\n",
       "  -0.27736357,\n",
       "  -0.10532098,\n",
       "  0.20192242,\n",
       "  -0.044861518,\n",
       "  -0.48931697,\n",
       "  -0.11078552,\n",
       "  -0.5195694,\n",
       "  -0.053764064,\n",
       "  -0.1408488,\n",
       "  -0.09870716,\n",
       "  0.17178832,\n",
       "  0.06110489,\n",
       "  -0.31892395,\n",
       "  -0.10149162,\n",
       "  -0.1982956,\n",
       "  0.20773765,\n",
       "  0.2791425,\n",
       "  0.035413735,\n",
       "  -0.18506269,\n",
       "  -0.0055274693,\n",
       "  -0.21865651,\n",
       "  -0.030960351,\n",
       "  0.35196415,\n",
       "  0.4146714,\n",
       "  0.18379022,\n",
       "  -0.17145665,\n",
       "  0.15478659,\n",
       "  -0.22911952,\n",
       "  0.07798218,\n",
       "  0.05783111,\n",
       "  0.15648605,\n",
       "  -0.3624885,\n",
       "  0.3060372,\n",
       "  -0.15660332,\n",
       "  -0.010235376,\n",
       "  -0.4181661,\n",
       "  0.101853386,\n",
       "  -0.08186978,\n",
       "  0.009600183,\n",
       "  -0.0065916814,\n",
       "  -0.12665956,\n",
       "  0.23974493,\n",
       "  0.13453408,\n",
       "  -0.017577305,\n",
       "  -0.078438506,\n",
       "  -0.21575244,\n",
       "  0.04278849,\n",
       "  -0.082732834,\n",
       "  0.048620638,\n",
       "  -0.028408956,\n",
       "  0.30661395,\n",
       "  -0.14815395,\n",
       "  -0.027691457,\n",
       "  -0.10797289,\n",
       "  0.21507563,\n",
       "  0.37966806,\n",
       "  0.37185207,\n",
       "  0.15812306,\n",
       "  0.009115583,\n",
       "  0.011790512,\n",
       "  0.124385156,\n",
       "  0.027201615,\n",
       "  0.4409809,\n",
       "  -0.01845196,\n",
       "  0.009021837,\n",
       "  0.07812696,\n",
       "  0.032742884],\n",
       " [0.028660228,\n",
       "  0.14340007,\n",
       "  0.059338972,\n",
       "  0.18561883,\n",
       "  0.035840653,\n",
       "  -0.2648793,\n",
       "  0.048984013,\n",
       "  0.40148318,\n",
       "  0.005114114,\n",
       "  -0.042301632,\n",
       "  -0.17714283,\n",
       "  -0.18065675,\n",
       "  -0.07473701,\n",
       "  0.084273495,\n",
       "  -0.038249843,\n",
       "  -0.07536973,\n",
       "  0.013449009,\n",
       "  -0.1865567,\n",
       "  -0.0042678523,\n",
       "  -0.22742137,\n",
       "  0.061839618,\n",
       "  0.06122782,\n",
       "  0.025826177,\n",
       "  -0.102959275,\n",
       "  -0.050829593,\n",
       "  0.041478697,\n",
       "  -0.27603877,\n",
       "  -0.18341655,\n",
       "  -0.06667878,\n",
       "  0.04983847,\n",
       "  0.25609934,\n",
       "  0.07650541,\n",
       "  -0.018305542,\n",
       "  -0.050683048,\n",
       "  0.0074913353,\n",
       "  0.12800084,\n",
       "  0.034621328,\n",
       "  -0.17750655,\n",
       "  -0.058760595,\n",
       "  -0.2240345,\n",
       "  0.05167555,\n",
       "  -0.19374081,\n",
       "  -0.0035470887,\n",
       "  -0.0204894,\n",
       "  0.046303988,\n",
       "  -0.07000236,\n",
       "  -0.19087474,\n",
       "  0.049179282,\n",
       "  0.0672302,\n",
       "  0.12544475,\n",
       "  0.14064796,\n",
       "  -0.14869496,\n",
       "  -0.021912022,\n",
       "  -0.004935939,\n",
       "  -0.13393325,\n",
       "  0.12632222,\n",
       "  0.2174465,\n",
       "  0.014935608,\n",
       "  -0.10286237,\n",
       "  -0.0020524436,\n",
       "  0.01789142,\n",
       "  0.04750823,\n",
       "  -0.05624693,\n",
       "  0.15869959,\n",
       "  -0.1602969,\n",
       "  0.04303235,\n",
       "  -0.01812057,\n",
       "  0.09926088,\n",
       "  -0.18449199,\n",
       "  0.24643692,\n",
       "  -0.100167,\n",
       "  -0.013783076,\n",
       "  0.08554402,\n",
       "  -0.017906804,\n",
       "  0.12369772,\n",
       "  0.0487879,\n",
       "  -0.010353977,\n",
       "  -0.052647687,\n",
       "  0.0022768297,\n",
       "  0.017886095,\n",
       "  -0.092349656,\n",
       "  -0.054594565,\n",
       "  -0.12953423,\n",
       "  0.2176153,\n",
       "  -0.03997161,\n",
       "  0.049092125,\n",
       "  -0.13910131,\n",
       "  0.16982964,\n",
       "  0.30757347,\n",
       "  0.11853989,\n",
       "  0.12614487,\n",
       "  0.004478202,\n",
       "  -0.00095052656,\n",
       "  0.039954737,\n",
       "  0.15439531,\n",
       "  0.20539427,\n",
       "  0.010669358,\n",
       "  -0.17780659,\n",
       "  0.06742222,\n",
       "  0.07954127],\n",
       " [0.057969976,\n",
       "  0.1904689,\n",
       "  0.09487749,\n",
       "  0.39967793,\n",
       "  -0.11951348,\n",
       "  -0.46020567,\n",
       "  0.20134975,\n",
       "  0.5588508,\n",
       "  -0.6683124,\n",
       "  -0.042767987,\n",
       "  -0.19071265,\n",
       "  -0.2732179,\n",
       "  -0.05834989,\n",
       "  0.2302021,\n",
       "  -0.040990505,\n",
       "  0.24567729,\n",
       "  0.014796727,\n",
       "  -0.4551544,\n",
       "  -0.3839671,\n",
       "  -0.61773014,\n",
       "  0.1313618,\n",
       "  0.599234,\n",
       "  0.12465362,\n",
       "  -0.3115422,\n",
       "  -0.32512334,\n",
       "  0.35727873,\n",
       "  -0.768129,\n",
       "  0.18519737,\n",
       "  0.16111404,\n",
       "  0.15596385,\n",
       "  0.20596889,\n",
       "  0.41795427,\n",
       "  0.24468483,\n",
       "  0.24342623,\n",
       "  -0.15441316,\n",
       "  0.5189784,\n",
       "  -0.17831077,\n",
       "  -0.15393727,\n",
       "  -0.0179502,\n",
       "  -0.035251,\n",
       "  0.12978025,\n",
       "  -0.35024592,\n",
       "  0.100244366,\n",
       "  -0.13771085,\n",
       "  0.21131605,\n",
       "  -0.01805609,\n",
       "  -0.70885795,\n",
       "  0.4285746,\n",
       "  0.05061743,\n",
       "  0.20878516,\n",
       "  -0.23249896,\n",
       "  -0.23405737,\n",
       "  -0.12114941,\n",
       "  -0.03993212,\n",
       "  -0.30962378,\n",
       "  0.18526141,\n",
       "  0.6378923,\n",
       "  0.27863097,\n",
       "  -0.24722792,\n",
       "  0.24942319,\n",
       "  -0.035690665,\n",
       "  -0.12000186,\n",
       "  0.28341445,\n",
       "  0.56204695,\n",
       "  -0.44946596,\n",
       "  0.19308951,\n",
       "  -0.24822591,\n",
       "  0.3682716,\n",
       "  -0.30701327,\n",
       "  0.37765285,\n",
       "  -0.13470891,\n",
       "  0.08174311,\n",
       "  0.29523942,\n",
       "  -0.62399465,\n",
       "  0.43177217,\n",
       "  0.022386841,\n",
       "  0.2848787,\n",
       "  -0.049938165,\n",
       "  0.21858844,\n",
       "  0.06617284,\n",
       "  -0.54331803,\n",
       "  0.11007319,\n",
       "  -0.28982484,\n",
       "  0.3624753,\n",
       "  -0.024063854,\n",
       "  0.31319627,\n",
       "  -0.017770886,\n",
       "  0.4591303,\n",
       "  0.91566664,\n",
       "  0.36457947,\n",
       "  0.4252663,\n",
       "  0.33805734,\n",
       "  0.1436249,\n",
       "  0.32824582,\n",
       "  0.41670144,\n",
       "  0.406461,\n",
       "  0.26602027,\n",
       "  -0.20355818,\n",
       "  0.4088893,\n",
       "  0.33649945],\n",
       " [0.21463709,\n",
       "  0.2196619,\n",
       "  -0.07778517,\n",
       "  -0.0040535047,\n",
       "  0.3078828,\n",
       "  -0.5604403,\n",
       "  -0.28161946,\n",
       "  0.9120923,\n",
       "  0.08061011,\n",
       "  0.027635863,\n",
       "  -0.6711026,\n",
       "  -0.29940683,\n",
       "  -0.38418517,\n",
       "  0.19651747,\n",
       "  -0.53551954,\n",
       "  -0.3049314,\n",
       "  -0.09334834,\n",
       "  -0.12772913,\n",
       "  0.06799091,\n",
       "  -0.24466275,\n",
       "  0.69135135,\n",
       "  -0.15465778,\n",
       "  0.045928873,\n",
       "  -0.26961702,\n",
       "  -0.1984447,\n",
       "  0.19396198,\n",
       "  -0.70030266,\n",
       "  -0.6805291,\n",
       "  -0.5715267,\n",
       "  -0.5867751,\n",
       "  0.2918937,\n",
       "  -0.05852103,\n",
       "  0.11025741,\n",
       "  0.2192416,\n",
       "  0.5578918,\n",
       "  0.46371588,\n",
       "  -0.018871771,\n",
       "  -0.05074558,\n",
       "  -0.3303093,\n",
       "  -0.5132378,\n",
       "  -0.26025957,\n",
       "  0.24901474,\n",
       "  0.20011564,\n",
       "  -0.04515846,\n",
       "  -0.086695865,\n",
       "  -0.2861612,\n",
       "  -0.6354668,\n",
       "  0.08386756,\n",
       "  -0.28679696,\n",
       "  0.21267706,\n",
       "  -0.067820095,\n",
       "  -0.22289109,\n",
       "  0.07213567,\n",
       "  -0.091450304,\n",
       "  -0.20217413,\n",
       "  -0.15035674,\n",
       "  0.13385396,\n",
       "  -0.27755967,\n",
       "  -0.23293367,\n",
       "  -0.23498656,\n",
       "  -0.44717965,\n",
       "  0.5026199,\n",
       "  -0.4128951,\n",
       "  0.16475132,\n",
       "  -0.11624969,\n",
       "  -0.22107069,\n",
       "  -0.18666425,\n",
       "  0.40020296,\n",
       "  0.003235605,\n",
       "  0.19440114,\n",
       "  -0.4266267,\n",
       "  0.29488036,\n",
       "  0.47571862,\n",
       "  0.08146117,\n",
       "  0.38291377,\n",
       "  -0.38403797,\n",
       "  0.41863725,\n",
       "  -0.35197762,\n",
       "  -0.16579798,\n",
       "  0.16501045,\n",
       "  -0.06608437,\n",
       "  0.13160995,\n",
       "  -0.6131234,\n",
       "  0.60887766,\n",
       "  0.22298782,\n",
       "  0.13935453,\n",
       "  -0.6018267,\n",
       "  0.36854097,\n",
       "  -0.19273297,\n",
       "  0.29617932,\n",
       "  0.19233361,\n",
       "  -0.18548477,\n",
       "  0.13410586,\n",
       "  -0.38622046,\n",
       "  0.9669708,\n",
       "  0.35651973,\n",
       "  0.27088523,\n",
       "  -0.48684454,\n",
       "  0.04220569,\n",
       "  0.25253814],\n",
       " [0.3901705,\n",
       "  0.17813717,\n",
       "  -0.11569639,\n",
       "  0.18625233,\n",
       "  0.22285862,\n",
       "  -0.40116543,\n",
       "  -0.06870844,\n",
       "  0.849751,\n",
       "  0.17732367,\n",
       "  0.053057887,\n",
       "  -0.7110064,\n",
       "  -0.0989705,\n",
       "  -0.25302914,\n",
       "  0.2450327,\n",
       "  -0.4115294,\n",
       "  0.020008992,\n",
       "  -0.27341202,\n",
       "  -0.150001,\n",
       "  0.13874498,\n",
       "  -0.21029614,\n",
       "  0.4350333,\n",
       "  -0.015564965,\n",
       "  -0.28042996,\n",
       "  -0.2891532,\n",
       "  -0.018271029,\n",
       "  0.12255463,\n",
       "  -0.65072364,\n",
       "  -0.478308,\n",
       "  -0.24744377,\n",
       "  0.03717053,\n",
       "  0.4276894,\n",
       "  0.1303561,\n",
       "  -0.1293982,\n",
       "  -0.04563297,\n",
       "  0.097341344,\n",
       "  0.40795743,\n",
       "  0.048294716,\n",
       "  -0.12589164,\n",
       "  0.040681727,\n",
       "  -0.28696635,\n",
       "  -0.00036030807,\n",
       "  -0.07479202,\n",
       "  -0.2650323,\n",
       "  0.29769483,\n",
       "  -0.117836036,\n",
       "  -0.24991675,\n",
       "  -0.6169956,\n",
       "  0.055283476,\n",
       "  0.008521255,\n",
       "  0.17012653,\n",
       "  0.07481791,\n",
       "  -0.20097221,\n",
       "  0.33328813,\n",
       "  0.08440956,\n",
       "  0.047569867,\n",
       "  -0.085170284,\n",
       "  0.34565014,\n",
       "  -0.07623,\n",
       "  -0.108615965,\n",
       "  -0.10653742,\n",
       "  -0.016650146,\n",
       "  0.17713463,\n",
       "  -0.23106584,\n",
       "  0.15700747,\n",
       "  -0.0069735884,\n",
       "  -0.247506,\n",
       "  0.04249898,\n",
       "  0.32152557,\n",
       "  -0.00093828264,\n",
       "  0.36295888,\n",
       "  -0.29357192,\n",
       "  0.058517415,\n",
       "  0.17409602,\n",
       "  0.2068357,\n",
       "  0.22492908,\n",
       "  -0.107836224,\n",
       "  0.24687785,\n",
       "  -0.30615756,\n",
       "  0.062440116,\n",
       "  0.0035286641,\n",
       "  -0.12741855,\n",
       "  -0.039521214,\n",
       "  -0.18487504,\n",
       "  0.37675837,\n",
       "  -0.07850821,\n",
       "  -0.1651987,\n",
       "  -0.57838535,\n",
       "  0.12533726,\n",
       "  -0.19669616,\n",
       "  0.3699799,\n",
       "  0.30587125,\n",
       "  -0.13031268,\n",
       "  0.08265796,\n",
       "  -0.23478632,\n",
       "  0.4782004,\n",
       "  0.44562086,\n",
       "  0.24927126,\n",
       "  -0.15519305,\n",
       "  0.27595985,\n",
       "  -0.029892696],\n",
       " [0.20740636,\n",
       "  0.25440735,\n",
       "  0.22908117,\n",
       "  0.19828857,\n",
       "  0.22681187,\n",
       "  -0.687233,\n",
       "  0.18628001,\n",
       "  0.54328173,\n",
       "  -0.32111773,\n",
       "  -0.07221368,\n",
       "  -0.11230899,\n",
       "  -0.32221016,\n",
       "  -0.18213949,\n",
       "  0.28436968,\n",
       "  0.20214355,\n",
       "  0.22354521,\n",
       "  0.15490218,\n",
       "  -0.33081734,\n",
       "  -0.5271855,\n",
       "  -0.6963044,\n",
       "  0.33725742,\n",
       "  0.6363615,\n",
       "  0.07285317,\n",
       "  -0.14637215,\n",
       "  -0.2730971,\n",
       "  0.33194628,\n",
       "  -0.80387735,\n",
       "  0.21761096,\n",
       "  0.040526774,\n",
       "  0.14022857,\n",
       "  0.12303686,\n",
       "  0.275049,\n",
       "  -0.20754273,\n",
       "  -0.1465277,\n",
       "  0.06358552,\n",
       "  0.44323328,\n",
       "  -0.39435583,\n",
       "  -0.49208525,\n",
       "  -0.059100192,\n",
       "  -0.32126638,\n",
       "  -0.008018193,\n",
       "  -0.45820656,\n",
       "  0.1260923,\n",
       "  0.05632227,\n",
       "  0.3716176,\n",
       "  -0.100042045,\n",
       "  -0.8092087,\n",
       "  0.42686298,\n",
       "  0.29277623,\n",
       "  0.21809952,\n",
       "  -0.16813844,\n",
       "  -0.0463414,\n",
       "  0.25218672,\n",
       "  0.045581445,\n",
       "  -0.22154053,\n",
       "  0.26720753,\n",
       "  0.58038414,\n",
       "  0.27413094,\n",
       "  -0.08338155,\n",
       "  0.44680613,\n",
       "  -0.051484816,\n",
       "  0.052196745,\n",
       "  -0.06899826,\n",
       "  0.5886767,\n",
       "  -0.63522696,\n",
       "  0.25169197,\n",
       "  -0.21077172,\n",
       "  0.061065048,\n",
       "  -0.184654,\n",
       "  0.31839323,\n",
       "  -0.17113143,\n",
       "  0.07786546,\n",
       "  0.4346109,\n",
       "  -0.4120123,\n",
       "  0.6037512,\n",
       "  0.09893034,\n",
       "  0.28847936,\n",
       "  -0.15987144,\n",
       "  0.15069993,\n",
       "  0.022054955,\n",
       "  -0.4471223,\n",
       "  0.1139331,\n",
       "  -0.28494358,\n",
       "  0.38440397,\n",
       "  0.056272674,\n",
       "  0.2895078,\n",
       "  -0.133936,\n",
       "  0.4432064,\n",
       "  0.98078126,\n",
       "  0.36541942,\n",
       "  0.4739462,\n",
       "  0.20035365,\n",
       "  0.31059837,\n",
       "  0.09330561,\n",
       "  0.021181883,\n",
       "  0.43677276,\n",
       "  0.18468593,\n",
       "  -0.30164716,\n",
       "  0.32351157,\n",
       "  0.25229308],\n",
       " [0.21463709,\n",
       "  0.2196619,\n",
       "  -0.07778517,\n",
       "  -0.0040535047,\n",
       "  0.3078828,\n",
       "  -0.5604403,\n",
       "  -0.28161946,\n",
       "  0.9120923,\n",
       "  0.08061011,\n",
       "  0.027635863,\n",
       "  -0.6711026,\n",
       "  -0.29940683,\n",
       "  -0.38418517,\n",
       "  0.19651747,\n",
       "  -0.53551954,\n",
       "  -0.3049314,\n",
       "  -0.09334834,\n",
       "  -0.12772913,\n",
       "  0.06799091,\n",
       "  -0.24466275,\n",
       "  0.69135135,\n",
       "  -0.15465778,\n",
       "  0.045928873,\n",
       "  -0.26961702,\n",
       "  -0.1984447,\n",
       "  0.19396198,\n",
       "  -0.70030266,\n",
       "  -0.6805291,\n",
       "  -0.5715267,\n",
       "  -0.5867751,\n",
       "  0.2918937,\n",
       "  -0.05852103,\n",
       "  0.11025741,\n",
       "  0.2192416,\n",
       "  0.5578918,\n",
       "  0.46371588,\n",
       "  -0.018871771,\n",
       "  -0.05074558,\n",
       "  -0.3303093,\n",
       "  -0.5132378,\n",
       "  -0.26025957,\n",
       "  0.24901474,\n",
       "  0.20011564,\n",
       "  -0.04515846,\n",
       "  -0.086695865,\n",
       "  -0.2861612,\n",
       "  -0.6354668,\n",
       "  0.08386756,\n",
       "  -0.28679696,\n",
       "  0.21267706,\n",
       "  -0.067820095,\n",
       "  -0.22289109,\n",
       "  0.07213567,\n",
       "  -0.091450304,\n",
       "  -0.20217413,\n",
       "  -0.15035674,\n",
       "  0.13385396,\n",
       "  -0.27755967,\n",
       "  -0.23293367,\n",
       "  -0.23498656,\n",
       "  -0.44717965,\n",
       "  0.5026199,\n",
       "  -0.4128951,\n",
       "  0.16475132,\n",
       "  -0.11624969,\n",
       "  -0.22107069,\n",
       "  -0.18666425,\n",
       "  0.40020296,\n",
       "  0.003235605,\n",
       "  0.19440114,\n",
       "  -0.4266267,\n",
       "  0.29488036,\n",
       "  0.47571862,\n",
       "  0.08146117,\n",
       "  0.38291377,\n",
       "  -0.38403797,\n",
       "  0.41863725,\n",
       "  -0.35197762,\n",
       "  -0.16579798,\n",
       "  0.16501045,\n",
       "  -0.06608437,\n",
       "  0.13160995,\n",
       "  -0.6131234,\n",
       "  0.60887766,\n",
       "  0.22298782,\n",
       "  0.13935453,\n",
       "  -0.6018267,\n",
       "  0.36854097,\n",
       "  -0.19273297,\n",
       "  0.29617932,\n",
       "  0.19233361,\n",
       "  -0.18548477,\n",
       "  0.13410586,\n",
       "  -0.38622046,\n",
       "  0.9669708,\n",
       "  0.35651973,\n",
       "  0.27088523,\n",
       "  -0.48684454,\n",
       "  0.04220569,\n",
       "  0.25253814],\n",
       " [0.09030947,\n",
       "  0.25929788,\n",
       "  0.111323856,\n",
       "  0.08677317,\n",
       "  0.22525139,\n",
       "  -0.5979714,\n",
       "  -0.18647301,\n",
       "  0.69316375,\n",
       "  -0.24234495,\n",
       "  -0.1005751,\n",
       "  -0.37019327,\n",
       "  -0.47820202,\n",
       "  -0.09434984,\n",
       "  0.22800401,\n",
       "  -0.29316306,\n",
       "  0.0432272,\n",
       "  0.055627577,\n",
       "  -0.46028697,\n",
       "  -0.14581233,\n",
       "  -0.47407466,\n",
       "  0.19751565,\n",
       "  0.16393453,\n",
       "  0.14926691,\n",
       "  -0.30547407,\n",
       "  -0.11609981,\n",
       "  0.3396321,\n",
       "  -0.61740965,\n",
       "  -0.20098314,\n",
       "  -0.20489751,\n",
       "  -0.13600962,\n",
       "  0.21176375,\n",
       "  0.16789842,\n",
       "  -0.0010658107,\n",
       "  -0.029000478,\n",
       "  0.09609638,\n",
       "  0.31900907,\n",
       "  -0.005714733,\n",
       "  -0.1672282,\n",
       "  -0.15848485,\n",
       "  -0.34788752,\n",
       "  -0.0069948304,\n",
       "  -0.07365124,\n",
       "  0.030972006,\n",
       "  0.03094169,\n",
       "  -0.03232468,\n",
       "  -0.17442031,\n",
       "  -0.5910418,\n",
       "  0.15444621,\n",
       "  0.082965314,\n",
       "  0.29231924,\n",
       "  -0.16322957,\n",
       "  -0.15392834,\n",
       "  0.00352904,\n",
       "  -0.060879704,\n",
       "  -0.24220298,\n",
       "  0.1526474,\n",
       "  0.23736309,\n",
       "  -0.059142563,\n",
       "  -0.24629354,\n",
       "  0.17487624,\n",
       "  -0.14254394,\n",
       "  0.42345846,\n",
       "  -0.082864374,\n",
       "  0.5733951,\n",
       "  -0.35522696,\n",
       "  0.014138849,\n",
       "  -0.19009446,\n",
       "  0.19522637,\n",
       "  -0.22168133,\n",
       "  0.23109472,\n",
       "  -0.1710275,\n",
       "  0.024846235,\n",
       "  0.40219623,\n",
       "  -0.1109689,\n",
       "  0.5123515,\n",
       "  -0.10942549,\n",
       "  0.24447593,\n",
       "  -0.26147044,\n",
       "  0.07897226,\n",
       "  0.14376543,\n",
       "  -0.18793833,\n",
       "  0.11078327,\n",
       "  -0.17137446,\n",
       "  0.36851123,\n",
       "  -0.06722179,\n",
       "  0.21072108,\n",
       "  -0.35312536,\n",
       "  0.33794963,\n",
       "  0.32105178,\n",
       "  0.2262854,\n",
       "  0.4522138,\n",
       "  0.107509464,\n",
       "  0.28609025,\n",
       "  -0.054232698,\n",
       "  0.13430306,\n",
       "  0.3725042,\n",
       "  0.17710373,\n",
       "  -0.47987348,\n",
       "  0.19273262,\n",
       "  0.18352413],\n",
       " [-0.39124072,\n",
       "  0.1936843,\n",
       "  0.11564545,\n",
       "  0.16406454,\n",
       "  -0.014892592,\n",
       "  -0.528913,\n",
       "  0.10053913,\n",
       "  0.26067904,\n",
       "  -0.64614475,\n",
       "  -0.20258613,\n",
       "  -0.12589459,\n",
       "  -0.3462128,\n",
       "  -0.10158561,\n",
       "  0.4106507,\n",
       "  -0.074945174,\n",
       "  0.1723461,\n",
       "  0.22263654,\n",
       "  -0.19231452,\n",
       "  -0.2659831,\n",
       "  -0.8226204,\n",
       "  -0.012886615,\n",
       "  0.37436327,\n",
       "  0.36591402,\n",
       "  -0.047672287,\n",
       "  -0.039224498,\n",
       "  0.16773218,\n",
       "  -0.4084737,\n",
       "  0.17805415,\n",
       "  0.2323072,\n",
       "  -0.19725296,\n",
       "  0.21312925,\n",
       "  0.2449093,\n",
       "  -0.06819308,\n",
       "  0.20386271,\n",
       "  -0.023792628,\n",
       "  0.36234805,\n",
       "  0.055652127,\n",
       "  -0.16930035,\n",
       "  -0.16233498,\n",
       "  0.009772729,\n",
       "  0.15588512,\n",
       "  -0.5971532,\n",
       "  0.13797094,\n",
       "  -0.27518636,\n",
       "  0.24562408,\n",
       "  0.25354862,\n",
       "  -0.6791822,\n",
       "  0.3964061,\n",
       "  0.17074808,\n",
       "  0.2528215,\n",
       "  -0.14099962,\n",
       "  -0.018821483,\n",
       "  -0.013262598,\n",
       "  0.39776862,\n",
       "  -0.3306017,\n",
       "  -0.037618797,\n",
       "  0.6080164,\n",
       "  0.06375754,\n",
       "  -0.16302583,\n",
       "  0.1915315,\n",
       "  0.13533105,\n",
       "  -0.062023398,\n",
       "  0.047813825,\n",
       "  0.56559455,\n",
       "  -0.43625614,\n",
       "  0.051219136,\n",
       "  -0.042120513,\n",
       "  0.28562394,\n",
       "  -0.3121972,\n",
       "  0.35019782,\n",
       "  -0.10134993,\n",
       "  -0.043932706,\n",
       "  0.2756143,\n",
       "  -0.40892437,\n",
       "  0.3739624,\n",
       "  -0.1120402,\n",
       "  0.1602844,\n",
       "  0.048814774,\n",
       "  0.2779792,\n",
       "  0.22600716,\n",
       "  -0.5692482,\n",
       "  0.15730809,\n",
       "  -0.16222085,\n",
       "  0.48596418,\n",
       "  -0.06687841,\n",
       "  0.23114178,\n",
       "  -0.22262982,\n",
       "  0.38573617,\n",
       "  0.78966916,\n",
       "  0.34963953,\n",
       "  0.19080652,\n",
       "  0.36469325,\n",
       "  -0.08830451,\n",
       "  0.20836498,\n",
       "  0.21351093,\n",
       "  0.44773066,\n",
       "  0.18484154,\n",
       "  -0.4962131,\n",
       "  0.28658605,\n",
       "  0.5724581],\n",
       " [0.27458096,\n",
       "  0.26965153,\n",
       "  0.26796705,\n",
       "  0.15170242,\n",
       "  0.19374427,\n",
       "  -0.38889596,\n",
       "  0.02918923,\n",
       "  0.57469815,\n",
       "  0.16548595,\n",
       "  -0.038266793,\n",
       "  -0.22495979,\n",
       "  -0.27818227,\n",
       "  -0.22320567,\n",
       "  -0.009256049,\n",
       "  0.023956463,\n",
       "  0.0006753419,\n",
       "  0.12466836,\n",
       "  -0.42417362,\n",
       "  -0.14173985,\n",
       "  -0.33970186,\n",
       "  0.028464248,\n",
       "  0.15380934,\n",
       "  0.15672341,\n",
       "  -0.2451663,\n",
       "  -0.18179588,\n",
       "  0.26349753,\n",
       "  -0.48584884,\n",
       "  -0.276908,\n",
       "  -0.24360467,\n",
       "  0.10898264,\n",
       "  0.33348843,\n",
       "  0.075710945,\n",
       "  -0.14615284,\n",
       "  0.004961621,\n",
       "  0.16813597,\n",
       "  0.051693592,\n",
       "  -0.10650742,\n",
       "  -0.364261,\n",
       "  -0.26131585,\n",
       "  -0.3922751,\n",
       "  -0.37529898,\n",
       "  0.024804747,\n",
       "  0.16813846,\n",
       "  -0.100630425,\n",
       "  -0.028012916,\n",
       "  -0.24926089,\n",
       "  -0.14442943,\n",
       "  0.19504543,\n",
       "  -0.07772985,\n",
       "  0.4676423,\n",
       "  0.006259304,\n",
       "  -0.30597633,\n",
       "  -0.054758146,\n",
       "  -0.21257983,\n",
       "  -0.18077332,\n",
       "  0.29763803,\n",
       "  0.32008627,\n",
       "  0.29205513,\n",
       "  -0.29678947,\n",
       "  0.088145405,\n",
       "  -0.406807,\n",
       "  0.34814852,\n",
       "  -0.03172315,\n",
       "  0.3767015,\n",
       "  -0.5193743,\n",
       "  0.27123016,\n",
       "  -0.3387044,\n",
       "  0.22052741,\n",
       "  -0.13006008,\n",
       "  0.15994728,\n",
       "  -0.12582178,\n",
       "  -0.22067456,\n",
       "  0.11655301,\n",
       "  -0.12694766,\n",
       "  0.21267517,\n",
       "  0.04165474,\n",
       "  -0.017383244,\n",
       "  -0.032151997,\n",
       "  -0.27620462,\n",
       "  0.09607001,\n",
       "  0.010683797,\n",
       "  0.15056661,\n",
       "  -0.4104985,\n",
       "  0.2598609,\n",
       "  0.083585404,\n",
       "  0.019224988,\n",
       "  0.09015758,\n",
       "  0.37805235,\n",
       "  0.2556452,\n",
       "  0.32243213,\n",
       "  0.1656871,\n",
       "  -0.022584194,\n",
       "  0.22405845,\n",
       "  0.048452545,\n",
       "  0.28032732,\n",
       "  0.40460777,\n",
       "  0.15404107,\n",
       "  -0.24880032,\n",
       "  0.14296192,\n",
       "  -0.12776525],\n",
       " [0.21463709,\n",
       "  0.2196619,\n",
       "  -0.07778517,\n",
       "  -0.0040535047,\n",
       "  0.3078828,\n",
       "  -0.5604403,\n",
       "  -0.28161946,\n",
       "  0.9120923,\n",
       "  0.08061011,\n",
       "  0.027635863,\n",
       "  -0.6711026,\n",
       "  -0.29940683,\n",
       "  -0.38418517,\n",
       "  0.19651747,\n",
       "  -0.53551954,\n",
       "  -0.3049314,\n",
       "  -0.09334834,\n",
       "  -0.12772913,\n",
       "  0.06799091,\n",
       "  -0.24466275,\n",
       "  0.69135135,\n",
       "  -0.15465778,\n",
       "  0.045928873,\n",
       "  -0.26961702,\n",
       "  -0.1984447,\n",
       "  0.19396198,\n",
       "  -0.70030266,\n",
       "  -0.6805291,\n",
       "  -0.5715267,\n",
       "  -0.5867751,\n",
       "  0.2918937,\n",
       "  -0.05852103,\n",
       "  0.11025741,\n",
       "  0.2192416,\n",
       "  0.5578918,\n",
       "  0.46371588,\n",
       "  -0.018871771,\n",
       "  -0.05074558,\n",
       "  -0.3303093,\n",
       "  -0.5132378,\n",
       "  -0.26025957,\n",
       "  0.24901474,\n",
       "  0.20011564,\n",
       "  -0.04515846,\n",
       "  -0.086695865,\n",
       "  -0.2861612,\n",
       "  -0.6354668,\n",
       "  0.08386756,\n",
       "  -0.28679696,\n",
       "  0.21267706,\n",
       "  -0.067820095,\n",
       "  -0.22289109,\n",
       "  0.07213567,\n",
       "  -0.091450304,\n",
       "  -0.20217413,\n",
       "  -0.15035674,\n",
       "  0.13385396,\n",
       "  -0.27755967,\n",
       "  -0.23293367,\n",
       "  -0.23498656,\n",
       "  -0.44717965,\n",
       "  0.5026199,\n",
       "  -0.4128951,\n",
       "  0.16475132,\n",
       "  -0.11624969,\n",
       "  -0.22107069,\n",
       "  -0.18666425,\n",
       "  0.40020296,\n",
       "  0.003235605,\n",
       "  0.19440114,\n",
       "  -0.4266267,\n",
       "  0.29488036,\n",
       "  0.47571862,\n",
       "  0.08146117,\n",
       "  0.38291377,\n",
       "  -0.38403797,\n",
       "  0.41863725,\n",
       "  -0.35197762,\n",
       "  -0.16579798,\n",
       "  0.16501045,\n",
       "  -0.06608437,\n",
       "  0.13160995,\n",
       "  -0.6131234,\n",
       "  0.60887766,\n",
       "  0.22298782,\n",
       "  0.13935453,\n",
       "  -0.6018267,\n",
       "  0.36854097,\n",
       "  -0.19273297,\n",
       "  0.29617932,\n",
       "  0.19233361,\n",
       "  -0.18548477,\n",
       "  0.13410586,\n",
       "  -0.38622046,\n",
       "  0.9669708,\n",
       "  0.35651973,\n",
       "  0.27088523,\n",
       "  -0.48684454,\n",
       "  0.04220569,\n",
       "  0.25253814],\n",
       " [-0.046685938,\n",
       "  0.4575059,\n",
       "  0.0017052819,\n",
       "  0.13726176,\n",
       "  0.44131216,\n",
       "  -0.6931022,\n",
       "  -0.3849683,\n",
       "  0.7078772,\n",
       "  -0.13984346,\n",
       "  0.056917764,\n",
       "  -0.65903825,\n",
       "  -0.27418193,\n",
       "  -0.18958095,\n",
       "  0.26752624,\n",
       "  -0.37368673,\n",
       "  -0.2689412,\n",
       "  -0.23230217,\n",
       "  -0.36492375,\n",
       "  0.114109464,\n",
       "  -0.3289712,\n",
       "  0.47281137,\n",
       "  -0.0596498,\n",
       "  0.10327429,\n",
       "  -0.11789463,\n",
       "  -0.25360867,\n",
       "  0.31743062,\n",
       "  -0.5168973,\n",
       "  -0.42350292,\n",
       "  -0.41880715,\n",
       "  -0.26258683,\n",
       "  0.09967685,\n",
       "  -0.03706106,\n",
       "  0.09427812,\n",
       "  0.025156235,\n",
       "  0.3505149,\n",
       "  0.37683257,\n",
       "  -0.014427335,\n",
       "  0.14951293,\n",
       "  -0.11283498,\n",
       "  -0.33097884,\n",
       "  0.10255479,\n",
       "  -0.09575417,\n",
       "  -0.28567094,\n",
       "  0.2829835,\n",
       "  -0.1138821,\n",
       "  -0.3175528,\n",
       "  -0.76986873,\n",
       "  0.09845044,\n",
       "  0.1193075,\n",
       "  0.124547094,\n",
       "  0.060198713,\n",
       "  -0.27434772,\n",
       "  0.21015297,\n",
       "  0.10136375,\n",
       "  -0.27730843,\n",
       "  0.08158959,\n",
       "  0.11967779,\n",
       "  -0.2692519,\n",
       "  -0.10320745,\n",
       "  0.017587224,\n",
       "  0.04444958,\n",
       "  0.35673165,\n",
       "  -0.55448973,\n",
       "  0.28645605,\n",
       "  0.019648055,\n",
       "  0.0035945375,\n",
       "  0.09537828,\n",
       "  0.30315885,\n",
       "  -0.080214374,\n",
       "  0.39616227,\n",
       "  -0.35508373,\n",
       "  0.095767215,\n",
       "  0.48621744,\n",
       "  -0.013923611,\n",
       "  0.23273082,\n",
       "  -0.021826478,\n",
       "  0.27752954,\n",
       "  -0.21284094,\n",
       "  0.17089428,\n",
       "  -0.019181296,\n",
       "  0.013158073,\n",
       "  -0.041861553,\n",
       "  -0.21926944,\n",
       "  0.14249505,\n",
       "  -0.052688878,\n",
       "  0.10964675,\n",
       "  -0.64669967,\n",
       "  0.22191852,\n",
       "  0.31533796,\n",
       "  0.06068702,\n",
       "  0.47085792,\n",
       "  -0.14323306,\n",
       "  0.11374387,\n",
       "  -0.27347335,\n",
       "  0.26753932,\n",
       "  0.15238301,\n",
       "  0.254286,\n",
       "  -0.5310338,\n",
       "  0.12547305,\n",
       "  0.2695699],\n",
       " [0.266254,\n",
       "  0.22484101,\n",
       "  0.18175681,\n",
       "  0.19723444,\n",
       "  0.09121052,\n",
       "  -0.5158152,\n",
       "  -0.046399903,\n",
       "  0.52576023,\n",
       "  0.03458703,\n",
       "  -0.077857256,\n",
       "  -0.09808188,\n",
       "  -0.37532082,\n",
       "  -0.040559914,\n",
       "  0.2677124,\n",
       "  0.013043381,\n",
       "  0.13234632,\n",
       "  0.17092983,\n",
       "  -0.39533705,\n",
       "  -0.112924695,\n",
       "  -0.38775638,\n",
       "  0.10150461,\n",
       "  0.2614735,\n",
       "  0.05104101,\n",
       "  -0.28285322,\n",
       "  -0.26878443,\n",
       "  0.20647494,\n",
       "  -0.46243545,\n",
       "  -0.314558,\n",
       "  -0.039070416,\n",
       "  0.21441992,\n",
       "  0.2906303,\n",
       "  0.12687126,\n",
       "  0.07572774,\n",
       "  -0.13227996,\n",
       "  -0.0634966,\n",
       "  0.2231362,\n",
       "  -0.11050507,\n",
       "  -0.24840248,\n",
       "  -0.16278344,\n",
       "  -0.39016736,\n",
       "  -0.043866657,\n",
       "  -0.18791753,\n",
       "  -0.04734424,\n",
       "  0.05707771,\n",
       "  0.053653494,\n",
       "  -0.34282756,\n",
       "  -0.34178582,\n",
       "  -0.008404161,\n",
       "  0.35795146,\n",
       "  0.31466332,\n",
       "  -0.06502421,\n",
       "  -0.17926328,\n",
       "  0.04974626,\n",
       "  -0.06709944,\n",
       "  -0.053742435,\n",
       "  0.38548803,\n",
       "  0.28135258,\n",
       "  0.13567021,\n",
       "  -0.21257219,\n",
       "  0.36305317,\n",
       "  -0.22778052,\n",
       "  0.2369604,\n",
       "  -0.13403237,\n",
       "  0.44162732,\n",
       "  -0.39161012,\n",
       "  0.15189804,\n",
       "  -0.18517722,\n",
       "  0.117756836,\n",
       "  -0.26133853,\n",
       "  0.2573943,\n",
       "  -0.011395387,\n",
       "  -0.084570974,\n",
       "  0.2750546,\n",
       "  -0.15012953,\n",
       "  0.35102963,\n",
       "  0.10283956,\n",
       "  0.183756,\n",
       "  -0.16839087,\n",
       "  -0.10594841,\n",
       "  0.07939421,\n",
       "  -0.16844726,\n",
       "  0.10017643,\n",
       "  -0.06791028,\n",
       "  0.23010185,\n",
       "  0.02050844,\n",
       "  0.08306121,\n",
       "  -0.2125524,\n",
       "  0.2112636,\n",
       "  0.5566163,\n",
       "  0.27394116,\n",
       "  0.36348015,\n",
       "  -0.04152715,\n",
       "  0.15489222,\n",
       "  0.10499249,\n",
       "  -0.050870147,\n",
       "  0.44355813,\n",
       "  0.12575606,\n",
       "  -0.33631757,\n",
       "  0.16892211,\n",
       "  0.14375022],\n",
       " [-0.05775811,\n",
       "  0.7019635,\n",
       "  -0.05604874,\n",
       "  0.32778215,\n",
       "  0.43326685,\n",
       "  -0.39523706,\n",
       "  0.4623973,\n",
       "  0.9606976,\n",
       "  0.2450577,\n",
       "  -0.15433747,\n",
       "  -0.3538003,\n",
       "  -0.732626,\n",
       "  -0.28016582,\n",
       "  -0.17579605,\n",
       "  -0.14624578,\n",
       "  -0.3575222,\n",
       "  0.4963781,\n",
       "  -0.24960361,\n",
       "  0.40401885,\n",
       "  -0.09640059,\n",
       "  0.18088074,\n",
       "  -0.079353616,\n",
       "  -0.5792801,\n",
       "  0.08385807,\n",
       "  -0.37087965,\n",
       "  0.28507063,\n",
       "  -0.5063285,\n",
       "  -0.5732767,\n",
       "  0.19355828,\n",
       "  0.063896105,\n",
       "  0.08494957,\n",
       "  -0.0011073686,\n",
       "  0.17212994,\n",
       "  -0.39798585,\n",
       "  -0.2686235,\n",
       "  0.012802147,\n",
       "  0.4323491,\n",
       "  0.08379228,\n",
       "  0.05402553,\n",
       "  -0.07451934,\n",
       "  -0.019724239,\n",
       "  0.15950967,\n",
       "  -0.044904053,\n",
       "  0.020886512,\n",
       "  0.010320755,\n",
       "  -0.19537884,\n",
       "  -0.061794814,\n",
       "  -0.25432146,\n",
       "  0.040475465,\n",
       "  0.4175145,\n",
       "  0.43734917,\n",
       "  -0.2205044,\n",
       "  0.15994312,\n",
       "  -0.8627279,\n",
       "  0.15149362,\n",
       "  0.09845107,\n",
       "  0.14931834,\n",
       "  -0.49708253,\n",
       "  -0.15230043,\n",
       "  0.35415578,\n",
       "  -0.3938824,\n",
       "  -0.34764355,\n",
       "  -0.12647216,\n",
       "  0.23592354,\n",
       "  -0.46266744,\n",
       "  0.18136965,\n",
       "  0.117962964,\n",
       "  0.32535335,\n",
       "  -0.5074622,\n",
       "  0.378326,\n",
       "  -0.001953894,\n",
       "  -0.34138638,\n",
       "  0.19413497,\n",
       "  0.24431619,\n",
       "  0.11386738,\n",
       "  -0.34696743,\n",
       "  -0.11986377,\n",
       "  -0.15435441,\n",
       "  0.10993699,\n",
       "  -0.30077344,\n",
       "  -0.16656083,\n",
       "  -0.08856692,\n",
       "  -0.25307417,\n",
       "  0.30745885,\n",
       "  0.7296016,\n",
       "  0.049689688,\n",
       "  0.3820422,\n",
       "  0.3343086,\n",
       "  0.16577457,\n",
       "  -0.68912303,\n",
       "  0.871021,\n",
       "  -0.61563295,\n",
       "  -0.0698895,\n",
       "  0.48891342,\n",
       "  0.856273,\n",
       "  -0.01697067,\n",
       "  0.22022992,\n",
       "  0.1445011,\n",
       "  -0.18847418,\n",
       "  0.0281653],\n",
       " [0.21463709,\n",
       "  0.2196619,\n",
       "  -0.07778517,\n",
       "  -0.0040535047,\n",
       "  0.3078828,\n",
       "  -0.5604403,\n",
       "  -0.28161946,\n",
       "  0.9120923,\n",
       "  0.08061011,\n",
       "  0.027635863,\n",
       "  -0.6711026,\n",
       "  -0.29940683,\n",
       "  -0.38418517,\n",
       "  0.19651747,\n",
       "  -0.53551954,\n",
       "  -0.3049314,\n",
       "  -0.09334834,\n",
       "  -0.12772913,\n",
       "  0.06799091,\n",
       "  -0.24466275,\n",
       "  0.69135135,\n",
       "  -0.15465778,\n",
       "  0.045928873,\n",
       "  -0.26961702,\n",
       "  -0.1984447,\n",
       "  0.19396198,\n",
       "  -0.70030266,\n",
       "  -0.6805291,\n",
       "  -0.5715267,\n",
       "  -0.5867751,\n",
       "  0.2918937,\n",
       "  -0.05852103,\n",
       "  0.11025741,\n",
       "  0.2192416,\n",
       "  0.5578918,\n",
       "  0.46371588,\n",
       "  -0.018871771,\n",
       "  -0.05074558,\n",
       "  -0.3303093,\n",
       "  -0.5132378,\n",
       "  -0.26025957,\n",
       "  0.24901474,\n",
       "  0.20011564,\n",
       "  -0.04515846,\n",
       "  -0.086695865,\n",
       "  -0.2861612,\n",
       "  -0.6354668,\n",
       "  0.08386756,\n",
       "  -0.28679696,\n",
       "  0.21267706,\n",
       "  -0.067820095,\n",
       "  -0.22289109,\n",
       "  0.07213567,\n",
       "  -0.091450304,\n",
       "  -0.20217413,\n",
       "  -0.15035674,\n",
       "  0.13385396,\n",
       "  -0.27755967,\n",
       "  -0.23293367,\n",
       "  -0.23498656,\n",
       "  -0.44717965,\n",
       "  0.5026199,\n",
       "  -0.4128951,\n",
       "  0.16475132,\n",
       "  -0.11624969,\n",
       "  -0.22107069,\n",
       "  -0.18666425,\n",
       "  0.40020296,\n",
       "  0.003235605,\n",
       "  0.19440114,\n",
       "  -0.4266267,\n",
       "  0.29488036,\n",
       "  0.47571862,\n",
       "  0.08146117,\n",
       "  0.38291377,\n",
       "  -0.38403797,\n",
       "  0.41863725,\n",
       "  -0.35197762,\n",
       "  -0.16579798,\n",
       "  0.16501045,\n",
       "  -0.06608437,\n",
       "  0.13160995,\n",
       "  -0.6131234,\n",
       "  0.60887766,\n",
       "  0.22298782,\n",
       "  0.13935453,\n",
       "  -0.6018267,\n",
       "  0.36854097,\n",
       "  -0.19273297,\n",
       "  0.29617932,\n",
       "  0.19233361,\n",
       "  -0.18548477,\n",
       "  0.13410586,\n",
       "  -0.38622046,\n",
       "  0.9669708,\n",
       "  0.35651973,\n",
       "  0.27088523,\n",
       "  -0.48684454,\n",
       "  0.04220569,\n",
       "  0.25253814],\n",
       " [0.63325953,\n",
       "  0.07702482,\n",
       "  0.19029099,\n",
       "  0.45067367,\n",
       "  0.005134413,\n",
       "  -0.36164528,\n",
       "  0.28856906,\n",
       "  1.050663,\n",
       "  0.08407817,\n",
       "  -0.08039928,\n",
       "  -0.43491548,\n",
       "  -0.23581605,\n",
       "  0.08146117,\n",
       "  -0.07360629,\n",
       "  0.010053525,\n",
       "  -0.1570465,\n",
       "  0.05893636,\n",
       "  -0.43347406,\n",
       "  -0.29988816,\n",
       "  -0.38750643,\n",
       "  0.11630442,\n",
       "  0.4076006,\n",
       "  -0.11116496,\n",
       "  -0.5895107,\n",
       "  -0.30112645,\n",
       "  0.12607984,\n",
       "  -0.50542897,\n",
       "  -0.50621367,\n",
       "  -0.05257991,\n",
       "  0.36381614,\n",
       "  0.48359028,\n",
       "  0.009068068,\n",
       "  -0.1037226,\n",
       "  -0.14019264,\n",
       "  -0.22712122,\n",
       "  0.22238414,\n",
       "  -0.23673415,\n",
       "  -0.52858406,\n",
       "  -0.082520664,\n",
       "  -0.64328784,\n",
       "  0.07511582,\n",
       "  0.025704032,\n",
       "  0.087670155,\n",
       "  0.24780649,\n",
       "  -0.016279507,\n",
       "  -0.3590073,\n",
       "  -0.10131879,\n",
       "  -0.18361373,\n",
       "  0.0076240837,\n",
       "  0.27633038,\n",
       "  -0.0457913,\n",
       "  -0.26547748,\n",
       "  -0.19359991,\n",
       "  -0.29667586,\n",
       "  -0.011849223,\n",
       "  0.24089475,\n",
       "  0.5367334,\n",
       "  0.49896395,\n",
       "  -0.1778388,\n",
       "  0.104832396,\n",
       "  -0.33011267,\n",
       "  0.023899216,\n",
       "  0.274117,\n",
       "  0.26732928,\n",
       "  -0.5667617,\n",
       "  0.22249904,\n",
       "  -0.04913922,\n",
       "  -0.08443253,\n",
       "  -0.41231185,\n",
       "  0.13548003,\n",
       "  -0.07725579,\n",
       "  0.04686722,\n",
       "  0.06639817,\n",
       "  -0.33215326,\n",
       "  0.30169103,\n",
       "  -0.07272943,\n",
       "  0.1863901,\n",
       "  -0.07663547,\n",
       "  -0.5121092,\n",
       "  0.19826397,\n",
       "  -0.11375352,\n",
       "  0.27143338,\n",
       "  -0.17112884,\n",
       "  0.5819404,\n",
       "  0.124582894,\n",
       "  0.010330212,\n",
       "  -0.35957506,\n",
       "  0.4807346,\n",
       "  0.5482508,\n",
       "  0.35470283,\n",
       "  0.26135433,\n",
       "  0.13992369,\n",
       "  0.080581106,\n",
       "  -0.035511628,\n",
       "  0.09636408,\n",
       "  0.3618881,\n",
       "  -0.12423327,\n",
       "  0.059601746,\n",
       "  0.20198628,\n",
       "  0.016974501],\n",
       " [-0.1564684,\n",
       "  0.26373905,\n",
       "  -0.08488034,\n",
       "  0.35950112,\n",
       "  0.17797141,\n",
       "  -0.21623346,\n",
       "  0.23553407,\n",
       "  0.7536057,\n",
       "  0.0773868,\n",
       "  -0.018646197,\n",
       "  -0.5982124,\n",
       "  -0.10393995,\n",
       "  -0.17463978,\n",
       "  -0.036490064,\n",
       "  -0.31251615,\n",
       "  -0.41453466,\n",
       "  -0.27730817,\n",
       "  -0.3318316,\n",
       "  0.26271904,\n",
       "  -0.21298073,\n",
       "  0.027796036,\n",
       "  -0.075715825,\n",
       "  0.21843946,\n",
       "  -0.080501035,\n",
       "  -0.15813771,\n",
       "  -0.046197552,\n",
       "  -0.13411282,\n",
       "  -0.48821273,\n",
       "  -0.3903958,\n",
       "  0.041022018,\n",
       "  0.44462204,\n",
       "  -0.104254,\n",
       "  -0.06763,\n",
       "  -0.27788362,\n",
       "  0.1499865,\n",
       "  0.04243734,\n",
       "  0.10667127,\n",
       "  0.006579392,\n",
       "  -0.09589442,\n",
       "  -0.3530898,\n",
       "  0.2241617,\n",
       "  -0.37866956,\n",
       "  -0.3669845,\n",
       "  0.21587986,\n",
       "  0.04853199,\n",
       "  -0.21839064,\n",
       "  -0.12975389,\n",
       "  -0.0029936626,\n",
       "  0.10567446,\n",
       "  0.073502325,\n",
       "  0.27340916,\n",
       "  -0.3774172,\n",
       "  0.21557595,\n",
       "  -0.038534548,\n",
       "  -0.37558544,\n",
       "  0.015186433,\n",
       "  0.17780736,\n",
       "  -0.3079905,\n",
       "  -0.30481005,\n",
       "  -0.39153415,\n",
       "  0.3692019,\n",
       "  -0.1873312,\n",
       "  -0.053216472,\n",
       "  -0.091712795,\n",
       "  -0.30351552,\n",
       "  0.10441986,\n",
       "  0.24023253,\n",
       "  0.20070949,\n",
       "  -0.39034995,\n",
       "  0.29436168,\n",
       "  -0.24166398,\n",
       "  0.1664636,\n",
       "  0.042308107,\n",
       "  0.2941962,\n",
       "  0.17905301,\n",
       "  0.1368759,\n",
       "  -0.23878351,\n",
       "  -0.025593683,\n",
       "  -0.08786185,\n",
       "  -0.17747085,\n",
       "  0.012439368,\n",
       "  -0.35328117,\n",
       "  0.057786778,\n",
       "  0.08403295,\n",
       "  -0.27345517,\n",
       "  -0.28438085,\n",
       "  -0.17398532,\n",
       "  0.35736302,\n",
       "  0.24220617,\n",
       "  0.08312482,\n",
       "  0.16560416,\n",
       "  0.04893569,\n",
       "  -0.2263996,\n",
       "  0.00016675747,\n",
       "  0.36342576,\n",
       "  0.28238985,\n",
       "  -0.055232815,\n",
       "  -0.18871953,\n",
       "  0.037370667,\n",
       "  0.058865733],\n",
       " [0.21463709,\n",
       "  0.2196619,\n",
       "  -0.07778517,\n",
       "  -0.0040535047,\n",
       "  0.3078828,\n",
       "  -0.5604403,\n",
       "  -0.28161946,\n",
       "  0.9120923,\n",
       "  0.08061011,\n",
       "  0.027635863,\n",
       "  -0.6711026,\n",
       "  -0.29940683,\n",
       "  -0.38418517,\n",
       "  0.19651747,\n",
       "  -0.53551954,\n",
       "  -0.3049314,\n",
       "  -0.09334834,\n",
       "  -0.12772913,\n",
       "  0.06799091,\n",
       "  -0.24466275,\n",
       "  0.69135135,\n",
       "  -0.15465778,\n",
       "  0.045928873,\n",
       "  -0.26961702,\n",
       "  -0.1984447,\n",
       "  0.19396198,\n",
       "  -0.70030266,\n",
       "  -0.6805291,\n",
       "  -0.5715267,\n",
       "  -0.5867751,\n",
       "  0.2918937,\n",
       "  -0.05852103,\n",
       "  0.11025741,\n",
       "  0.2192416,\n",
       "  0.5578918,\n",
       "  0.46371588,\n",
       "  -0.018871771,\n",
       "  -0.05074558,\n",
       "  -0.3303093,\n",
       "  -0.5132378,\n",
       "  -0.26025957,\n",
       "  0.24901474,\n",
       "  0.20011564,\n",
       "  -0.04515846,\n",
       "  -0.086695865,\n",
       "  -0.2861612,\n",
       "  -0.6354668,\n",
       "  0.08386756,\n",
       "  -0.28679696,\n",
       "  0.21267706,\n",
       "  -0.067820095,\n",
       "  -0.22289109,\n",
       "  0.07213567,\n",
       "  -0.091450304,\n",
       "  -0.20217413,\n",
       "  -0.15035674,\n",
       "  0.13385396,\n",
       "  -0.27755967,\n",
       "  -0.23293367,\n",
       "  -0.23498656,\n",
       "  -0.44717965,\n",
       "  0.5026199,\n",
       "  -0.4128951,\n",
       "  0.16475132,\n",
       "  -0.11624969,\n",
       "  -0.22107069,\n",
       "  -0.18666425,\n",
       "  0.40020296,\n",
       "  0.003235605,\n",
       "  0.19440114,\n",
       "  -0.4266267,\n",
       "  0.29488036,\n",
       "  0.47571862,\n",
       "  0.08146117,\n",
       "  0.38291377,\n",
       "  -0.38403797,\n",
       "  0.41863725,\n",
       "  -0.35197762,\n",
       "  -0.16579798,\n",
       "  0.16501045,\n",
       "  -0.06608437,\n",
       "  0.13160995,\n",
       "  -0.6131234,\n",
       "  0.60887766,\n",
       "  0.22298782,\n",
       "  0.13935453,\n",
       "  -0.6018267,\n",
       "  0.36854097,\n",
       "  -0.19273297,\n",
       "  0.29617932,\n",
       "  0.19233361,\n",
       "  -0.18548477,\n",
       "  0.13410586,\n",
       "  -0.38622046,\n",
       "  0.9669708,\n",
       "  0.35651973,\n",
       "  0.27088523,\n",
       "  -0.48684454,\n",
       "  0.04220569,\n",
       "  0.25253814],\n",
       " [-0.046685938,\n",
       "  0.4575059,\n",
       "  0.0017052819,\n",
       "  0.13726176,\n",
       "  0.44131216,\n",
       "  -0.6931022,\n",
       "  -0.3849683,\n",
       "  0.7078772,\n",
       "  -0.13984346,\n",
       "  0.056917764,\n",
       "  -0.65903825,\n",
       "  -0.27418193,\n",
       "  -0.18958095,\n",
       "  0.26752624,\n",
       "  -0.37368673,\n",
       "  -0.2689412,\n",
       "  -0.23230217,\n",
       "  -0.36492375,\n",
       "  0.114109464,\n",
       "  -0.3289712,\n",
       "  0.47281137,\n",
       "  -0.0596498,\n",
       "  0.10327429,\n",
       "  -0.11789463,\n",
       "  -0.25360867,\n",
       "  0.31743062,\n",
       "  -0.5168973,\n",
       "  -0.42350292,\n",
       "  -0.41880715,\n",
       "  -0.26258683,\n",
       "  0.09967685,\n",
       "  -0.03706106,\n",
       "  0.09427812,\n",
       "  0.025156235,\n",
       "  0.3505149,\n",
       "  0.37683257,\n",
       "  -0.014427335,\n",
       "  0.14951293,\n",
       "  -0.11283498,\n",
       "  -0.33097884,\n",
       "  0.10255479,\n",
       "  -0.09575417,\n",
       "  -0.28567094,\n",
       "  0.2829835,\n",
       "  -0.1138821,\n",
       "  -0.3175528,\n",
       "  -0.76986873,\n",
       "  0.09845044,\n",
       "  0.1193075,\n",
       "  0.124547094,\n",
       "  0.060198713,\n",
       "  -0.27434772,\n",
       "  0.21015297,\n",
       "  0.10136375,\n",
       "  -0.27730843,\n",
       "  0.08158959,\n",
       "  0.11967779,\n",
       "  -0.2692519,\n",
       "  -0.10320745,\n",
       "  0.017587224,\n",
       "  0.04444958,\n",
       "  0.35673165,\n",
       "  -0.55448973,\n",
       "  0.28645605,\n",
       "  0.019648055,\n",
       "  0.0035945375,\n",
       "  0.09537828,\n",
       "  0.30315885,\n",
       "  -0.080214374,\n",
       "  0.39616227,\n",
       "  -0.35508373,\n",
       "  0.095767215,\n",
       "  0.48621744,\n",
       "  -0.013923611,\n",
       "  0.23273082,\n",
       "  -0.021826478,\n",
       "  0.27752954,\n",
       "  -0.21284094,\n",
       "  0.17089428,\n",
       "  -0.019181296,\n",
       "  0.013158073,\n",
       "  -0.041861553,\n",
       "  -0.21926944,\n",
       "  0.14249505,\n",
       "  -0.052688878,\n",
       "  0.10964675,\n",
       "  -0.64669967,\n",
       "  0.22191852,\n",
       "  0.31533796,\n",
       "  0.06068702,\n",
       "  0.47085792,\n",
       "  -0.14323306,\n",
       "  0.11374387,\n",
       "  -0.27347335,\n",
       "  0.26753932,\n",
       "  0.15238301,\n",
       "  0.254286,\n",
       "  -0.5310338,\n",
       "  0.12547305,\n",
       "  0.2695699],\n",
       " [0.13477582,\n",
       "  0.3234223,\n",
       "  0.051736,\n",
       "  0.21321617,\n",
       "  -0.20612636,\n",
       "  -0.23754385,\n",
       "  -0.15087508,\n",
       "  0.45428368,\n",
       "  -0.036799297,\n",
       "  0.26266107,\n",
       "  -0.37136683,\n",
       "  -0.17388234,\n",
       "  -0.20793259,\n",
       "  -0.17141515,\n",
       "  -0.12644613,\n",
       "  -0.39025187,\n",
       "  -0.21735123,\n",
       "  -0.31521046,\n",
       "  0.14875726,\n",
       "  -0.38024625,\n",
       "  0.4612119,\n",
       "  -0.048996944,\n",
       "  0.034742408,\n",
       "  -0.016580917,\n",
       "  -0.25235367,\n",
       "  -0.16586775,\n",
       "  -0.6211634,\n",
       "  -0.4114721,\n",
       "  -0.19497745,\n",
       "  0.20356467,\n",
       "  0.00790897,\n",
       "  0.10398826,\n",
       "  0.30515745,\n",
       "  -0.2990686,\n",
       "  0.2481546,\n",
       "  -0.014406709,\n",
       "  -0.22032127,\n",
       "  0.10017637,\n",
       "  0.23666455,\n",
       "  -0.17531328,\n",
       "  0.28240994,\n",
       "  -0.28711724,\n",
       "  0.0554655,\n",
       "  0.32817805,\n",
       "  0.14904994,\n",
       "  -0.12650883,\n",
       "  -0.4413847,\n",
       "  -0.22621605,\n",
       "  0.39650035,\n",
       "  0.19919908,\n",
       "  0.15630014,\n",
       "  -0.21780305,\n",
       "  0.055054743,\n",
       "  -0.26933286,\n",
       "  -0.12757306,\n",
       "  0.509236,\n",
       "  0.21283348,\n",
       "  -0.026081674,\n",
       "  -0.2585135,\n",
       "  0.12660916,\n",
       "  -0.33951113,\n",
       "  0.38076314,\n",
       "  -0.14844273,\n",
       "  0.24909714,\n",
       "  -0.32454938,\n",
       "  0.050077505,\n",
       "  0.18830208,\n",
       "  0.34549046,\n",
       "  -0.36068645,\n",
       "  0.41181874,\n",
       "  -0.085450634,\n",
       "  -0.12946747,\n",
       "  0.0967988,\n",
       "  0.1824189,\n",
       "  0.11484149,\n",
       "  0.25830588,\n",
       "  0.05892156,\n",
       "  -0.14636268,\n",
       "  -0.036282033,\n",
       "  -0.018833539,\n",
       "  -0.5516776,\n",
       "  -0.27961892,\n",
       "  -0.16161728,\n",
       "  0.0631119,\n",
       "  0.1240344,\n",
       "  0.39465415,\n",
       "  -0.23339882,\n",
       "  0.47135183,\n",
       "  0.73237014,\n",
       "  0.017588852,\n",
       "  0.44627416,\n",
       "  -0.1004326,\n",
       "  -0.0484402,\n",
       "  -0.14909332,\n",
       "  0.12401783,\n",
       "  0.38544655,\n",
       "  -0.16107944,\n",
       "  -0.34941193,\n",
       "  0.18014811,\n",
       "  0.17098695],\n",
       " [0.029849399,\n",
       "  0.19517148,\n",
       "  0.074076205,\n",
       "  0.20388342,\n",
       "  0.051046666,\n",
       "  -0.2968277,\n",
       "  0.022557098,\n",
       "  0.4699976,\n",
       "  0.08455485,\n",
       "  -0.0014880521,\n",
       "  -0.23683102,\n",
       "  -0.21627475,\n",
       "  -0.07952194,\n",
       "  0.037347816,\n",
       "  -0.053053312,\n",
       "  -0.12435282,\n",
       "  0.000318716,\n",
       "  -0.22547989,\n",
       "  0.04797019,\n",
       "  -0.18704575,\n",
       "  0.097245015,\n",
       "  0.03252486,\n",
       "  0.022851096,\n",
       "  -0.12360375,\n",
       "  -0.07852719,\n",
       "  0.026525969,\n",
       "  -0.29035935,\n",
       "  -0.28612942,\n",
       "  -0.11907991,\n",
       "  0.057965025,\n",
       "  0.27437958,\n",
       "  0.03797787,\n",
       "  -0.011236473,\n",
       "  -0.06624003,\n",
       "  0.035680022,\n",
       "  0.08560797,\n",
       "  0.03166613,\n",
       "  -0.15284687,\n",
       "  -0.081654586,\n",
       "  -0.25720966,\n",
       "  0.02198235,\n",
       "  -0.15813388,\n",
       "  -0.028912451,\n",
       "  0.032674037,\n",
       "  0.04572483,\n",
       "  -0.13786048,\n",
       "  -0.15375863,\n",
       "  0.010192098,\n",
       "  0.08584707,\n",
       "  0.16633195,\n",
       "  0.15055516,\n",
       "  -0.21299854,\n",
       "  -0.026353562,\n",
       "  -0.071360484,\n",
       "  -0.13571271,\n",
       "  0.16925368,\n",
       "  0.1895205,\n",
       "  0.0013494444,\n",
       "  -0.14410275,\n",
       "  0.022004517,\n",
       "  -0.04485315,\n",
       "  0.10985709,\n",
       "  -0.10065389,\n",
       "  0.1509449,\n",
       "  -0.20693679,\n",
       "  0.052598815,\n",
       "  -0.005076487,\n",
       "  0.16133437,\n",
       "  -0.1905021,\n",
       "  0.2730529,\n",
       "  -0.1052613,\n",
       "  -0.030362755,\n",
       "  0.11089316,\n",
       "  0.018217409,\n",
       "  0.14040755,\n",
       "  0.0901788,\n",
       "  -0.013803726,\n",
       "  -0.09764351,\n",
       "  -0.07105882,\n",
       "  -0.016048457,\n",
       "  -0.08653791,\n",
       "  -0.037067946,\n",
       "  -0.13537548,\n",
       "  0.20825449,\n",
       "  0.011923655,\n",
       "  0.016050413,\n",
       "  -0.1408903,\n",
       "  0.16551451,\n",
       "  0.30682015,\n",
       "  0.13243036,\n",
       "  0.1744289,\n",
       "  -0.023629664,\n",
       "  0.020580549,\n",
       "  0.021213617,\n",
       "  0.20466372,\n",
       "  0.24371584,\n",
       "  0.019803023,\n",
       "  -0.22022901,\n",
       "  0.076398745,\n",
       "  0.035295412],\n",
       " [-0.082463235,\n",
       "  0.06490985,\n",
       "  0.06348815,\n",
       "  0.38498482,\n",
       "  0.20396428,\n",
       "  -0.17980534,\n",
       "  0.40412107,\n",
       "  0.73995936,\n",
       "  0.15229015,\n",
       "  -0.09407867,\n",
       "  -0.34782678,\n",
       "  -0.42360115,\n",
       "  0.070412755,\n",
       "  -0.04622153,\n",
       "  -0.14859253,\n",
       "  -0.1505846,\n",
       "  0.007935036,\n",
       "  -0.2654112,\n",
       "  0.13985771,\n",
       "  -0.28179023,\n",
       "  0.06981374,\n",
       "  -0.008028393,\n",
       "  0.1269165,\n",
       "  -0.2609345,\n",
       "  -0.28503427,\n",
       "  -0.08353286,\n",
       "  -0.32128614,\n",
       "  -0.500081,\n",
       "  -0.20825651,\n",
       "  0.07096725,\n",
       "  0.3791345,\n",
       "  -0.24072479,\n",
       "  -0.07187372,\n",
       "  -0.08715303,\n",
       "  0.07142076,\n",
       "  0.007638765,\n",
       "  -0.014653978,\n",
       "  -0.18015422,\n",
       "  -0.31882048,\n",
       "  -0.4501295,\n",
       "  0.08078897,\n",
       "  -0.2581104,\n",
       "  -0.1644884,\n",
       "  0.22456717,\n",
       "  0.08104171,\n",
       "  -0.36992308,\n",
       "  0.13669083,\n",
       "  -0.25819048,\n",
       "  0.14412372,\n",
       "  0.13479413,\n",
       "  0.02834375,\n",
       "  -0.39794064,\n",
       "  0.15227908,\n",
       "  -0.31565532,\n",
       "  -0.24756746,\n",
       "  0.10026783,\n",
       "  0.07430659,\n",
       "  -0.20522031,\n",
       "  -0.2506857,\n",
       "  0.10073316,\n",
       "  -0.4097684,\n",
       "  -0.08955543,\n",
       "  0.29922852,\n",
       "  -0.032141887,\n",
       "  -0.69807106,\n",
       "  0.1883784,\n",
       "  -0.09866033,\n",
       "  0.3727447,\n",
       "  -0.42398536,\n",
       "  0.10684148,\n",
       "  -0.005587304,\n",
       "  0.05811186,\n",
       "  0.11052103,\n",
       "  0.16442637,\n",
       "  0.2782723,\n",
       "  0.095354155,\n",
       "  -0.0993445,\n",
       "  0.01974666,\n",
       "  -0.44566947,\n",
       "  -0.09800174,\n",
       "  -0.14635956,\n",
       "  -0.13650033,\n",
       "  -0.11104078,\n",
       "  0.15936323,\n",
       "  0.06427263,\n",
       "  -0.14316225,\n",
       "  0.1136574,\n",
       "  0.39006674,\n",
       "  0.38965666,\n",
       "  0.22579005,\n",
       "  0.27800444,\n",
       "  0.09014343,\n",
       "  0.07991291,\n",
       "  0.23516433,\n",
       "  0.5881447,\n",
       "  0.31193715,\n",
       "  -0.06698463,\n",
       "  -0.19042324,\n",
       "  0.20530339,\n",
       "  -0.1300792],\n",
       " [-0.05775811,\n",
       "  0.7019635,\n",
       "  -0.05604874,\n",
       "  0.32778215,\n",
       "  0.43326685,\n",
       "  -0.39523706,\n",
       "  0.4623973,\n",
       "  0.9606976,\n",
       "  0.2450577,\n",
       "  -0.15433747,\n",
       "  -0.3538003,\n",
       "  -0.732626,\n",
       "  -0.28016582,\n",
       "  -0.17579605,\n",
       "  -0.14624578,\n",
       "  -0.3575222,\n",
       "  0.4963781,\n",
       "  -0.24960361,\n",
       "  0.40401885,\n",
       "  -0.09640059,\n",
       "  0.18088074,\n",
       "  -0.079353616,\n",
       "  -0.5792801,\n",
       "  0.08385807,\n",
       "  -0.37087965,\n",
       "  0.28507063,\n",
       "  -0.5063285,\n",
       "  -0.5732767,\n",
       "  0.19355828,\n",
       "  0.063896105,\n",
       "  0.08494957,\n",
       "  -0.0011073686,\n",
       "  0.17212994,\n",
       "  -0.39798585,\n",
       "  -0.2686235,\n",
       "  0.012802147,\n",
       "  0.4323491,\n",
       "  0.08379228,\n",
       "  0.05402553,\n",
       "  -0.07451934,\n",
       "  -0.019724239,\n",
       "  0.15950967,\n",
       "  -0.044904053,\n",
       "  0.020886512,\n",
       "  0.010320755,\n",
       "  -0.19537884,\n",
       "  -0.061794814,\n",
       "  -0.25432146,\n",
       "  0.040475465,\n",
       "  0.4175145,\n",
       "  0.43734917,\n",
       "  -0.2205044,\n",
       "  0.15994312,\n",
       "  -0.8627279,\n",
       "  0.15149362,\n",
       "  0.09845107,\n",
       "  0.14931834,\n",
       "  -0.49708253,\n",
       "  -0.15230043,\n",
       "  0.35415578,\n",
       "  -0.3938824,\n",
       "  -0.34764355,\n",
       "  -0.12647216,\n",
       "  0.23592354,\n",
       "  -0.46266744,\n",
       "  0.18136965,\n",
       "  0.117962964,\n",
       "  0.32535335,\n",
       "  -0.5074622,\n",
       "  0.378326,\n",
       "  -0.001953894,\n",
       "  -0.34138638,\n",
       "  0.19413497,\n",
       "  0.24431619,\n",
       "  0.11386738,\n",
       "  -0.34696743,\n",
       "  -0.11986377,\n",
       "  -0.15435441,\n",
       "  0.10993699,\n",
       "  -0.30077344,\n",
       "  -0.16656083,\n",
       "  -0.08856692,\n",
       "  -0.25307417,\n",
       "  0.30745885,\n",
       "  0.7296016,\n",
       "  0.049689688,\n",
       "  0.3820422,\n",
       "  0.3343086,\n",
       "  0.16577457,\n",
       "  -0.68912303,\n",
       "  0.871021,\n",
       "  -0.61563295,\n",
       "  -0.0698895,\n",
       "  0.48891342,\n",
       "  0.856273,\n",
       "  -0.01697067,\n",
       "  0.22022992,\n",
       "  0.1445011,\n",
       "  -0.18847418,\n",
       "  0.0281653],\n",
       " [0.21463709,\n",
       "  0.2196619,\n",
       "  -0.07778517,\n",
       "  -0.0040535047,\n",
       "  0.3078828,\n",
       "  -0.5604403,\n",
       "  -0.28161946,\n",
       "  0.9120923,\n",
       "  0.08061011,\n",
       "  0.027635863,\n",
       "  -0.6711026,\n",
       "  -0.29940683,\n",
       "  -0.38418517,\n",
       "  0.19651747,\n",
       "  -0.53551954,\n",
       "  -0.3049314,\n",
       "  -0.09334834,\n",
       "  -0.12772913,\n",
       "  0.06799091,\n",
       "  -0.24466275,\n",
       "  0.69135135,\n",
       "  -0.15465778,\n",
       "  0.045928873,\n",
       "  -0.26961702,\n",
       "  -0.1984447,\n",
       "  0.19396198,\n",
       "  -0.70030266,\n",
       "  -0.6805291,\n",
       "  -0.5715267,\n",
       "  -0.5867751,\n",
       "  0.2918937,\n",
       "  -0.05852103,\n",
       "  0.11025741,\n",
       "  0.2192416,\n",
       "  0.5578918,\n",
       "  0.46371588,\n",
       "  -0.018871771,\n",
       "  -0.05074558,\n",
       "  -0.3303093,\n",
       "  -0.5132378,\n",
       "  -0.26025957,\n",
       "  0.24901474,\n",
       "  0.20011564,\n",
       "  -0.04515846,\n",
       "  -0.086695865,\n",
       "  -0.2861612,\n",
       "  -0.6354668,\n",
       "  0.08386756,\n",
       "  -0.28679696,\n",
       "  0.21267706,\n",
       "  -0.067820095,\n",
       "  -0.22289109,\n",
       "  0.07213567,\n",
       "  -0.091450304,\n",
       "  -0.20217413,\n",
       "  -0.15035674,\n",
       "  0.13385396,\n",
       "  -0.27755967,\n",
       "  -0.23293367,\n",
       "  -0.23498656,\n",
       "  -0.44717965,\n",
       "  0.5026199,\n",
       "  -0.4128951,\n",
       "  0.16475132,\n",
       "  -0.11624969,\n",
       "  -0.22107069,\n",
       "  -0.18666425,\n",
       "  0.40020296,\n",
       "  0.003235605,\n",
       "  0.19440114,\n",
       "  -0.4266267,\n",
       "  0.29488036,\n",
       "  0.47571862,\n",
       "  0.08146117,\n",
       "  0.38291377,\n",
       "  -0.38403797,\n",
       "  0.41863725,\n",
       "  -0.35197762,\n",
       "  -0.16579798,\n",
       "  0.16501045,\n",
       "  -0.06608437,\n",
       "  0.13160995,\n",
       "  -0.6131234,\n",
       "  0.60887766,\n",
       "  0.22298782,\n",
       "  0.13935453,\n",
       "  -0.6018267,\n",
       "  0.36854097,\n",
       "  -0.19273297,\n",
       "  0.29617932,\n",
       "  0.19233361,\n",
       "  -0.18548477,\n",
       "  0.13410586,\n",
       "  -0.38622046,\n",
       "  0.9669708,\n",
       "  0.35651973,\n",
       "  0.27088523,\n",
       "  -0.48684454,\n",
       "  0.04220569,\n",
       "  0.25253814],\n",
       " [-0.09069662,\n",
       "  0.091049105,\n",
       "  0.11556381,\n",
       "  0.17124584,\n",
       "  -0.1165955,\n",
       "  -0.30081218,\n",
       "  0.354961,\n",
       "  0.41752774,\n",
       "  0.2939936,\n",
       "  0.11014941,\n",
       "  -0.022932805,\n",
       "  -0.29171896,\n",
       "  0.07988367,\n",
       "  -0.053922575,\n",
       "  0.122576244,\n",
       "  -0.2132168,\n",
       "  0.1543524,\n",
       "  -0.0043597184,\n",
       "  -0.15666713,\n",
       "  -0.28176093,\n",
       "  -0.03180798,\n",
       "  0.015391121,\n",
       "  0.1003483,\n",
       "  -0.52603626,\n",
       "  0.074003994,\n",
       "  0.19963852,\n",
       "  -0.20597368,\n",
       "  -0.4699977,\n",
       "  -0.10047403,\n",
       "  0.14274564,\n",
       "  0.5701333,\n",
       "  0.20510575,\n",
       "  0.15745513,\n",
       "  0.46013615,\n",
       "  -0.0034427815,\n",
       "  0.21028191,\n",
       "  0.06846715,\n",
       "  -0.18404652,\n",
       "  -0.077215485,\n",
       "  -0.19907352,\n",
       "  -0.28971222,\n",
       "  -0.04677515,\n",
       "  0.23741445,\n",
       "  -0.23822038,\n",
       "  0.066138454,\n",
       "  -0.03669194,\n",
       "  0.40072352,\n",
       "  -0.14659938,\n",
       "  0.010992445,\n",
       "  0.29989666,\n",
       "  0.1794105,\n",
       "  -0.3088565,\n",
       "  -0.3406068,\n",
       "  -0.0037964599,\n",
       "  -0.10475945,\n",
       "  0.18181156,\n",
       "  0.39743835,\n",
       "  0.05719744,\n",
       "  -0.19020587,\n",
       "  0.06698596,\n",
       "  -0.040478718,\n",
       "  0.21251546,\n",
       "  -0.037200462,\n",
       "  -0.0049083657,\n",
       "  -0.2836326,\n",
       "  -0.19488928,\n",
       "  -0.31563535,\n",
       "  0.30319557,\n",
       "  0.10563656,\n",
       "  0.41014516,\n",
       "  -0.08853798,\n",
       "  -0.40864915,\n",
       "  0.37676534,\n",
       "  -0.11605679,\n",
       "  0.0072712633,\n",
       "  0.23047379,\n",
       "  0.048808973,\n",
       "  -0.2768887,\n",
       "  -0.26644066,\n",
       "  0.06196686,\n",
       "  0.11425802,\n",
       "  -0.0035750421,\n",
       "  -0.65427417,\n",
       "  0.45237273,\n",
       "  -0.09138225,\n",
       "  0.064337775,\n",
       "  0.05108018,\n",
       "  0.051104933,\n",
       "  0.13783704,\n",
       "  0.38733116,\n",
       "  -0.040193763,\n",
       "  -0.004034043,\n",
       "  0.08327865,\n",
       "  0.0678514,\n",
       "  0.5038766,\n",
       "  0.4123403,\n",
       "  0.13785446,\n",
       "  -0.39961115,\n",
       "  -0.31454235,\n",
       "  -0.1814661],\n",
       " [-0.19747548,\n",
       "  0.44635332,\n",
       "  0.039430883,\n",
       "  0.21978547,\n",
       "  -0.07270557,\n",
       "  -0.31553844,\n",
       "  0.5827015,\n",
       "  0.5394491,\n",
       "  0.2580675,\n",
       "  -0.31589353,\n",
       "  -0.13737181,\n",
       "  -0.08803931,\n",
       "  0.075259,\n",
       "  -0.051218666,\n",
       "  0.19658424,\n",
       "  -0.12750217,\n",
       "  0.23024935,\n",
       "  -0.06796468,\n",
       "  -0.22358061,\n",
       "  -0.32557285,\n",
       "  -0.17094441,\n",
       "  0.09747073,\n",
       "  -0.02016853,\n",
       "  -0.33111978,\n",
       "  0.3135409,\n",
       "  -0.10332385,\n",
       "  -0.33558103,\n",
       "  -0.4529718,\n",
       "  -0.06885772,\n",
       "  0.30437246,\n",
       "  0.71495944,\n",
       "  0.030927593,\n",
       "  -0.1153174,\n",
       "  0.066233866,\n",
       "  -0.28237048,\n",
       "  0.21420228,\n",
       "  0.18860464,\n",
       "  -0.2627016,\n",
       "  0.15411298,\n",
       "  -0.2799594,\n",
       "  -0.31168267,\n",
       "  -0.18530075,\n",
       "  -0.07749236,\n",
       "  -0.25535673,\n",
       "  0.10637335,\n",
       "  -0.07351732,\n",
       "  0.28798023,\n",
       "  -0.08675951,\n",
       "  -0.14574626,\n",
       "  0.59296185,\n",
       "  0.13276589,\n",
       "  -0.23639855,\n",
       "  -0.395602,\n",
       "  -0.07972432,\n",
       "  0.011615442,\n",
       "  0.12318837,\n",
       "  0.5907126,\n",
       "  0.1872772,\n",
       "  -0.27118403,\n",
       "  -0.02659379,\n",
       "  0.016771138,\n",
       "  0.08968666,\n",
       "  0.025699917,\n",
       "  -0.09154835,\n",
       "  -0.22653735,\n",
       "  -0.095576055,\n",
       "  0.10340584,\n",
       "  0.18246533,\n",
       "  -0.1491388,\n",
       "  0.58507675,\n",
       "  0.08441934,\n",
       "  -0.3563632,\n",
       "  0.058942292,\n",
       "  0.04453088,\n",
       "  0.10418907,\n",
       "  0.3894291,\n",
       "  -0.15392505,\n",
       "  -0.14188112,\n",
       "  -0.1347467,\n",
       "  -0.31355283,\n",
       "  0.097520255,\n",
       "  0.042989027,\n",
       "  -0.14292455,\n",
       "  0.44245404,\n",
       "  0.28494957,\n",
       "  -0.3156383,\n",
       "  0.0629241,\n",
       "  -0.13813648,\n",
       "  0.0016389913,\n",
       "  0.34304434,\n",
       "  -0.20813696,\n",
       "  0.1484263,\n",
       "  0.08244332,\n",
       "  0.14668648,\n",
       "  0.5167026,\n",
       "  0.23937418,\n",
       "  0.11435399,\n",
       "  -0.41628876,\n",
       "  -0.025001787,\n",
       "  -0.3980782],\n",
       " [0.042387772,\n",
       "  0.17044564,\n",
       "  0.09754384,\n",
       "  0.16903462,\n",
       "  0.12570255,\n",
       "  -0.36967853,\n",
       "  0.16771713,\n",
       "  0.6514417,\n",
       "  0.084467195,\n",
       "  -0.094593056,\n",
       "  -0.18916814,\n",
       "  -0.28353763,\n",
       "  -0.07010775,\n",
       "  -0.010482442,\n",
       "  0.048929468,\n",
       "  -0.073511444,\n",
       "  0.22139233,\n",
       "  -0.2739946,\n",
       "  -0.20677663,\n",
       "  -0.30370075,\n",
       "  0.061632417,\n",
       "  0.19011275,\n",
       "  -0.013060421,\n",
       "  -0.332456,\n",
       "  -0.15148155,\n",
       "  0.07756403,\n",
       "  -0.43369725,\n",
       "  -0.36963,\n",
       "  -0.12373378,\n",
       "  -0.01941526,\n",
       "  0.4521295,\n",
       "  0.01259622,\n",
       "  -0.12486879,\n",
       "  -0.023613753,\n",
       "  -0.0495633,\n",
       "  0.15006717,\n",
       "  0.04400009,\n",
       "  -0.30979574,\n",
       "  -0.093042664,\n",
       "  -0.3342686,\n",
       "  -0.15554911,\n",
       "  -0.012570175,\n",
       "  0.03345139,\n",
       "  -0.021113116,\n",
       "  0.10226446,\n",
       "  -0.12375226,\n",
       "  0.049167927,\n",
       "  0.042392734,\n",
       "  0.021441145,\n",
       "  0.3045489,\n",
       "  0.0063699516,\n",
       "  -0.1661591,\n",
       "  -0.10423379,\n",
       "  -0.09933882,\n",
       "  -0.1589649,\n",
       "  0.21327251,\n",
       "  0.30797404,\n",
       "  0.11184638,\n",
       "  -0.1963382,\n",
       "  0.15299888,\n",
       "  -0.22013913,\n",
       "  0.21530683,\n",
       "  0.05115122,\n",
       "  0.23008391,\n",
       "  -0.4599995,\n",
       "  0.1190485,\n",
       "  -0.16573364,\n",
       "  0.10590615,\n",
       "  -0.16661133,\n",
       "  0.19662899,\n",
       "  -0.07009055,\n",
       "  -0.010813442,\n",
       "  0.18482174,\n",
       "  0.017102206,\n",
       "  0.3951742,\n",
       "  0.05716265,\n",
       "  0.056439113,\n",
       "  -0.18647836,\n",
       "  -0.30172217,\n",
       "  -0.017266965,\n",
       "  -0.045299258,\n",
       "  0.040870536,\n",
       "  -0.2040332,\n",
       "  0.31312308,\n",
       "  0.20604381,\n",
       "  0.008805485,\n",
       "  -0.05352608,\n",
       "  0.2046091,\n",
       "  0.28642488,\n",
       "  0.2817455,\n",
       "  0.10671941,\n",
       "  0.13522649,\n",
       "  0.24192035,\n",
       "  0.0145941535,\n",
       "  0.35574114,\n",
       "  0.3515255,\n",
       "  0.067456536,\n",
       "  -0.28957453,\n",
       "  0.099210076,\n",
       "  -0.16525543],\n",
       " [0.27458096,\n",
       "  0.26965153,\n",
       "  0.26796705,\n",
       "  0.15170242,\n",
       "  0.19374427,\n",
       "  -0.38889596,\n",
       "  0.02918923,\n",
       "  0.57469815,\n",
       "  0.16548595,\n",
       "  -0.038266793,\n",
       "  -0.22495979,\n",
       "  -0.27818227,\n",
       "  -0.22320567,\n",
       "  -0.009256049,\n",
       "  0.023956463,\n",
       "  0.0006753419,\n",
       "  0.12466836,\n",
       "  -0.42417362,\n",
       "  -0.14173985,\n",
       "  -0.33970186,\n",
       "  0.028464248,\n",
       "  0.15380934,\n",
       "  0.15672341,\n",
       "  -0.2451663,\n",
       "  -0.18179588,\n",
       "  0.26349753,\n",
       "  -0.48584884,\n",
       "  -0.276908,\n",
       "  -0.24360467,\n",
       "  0.10898264,\n",
       "  0.33348843,\n",
       "  0.075710945,\n",
       "  -0.14615284,\n",
       "  0.004961621,\n",
       "  0.16813597,\n",
       "  0.051693592,\n",
       "  -0.10650742,\n",
       "  -0.364261,\n",
       "  -0.26131585,\n",
       "  -0.3922751,\n",
       "  -0.37529898,\n",
       "  0.024804747,\n",
       "  0.16813846,\n",
       "  -0.100630425,\n",
       "  -0.028012916,\n",
       "  -0.24926089,\n",
       "  -0.14442943,\n",
       "  0.19504543,\n",
       "  -0.07772985,\n",
       "  0.4676423,\n",
       "  0.006259304,\n",
       "  -0.30597633,\n",
       "  -0.054758146,\n",
       "  -0.21257983,\n",
       "  -0.18077332,\n",
       "  0.29763803,\n",
       "  0.32008627,\n",
       "  0.29205513,\n",
       "  -0.29678947,\n",
       "  0.088145405,\n",
       "  -0.406807,\n",
       "  0.34814852,\n",
       "  -0.03172315,\n",
       "  0.3767015,\n",
       "  -0.5193743,\n",
       "  0.27123016,\n",
       "  -0.3387044,\n",
       "  0.22052741,\n",
       "  -0.13006008,\n",
       "  0.15994728,\n",
       "  -0.12582178,\n",
       "  -0.22067456,\n",
       "  0.11655301,\n",
       "  -0.12694766,\n",
       "  0.21267517,\n",
       "  0.04165474,\n",
       "  -0.017383244,\n",
       "  -0.032151997,\n",
       "  -0.27620462,\n",
       "  0.09607001,\n",
       "  0.010683797,\n",
       "  0.15056661,\n",
       "  -0.4104985,\n",
       "  0.2598609,\n",
       "  0.083585404,\n",
       "  0.019224988,\n",
       "  0.09015758,\n",
       "  0.37805235,\n",
       "  0.2556452,\n",
       "  0.32243213,\n",
       "  0.1656871,\n",
       "  -0.022584194,\n",
       "  0.22405845,\n",
       "  0.048452545,\n",
       "  0.28032732,\n",
       "  0.40460777,\n",
       "  0.15404107,\n",
       "  -0.24880032,\n",
       "  0.14296192,\n",
       "  -0.12776525],\n",
       " [-0.030416496,\n",
       "  0.25461662,\n",
       "  0.08412249,\n",
       "  0.2251566,\n",
       "  0.13660562,\n",
       "  -0.2978187,\n",
       "  0.33257028,\n",
       "  0.5956279,\n",
       "  0.21282022,\n",
       "  -0.12780985,\n",
       "  -0.3453265,\n",
       "  -0.2866808,\n",
       "  -0.07832878,\n",
       "  0.040760286,\n",
       "  -0.047876447,\n",
       "  -0.028308949,\n",
       "  -0.2137154,\n",
       "  -0.40337744,\n",
       "  -0.021238122,\n",
       "  -0.43178603,\n",
       "  0.10117211,\n",
       "  0.008815487,\n",
       "  0.29306373,\n",
       "  -0.22598432,\n",
       "  -0.054777656,\n",
       "  0.1287468,\n",
       "  -0.40848017,\n",
       "  -0.23158301,\n",
       "  -0.2036948,\n",
       "  0.096580155,\n",
       "  0.27075619,\n",
       "  -0.035678882,\n",
       "  -0.26036742,\n",
       "  -0.055125363,\n",
       "  0.07660276,\n",
       "  0.20690733,\n",
       "  0.31792322,\n",
       "  0.17754737,\n",
       "  0.059836503,\n",
       "  -0.043718293,\n",
       "  -0.12330553,\n",
       "  -0.16588037,\n",
       "  0.06734737,\n",
       "  0.015345916,\n",
       "  0.09264228,\n",
       "  -0.047026817,\n",
       "  -0.09939629,\n",
       "  0.10433791,\n",
       "  -0.04187977,\n",
       "  0.5173472,\n",
       "  -0.08759972,\n",
       "  -0.25058475,\n",
       "  0.15820953,\n",
       "  -0.5599331,\n",
       "  -0.086242646,\n",
       "  0.016272506,\n",
       "  0.42237407,\n",
       "  -0.061323464,\n",
       "  -0.31328326,\n",
       "  -0.06066331,\n",
       "  -0.29935136,\n",
       "  0.027777536,\n",
       "  0.17042965,\n",
       "  0.1085337,\n",
       "  -0.5574638,\n",
       "  0.008360956,\n",
       "  -0.08370574,\n",
       "  0.4294804,\n",
       "  -0.23940635,\n",
       "  0.18921128,\n",
       "  0.0060572373,\n",
       "  -0.23993127,\n",
       "  -0.08014752,\n",
       "  0.18781574,\n",
       "  0.38701183,\n",
       "  0.14132552,\n",
       "  -0.015044878,\n",
       "  0.12672901,\n",
       "  0.03283627,\n",
       "  -0.13742462,\n",
       "  -0.14905122,\n",
       "  -0.35530123,\n",
       "  -0.08492057,\n",
       "  0.048198346,\n",
       "  0.14128837,\n",
       "  -0.00044679304,\n",
       "  0.14813153,\n",
       "  0.20809536,\n",
       "  0.21814972,\n",
       "  0.06588103,\n",
       "  0.22908604,\n",
       "  0.03679661,\n",
       "  0.21988676,\n",
       "  0.14360332,\n",
       "  0.32610506,\n",
       "  0.33175534,\n",
       "  0.122698374,\n",
       "  -0.45113528,\n",
       "  0.050432317,\n",
       "  -0.20691943],\n",
       " [0.09926237,\n",
       "  0.13215788,\n",
       "  -0.089510456,\n",
       "  0.323871,\n",
       "  -0.03681083,\n",
       "  -0.18557225,\n",
       "  0.3541478,\n",
       "  0.62202424,\n",
       "  0.12862588,\n",
       "  -0.045671307,\n",
       "  -0.16180071,\n",
       "  -0.2768666,\n",
       "  -0.019029304,\n",
       "  0.09961787,\n",
       "  -0.086401455,\n",
       "  -0.15894032,\n",
       "  -0.17582943,\n",
       "  -0.37954834,\n",
       "  0.10681827,\n",
       "  -0.30993387,\n",
       "  -0.008402058,\n",
       "  0.064210676,\n",
       "  0.3328601,\n",
       "  -0.20108412,\n",
       "  -0.15670967,\n",
       "  -0.001620136,\n",
       "  -0.2729228,\n",
       "  -0.4066002,\n",
       "  0.0062211608,\n",
       "  0.24553414,\n",
       "  0.2702564,\n",
       "  0.038945332,\n",
       "  -0.022738935,\n",
       "  -0.2996013,\n",
       "  -0.005236988,\n",
       "  0.10330839,\n",
       "  0.107512966,\n",
       "  -0.11023054,\n",
       "  -0.013580322,\n",
       "  -0.047147196,\n",
       "  0.20865546,\n",
       "  -0.3430551,\n",
       "  -0.24920376,\n",
       "  0.09256762,\n",
       "  0.22188435,\n",
       "  -0.25073716,\n",
       "  -0.003265002,\n",
       "  -0.16416548,\n",
       "  0.34136432,\n",
       "  0.1386341,\n",
       "  0.114783116,\n",
       "  -0.32606003,\n",
       "  0.13448212,\n",
       "  -0.29522976,\n",
       "  -0.18612772,\n",
       "  0.07584345,\n",
       "  0.2663345,\n",
       "  -0.1167951,\n",
       "  -0.482127,\n",
       "  -0.0909004,\n",
       "  0.09662182,\n",
       "  -0.33400926,\n",
       "  0.168689,\n",
       "  0.18863937,\n",
       "  -0.42336774,\n",
       "  0.20866051,\n",
       "  0.002455075,\n",
       "  0.35929865,\n",
       "  -0.46228588,\n",
       "  0.25092936,\n",
       "  0.010982016,\n",
       "  0.05152227,\n",
       "  -0.06451315,\n",
       "  0.09509258,\n",
       "  0.10376344,\n",
       "  0.25828123,\n",
       "  -0.12553772,\n",
       "  -0.012244807,\n",
       "  -0.009286651,\n",
       "  0.014539272,\n",
       "  -0.15702447,\n",
       "  -0.29079616,\n",
       "  -0.0027854631,\n",
       "  0.1647144,\n",
       "  -0.16526683,\n",
       "  -0.27619478,\n",
       "  -0.018885259,\n",
       "  0.35074744,\n",
       "  0.28960246,\n",
       "  0.22495282,\n",
       "  0.26775223,\n",
       "  -0.11637213,\n",
       "  -0.20054471,\n",
       "  0.24322236,\n",
       "  0.21443808,\n",
       "  0.4468625,\n",
       "  -0.07336236,\n",
       "  -0.05644153,\n",
       "  0.04162162,\n",
       "  0.06340397],\n",
       " [-0.2112699,\n",
       "  0.051888082,\n",
       "  -0.0694377,\n",
       "  0.17191716,\n",
       "  0.042820834,\n",
       "  -0.14575976,\n",
       "  0.24165292,\n",
       "  0.6449612,\n",
       "  0.19505775,\n",
       "  -0.3805583,\n",
       "  -0.20583396,\n",
       "  -0.34817383,\n",
       "  -0.035498634,\n",
       "  0.19315644,\n",
       "  -0.09425183,\n",
       "  -0.27510884,\n",
       "  0.12601781,\n",
       "  -0.21312526,\n",
       "  0.042894255,\n",
       "  -0.47736531,\n",
       "  0.16083592,\n",
       "  -0.041868772,\n",
       "  0.41384792,\n",
       "  0.002002267,\n",
       "  -0.04058733,\n",
       "  -0.02192963,\n",
       "  -0.08703978,\n",
       "  -0.107885435,\n",
       "  -0.18040226,\n",
       "  0.14562832,\n",
       "  0.4478351,\n",
       "  -0.074599616,\n",
       "  -0.14975356,\n",
       "  0.14685991,\n",
       "  -0.0039042314,\n",
       "  0.14397903,\n",
       "  -0.02675846,\n",
       "  -0.16272421,\n",
       "  -0.46644378,\n",
       "  -0.57155776,\n",
       "  -0.04500823,\n",
       "  -0.10033569,\n",
       "  0.053199958,\n",
       "  -0.12174605,\n",
       "  0.29999956,\n",
       "  -0.040983047,\n",
       "  0.15787429,\n",
       "  -0.104995385,\n",
       "  0.1981651,\n",
       "  0.14427437,\n",
       "  0.00047093298,\n",
       "  -0.24865973,\n",
       "  0.003537501,\n",
       "  -0.16844882,\n",
       "  -0.39226952,\n",
       "  -0.09398212,\n",
       "  -0.003312042,\n",
       "  -0.26834622,\n",
       "  -0.3871856,\n",
       "  -0.12052855,\n",
       "  0.09678957,\n",
       "  -0.06659383,\n",
       "  0.24308944,\n",
       "  0.10306065,\n",
       "  -0.6806316,\n",
       "  0.045656215,\n",
       "  -0.11325812,\n",
       "  0.21016113,\n",
       "  -0.5799629,\n",
       "  0.17829002,\n",
       "  0.09347346,\n",
       "  0.011521899,\n",
       "  0.12558548,\n",
       "  0.34705043,\n",
       "  0.32342327,\n",
       "  -0.051044013,\n",
       "  -0.08310266,\n",
       "  -0.041012373,\n",
       "  -0.28932664,\n",
       "  -0.0076279794,\n",
       "  -0.034677442,\n",
       "  0.23617351,\n",
       "  -0.027476672,\n",
       "  0.20923743,\n",
       "  0.29377824,\n",
       "  -0.23919933,\n",
       "  0.3247793,\n",
       "  0.33137718,\n",
       "  0.09551556,\n",
       "  0.13772279,\n",
       "  0.056872535,\n",
       "  0.21196288,\n",
       "  -0.22072726,\n",
       "  0.122996636,\n",
       "  0.57250166,\n",
       "  0.32066837,\n",
       "  -0.09615256,\n",
       "  -0.3404994,\n",
       "  0.11683802,\n",
       "  0.18034147],\n",
       " [0.21463709,\n",
       "  0.2196619,\n",
       "  -0.07778517,\n",
       "  -0.0040535047,\n",
       "  0.3078828,\n",
       "  -0.5604403,\n",
       "  -0.28161946,\n",
       "  0.9120923,\n",
       "  0.08061011,\n",
       "  0.027635863,\n",
       "  -0.6711026,\n",
       "  -0.29940683,\n",
       "  -0.38418517,\n",
       "  0.19651747,\n",
       "  -0.53551954,\n",
       "  -0.3049314,\n",
       "  -0.09334834,\n",
       "  -0.12772913,\n",
       "  0.06799091,\n",
       "  -0.24466275,\n",
       "  0.69135135,\n",
       "  -0.15465778,\n",
       "  0.045928873,\n",
       "  -0.26961702,\n",
       "  -0.1984447,\n",
       "  0.19396198,\n",
       "  -0.70030266,\n",
       "  -0.6805291,\n",
       "  -0.5715267,\n",
       "  -0.5867751,\n",
       "  0.2918937,\n",
       "  -0.05852103,\n",
       "  0.11025741,\n",
       "  0.2192416,\n",
       "  0.5578918,\n",
       "  0.46371588,\n",
       "  -0.018871771,\n",
       "  -0.05074558,\n",
       "  -0.3303093,\n",
       "  -0.5132378,\n",
       "  -0.26025957,\n",
       "  0.24901474,\n",
       "  0.20011564,\n",
       "  -0.04515846,\n",
       "  -0.086695865,\n",
       "  -0.2861612,\n",
       "  -0.6354668,\n",
       "  0.08386756,\n",
       "  -0.28679696,\n",
       "  0.21267706,\n",
       "  -0.067820095,\n",
       "  -0.22289109,\n",
       "  0.07213567,\n",
       "  -0.091450304,\n",
       "  -0.20217413,\n",
       "  -0.15035674,\n",
       "  0.13385396,\n",
       "  -0.27755967,\n",
       "  -0.23293367,\n",
       "  -0.23498656,\n",
       "  -0.44717965,\n",
       "  0.5026199,\n",
       "  -0.4128951,\n",
       "  0.16475132,\n",
       "  -0.11624969,\n",
       "  -0.22107069,\n",
       "  -0.18666425,\n",
       "  0.40020296,\n",
       "  0.003235605,\n",
       "  0.19440114,\n",
       "  -0.4266267,\n",
       "  0.29488036,\n",
       "  0.47571862,\n",
       "  0.08146117,\n",
       "  0.38291377,\n",
       "  -0.38403797,\n",
       "  0.41863725,\n",
       "  -0.35197762,\n",
       "  -0.16579798,\n",
       "  0.16501045,\n",
       "  -0.06608437,\n",
       "  0.13160995,\n",
       "  -0.6131234,\n",
       "  0.60887766,\n",
       "  0.22298782,\n",
       "  0.13935453,\n",
       "  -0.6018267,\n",
       "  0.36854097,\n",
       "  -0.19273297,\n",
       "  0.29617932,\n",
       "  0.19233361,\n",
       "  -0.18548477,\n",
       "  0.13410586,\n",
       "  -0.38622046,\n",
       "  0.9669708,\n",
       "  0.35651973,\n",
       "  0.27088523,\n",
       "  -0.48684454,\n",
       "  0.04220569,\n",
       "  0.25253814],\n",
       " [0.63325953,\n",
       "  0.07702482,\n",
       "  0.19029099,\n",
       "  0.45067367,\n",
       "  0.005134413,\n",
       "  -0.36164528,\n",
       "  0.28856906,\n",
       "  1.050663,\n",
       "  0.08407817,\n",
       "  -0.08039928,\n",
       "  -0.43491548,\n",
       "  -0.23581605,\n",
       "  0.08146117,\n",
       "  -0.07360629,\n",
       "  0.010053525,\n",
       "  -0.1570465,\n",
       "  0.05893636,\n",
       "  -0.43347406,\n",
       "  -0.29988816,\n",
       "  -0.38750643,\n",
       "  0.11630442,\n",
       "  0.4076006,\n",
       "  -0.11116496,\n",
       "  -0.5895107,\n",
       "  -0.30112645,\n",
       "  0.12607984,\n",
       "  -0.50542897,\n",
       "  -0.50621367,\n",
       "  -0.05257991,\n",
       "  0.36381614,\n",
       "  0.48359028,\n",
       "  0.009068068,\n",
       "  -0.1037226,\n",
       "  -0.14019264,\n",
       "  -0.22712122,\n",
       "  0.22238414,\n",
       "  -0.23673415,\n",
       "  -0.52858406,\n",
       "  -0.082520664,\n",
       "  -0.64328784,\n",
       "  0.07511582,\n",
       "  0.025704032,\n",
       "  0.087670155,\n",
       "  0.24780649,\n",
       "  -0.016279507,\n",
       "  -0.3590073,\n",
       "  -0.10131879,\n",
       "  -0.18361373,\n",
       "  0.0076240837,\n",
       "  0.27633038,\n",
       "  -0.0457913,\n",
       "  -0.26547748,\n",
       "  -0.19359991,\n",
       "  -0.29667586,\n",
       "  -0.011849223,\n",
       "  0.24089475,\n",
       "  0.5367334,\n",
       "  0.49896395,\n",
       "  -0.1778388,\n",
       "  0.104832396,\n",
       "  -0.33011267,\n",
       "  0.023899216,\n",
       "  0.274117,\n",
       "  0.26732928,\n",
       "  -0.5667617,\n",
       "  0.22249904,\n",
       "  -0.04913922,\n",
       "  -0.08443253,\n",
       "  -0.41231185,\n",
       "  0.13548003,\n",
       "  -0.07725579,\n",
       "  0.04686722,\n",
       "  0.06639817,\n",
       "  -0.33215326,\n",
       "  0.30169103,\n",
       "  -0.07272943,\n",
       "  0.1863901,\n",
       "  -0.07663547,\n",
       "  -0.5121092,\n",
       "  0.19826397,\n",
       "  -0.11375352,\n",
       "  0.27143338,\n",
       "  -0.17112884,\n",
       "  0.5819404,\n",
       "  0.124582894,\n",
       "  0.010330212,\n",
       "  -0.35957506,\n",
       "  0.4807346,\n",
       "  0.5482508,\n",
       "  0.35470283,\n",
       "  0.26135433,\n",
       "  0.13992369,\n",
       "  0.080581106,\n",
       "  -0.035511628,\n",
       "  0.09636408,\n",
       "  0.3618881,\n",
       "  -0.12423327,\n",
       "  0.059601746,\n",
       "  0.20198628,\n",
       "  0.016974501],\n",
       " [0.042387772,\n",
       "  0.17044564,\n",
       "  0.09754384,\n",
       "  0.16903462,\n",
       "  0.12570255,\n",
       "  -0.36967853,\n",
       "  0.16771713,\n",
       "  0.6514417,\n",
       "  0.084467195,\n",
       "  -0.094593056,\n",
       "  -0.18916814,\n",
       "  -0.28353763,\n",
       "  -0.07010775,\n",
       "  -0.010482442,\n",
       "  0.048929468,\n",
       "  -0.073511444,\n",
       "  0.22139233,\n",
       "  -0.2739946,\n",
       "  -0.20677663,\n",
       "  -0.30370075,\n",
       "  0.061632417,\n",
       "  0.19011275,\n",
       "  -0.013060421,\n",
       "  -0.332456,\n",
       "  -0.15148155,\n",
       "  0.07756403,\n",
       "  -0.43369725,\n",
       "  -0.36963,\n",
       "  -0.12373378,\n",
       "  -0.01941526,\n",
       "  0.4521295,\n",
       "  0.01259622,\n",
       "  -0.12486879,\n",
       "  -0.023613753,\n",
       "  -0.0495633,\n",
       "  0.15006717,\n",
       "  0.04400009,\n",
       "  -0.30979574,\n",
       "  -0.093042664,\n",
       "  -0.3342686,\n",
       "  -0.15554911,\n",
       "  -0.012570175,\n",
       "  0.03345139,\n",
       "  -0.021113116,\n",
       "  0.10226446,\n",
       "  -0.12375226,\n",
       "  0.049167927,\n",
       "  0.042392734,\n",
       "  0.021441145,\n",
       "  0.3045489,\n",
       "  0.0063699516,\n",
       "  -0.1661591,\n",
       "  -0.10423379,\n",
       "  -0.09933882,\n",
       "  -0.1589649,\n",
       "  0.21327251,\n",
       "  0.30797404,\n",
       "  0.11184638,\n",
       "  -0.1963382,\n",
       "  0.15299888,\n",
       "  -0.22013913,\n",
       "  0.21530683,\n",
       "  0.05115122,\n",
       "  0.23008391,\n",
       "  -0.4599995,\n",
       "  0.1190485,\n",
       "  -0.16573364,\n",
       "  0.10590615,\n",
       "  -0.16661133,\n",
       "  0.19662899,\n",
       "  -0.07009055,\n",
       "  -0.010813442,\n",
       "  0.18482174,\n",
       "  0.017102206,\n",
       "  0.3951742,\n",
       "  0.05716265,\n",
       "  0.056439113,\n",
       "  -0.18647836,\n",
       "  -0.30172217,\n",
       "  -0.017266965,\n",
       "  -0.045299258,\n",
       "  0.040870536,\n",
       "  -0.2040332,\n",
       "  0.31312308,\n",
       "  0.20604381,\n",
       "  0.008805485,\n",
       "  -0.05352608,\n",
       "  0.2046091,\n",
       "  0.28642488,\n",
       "  0.2817455,\n",
       "  0.10671941,\n",
       "  0.13522649,\n",
       "  0.24192035,\n",
       "  0.0145941535,\n",
       "  0.35574114,\n",
       "  0.3515255,\n",
       "  0.067456536,\n",
       "  -0.28957453,\n",
       "  0.099210076,\n",
       "  -0.16525543],\n",
       " [0.007971678,\n",
       "  0.10799702,\n",
       "  0.10354149,\n",
       "  0.20188875,\n",
       "  0.107362434,\n",
       "  -0.34048975,\n",
       "  0.016923029,\n",
       "  0.60958534,\n",
       "  -0.016915556,\n",
       "  -0.0041051777,\n",
       "  -0.25354213,\n",
       "  -0.35097775,\n",
       "  -0.059252568,\n",
       "  0.07486539,\n",
       "  -0.12421592,\n",
       "  -0.056377593,\n",
       "  0.09886013,\n",
       "  -0.30602694,\n",
       "  0.011972004,\n",
       "  -0.34036633,\n",
       "  0.105328366,\n",
       "  0.07425483,\n",
       "  0.13513654,\n",
       "  -0.19685708,\n",
       "  -0.16737813,\n",
       "  0.0696562,\n",
       "  -0.389933,\n",
       "  -0.26711383,\n",
       "  -0.09352713,\n",
       "  -0.070757166,\n",
       "  0.27422994,\n",
       "  0.04544663,\n",
       "  0.046660118,\n",
       "  0.056410205,\n",
       "  0.0561808,\n",
       "  0.14178628,\n",
       "  0.045825563,\n",
       "  -0.17484316,\n",
       "  -0.1982095,\n",
       "  -0.28788236,\n",
       "  0.008308841,\n",
       "  -0.11492291,\n",
       "  0.060640678,\n",
       "  -0.02376988,\n",
       "  0.08817451,\n",
       "  -0.09959101,\n",
       "  -0.2254299,\n",
       "  0.06144609,\n",
       "  0.031121781,\n",
       "  0.19567257,\n",
       "  0.009883728,\n",
       "  -0.1856619,\n",
       "  -0.0016605092,\n",
       "  -0.08036179,\n",
       "  -0.25685292,\n",
       "  0.11653175,\n",
       "  0.21050736,\n",
       "  -0.014231129,\n",
       "  -0.21353778,\n",
       "  0.06567321,\n",
       "  -0.12376806,\n",
       "  0.08163763,\n",
       "  0.0006380751,\n",
       "  0.28585073,\n",
       "  -0.37232012,\n",
       "  0.074661866,\n",
       "  -0.12302846,\n",
       "  0.21960054,\n",
       "  -0.21312787,\n",
       "  0.22184645,\n",
       "  -0.114530824,\n",
       "  0.032453284,\n",
       "  0.1823649,\n",
       "  -0.006436684,\n",
       "  0.283454,\n",
       "  -0.056044087,\n",
       "  0.09983142,\n",
       "  -0.11995094,\n",
       "  -0.12058459,\n",
       "  0.072787575,\n",
       "  -0.10878057,\n",
       "  0.021001887,\n",
       "  -0.15416339,\n",
       "  0.2936006,\n",
       "  0.03827813,\n",
       "  0.08551212,\n",
       "  -0.10145114,\n",
       "  0.3032873,\n",
       "  0.4084442,\n",
       "  0.20392127,\n",
       "  0.2192817,\n",
       "  0.07735871,\n",
       "  0.10263533,\n",
       "  0.057144687,\n",
       "  0.3316202,\n",
       "  0.32116753,\n",
       "  0.008217863,\n",
       "  -0.25854176,\n",
       "  0.109401725,\n",
       "  0.07310091],\n",
       " [0.63325953,\n",
       "  0.07702482,\n",
       "  0.19029099,\n",
       "  0.45067367,\n",
       "  0.005134413,\n",
       "  -0.36164528,\n",
       "  0.28856906,\n",
       "  1.050663,\n",
       "  0.08407817,\n",
       "  -0.08039928,\n",
       "  -0.43491548,\n",
       "  -0.23581605,\n",
       "  0.08146117,\n",
       "  -0.07360629,\n",
       "  0.010053525,\n",
       "  -0.1570465,\n",
       "  0.05893636,\n",
       "  -0.43347406,\n",
       "  -0.29988816,\n",
       "  -0.38750643,\n",
       "  0.11630442,\n",
       "  0.4076006,\n",
       "  -0.11116496,\n",
       "  -0.5895107,\n",
       "  -0.30112645,\n",
       "  0.12607984,\n",
       "  -0.50542897,\n",
       "  -0.50621367,\n",
       "  -0.05257991,\n",
       "  0.36381614,\n",
       "  0.48359028,\n",
       "  0.009068068,\n",
       "  -0.1037226,\n",
       "  -0.14019264,\n",
       "  -0.22712122,\n",
       "  0.22238414,\n",
       "  -0.23673415,\n",
       "  -0.52858406,\n",
       "  -0.082520664,\n",
       "  -0.64328784,\n",
       "  0.07511582,\n",
       "  0.025704032,\n",
       "  0.087670155,\n",
       "  0.24780649,\n",
       "  -0.016279507,\n",
       "  -0.3590073,\n",
       "  -0.10131879,\n",
       "  -0.18361373,\n",
       "  0.0076240837,\n",
       "  0.27633038,\n",
       "  -0.0457913,\n",
       "  -0.26547748,\n",
       "  -0.19359991,\n",
       "  -0.29667586,\n",
       "  -0.011849223,\n",
       "  0.24089475,\n",
       "  0.5367334,\n",
       "  0.49896395,\n",
       "  -0.1778388,\n",
       "  0.104832396,\n",
       "  -0.33011267,\n",
       "  0.023899216,\n",
       "  0.274117,\n",
       "  0.26732928,\n",
       "  -0.5667617,\n",
       "  0.22249904,\n",
       "  -0.04913922,\n",
       "  -0.08443253,\n",
       "  -0.41231185,\n",
       "  0.13548003,\n",
       "  -0.07725579,\n",
       "  0.04686722,\n",
       "  0.06639817,\n",
       "  -0.33215326,\n",
       "  0.30169103,\n",
       "  -0.07272943,\n",
       "  0.1863901,\n",
       "  -0.07663547,\n",
       "  -0.5121092,\n",
       "  0.19826397,\n",
       "  -0.11375352,\n",
       "  0.27143338,\n",
       "  -0.17112884,\n",
       "  0.5819404,\n",
       "  0.124582894,\n",
       "  0.010330212,\n",
       "  -0.35957506,\n",
       "  0.4807346,\n",
       "  0.5482508,\n",
       "  0.35470283,\n",
       "  0.26135433,\n",
       "  0.13992369,\n",
       "  0.080581106,\n",
       "  -0.035511628,\n",
       "  0.09636408,\n",
       "  0.3618881,\n",
       "  -0.12423327,\n",
       "  0.059601746,\n",
       "  0.20198628,\n",
       "  0.016974501],\n",
       " [0.13477582,\n",
       "  0.3234223,\n",
       "  0.051736,\n",
       "  0.21321617,\n",
       "  -0.20612636,\n",
       "  -0.23754385,\n",
       "  -0.15087508,\n",
       "  0.45428368,\n",
       "  -0.036799297,\n",
       "  0.26266107,\n",
       "  -0.37136683,\n",
       "  -0.17388234,\n",
       "  -0.20793259,\n",
       "  -0.17141515,\n",
       "  -0.12644613,\n",
       "  -0.39025187,\n",
       "  -0.21735123,\n",
       "  -0.31521046,\n",
       "  0.14875726,\n",
       "  -0.38024625,\n",
       "  0.4612119,\n",
       "  -0.048996944,\n",
       "  0.034742408,\n",
       "  -0.016580917,\n",
       "  -0.25235367,\n",
       "  -0.16586775,\n",
       "  -0.6211634,\n",
       "  -0.4114721,\n",
       "  -0.19497745,\n",
       "  0.20356467,\n",
       "  0.00790897,\n",
       "  0.10398826,\n",
       "  0.30515745,\n",
       "  -0.2990686,\n",
       "  0.2481546,\n",
       "  -0.014406709,\n",
       "  -0.22032127,\n",
       "  0.10017637,\n",
       "  0.23666455,\n",
       "  -0.17531328,\n",
       "  0.28240994,\n",
       "  -0.28711724,\n",
       "  0.0554655,\n",
       "  0.32817805,\n",
       "  0.14904994,\n",
       "  -0.12650883,\n",
       "  -0.4413847,\n",
       "  -0.22621605,\n",
       "  0.39650035,\n",
       "  0.19919908,\n",
       "  0.15630014,\n",
       "  -0.21780305,\n",
       "  0.055054743,\n",
       "  -0.26933286,\n",
       "  -0.12757306,\n",
       "  0.509236,\n",
       "  0.21283348,\n",
       "  -0.026081674,\n",
       "  -0.2585135,\n",
       "  0.12660916,\n",
       "  -0.33951113,\n",
       "  0.38076314,\n",
       "  -0.14844273,\n",
       "  0.24909714,\n",
       "  -0.32454938,\n",
       "  0.050077505,\n",
       "  0.18830208,\n",
       "  0.34549046,\n",
       "  -0.36068645,\n",
       "  0.41181874,\n",
       "  -0.085450634,\n",
       "  -0.12946747,\n",
       "  0.0967988,\n",
       "  0.1824189,\n",
       "  0.11484149,\n",
       "  0.25830588,\n",
       "  0.05892156,\n",
       "  -0.14636268,\n",
       "  -0.036282033,\n",
       "  -0.018833539,\n",
       "  -0.5516776,\n",
       "  -0.27961892,\n",
       "  -0.16161728,\n",
       "  0.0631119,\n",
       "  0.1240344,\n",
       "  0.39465415,\n",
       "  -0.23339882,\n",
       "  0.47135183,\n",
       "  0.73237014,\n",
       "  0.017588852,\n",
       "  0.44627416,\n",
       "  -0.1004326,\n",
       "  -0.0484402,\n",
       "  -0.14909332,\n",
       "  0.12401783,\n",
       "  0.38544655,\n",
       "  -0.16107944,\n",
       "  -0.34941193,\n",
       "  0.18014811,\n",
       "  0.17098695],\n",
       " [0.029849399,\n",
       "  0.19517148,\n",
       "  0.074076205,\n",
       "  0.20388342,\n",
       "  0.051046666,\n",
       "  -0.2968277,\n",
       "  0.022557098,\n",
       "  0.4699976,\n",
       "  0.08455485,\n",
       "  -0.0014880521,\n",
       "  -0.23683102,\n",
       "  -0.21627475,\n",
       "  -0.07952194,\n",
       "  0.037347816,\n",
       "  -0.053053312,\n",
       "  -0.12435282,\n",
       "  0.000318716,\n",
       "  -0.22547989,\n",
       "  0.04797019,\n",
       "  -0.18704575,\n",
       "  0.097245015,\n",
       "  0.03252486,\n",
       "  0.022851096,\n",
       "  -0.12360375,\n",
       "  -0.07852719,\n",
       "  0.026525969,\n",
       "  -0.29035935,\n",
       "  -0.28612942,\n",
       "  -0.11907991,\n",
       "  0.057965025,\n",
       "  0.27437958,\n",
       "  0.03797787,\n",
       "  -0.011236473,\n",
       "  -0.06624003,\n",
       "  0.035680022,\n",
       "  0.08560797,\n",
       "  0.03166613,\n",
       "  -0.15284687,\n",
       "  -0.081654586,\n",
       "  -0.25720966,\n",
       "  0.02198235,\n",
       "  -0.15813388,\n",
       "  -0.028912451,\n",
       "  0.032674037,\n",
       "  0.04572483,\n",
       "  -0.13786048,\n",
       "  -0.15375863,\n",
       "  0.010192098,\n",
       "  0.08584707,\n",
       "  0.16633195,\n",
       "  0.15055516,\n",
       "  -0.21299854,\n",
       "  -0.026353562,\n",
       "  -0.071360484,\n",
       "  -0.13571271,\n",
       "  0.16925368,\n",
       "  0.1895205,\n",
       "  0.0013494444,\n",
       "  -0.14410275,\n",
       "  0.022004517,\n",
       "  -0.04485315,\n",
       "  0.10985709,\n",
       "  -0.10065389,\n",
       "  0.1509449,\n",
       "  -0.20693679,\n",
       "  0.052598815,\n",
       "  -0.005076487,\n",
       "  0.16133437,\n",
       "  -0.1905021,\n",
       "  0.2730529,\n",
       "  -0.1052613,\n",
       "  -0.030362755,\n",
       "  0.11089316,\n",
       "  0.018217409,\n",
       "  0.14040755,\n",
       "  0.0901788,\n",
       "  -0.013803726,\n",
       "  -0.09764351,\n",
       "  -0.07105882,\n",
       "  -0.016048457,\n",
       "  -0.08653791,\n",
       "  -0.037067946,\n",
       "  -0.13537548,\n",
       "  0.20825449,\n",
       "  0.011923655,\n",
       "  0.016050413,\n",
       "  -0.1408903,\n",
       "  0.16551451,\n",
       "  0.30682015,\n",
       "  0.13243036,\n",
       "  0.1744289,\n",
       "  -0.023629664,\n",
       "  0.020580549,\n",
       "  0.021213617,\n",
       "  0.20466372,\n",
       "  0.24371584,\n",
       "  0.019803023,\n",
       "  -0.22022901,\n",
       "  0.076398745,\n",
       "  0.035295412],\n",
       " [0.21463709,\n",
       "  0.2196619,\n",
       "  -0.07778517,\n",
       "  -0.0040535047,\n",
       "  0.3078828,\n",
       "  -0.5604403,\n",
       "  -0.28161946,\n",
       "  0.9120923,\n",
       "  0.08061011,\n",
       "  0.027635863,\n",
       "  -0.6711026,\n",
       "  -0.29940683,\n",
       "  -0.38418517,\n",
       "  0.19651747,\n",
       "  -0.53551954,\n",
       "  -0.3049314,\n",
       "  -0.09334834,\n",
       "  -0.12772913,\n",
       "  0.06799091,\n",
       "  -0.24466275,\n",
       "  0.69135135,\n",
       "  -0.15465778,\n",
       "  0.045928873,\n",
       "  -0.26961702,\n",
       "  -0.1984447,\n",
       "  0.19396198,\n",
       "  -0.70030266,\n",
       "  -0.6805291,\n",
       "  -0.5715267,\n",
       "  -0.5867751,\n",
       "  0.2918937,\n",
       "  -0.05852103,\n",
       "  0.11025741,\n",
       "  0.2192416,\n",
       "  0.5578918,\n",
       "  0.46371588,\n",
       "  -0.018871771,\n",
       "  -0.05074558,\n",
       "  -0.3303093,\n",
       "  -0.5132378,\n",
       "  -0.26025957,\n",
       "  0.24901474,\n",
       "  0.20011564,\n",
       "  -0.04515846,\n",
       "  -0.086695865,\n",
       "  -0.2861612,\n",
       "  -0.6354668,\n",
       "  0.08386756,\n",
       "  -0.28679696,\n",
       "  0.21267706,\n",
       "  -0.067820095,\n",
       "  -0.22289109,\n",
       "  0.07213567,\n",
       "  -0.091450304,\n",
       "  -0.20217413,\n",
       "  -0.15035674,\n",
       "  0.13385396,\n",
       "  -0.27755967,\n",
       "  -0.23293367,\n",
       "  -0.23498656,\n",
       "  -0.44717965,\n",
       "  0.5026199,\n",
       "  -0.4128951,\n",
       "  0.16475132,\n",
       "  -0.11624969,\n",
       "  -0.22107069,\n",
       "  -0.18666425,\n",
       "  0.40020296,\n",
       "  0.003235605,\n",
       "  0.19440114,\n",
       "  -0.4266267,\n",
       "  0.29488036,\n",
       "  0.47571862,\n",
       "  0.08146117,\n",
       "  0.38291377,\n",
       "  -0.38403797,\n",
       "  0.41863725,\n",
       "  -0.35197762,\n",
       "  -0.16579798,\n",
       "  0.16501045,\n",
       "  -0.06608437,\n",
       "  0.13160995,\n",
       "  -0.6131234,\n",
       "  0.60887766,\n",
       "  0.22298782,\n",
       "  0.13935453,\n",
       "  -0.6018267,\n",
       "  0.36854097,\n",
       "  -0.19273297,\n",
       "  0.29617932,\n",
       "  0.19233361,\n",
       "  -0.18548477,\n",
       "  0.13410586,\n",
       "  -0.38622046,\n",
       "  0.9669708,\n",
       "  0.35651973,\n",
       "  0.27088523,\n",
       "  -0.48684454,\n",
       "  0.04220569,\n",
       "  0.25253814],\n",
       " [0.27458096,\n",
       "  0.26965153,\n",
       "  0.26796705,\n",
       "  0.15170242,\n",
       "  0.19374427,\n",
       "  -0.38889596,\n",
       "  0.02918923,\n",
       "  0.57469815,\n",
       "  0.16548595,\n",
       "  -0.038266793,\n",
       "  -0.22495979,\n",
       "  -0.27818227,\n",
       "  -0.22320567,\n",
       "  -0.009256049,\n",
       "  0.023956463,\n",
       "  0.0006753419,\n",
       "  0.12466836,\n",
       "  -0.42417362,\n",
       "  -0.14173985,\n",
       "  -0.33970186,\n",
       "  0.028464248,\n",
       "  0.15380934,\n",
       "  0.15672341,\n",
       "  -0.2451663,\n",
       "  -0.18179588,\n",
       "  0.26349753,\n",
       "  -0.48584884,\n",
       "  -0.276908,\n",
       "  -0.24360467,\n",
       "  0.10898264,\n",
       "  0.33348843,\n",
       "  0.075710945,\n",
       "  -0.14615284,\n",
       "  0.004961621,\n",
       "  0.16813597,\n",
       "  0.051693592,\n",
       "  -0.10650742,\n",
       "  -0.364261,\n",
       "  -0.26131585,\n",
       "  -0.3922751,\n",
       "  -0.37529898,\n",
       "  0.024804747,\n",
       "  0.16813846,\n",
       "  -0.100630425,\n",
       "  -0.028012916,\n",
       "  -0.24926089,\n",
       "  -0.14442943,\n",
       "  0.19504543,\n",
       "  -0.07772985,\n",
       "  0.4676423,\n",
       "  0.006259304,\n",
       "  -0.30597633,\n",
       "  -0.054758146,\n",
       "  -0.21257983,\n",
       "  -0.18077332,\n",
       "  0.29763803,\n",
       "  0.32008627,\n",
       "  0.29205513,\n",
       "  -0.29678947,\n",
       "  0.088145405,\n",
       "  -0.406807,\n",
       "  0.34814852,\n",
       "  -0.03172315,\n",
       "  0.3767015,\n",
       "  -0.5193743,\n",
       "  0.27123016,\n",
       "  -0.3387044,\n",
       "  0.22052741,\n",
       "  -0.13006008,\n",
       "  0.15994728,\n",
       "  -0.12582178,\n",
       "  -0.22067456,\n",
       "  0.11655301,\n",
       "  -0.12694766,\n",
       "  0.21267517,\n",
       "  0.04165474,\n",
       "  -0.017383244,\n",
       "  -0.032151997,\n",
       "  -0.27620462,\n",
       "  0.09607001,\n",
       "  0.010683797,\n",
       "  0.15056661,\n",
       "  -0.4104985,\n",
       "  0.2598609,\n",
       "  0.083585404,\n",
       "  0.019224988,\n",
       "  0.09015758,\n",
       "  0.37805235,\n",
       "  0.2556452,\n",
       "  0.32243213,\n",
       "  0.1656871,\n",
       "  -0.022584194,\n",
       "  0.22405845,\n",
       "  0.048452545,\n",
       "  0.28032732,\n",
       "  0.40460777,\n",
       "  0.15404107,\n",
       "  -0.24880032,\n",
       "  0.14296192,\n",
       "  -0.12776525]]"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[51]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "43a1efdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = [np.array(x) for x in X]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "ac8b9929",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "793"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_len = max([sentence.shape[0] for sentence in X])\n",
    "max_len"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2be35ed",
   "metadata": {},
   "source": [
    "Geralmente o valor 0 é utilizado no padding de word embeddings, pois ele representa a ausência de valor para aquele elemento. O padding é usado para que todas as amostras tenham o mesmo tamanho, por exemplo, para que todas as frases tenham o mesmo número de palavras. Ao usar o valor 0 para o padding, estamos representando que aquela posição é uma palavra \"fictícia\" que não possui significado. Dessa forma, a rede neural não dará importância a essas palavras fictícias durante o processo de treinamento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "eef9d76d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = tf.keras.preprocessing.sequence.pad_sequences(X, value = 0, padding = 'post', maxlen = max_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "99131d13",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = dataset.iloc[:, 3].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "09bb144c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 2, 3], dtype=int64)"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = np.array(y)\n",
    "np.unique(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "5399c97c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1441, 793, 100), (1441,))"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape, y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8d13a75",
   "metadata": {},
   "source": [
    "O TensorFlow não suporta tensores com formas variadas, então todas as listas precisam ter o mesmo tamanho. Para resolver este problema, pode-se usar uma biblioteca de processamento de dados para garantir que todas as listas tenham o mesmo tamanho, ou pode-se remover as listas que têm tamanhos diferentes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "b15b4f8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_tensor = tf.convert_to_tensor(X, dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "9d02c4fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([1441, 793, 100])"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_tensor.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc878b21",
   "metadata": {},
   "source": [
    " ## treinamento de uma rede neural convolucional"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "558cf9a6",
   "metadata": {},
   "source": [
    "### Camada de convolução\n",
    "\n",
    "A **camada de convolução** é uma das camadas fundamentais de uma rede neural convolucional (CNN) para classificação de texto. Essa camada é responsável por extrair as características dos dados de entrada, que podem ser, por exemplo, palavras ou frases de um texto. A convolução é uma operação matemática que envolve a multiplicação da entrada com um pequeno filtro (também chamado de kernel ou janela), que se desloca pela entrada em uma determinada direção. A cada posição, o resultado da multiplicação é somado e a saída é produzida.\n",
    "\n",
    "A camada de convolução pode ter vários filtros diferentes, cada um aprendendo uma característica diferente dos dados. Isso permite que a CNN capture uma variedade de informações importantes do texto, como a presença de palavras-chave, a estrutura gramatical e o contexto em que as palavras são usadas.\n",
    "\n",
    "O número de filtros recomendados para a camada de convolução em uma rede neural convolucional pode variar dependendo da complexidade do problema e da arquitetura da rede. Não há um número fixo que seja considerado ideal ou padrão, mas é comum utilizar potências de 2, como 32, 64, 128, 256, etc. para o número de filtros em cada camada. O número de filtros também pode ser aumentado à medida que se avança nas camadas da rede, com o objetivo de aprender características mais complexas e abstratas\n",
    "\n",
    "Além disso, é comum usar outras camadas, como camadas de pooling e camadas de dropout, para aumentar a eficiência e evitar overfitting, que é um problema comum em redes neurais.\n",
    "\n",
    "Em resumo, a camada de convolução é uma peça fundamental na arquitetura de uma rede neural convolucional para classificação de texto, permitindo a extração de características relevantes dos dados de entrada.\n",
    "\n",
    "Na arquitetura de uma Rede Neural Convolucional (CNN), a camada de pooling é uma das camadas fundamentais. Essa camada é responsável por reduzir a dimensionalidade espacial do mapa de características gerado pela camada de convolução anterior.\n",
    "\n",
    "Não há um valor recomendado fixo de kernel_size para todos os casos, pois ele depende do tamanho da sequência, da natureza dos dados e dos objetivos do modelo. Em geral, valores comuns de kernel_size para sequências de texto variam de 2 a 5. No entanto, pode ser necessário testar diferentes valores para encontrar o melhor desempenho para o seu conjunto de dados específico. Além disso, a escolha do kernel_size também pode ser influenciada pelo tamanho da dimensão embutida (word embedding), pelo número de camadas na rede e pelo número de filtros. É importante experimentar diferentes configurações e avaliar o desempenho para encontrar o melhor modelo.\n",
    "\n",
    "Se a rede neural convolucional não converge com 1000 épocas, significa que o modelo ainda não atingiu a performance desejada após 1000 iterações de treinamento. Neste caso, aumentar o número de **filtros** pode ser uma possível solução, mas existem outros fatores que precisam ser considerados, como o tipo de otimizador, taxa de aprendizado, regularização, e se o conjunto de dados de treinamento é suficientemente grande e representativo. Além disso, é importante verificar se o modelo não está sofrendo de overfitting, ou seja, se ele está generalizando bem para dados não vistos durante o treinamento. Não há uma única resposta para essa questão, e a solução pode envolver uma combinação de diferentes ajustes e experimentos.\n",
    "\n",
    "### Camada de pooling\n",
    "\n",
    "A ideia básica da **camada de pooling** é reduzir a resolução espacial da representação do mapa de características, a fim de reduzir a quantidade de parâmetros e poder generalizar melhor o modelo para novos dados. Ela funciona selecionando um valor de um conjunto de valores de características próximos, agrupando-os e reduzindo-os a um único valor representativo. Essa operação é realizada em cada \"sub-região\" do mapa de características, onde cada sub-região é definida por um filtro.\n",
    "\n",
    "Existem vários tipos de pooling, sendo os mais comuns o max pooling e o average pooling. No max pooling, é selecionado o valor máximo dentro da sub-região para ser o valor representativo. Já no average pooling, é calculada a média dos valores da sub-região para ser o valor representativo.\n",
    "\n",
    "A camada de pooling é uma forma de regularização, já que ela reduz a dimensionalidade da representação do mapa de características e, consequentemente, o número de parâmetros a serem treinados. Isso reduz o risco de overfitting, tornando o modelo.\n",
    "\n",
    "### Camada totalmente conectada\n",
    "\n",
    "A **camada totalmente conectada** é uma camada de rede neural que recebe as características extraídas pela camada de convolução e/ou de pooling e as usa para realizar a classificação final. Essa camada é composta por neurônios que estão totalmente conectados com os neurônios da camada anterior.\n",
    "\n",
    "Na tarefa de classificação de texto, a camada totalmente conectada pode ser usada para gerar a pontuação da classe correspondente a cada possível categoria. Por exemplo, em uma tarefa de classificação de texto em que há duas categorias, \"positivo\" e \"negativo\", a camada totalmente conectada pode gerar uma pontuação para cada uma dessas categorias. Em seguida, a classe final é escolhida com base na pontuação mais alta.\n",
    "\n",
    "Uma das desvantagens da camada totalmente conectada é que ela pode causar overfitting (sobreajuste) aos dados de treinamento. Para lidar com esse problema, é comum o uso de técnicas como **dropout** ou **regularização L2** na camada totalmente conectada para reduzir a complexidade do modelo e evitar overfitting.\n",
    "\n",
    "Não existe um número recomendado exato de **camadas e neurônios** para uma camada densa em uma rede neural, pois isso depende de vários fatores, como o tamanho do conjunto de dados, a complexidade do modelo, a precisão desejada, entre outros. Algumas boas práticas incluem começar com uma camada densa com uma pequena quantidade de neurônios, como 32 ou 64, e aumentar gradativamente até atingir uma boa precisão. É importante também usar **regularização** para evitar **overfitting**. Uma boa prática é experimentar com diferentes configurações e comparar os resultados para escolher a melhor opção.\n",
    "\n",
    "Aumentar o número de camadas em uma rede neural convolucional pode ser considerado como uma técnica para melhorar a performance do modelo em uma **tarefa de classificação de texto**, mas isso depende de vários fatores, tais como a quantidade de dados disponíveis, a complexidade do modelo e a quantidade de recursos computacionais disponíveis.\n",
    "\n",
    "A adição de camadas pode permitir que o modelo capture **padrões mais complexos nas sequências de texto**, o que pode levar a uma melhora na acurácia. _No entanto, também é importante ter em mente que a adição de muitas camadas pode tornar o modelo propenso a overfitting, especialmente se a quantidade de dados disponíveis for limitada_.\n",
    "\n",
    "Além disso, o número de camadas também pode impactar a velocidade de treinamento do modelo e a complexidade computacional. É importante encontrar um equilíbrio entre a capacidade do modelo de aprender padrões importantes e a capacidade de manter uma performance eficiente.\n",
    "\n",
    "Em geral, é recomendado experimentar diferentes configurações, incluindo diferentes números de camadas, para encontrar a melhor configuração para o problema específico de classificação de texto em questão.\n",
    "\n",
    "### Dropout\n",
    "\n",
    "A **técnica de \"dropout\"** é um método de regularização que é frequentemente utilizado em redes neurais, incluindo as camadas totalmente conectadas. O objetivo do dropout é evitar o overfitting, que é quando a rede se ajusta demais aos dados de treinamento, e não generaliza bem para novos dados.\n",
    "\n",
    "O dropout funciona desativando aleatoriamente um conjunto de neurônios da camada em cada passagem de treinamento. Isso significa que a camada tem que aprender a confiar em diferentes combinações de neurônios em cada passagem de treinamento, em vez de depender sempre dos mesmos neurônios. Isso faz com que a rede se torne mais robusta, pois não pode confiar em um subconjunto específico de neurônios para a classificação de uma entrada.\n",
    "\n",
    "Durante o processo de teste, todos os neurônios são ativados, pois não há necessidade de regularização neste momento. Em resumo, o dropout é uma técnica simples e eficaz para reduzir o overfitting em redes neurais, tornando as camadas totalmente conectadas mais robustas e generalizáveis.\n",
    "\n",
    "O valor recomendado para o dropout_rate varia dependendo da aplicação e dos dados. Em geral, o dropout_rate varia entre 0.2 e 0.5. O dropout_rate de 0.5 significa que 50% dos neurônios serão \"desligados\" durante o treinamento para evitar overfitting, enquanto o dropout_rate de 0.2 significa que 20% dos neurônios serão desligados. O valor ótimo par'a o dropout_rate deve ser determinado experimentando com diferentes valores e avaliando o desempenho do modelo.\n",
    "\n",
    "### Regularização L2\n",
    "\n",
    "Em redes neurais, a **regularização L2** é uma técnica usada para evitar o overfitting, ou seja, o modelo aprender demais o conjunto de treinamento, e não generalizar bem para novos dados. A regularização L2 adiciona um termo à função de custo da rede neural, que penaliza pesos grandes. Especificamente, a função de custo adiciona a soma dos quadrados dos pesos multiplicada por um parâmetro de regularização lambda. Essa penalização faz com que a rede favoreça pesos menores, o que pode ajudar a evitar o overfitting.\n",
    "\n",
    "Na camada totalmente conectada, onde cada neurônio está conectado a todos os neurônios da camada anterior, a regularização L2 é aplicada aos pesos da camada. Isso ajuda a controlar a complexidade do modelo, evitando que os pesos da rede se tornem muito grandes. Além disso, a regularização L2 pode melhorar o desempenho da rede em conjuntos de dados de teste, onde o modelo não foi treinado, ajudando a rede a generalizar melhor para novos dados.\n",
    "\n",
    "A recomendação geral é aplicar a regularização L2 em camadas densas ou camadas totalmente conectadas, em vez de nas camadas de convolução. Isso se deve ao fato de que a regularização L2 é mais eficaz na prevenção do overfitting em camadas densas, já que as camadas densas tendem a ter muitos parâmetros e a possibilidade de aprender padrões redundantes.\n",
    "\n",
    "O parâmetro \"kernel_regularizer=keras.regularizers.l2(0.01)\" é um argumento que pode ser passado em uma camada de rede neural no Keras para aplicar regularização L2 aos pesos (kernels) dessa camada. O valor 0,01 passado como argumento representa a força da regularização L2, onde valores maiores levarão a uma penalidade mais forte e pesos mais próximos de zero.\n",
    "\n",
    "No entanto, é importante lembrar que a implementação da regularização L2 depende do problema específico e dos dados de treinamento. É possível que a aplicação da regularização L2 nas camadas de convolução seja benéfica em algumas situações específicas. Portanto, é sempre recomendável experimentar diferentes abordagens e verificar qual funciona melhor para o problema em questão.\n",
    "\n",
    "A saída de uma rede neural convolucional de classificação de texto com 4 classes é uma matriz de probabilidade com 4 colunas, onde cada coluna representa a probabilidade de uma determinada classe. O valor da saída é o índice da coluna que apresenta o maior valor. Por exemplo, se o maior valor da saída for na primeira coluna, então o modelo preveu a classe 0. Se o maior valor da saída for na segunda coluna, então o modelo preveu a classe 1 e assim por diante.\n",
    "\n",
    "O número de épocas recomendado para uma rede neural convolucional varia dependendo do tamanho do seu conjunto de dados e da complexidade do modelo. Em geral, um número de épocas entre 10 e 100 é considerado um bom ponto de partida. Se o treinamento da rede não estiver levando a uma boa precisão, você pode aumentar o número de épocas. De maneira geral, é importante observar o comportamento do modelo em relação à precisão e loss ao longo do treinamento para determinar o melhor número de épocas. Além disso, é importante utilizar uma técnica de validação cruzada para evitar o overfitting do modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "c9cd04d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# o vetor de word embbeding é de tamanho 100-\n",
    "tamanho_word_embbeding = 100\n",
    "# o número de filtros de convolução é 32\n",
    "qtd_filtros = 32\n",
    "# quantidade de neuronios na camada densa é 64\n",
    "qtd_neuronios_camada_densa = 64\n",
    "# o tamanho do bath é 256\n",
    "tamanho_batch = 100\n",
    "# a quantidade de classes é quatro\n",
    "qtd_classes = len(set(y))\n",
    "# taxa de dropout é a taxa de neurônios que serão desligados no treinamento\n",
    "#o valor 0.2 é um valor que empiricamente evita overffiting\n",
    "taxa_dropout = 0.2\n",
    "#é a quantidade de épocas de treinamento\n",
    "qtd_epocas = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "0e73a9c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "classe que representa a rede neural convolucional  para classificação de textos\n",
    "'''\n",
    "class DCNN(tf.keras.Model):\n",
    "    \n",
    "    '''\n",
    "        tamanho_word_embbeding: tamanho do vetor de números representando a palavra;\n",
    "        qtd_filtros: número de filtros para cada dimensão;\n",
    "        qtd_neuronios_camada_densa: número de neurônios da rede neural densa;\n",
    "        qtd_classes: número de classes para classificação;\n",
    "        taxa_dropout: porcentagem de desativação de neurônios;\n",
    "    '''\n",
    "    def __init__(self,  \n",
    "                 tamanho_word_embbeding = 1, \n",
    "                 qtd_filtros = 8, \n",
    "                 qtd_neuronios_camada_densa = 64, \n",
    "                 qtd_classes = 2,\n",
    "                 taxa_dropout = 0.2, \n",
    "                 training = False, \n",
    "                 name = 'dcnn'):\n",
    "        super(DCNN, self).__init__(name=name)\n",
    "        #gera a matriz de embedding do vocabulário ou a representação vetorial de cada palavra\n",
    "        #camadas de convolução\n",
    "        #define os filtros\n",
    "        #same: retorna os mesmos dados no mesmo formato\n",
    "        # para cada sentença, extrai as fetures e realiza o treinamento das feature vector\n",
    "        self.bigram = layers.Conv1D(filters=qtd_filtros, kernel_size=2, padding='same', activation = 'relu', kernel_regularizer=keras.regularizers.l2(0.01))\n",
    "        self.trigram = layers.Conv1D(filters=qtd_filtros, kernel_size=3, padding='same', activation = 'relu')\n",
    "        self.fourgram = layers.Conv1D(filters=qtd_filtros, kernel_size=4, padding='same', activation = 'relu')\n",
    "        self.fivegram = layers.Conv1D(filters=qtd_filtros, kernel_size=5, padding='same', activation = 'relu')\n",
    "        #camada max pooling\n",
    "        self.pool = layers.GlobalMaxPool1D()\n",
    "        #camada densa\n",
    "        self.dense_1 = layers.Dense(units = qtd_neuronios_camada_densa, activation = 'relu')\n",
    "        self.dense_2 = layers.Dense(units = qtd_neuronios_camada_densa, activation = 'relu')\n",
    "        self.dense_3 = layers.Dense(units = qtd_neuronios_camada_densa, activation = 'relu')\n",
    "        self.dropout = layers.Dropout(rate = taxa_dropout)\n",
    "        if qtd_classes == 2:\n",
    "            self.last_dense = layers.Dense(units = 1, activation = 'sigmoid')\n",
    "        else:\n",
    "            #problemas de classificação com mais de 2 classes utilizar a softmax\n",
    "            self.last_dense = layers.Dense(units = qtd_classes, activation = 'softmax', kernel_regularizer=keras.regularizers.l2(0.01))\n",
    "            \n",
    "    def call(self, inputs, training):\n",
    "        x = inputs\n",
    "        x_1 = self.bigram(x)\n",
    "        x_1 = self.pool(x_1)\n",
    "        x_2 = self.trigram(x)\n",
    "        x_2 = self.pool(x_2)\n",
    "        x_3 = self.fourgram(x)\n",
    "        x_3 = self.pool(x_3)\n",
    "        x_4 = self.fivegram(x)\n",
    "        x_4 = self.pool(x_4)\n",
    "        \n",
    "        merged = tf.concat([x_1, x_2, x_3,x_4], axis = -1) # (batch_size, 3*qtd_filtros)\n",
    "        print(merged.shape)\n",
    "        merged = self.dense_1(merged)\n",
    "        merged = self.dropout(merged, training)\n",
    "        merged = self.dense_2(merged)\n",
    "        merged = self.dropout(merged, training)\n",
    "        merged = self.dense_3(merged)\n",
    "        merged = self.dropout(merged, training)\n",
    "        output = self.last_dense(merged)\n",
    "        \n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "d36b9e2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#criar a instância da rede neural especificada\n",
    "Dcnn = DCNN(tamanho_word_embbeding=tamanho_word_embbeding, qtd_filtros=qtd_filtros, qtd_neuronios_camada_densa=qtd_neuronios_camada_densa, qtd_classes=qtd_classes, taxa_dropout=taxa_dropout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "05b3c2a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"dcnn\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv1d_4 (Conv1D)           multiple                  6432      \n",
      "                                                                 \n",
      " conv1d_5 (Conv1D)           multiple                  9632      \n",
      "                                                                 \n",
      " conv1d_6 (Conv1D)           multiple                  12832     \n",
      "                                                                 \n",
      " conv1d_7 (Conv1D)           multiple                  16032     \n",
      "                                                                 \n",
      " global_max_pooling1d_1 (Glo  multiple                 0         \n",
      " balMaxPooling1D)                                                \n",
      "                                                                 \n",
      " dense_4 (Dense)             multiple                  8256      \n",
      "                                                                 \n",
      " dense_5 (Dense)             multiple                  4160      \n",
      "                                                                 \n",
      " dense_6 (Dense)             multiple                  4160      \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         multiple                  0         \n",
      "                                                                 \n",
      " dense_7 (Dense)             multiple                  260       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 61,764\n",
      "Trainable params: 61,764\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "Dcnn.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abca85a0",
   "metadata": {},
   "source": [
    "### Função de perda e otimizador\n",
    "\n",
    "As linhas a seguir definem a **função de perda** e o **otimizador** que serão usados durante o treinamento da rede neural. Especificamente, essas linhas determinam se a rede neural será usada para classificação binária ou multiclasse. Se nb_classes for igual a 2, a rede neural será usada para classificação binária e a função de perda será **binary_crossentropy**. Neste caso, o otimizador será **adam**. Se nb_classes for diferente de 2, a rede neural será usada para classificação multiclasse e a função de perda será **sparse_categorical_crossentropy**. Neste caso, o otimizador também será adam. Além disso, o desempenho será avaliado usando a métrica de acurácia.\n",
    "\n",
    "A **binary_crossentropy** é uma função de perda utilizada em problemas de classificação binária. Ela mede a diferença entre a previsão do modelo e o valor alvo (verdadeiro). Isso é feito calculando a **entropia cruzada** (cross-entropy) entre a distribuição de probabilidade predita pelo modelo e a distribuição de probabilidade real.\n",
    "\n",
    "A **sparse_categorical_crossentropy**, por outro lado, é uma função de perda utilizada em problemas de classificação multiclasse. Nestes problemas, cada exemplo de treinamento pode ser classificado como uma das várias categorias possíveis. Esta função de perda compara a previsão do modelo com o valor alvo e calcula a **entropia cruzada (cross-entropy)** entre a distribuição de probabilidade predita e a distribuição de probabilidade verdadeira.\n",
    "\n",
    "A diferença entre binary_crossentropy e sparse_categorical_crossentropy é que a última é mais eficiente para problemas com muitas categorias, pois permite que os valores-alvo sejam especificados como inteiros (índices) em vez de vetores one-hot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "5544e284",
   "metadata": {},
   "outputs": [],
   "source": [
    "if qtd_classes == 2:\n",
    "    Dcnn.compile(loss = 'binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "else:\n",
    "    Dcnn.compile(loss = 'sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65145b2f",
   "metadata": {},
   "source": [
    "### Objeto de verificação de ponto\n",
    "\n",
    "As linhas a seguir são uma implementação de salvar e restaurar os pesos de uma rede neural no TensorFlow.\n",
    "\n",
    "O código cria um **objeto de verificação de ponto (ckpt)** que é associado à rede neural (Dcnn). Em seguida, cria um gerenciador de ponto de verificação (ckpt_manager) que controla o local onde os checkpoints são salvos e quantos checkpoints são mantidos.\n",
    "\n",
    "A linha seguinte verifica se existe um checkpoint mais recente. Se houver, o checkpoint é restaurado, o que significa que os pesos salvos da última vez em que o modelo foi treinado são carregados na rede neural. Finalmente, a mensagem \"Latest checkpoint restored\" é impressa na tela para indicar que o checkpoint foi restaurado com sucesso."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "36adc501",
   "metadata": {},
   "outputs": [],
   "source": [
    "ckpt = tf.train.Checkpoint(Dcnn=Dcnn)\n",
    "ckpt_manager = tf.train.CheckpointManager(ckpt, '', max_to_keep=5)\n",
    "if ckpt_manager.latest_checkpoint:\n",
    "    ckpt.restore(ckpt_manager.latest_checkpoint)\n",
    "    print('Latest checkpoint restored')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db37f635",
   "metadata": {},
   "source": [
    "### Parâmetros do método fit\n",
    "\n",
    "A função fit da classe tf.keras.Model tem os seguintes tipos de parâmetros:\n",
    "\n",
    "**x**: array Numpy ou tensor, ou seja, dados de treinamento para o modelo.\n",
    "\n",
    "**y**: array Numpy ou tensor, ou seja, etiquetas de treinamento para o modelo.\n",
    "\n",
    "**batch_size**: inteiro, ou seja, o número de amostras de treinamento por atualização de peso.\n",
    "\n",
    "**epochs**: inteiro, ou seja, o número de épocas (ciclos) a serem executados sobre os dados de treinamento.\n",
    "\n",
    "**verbose**: inteiro, ou seja, o nível de verbosidade da função. 0 significa que não há saída, 1 significa que a saída de progresso é exibida em forma de barra de progresso, 2 significa que o progresso é exibido como uma única linha.\n",
    "\n",
    "**callbacks**: lista, ou seja, lista de instâncias de Callback, que são funções de retorno de chamada a serem executadas durante o treinamento.\n",
    "\n",
    "**validation_data**: tupla (x_val, y_val), ou seja, conjunto de dados de validação, onde x_val é um array Numpy ou tensor e y_val é uma lista ou array Numpy ou tensor.\n",
    "\n",
    "**shuffle**: booleano, ou seja, se os dados de treinamento devem ser embaralhados antes de cada época.\n",
    "\n",
    "**class_weight**: dicionário, ou seja, pesos das classes, usados para lidar com desequilíbrios de classes em dados de treinamento.\n",
    "\n",
    "**sample_weight**: array Numpy ou tensor, ou seja, pesos amostrais, usados para lidar com desequilíbrios de amostras em dados de treinamento.\n",
    "\n",
    "**initial_epoch**: inteiro, ou seja, época inicial para iniciar a contagem de épocas. Útil quando você quer retomar o treinamento de um modelo interrompido.\n",
    "\n",
    "**steps_per_epoch**: inteiro, ou seja, o número de etapas (batches) por época. Se for fornecido, sobrescreve o cálculo automático baseado na quantidade de amostras de treinamento.\n",
    "\n",
    "**validation_steps**: inteiro, ou seja, o número de etapas (batches) de validação por época. Se for fornecido, sobrescreve o cálculo automático baseado na quantidade de amostras de validação.\n",
    "\n",
    "A vantagem de usar o **parâmetro shuffle** no método fit é que ele embaralha os dados de treinamento a cada época, o que pode melhorar a generalização do modelo e prevenir overfitting. Isso acontece porque o modelo não é treinado com um conjunto de dados sempre na mesma ordem, o que pode evitar que ele memorize as informações e não generalize corretamente.\n",
    "\n",
    "No entanto, há também uma desvantagem ao usar shuffle. Embaralhar os dados a cada época pode tornar o treinamento mais lento, especialmente se o conjunto de dados for grande. Além disso, o embaralhamento pode ser inadequado para algumas aplicações em que a ordem dos dados é importante, como previsão de séries temporais.\n",
    "\n",
    "Em geral, usar shuffle é uma boa prática para muitos tipos de modelos, mas é importante avaliar se o uso é adequado para o problema em questão.\n",
    "\n",
    "### Valores de accuracy e val_accuracy durante o treinamento\n",
    "\n",
    "Durante o treinamento de uma rede neural convolucional, é ideal que a **\"accuracy\"** (acurácia do treinamento) e **\"val_accuracy\"** (acurácia da validação) aumentem ao longo das épocas. A acurácia de treinamento deve aumentar até alcançar um valor próximo de 100% e a acurácia de validação deve aumentar até alcançar um valor próximo do valor da acurácia de treinamento. _Se a acurácia de validação estiver ficando muito abaixo da acurácia de treinamento, pode ser um sinal de overfitting_.\n",
    "\n",
    "O overfitting ocorre quando a rede neural é muito complexa para o conjunto de dados de treinamento e aprende características específicas dos dados de treinamento que não são genéricas e não se aplicam a novos dados. Isso pode ser solucionado usando técnicas de regularização, diminuindo o número de camadas ou de neurônios, ou aumentando o número de exemplos de treinamento.\n",
    "\n",
    "Uma acurácia de treinamento alta e uma acurácia de validação baixa em uma rede neural convolucional (CNN) ao longo das épocas geralmente significa que a rede está sofrendo de overfitting, ou seja, ela está memorizando os dados de treinamento em vez de generalizar e aprender padrões mais amplos que possam ser aplicados a novos dados. Isso pode ser indicado pelo fato de que a rede é capaz de classificar corretamente a maioria dos dados de treinamento, mas não é capaz de classificar corretamente uma quantidade significativa de dados de validação.\n",
    "\n",
    "Uma abordagem para lidar com esse problema é adicionar regularização à rede, como dropout, L1 ou L2 regularization, ou usar data augmentation para aumentar o tamanho do conjunto de treinamento. Também pode ser útil ajustar os hiperparâmetros da rede, como a taxa de aprendizado, tamanho do lote, número de camadas, tamanho dos filtros convolucionais e tamanho dos mapas de características."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "0acca61b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "(None, 32)\n",
      "(None, 32)\n",
      "12/12 [==============================] - ETA: 0s - loss: 1.6037 - accuracy: 0.2309(None, 32)\n",
      "12/12 [==============================] - 8s 121ms/step - loss: 1.6037 - accuracy: 0.2309 - val_loss: 1.5761 - val_accuracy: 0.2111\n",
      "Epoch 2/200\n",
      "12/12 [==============================] - 1s 95ms/step - loss: 1.5592 - accuracy: 0.2587 - val_loss: 1.5444 - val_accuracy: 0.2422\n",
      "Epoch 3/200\n",
      "12/12 [==============================] - 1s 93ms/step - loss: 1.5290 - accuracy: 0.2769 - val_loss: 1.5207 - val_accuracy: 0.2318\n",
      "Epoch 4/200\n",
      "12/12 [==============================] - 1s 91ms/step - loss: 1.5089 - accuracy: 0.2595 - val_loss: 1.5004 - val_accuracy: 0.2318\n",
      "Epoch 5/200\n",
      "12/12 [==============================] - 1s 91ms/step - loss: 1.4894 - accuracy: 0.2856 - val_loss: 1.4851 - val_accuracy: 0.2111\n",
      "Epoch 6/200\n",
      "12/12 [==============================] - 1s 91ms/step - loss: 1.4695 - accuracy: 0.2812 - val_loss: 1.4702 - val_accuracy: 0.2318\n",
      "Epoch 7/200\n",
      "12/12 [==============================] - 1s 94ms/step - loss: 1.4539 - accuracy: 0.2986 - val_loss: 1.4577 - val_accuracy: 0.2284\n",
      "Epoch 8/200\n",
      "12/12 [==============================] - 1s 92ms/step - loss: 1.4403 - accuracy: 0.3116 - val_loss: 1.4508 - val_accuracy: 0.2353\n",
      "Epoch 9/200\n",
      "12/12 [==============================] - 1s 90ms/step - loss: 1.4307 - accuracy: 0.3134 - val_loss: 1.4449 - val_accuracy: 0.2284\n",
      "Epoch 10/200\n",
      "12/12 [==============================] - 1s 93ms/step - loss: 1.4178 - accuracy: 0.3273 - val_loss: 1.4339 - val_accuracy: 0.2422\n",
      "Epoch 11/200\n",
      "12/12 [==============================] - 1s 89ms/step - loss: 1.4041 - accuracy: 0.3394 - val_loss: 1.4338 - val_accuracy: 0.2318\n",
      "Epoch 12/200\n",
      "12/12 [==============================] - 1s 90ms/step - loss: 1.4017 - accuracy: 0.3194 - val_loss: 1.4281 - val_accuracy: 0.2318\n",
      "Epoch 13/200\n",
      "12/12 [==============================] - 1s 97ms/step - loss: 1.3923 - accuracy: 0.3342 - val_loss: 1.4356 - val_accuracy: 0.2180\n",
      "Epoch 14/200\n",
      "12/12 [==============================] - 1s 90ms/step - loss: 1.3755 - accuracy: 0.3516 - val_loss: 1.4297 - val_accuracy: 0.2249\n",
      "Epoch 15/200\n",
      "12/12 [==============================] - 1s 90ms/step - loss: 1.3753 - accuracy: 0.3464 - val_loss: 1.4319 - val_accuracy: 0.2457\n",
      "Epoch 16/200\n",
      "12/12 [==============================] - 1s 88ms/step - loss: 1.3557 - accuracy: 0.3672 - val_loss: 1.4354 - val_accuracy: 0.2180\n",
      "Epoch 17/200\n",
      "12/12 [==============================] - 1s 88ms/step - loss: 1.3509 - accuracy: 0.3689 - val_loss: 1.4352 - val_accuracy: 0.2284\n",
      "Epoch 18/200\n",
      "12/12 [==============================] - 1s 96ms/step - loss: 1.3354 - accuracy: 0.3646 - val_loss: 1.4376 - val_accuracy: 0.2734\n",
      "Epoch 19/200\n",
      "12/12 [==============================] - 1s 89ms/step - loss: 1.3142 - accuracy: 0.3793 - val_loss: 1.4455 - val_accuracy: 0.2249\n",
      "Epoch 20/200\n",
      "12/12 [==============================] - 1s 88ms/step - loss: 1.2939 - accuracy: 0.4080 - val_loss: 1.4424 - val_accuracy: 0.2630\n",
      "Epoch 21/200\n",
      "12/12 [==============================] - 1s 92ms/step - loss: 1.2718 - accuracy: 0.4236 - val_loss: 1.4638 - val_accuracy: 0.2595\n",
      "Epoch 22/200\n",
      "12/12 [==============================] - 1s 87ms/step - loss: 1.2486 - accuracy: 0.4306 - val_loss: 1.4855 - val_accuracy: 0.2215\n",
      "Epoch 23/200\n",
      "12/12 [==============================] - 1s 92ms/step - loss: 1.2325 - accuracy: 0.4375 - val_loss: 1.4870 - val_accuracy: 0.2630\n",
      "Epoch 24/200\n",
      "12/12 [==============================] - 1s 91ms/step - loss: 1.2173 - accuracy: 0.4627 - val_loss: 1.5782 - val_accuracy: 0.2457\n",
      "Epoch 25/200\n",
      "12/12 [==============================] - 1s 89ms/step - loss: 1.1966 - accuracy: 0.4644 - val_loss: 1.5332 - val_accuracy: 0.2491\n",
      "Epoch 26/200\n",
      "12/12 [==============================] - 1s 91ms/step - loss: 1.1668 - accuracy: 0.4922 - val_loss: 1.5739 - val_accuracy: 0.2215\n",
      "Epoch 27/200\n",
      "12/12 [==============================] - 1s 93ms/step - loss: 1.1497 - accuracy: 0.5000 - val_loss: 1.5620 - val_accuracy: 0.2388\n",
      "Epoch 28/200\n",
      "12/12 [==============================] - 1s 87ms/step - loss: 1.1086 - accuracy: 0.5087 - val_loss: 1.6168 - val_accuracy: 0.2145\n",
      "Epoch 29/200\n",
      "12/12 [==============================] - 1s 91ms/step - loss: 1.0962 - accuracy: 0.5113 - val_loss: 1.6283 - val_accuracy: 0.2318\n",
      "Epoch 30/200\n",
      "12/12 [==============================] - 1s 89ms/step - loss: 1.0989 - accuracy: 0.5148 - val_loss: 1.7037 - val_accuracy: 0.2491\n",
      "Epoch 31/200\n",
      "12/12 [==============================] - 1s 86ms/step - loss: 1.0563 - accuracy: 0.5373 - val_loss: 1.7006 - val_accuracy: 0.2491\n",
      "Epoch 32/200\n",
      "12/12 [==============================] - 1s 86ms/step - loss: 1.0280 - accuracy: 0.5503 - val_loss: 1.7043 - val_accuracy: 0.2422\n",
      "Epoch 33/200\n",
      "12/12 [==============================] - 1s 87ms/step - loss: 1.0148 - accuracy: 0.5608 - val_loss: 1.7592 - val_accuracy: 0.2491\n",
      "Epoch 34/200\n",
      "12/12 [==============================] - 1s 91ms/step - loss: 1.0012 - accuracy: 0.5512 - val_loss: 1.7805 - val_accuracy: 0.2422\n",
      "Epoch 35/200\n",
      "12/12 [==============================] - 1s 96ms/step - loss: 0.9897 - accuracy: 0.5799 - val_loss: 1.8415 - val_accuracy: 0.2353\n",
      "Epoch 36/200\n",
      "12/12 [==============================] - 1s 92ms/step - loss: 0.9672 - accuracy: 0.5660 - val_loss: 1.8382 - val_accuracy: 0.2526\n",
      "Epoch 37/200\n",
      "12/12 [==============================] - 1s 91ms/step - loss: 0.9566 - accuracy: 0.5964 - val_loss: 1.8816 - val_accuracy: 0.2699\n",
      "Epoch 38/200\n",
      "12/12 [==============================] - 1s 90ms/step - loss: 0.9477 - accuracy: 0.5877 - val_loss: 1.9768 - val_accuracy: 0.2526\n",
      "Epoch 39/200\n",
      "12/12 [==============================] - 1s 90ms/step - loss: 0.9100 - accuracy: 0.5998 - val_loss: 1.9934 - val_accuracy: 0.2630\n",
      "Epoch 40/200\n",
      "12/12 [==============================] - 1s 91ms/step - loss: 0.9420 - accuracy: 0.5859 - val_loss: 1.9411 - val_accuracy: 0.2803\n",
      "Epoch 41/200\n",
      "12/12 [==============================] - 1s 93ms/step - loss: 0.9095 - accuracy: 0.6198 - val_loss: 1.9968 - val_accuracy: 0.2734\n",
      "Epoch 42/200\n",
      "12/12 [==============================] - 1s 89ms/step - loss: 0.9175 - accuracy: 0.6016 - val_loss: 2.0204 - val_accuracy: 0.2353\n",
      "Epoch 43/200\n",
      "12/12 [==============================] - 1s 89ms/step - loss: 0.8918 - accuracy: 0.6155 - val_loss: 1.9982 - val_accuracy: 0.2595\n",
      "Epoch 44/200\n",
      "12/12 [==============================] - 1s 87ms/step - loss: 0.8501 - accuracy: 0.6450 - val_loss: 2.1274 - val_accuracy: 0.2630\n",
      "Epoch 45/200\n",
      "12/12 [==============================] - 1s 86ms/step - loss: 0.8391 - accuracy: 0.6649 - val_loss: 2.2086 - val_accuracy: 0.2284\n",
      "Epoch 46/200\n",
      "12/12 [==============================] - 1s 93ms/step - loss: 0.8503 - accuracy: 0.6372 - val_loss: 2.1786 - val_accuracy: 0.2664\n",
      "Epoch 47/200\n",
      "12/12 [==============================] - 1s 89ms/step - loss: 0.8420 - accuracy: 0.6684 - val_loss: 2.1491 - val_accuracy: 0.2941\n",
      "Epoch 48/200\n",
      "12/12 [==============================] - 1s 89ms/step - loss: 0.8262 - accuracy: 0.6536 - val_loss: 2.2436 - val_accuracy: 0.2491\n",
      "Epoch 49/200\n",
      "12/12 [==============================] - 1s 88ms/step - loss: 0.8026 - accuracy: 0.6780 - val_loss: 2.2756 - val_accuracy: 0.2699\n",
      "Epoch 50/200\n",
      "12/12 [==============================] - 1s 89ms/step - loss: 0.8172 - accuracy: 0.6623 - val_loss: 2.3575 - val_accuracy: 0.2595\n",
      "Epoch 51/200\n",
      "12/12 [==============================] - 1s 88ms/step - loss: 0.8167 - accuracy: 0.6589 - val_loss: 2.2971 - val_accuracy: 0.2664\n",
      "Epoch 52/200\n",
      "12/12 [==============================] - 1s 86ms/step - loss: 0.7951 - accuracy: 0.6797 - val_loss: 2.3560 - val_accuracy: 0.2768\n",
      "Epoch 53/200\n",
      "12/12 [==============================] - 1s 90ms/step - loss: 0.8144 - accuracy: 0.6693 - val_loss: 2.4373 - val_accuracy: 0.2768\n",
      "Epoch 54/200\n",
      "12/12 [==============================] - 1s 101ms/step - loss: 0.7851 - accuracy: 0.6849 - val_loss: 2.4008 - val_accuracy: 0.2595\n",
      "Epoch 55/200\n",
      "12/12 [==============================] - 1s 89ms/step - loss: 0.7391 - accuracy: 0.7188 - val_loss: 2.4469 - val_accuracy: 0.2595\n",
      "Epoch 56/200\n",
      "12/12 [==============================] - 1s 89ms/step - loss: 0.7365 - accuracy: 0.7101 - val_loss: 2.4630 - val_accuracy: 0.2561\n",
      "Epoch 57/200\n",
      "12/12 [==============================] - 1s 89ms/step - loss: 0.7384 - accuracy: 0.7127 - val_loss: 2.5002 - val_accuracy: 0.2457\n",
      "Epoch 58/200\n",
      "12/12 [==============================] - 1s 86ms/step - loss: 0.7242 - accuracy: 0.7205 - val_loss: 2.5281 - val_accuracy: 0.2734\n",
      "Epoch 59/200\n",
      "12/12 [==============================] - 1s 89ms/step - loss: 0.7465 - accuracy: 0.7057 - val_loss: 2.4841 - val_accuracy: 0.2249\n",
      "Epoch 60/200\n",
      "12/12 [==============================] - 1s 91ms/step - loss: 0.7451 - accuracy: 0.7083 - val_loss: 2.4162 - val_accuracy: 0.2664\n",
      "Epoch 61/200\n",
      "12/12 [==============================] - 1s 91ms/step - loss: 0.7074 - accuracy: 0.7214 - val_loss: 2.5707 - val_accuracy: 0.2630\n",
      "Epoch 62/200\n",
      "12/12 [==============================] - 1s 91ms/step - loss: 0.7352 - accuracy: 0.7118 - val_loss: 2.5223 - val_accuracy: 0.2803\n",
      "Epoch 63/200\n",
      "12/12 [==============================] - 1s 94ms/step - loss: 0.7024 - accuracy: 0.7196 - val_loss: 2.4944 - val_accuracy: 0.2457\n",
      "Epoch 64/200\n",
      "12/12 [==============================] - 1s 92ms/step - loss: 0.7101 - accuracy: 0.7153 - val_loss: 2.4964 - val_accuracy: 0.2595\n",
      "Epoch 65/200\n",
      "12/12 [==============================] - 1s 88ms/step - loss: 0.6842 - accuracy: 0.7378 - val_loss: 2.5216 - val_accuracy: 0.2561\n",
      "Epoch 66/200\n",
      "12/12 [==============================] - 1s 93ms/step - loss: 0.6774 - accuracy: 0.7378 - val_loss: 2.6501 - val_accuracy: 0.2734\n",
      "Epoch 67/200\n",
      "12/12 [==============================] - 1s 90ms/step - loss: 0.6832 - accuracy: 0.7283 - val_loss: 2.6863 - val_accuracy: 0.2872\n",
      "Epoch 68/200\n",
      "12/12 [==============================] - 1s 90ms/step - loss: 0.6555 - accuracy: 0.7595 - val_loss: 2.6774 - val_accuracy: 0.2595\n",
      "Epoch 69/200\n",
      "12/12 [==============================] - 1s 90ms/step - loss: 0.6460 - accuracy: 0.7700 - val_loss: 2.6740 - val_accuracy: 0.2353\n",
      "Epoch 70/200\n",
      "12/12 [==============================] - 1s 88ms/step - loss: 0.6622 - accuracy: 0.7396 - val_loss: 2.7530 - val_accuracy: 0.2630\n",
      "Epoch 71/200\n",
      "12/12 [==============================] - 1s 91ms/step - loss: 0.6553 - accuracy: 0.7483 - val_loss: 2.6682 - val_accuracy: 0.2768\n",
      "Epoch 72/200\n",
      "12/12 [==============================] - 1s 89ms/step - loss: 0.6575 - accuracy: 0.7569 - val_loss: 2.7822 - val_accuracy: 0.2353\n",
      "Epoch 73/200\n",
      "12/12 [==============================] - 1s 90ms/step - loss: 0.6424 - accuracy: 0.7500 - val_loss: 2.7671 - val_accuracy: 0.2561\n",
      "Epoch 74/200\n",
      "12/12 [==============================] - 1s 87ms/step - loss: 0.6413 - accuracy: 0.7509 - val_loss: 2.8667 - val_accuracy: 0.2699\n",
      "Epoch 75/200\n",
      "12/12 [==============================] - 1s 87ms/step - loss: 0.6317 - accuracy: 0.7743 - val_loss: 2.8000 - val_accuracy: 0.2595\n",
      "Epoch 76/200\n",
      "12/12 [==============================] - 1s 87ms/step - loss: 0.6208 - accuracy: 0.7752 - val_loss: 2.8647 - val_accuracy: 0.2699\n",
      "Epoch 77/200\n",
      "12/12 [==============================] - 1s 86ms/step - loss: 0.6076 - accuracy: 0.7717 - val_loss: 2.8738 - val_accuracy: 0.2734\n",
      "Epoch 78/200\n",
      "12/12 [==============================] - 1s 87ms/step - loss: 0.6254 - accuracy: 0.7691 - val_loss: 2.8476 - val_accuracy: 0.2630\n",
      "Epoch 79/200\n",
      "12/12 [==============================] - 1s 88ms/step - loss: 0.6097 - accuracy: 0.7630 - val_loss: 2.9587 - val_accuracy: 0.2768\n",
      "Epoch 80/200\n",
      "12/12 [==============================] - 1s 88ms/step - loss: 0.5961 - accuracy: 0.7760 - val_loss: 2.8793 - val_accuracy: 0.2595\n",
      "Epoch 81/200\n",
      "12/12 [==============================] - 1s 88ms/step - loss: 0.6002 - accuracy: 0.7943 - val_loss: 3.0789 - val_accuracy: 0.2699\n",
      "Epoch 82/200\n",
      "12/12 [==============================] - 1s 84ms/step - loss: 0.5964 - accuracy: 0.7960 - val_loss: 3.0123 - val_accuracy: 0.2699\n",
      "Epoch 83/200\n",
      "12/12 [==============================] - 1s 87ms/step - loss: 0.6094 - accuracy: 0.7778 - val_loss: 2.8610 - val_accuracy: 0.2561\n",
      "Epoch 84/200\n",
      "12/12 [==============================] - 1s 89ms/step - loss: 0.6087 - accuracy: 0.7839 - val_loss: 2.8346 - val_accuracy: 0.2630\n",
      "Epoch 85/200\n",
      "12/12 [==============================] - 1s 88ms/step - loss: 0.6179 - accuracy: 0.7769 - val_loss: 2.7752 - val_accuracy: 0.2803\n",
      "Epoch 86/200\n",
      "12/12 [==============================] - 1s 89ms/step - loss: 0.5646 - accuracy: 0.8056 - val_loss: 2.9441 - val_accuracy: 0.2699\n",
      "Epoch 87/200\n",
      "12/12 [==============================] - 1s 94ms/step - loss: 0.5959 - accuracy: 0.7812 - val_loss: 3.0010 - val_accuracy: 0.2595\n",
      "Epoch 88/200\n",
      "12/12 [==============================] - 1s 90ms/step - loss: 0.6070 - accuracy: 0.7969 - val_loss: 2.9111 - val_accuracy: 0.2595\n",
      "Epoch 89/200\n",
      "12/12 [==============================] - 1s 88ms/step - loss: 0.5681 - accuracy: 0.7917 - val_loss: 2.9429 - val_accuracy: 0.2422\n",
      "Epoch 90/200\n",
      "12/12 [==============================] - 1s 87ms/step - loss: 0.5610 - accuracy: 0.8038 - val_loss: 3.0364 - val_accuracy: 0.2664\n",
      "Epoch 91/200\n",
      "12/12 [==============================] - 1s 91ms/step - loss: 0.5597 - accuracy: 0.8030 - val_loss: 3.0138 - val_accuracy: 0.2630\n",
      "Epoch 92/200\n",
      "12/12 [==============================] - 1s 91ms/step - loss: 0.5547 - accuracy: 0.8125 - val_loss: 3.0103 - val_accuracy: 0.2561\n",
      "Epoch 93/200\n",
      "12/12 [==============================] - 1s 86ms/step - loss: 0.5464 - accuracy: 0.8134 - val_loss: 3.0084 - val_accuracy: 0.2699\n",
      "Epoch 94/200\n",
      "12/12 [==============================] - 1s 87ms/step - loss: 0.5655 - accuracy: 0.8021 - val_loss: 2.9302 - val_accuracy: 0.2803\n",
      "Epoch 95/200\n",
      "12/12 [==============================] - 1s 86ms/step - loss: 0.5421 - accuracy: 0.8116 - val_loss: 3.0506 - val_accuracy: 0.2803\n",
      "Epoch 96/200\n",
      "12/12 [==============================] - 1s 87ms/step - loss: 0.5171 - accuracy: 0.8151 - val_loss: 3.1647 - val_accuracy: 0.2768\n",
      "Epoch 97/200\n",
      "12/12 [==============================] - 1s 90ms/step - loss: 0.5159 - accuracy: 0.8030 - val_loss: 3.2522 - val_accuracy: 0.2664\n",
      "Epoch 98/200\n",
      "12/12 [==============================] - 1s 92ms/step - loss: 0.5327 - accuracy: 0.8194 - val_loss: 3.2142 - val_accuracy: 0.2526\n",
      "Epoch 99/200\n",
      "12/12 [==============================] - 1s 94ms/step - loss: 0.5073 - accuracy: 0.8247 - val_loss: 3.2295 - val_accuracy: 0.2699\n",
      "Epoch 100/200\n",
      "12/12 [==============================] - 1s 90ms/step - loss: 0.4989 - accuracy: 0.8281 - val_loss: 3.3323 - val_accuracy: 0.2768\n",
      "Epoch 101/200\n",
      "12/12 [==============================] - 1s 90ms/step - loss: 0.5037 - accuracy: 0.8325 - val_loss: 3.2788 - val_accuracy: 0.2734\n",
      "Epoch 102/200\n",
      "12/12 [==============================] - 1s 89ms/step - loss: 0.5111 - accuracy: 0.8168 - val_loss: 3.3098 - val_accuracy: 0.2734\n",
      "Epoch 103/200\n",
      "12/12 [==============================] - 1s 90ms/step - loss: 0.5239 - accuracy: 0.8238 - val_loss: 3.1997 - val_accuracy: 0.2768\n",
      "Epoch 104/200\n",
      "12/12 [==============================] - 1s 89ms/step - loss: 0.5147 - accuracy: 0.8160 - val_loss: 3.2554 - val_accuracy: 0.2630\n",
      "Epoch 105/200\n",
      "12/12 [==============================] - 1s 92ms/step - loss: 0.5212 - accuracy: 0.8203 - val_loss: 3.2721 - val_accuracy: 0.2803\n",
      "Epoch 106/200\n",
      "12/12 [==============================] - 1s 89ms/step - loss: 0.5010 - accuracy: 0.8247 - val_loss: 3.2726 - val_accuracy: 0.2664\n",
      "Epoch 107/200\n",
      "12/12 [==============================] - 1s 89ms/step - loss: 0.4913 - accuracy: 0.8325 - val_loss: 3.3583 - val_accuracy: 0.2699\n",
      "Epoch 108/200\n",
      "12/12 [==============================] - 1s 90ms/step - loss: 0.4744 - accuracy: 0.8446 - val_loss: 3.4171 - val_accuracy: 0.2664\n",
      "Epoch 109/200\n",
      "12/12 [==============================] - 1s 87ms/step - loss: 0.4858 - accuracy: 0.8411 - val_loss: 3.3969 - val_accuracy: 0.2595\n",
      "Epoch 110/200\n",
      "12/12 [==============================] - 1s 94ms/step - loss: 0.5068 - accuracy: 0.8238 - val_loss: 3.2839 - val_accuracy: 0.2803\n",
      "Epoch 111/200\n",
      "12/12 [==============================] - 1s 87ms/step - loss: 0.4683 - accuracy: 0.8507 - val_loss: 3.3200 - val_accuracy: 0.2734\n",
      "Epoch 112/200\n",
      "12/12 [==============================] - 1s 87ms/step - loss: 0.4766 - accuracy: 0.8351 - val_loss: 3.4243 - val_accuracy: 0.2907\n",
      "Epoch 113/200\n",
      "12/12 [==============================] - 1s 90ms/step - loss: 0.4721 - accuracy: 0.8429 - val_loss: 3.4484 - val_accuracy: 0.3010\n",
      "Epoch 114/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12/12 [==============================] - 1s 88ms/step - loss: 0.4971 - accuracy: 0.8255 - val_loss: 3.3938 - val_accuracy: 0.3010\n",
      "Epoch 115/200\n",
      "12/12 [==============================] - 1s 85ms/step - loss: 0.4856 - accuracy: 0.8394 - val_loss: 3.4364 - val_accuracy: 0.2699\n",
      "Epoch 116/200\n",
      "12/12 [==============================] - 1s 86ms/step - loss: 0.4535 - accuracy: 0.8481 - val_loss: 3.5213 - val_accuracy: 0.2941\n",
      "Epoch 117/200\n",
      "12/12 [==============================] - 1s 89ms/step - loss: 0.4601 - accuracy: 0.8394 - val_loss: 3.5510 - val_accuracy: 0.2630\n",
      "Epoch 118/200\n",
      "12/12 [==============================] - 1s 87ms/step - loss: 0.4513 - accuracy: 0.8455 - val_loss: 3.5493 - val_accuracy: 0.2630\n",
      "Epoch 119/200\n",
      "12/12 [==============================] - 1s 87ms/step - loss: 0.4801 - accuracy: 0.8472 - val_loss: 3.5659 - val_accuracy: 0.2699\n",
      "Epoch 120/200\n",
      "12/12 [==============================] - 1s 88ms/step - loss: 0.4577 - accuracy: 0.8429 - val_loss: 3.4982 - val_accuracy: 0.2734\n",
      "Epoch 121/200\n",
      "12/12 [==============================] - 1s 86ms/step - loss: 0.4513 - accuracy: 0.8611 - val_loss: 3.5026 - val_accuracy: 0.2595\n",
      "Epoch 122/200\n",
      "12/12 [==============================] - 1s 87ms/step - loss: 0.4508 - accuracy: 0.8438 - val_loss: 3.5673 - val_accuracy: 0.2734\n",
      "Epoch 123/200\n",
      "12/12 [==============================] - 1s 85ms/step - loss: 0.4416 - accuracy: 0.8464 - val_loss: 3.5144 - val_accuracy: 0.2561\n",
      "Epoch 124/200\n",
      "12/12 [==============================] - 1s 87ms/step - loss: 0.4306 - accuracy: 0.8602 - val_loss: 3.6322 - val_accuracy: 0.2803\n",
      "Epoch 125/200\n",
      "12/12 [==============================] - 1s 88ms/step - loss: 0.4298 - accuracy: 0.8637 - val_loss: 3.6349 - val_accuracy: 0.2837\n",
      "Epoch 126/200\n",
      "12/12 [==============================] - 1s 92ms/step - loss: 0.4419 - accuracy: 0.8550 - val_loss: 3.5582 - val_accuracy: 0.2837\n",
      "Epoch 127/200\n",
      "12/12 [==============================] - 1s 98ms/step - loss: 0.4433 - accuracy: 0.8472 - val_loss: 3.4660 - val_accuracy: 0.2837\n",
      "Epoch 128/200\n",
      "12/12 [==============================] - 1s 89ms/step - loss: 0.4483 - accuracy: 0.8446 - val_loss: 3.4872 - val_accuracy: 0.2941\n",
      "Epoch 129/200\n",
      "12/12 [==============================] - 1s 84ms/step - loss: 0.4549 - accuracy: 0.8429 - val_loss: 3.8061 - val_accuracy: 0.2561\n",
      "Epoch 130/200\n",
      "12/12 [==============================] - 1s 85ms/step - loss: 0.4555 - accuracy: 0.8542 - val_loss: 3.4784 - val_accuracy: 0.2768\n",
      "Epoch 131/200\n",
      "12/12 [==============================] - 1s 88ms/step - loss: 0.4377 - accuracy: 0.8568 - val_loss: 3.5781 - val_accuracy: 0.2837\n",
      "Epoch 132/200\n",
      "12/12 [==============================] - 1s 88ms/step - loss: 0.4432 - accuracy: 0.8516 - val_loss: 3.5916 - val_accuracy: 0.2907\n",
      "Epoch 133/200\n",
      "12/12 [==============================] - 1s 88ms/step - loss: 0.4068 - accuracy: 0.8620 - val_loss: 3.7632 - val_accuracy: 0.2803\n",
      "Epoch 134/200\n",
      "12/12 [==============================] - 1s 88ms/step - loss: 0.3995 - accuracy: 0.8681 - val_loss: 3.7984 - val_accuracy: 0.2630\n",
      "Epoch 135/200\n",
      "12/12 [==============================] - 1s 85ms/step - loss: 0.4241 - accuracy: 0.8655 - val_loss: 3.8004 - val_accuracy: 0.2699\n",
      "Epoch 136/200\n",
      "12/12 [==============================] - 1s 83ms/step - loss: 0.3926 - accuracy: 0.8655 - val_loss: 3.9163 - val_accuracy: 0.2664\n",
      "Epoch 137/200\n",
      "12/12 [==============================] - 1s 93ms/step - loss: 0.4056 - accuracy: 0.8663 - val_loss: 3.7934 - val_accuracy: 0.2595\n",
      "Epoch 138/200\n",
      "12/12 [==============================] - 1s 93ms/step - loss: 0.4012 - accuracy: 0.8576 - val_loss: 3.7619 - val_accuracy: 0.2734\n",
      "Epoch 139/200\n",
      "12/12 [==============================] - 1s 93ms/step - loss: 0.3962 - accuracy: 0.8637 - val_loss: 3.9635 - val_accuracy: 0.2561\n",
      "Epoch 140/200\n",
      "12/12 [==============================] - 1s 90ms/step - loss: 0.3996 - accuracy: 0.8655 - val_loss: 3.9472 - val_accuracy: 0.2699\n",
      "Epoch 141/200\n",
      "12/12 [==============================] - 1s 89ms/step - loss: 0.3820 - accuracy: 0.8802 - val_loss: 3.8851 - val_accuracy: 0.2803\n",
      "Epoch 142/200\n",
      "12/12 [==============================] - 1s 89ms/step - loss: 0.3818 - accuracy: 0.8759 - val_loss: 3.8207 - val_accuracy: 0.2941\n",
      "Epoch 143/200\n",
      "12/12 [==============================] - 1s 88ms/step - loss: 0.3737 - accuracy: 0.8828 - val_loss: 3.9152 - val_accuracy: 0.2768\n",
      "Epoch 144/200\n",
      "12/12 [==============================] - 1s 86ms/step - loss: 0.3765 - accuracy: 0.8750 - val_loss: 4.0565 - val_accuracy: 0.2907\n",
      "Epoch 145/200\n",
      "12/12 [==============================] - 1s 87ms/step - loss: 0.3828 - accuracy: 0.8776 - val_loss: 4.1454 - val_accuracy: 0.2699\n",
      "Epoch 146/200\n",
      "12/12 [==============================] - 1s 86ms/step - loss: 0.3707 - accuracy: 0.8811 - val_loss: 3.9564 - val_accuracy: 0.2941\n",
      "Epoch 147/200\n",
      "12/12 [==============================] - 1s 89ms/step - loss: 0.3593 - accuracy: 0.8750 - val_loss: 4.0528 - val_accuracy: 0.3010\n",
      "Epoch 148/200\n",
      "12/12 [==============================] - 1s 92ms/step - loss: 0.3552 - accuracy: 0.8950 - val_loss: 4.0823 - val_accuracy: 0.2907\n",
      "Epoch 149/200\n",
      "12/12 [==============================] - 1s 89ms/step - loss: 0.3739 - accuracy: 0.8776 - val_loss: 4.2239 - val_accuracy: 0.2803\n",
      "Epoch 150/200\n",
      "12/12 [==============================] - 1s 92ms/step - loss: 0.3750 - accuracy: 0.8750 - val_loss: 4.0313 - val_accuracy: 0.2630\n",
      "Epoch 151/200\n",
      "12/12 [==============================] - 1s 91ms/step - loss: 0.3678 - accuracy: 0.8793 - val_loss: 3.9903 - val_accuracy: 0.2803\n",
      "Epoch 152/200\n",
      "12/12 [==============================] - 1s 92ms/step - loss: 0.3845 - accuracy: 0.8828 - val_loss: 4.2945 - val_accuracy: 0.2664\n",
      "Epoch 153/200\n",
      "12/12 [==============================] - 1s 98ms/step - loss: 0.3860 - accuracy: 0.8785 - val_loss: 4.0322 - val_accuracy: 0.2734\n",
      "Epoch 154/200\n",
      "12/12 [==============================] - 1s 91ms/step - loss: 0.3581 - accuracy: 0.8932 - val_loss: 4.0275 - val_accuracy: 0.3010\n",
      "Epoch 155/200\n",
      "12/12 [==============================] - 1s 93ms/step - loss: 0.3587 - accuracy: 0.8854 - val_loss: 4.0824 - val_accuracy: 0.2699\n",
      "Epoch 156/200\n",
      "12/12 [==============================] - 1s 93ms/step - loss: 0.3532 - accuracy: 0.8854 - val_loss: 4.2645 - val_accuracy: 0.2595\n",
      "Epoch 157/200\n",
      "12/12 [==============================] - 1s 90ms/step - loss: 0.3693 - accuracy: 0.8750 - val_loss: 4.3539 - val_accuracy: 0.2561\n",
      "Epoch 158/200\n",
      "12/12 [==============================] - 1s 88ms/step - loss: 0.3860 - accuracy: 0.8672 - val_loss: 4.0750 - val_accuracy: 0.2734\n",
      "Epoch 159/200\n",
      "12/12 [==============================] - 1s 89ms/step - loss: 0.4119 - accuracy: 0.8628 - val_loss: 4.0477 - val_accuracy: 0.2630\n",
      "Epoch 160/200\n",
      "12/12 [==============================] - 1s 92ms/step - loss: 0.3610 - accuracy: 0.8733 - val_loss: 4.1042 - val_accuracy: 0.2630\n",
      "Epoch 161/200\n",
      "12/12 [==============================] - 1s 90ms/step - loss: 0.3477 - accuracy: 0.8889 - val_loss: 4.1072 - val_accuracy: 0.2803\n",
      "Epoch 162/200\n",
      "12/12 [==============================] - 1s 90ms/step - loss: 0.3306 - accuracy: 0.8950 - val_loss: 4.1225 - val_accuracy: 0.2768\n",
      "Epoch 163/200\n",
      "12/12 [==============================] - 1s 87ms/step - loss: 0.3354 - accuracy: 0.8924 - val_loss: 4.1212 - val_accuracy: 0.2768\n",
      "Epoch 164/200\n",
      "12/12 [==============================] - 1s 85ms/step - loss: 0.3517 - accuracy: 0.8906 - val_loss: 4.0652 - val_accuracy: 0.2907\n",
      "Epoch 165/200\n",
      "12/12 [==============================] - 1s 86ms/step - loss: 0.3476 - accuracy: 0.8993 - val_loss: 4.3068 - val_accuracy: 0.2664\n",
      "Epoch 166/200\n",
      "12/12 [==============================] - 1s 95ms/step - loss: 0.3380 - accuracy: 0.8906 - val_loss: 4.2258 - val_accuracy: 0.2734\n",
      "Epoch 167/200\n",
      "12/12 [==============================] - 1s 96ms/step - loss: 0.3320 - accuracy: 0.8984 - val_loss: 4.2158 - val_accuracy: 0.2768\n",
      "Epoch 168/200\n",
      "12/12 [==============================] - 1s 91ms/step - loss: 0.3602 - accuracy: 0.8767 - val_loss: 4.0721 - val_accuracy: 0.2976\n",
      "Epoch 169/200\n",
      "12/12 [==============================] - 1s 92ms/step - loss: 0.3320 - accuracy: 0.8976 - val_loss: 4.3278 - val_accuracy: 0.2699\n",
      "Epoch 170/200\n",
      "12/12 [==============================] - 1s 90ms/step - loss: 0.3077 - accuracy: 0.9097 - val_loss: 4.4651 - val_accuracy: 0.2664\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 171/200\n",
      "12/12 [==============================] - 1s 88ms/step - loss: 0.3308 - accuracy: 0.8906 - val_loss: 4.4867 - val_accuracy: 0.2768\n",
      "Epoch 172/200\n",
      "12/12 [==============================] - 1s 88ms/step - loss: 0.3314 - accuracy: 0.8837 - val_loss: 4.4669 - val_accuracy: 0.2768\n",
      "Epoch 173/200\n",
      "12/12 [==============================] - 1s 90ms/step - loss: 0.3082 - accuracy: 0.9175 - val_loss: 4.6496 - val_accuracy: 0.2630\n",
      "Epoch 174/200\n",
      "12/12 [==============================] - 1s 91ms/step - loss: 0.3304 - accuracy: 0.8837 - val_loss: 4.4014 - val_accuracy: 0.2664\n",
      "Epoch 175/200\n",
      "12/12 [==============================] - 1s 93ms/step - loss: 0.3124 - accuracy: 0.9002 - val_loss: 4.3443 - val_accuracy: 0.2768\n",
      "Epoch 176/200\n",
      "12/12 [==============================] - 1s 92ms/step - loss: 0.3004 - accuracy: 0.9045 - val_loss: 4.6375 - val_accuracy: 0.2699\n",
      "Epoch 177/200\n",
      "12/12 [==============================] - 1s 91ms/step - loss: 0.3352 - accuracy: 0.8967 - val_loss: 4.4304 - val_accuracy: 0.2803\n",
      "Epoch 178/200\n",
      "12/12 [==============================] - 1s 90ms/step - loss: 0.3177 - accuracy: 0.8967 - val_loss: 4.5107 - val_accuracy: 0.2664\n",
      "Epoch 179/200\n",
      "12/12 [==============================] - 1s 91ms/step - loss: 0.2885 - accuracy: 0.9158 - val_loss: 4.4735 - val_accuracy: 0.2907\n",
      "Epoch 180/200\n",
      "12/12 [==============================] - 1s 89ms/step - loss: 0.2866 - accuracy: 0.9010 - val_loss: 4.6707 - val_accuracy: 0.2734\n",
      "Epoch 181/200\n",
      "12/12 [==============================] - 1s 91ms/step - loss: 0.3045 - accuracy: 0.9002 - val_loss: 4.6103 - val_accuracy: 0.2699\n",
      "Epoch 182/200\n",
      "12/12 [==============================] - 1s 92ms/step - loss: 0.2971 - accuracy: 0.9115 - val_loss: 4.5571 - val_accuracy: 0.2872\n",
      "Epoch 183/200\n",
      "12/12 [==============================] - 1s 90ms/step - loss: 0.3037 - accuracy: 0.9062 - val_loss: 4.6825 - val_accuracy: 0.2699\n",
      "Epoch 184/200\n",
      "12/12 [==============================] - 1s 90ms/step - loss: 0.3218 - accuracy: 0.8976 - val_loss: 4.6149 - val_accuracy: 0.2803\n",
      "Epoch 185/200\n",
      "12/12 [==============================] - 1s 88ms/step - loss: 0.3262 - accuracy: 0.8950 - val_loss: 4.5720 - val_accuracy: 0.2595\n",
      "Epoch 186/200\n",
      "12/12 [==============================] - 1s 89ms/step - loss: 0.3239 - accuracy: 0.8941 - val_loss: 4.4423 - val_accuracy: 0.2699\n",
      "Epoch 187/200\n",
      "12/12 [==============================] - 1s 89ms/step - loss: 0.3100 - accuracy: 0.8967 - val_loss: 4.8074 - val_accuracy: 0.2664\n",
      "Epoch 188/200\n",
      "12/12 [==============================] - 1s 92ms/step - loss: 0.3049 - accuracy: 0.9028 - val_loss: 4.5237 - val_accuracy: 0.2941\n",
      "Epoch 189/200\n",
      "12/12 [==============================] - 1s 90ms/step - loss: 0.3025 - accuracy: 0.9062 - val_loss: 4.5735 - val_accuracy: 0.2803\n",
      "Epoch 190/200\n",
      "12/12 [==============================] - 1s 89ms/step - loss: 0.3015 - accuracy: 0.8950 - val_loss: 4.7877 - val_accuracy: 0.2734\n",
      "Epoch 191/200\n",
      "12/12 [==============================] - 1s 86ms/step - loss: 0.2980 - accuracy: 0.9132 - val_loss: 4.8990 - val_accuracy: 0.2491\n",
      "Epoch 192/200\n",
      "12/12 [==============================] - 1s 89ms/step - loss: 0.2798 - accuracy: 0.9149 - val_loss: 4.8512 - val_accuracy: 0.2630\n",
      "Epoch 193/200\n",
      "12/12 [==============================] - 1s 95ms/step - loss: 0.2747 - accuracy: 0.9149 - val_loss: 4.7558 - val_accuracy: 0.2526\n",
      "Epoch 194/200\n",
      "12/12 [==============================] - 1s 98ms/step - loss: 0.3194 - accuracy: 0.8906 - val_loss: 4.8104 - val_accuracy: 0.2561\n",
      "Epoch 195/200\n",
      "12/12 [==============================] - 1s 94ms/step - loss: 0.3062 - accuracy: 0.9028 - val_loss: 4.7241 - val_accuracy: 0.2630\n",
      "Epoch 196/200\n",
      "12/12 [==============================] - 1s 95ms/step - loss: 0.2689 - accuracy: 0.9210 - val_loss: 4.7640 - val_accuracy: 0.2734\n",
      "Epoch 197/200\n",
      "12/12 [==============================] - 1s 88ms/step - loss: 0.2862 - accuracy: 0.9045 - val_loss: 4.8600 - val_accuracy: 0.2803\n",
      "Epoch 198/200\n",
      "12/12 [==============================] - 1s 91ms/step - loss: 0.2904 - accuracy: 0.9062 - val_loss: 4.8643 - val_accuracy: 0.2803\n",
      "Epoch 199/200\n",
      "12/12 [==============================] - 1s 88ms/step - loss: 0.2861 - accuracy: 0.9054 - val_loss: 4.7410 - val_accuracy: 0.2561\n",
      "Epoch 200/200\n",
      "12/12 [==============================] - 1s 88ms/step - loss: 0.2858 - accuracy: 0.9149 - val_loss: 4.8017 - val_accuracy: 0.2595\n"
     ]
    }
   ],
   "source": [
    "#treinar a rede neural convolucional\n",
    "history = Dcnn.fit(X_tensor, y, batch_size = tamanho_batch, epochs = qtd_epocas, verbose = 1, validation_split = 0.2, shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "564e3903",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ckpt-1'"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# salvar o checkpoint\n",
    "ckpt_manager.save()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1eebdd41",
   "metadata": {},
   "source": [
    "## avaliação do modelo de rede neural convolucional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "1c91397d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# carregar os dados de teste\n",
    "with open(os.path.join('data', 'dataset_param_a_test.pkl'), 'rb') as f:\n",
    "    df_test = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "523b2163",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['tf_idf', 'wes', 'wes_own', 'classes_param_a_1', 'classes_param_b_1',\n",
       "       'classes_param_c_1'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "deab1847",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(481, 793, 100)\n",
      "(481,)\n"
     ]
    }
   ],
   "source": [
    "#obtém os dados do conjunto de teste\n",
    "X_test = df_test.iloc[:, 2].values\n",
    "X_test = tf.keras.preprocessing.sequence.pad_sequences(X_test, value = 0, padding = 'post', maxlen = max_len)\n",
    "X_test = tf.convert_to_tensor(X_test, dtype=tf.float32)\n",
    "print(X_test.shape)\n",
    "y_test = np.array(df_test.iloc[:, 3].values)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d03456bc",
   "metadata": {},
   "source": [
    "O trecho results = Dcnn.evaluate(X_test, y_test, batch_size=tamanho_batch) é utilizado para avaliar o desempenho de um modelo de rede neural convolucional (CNN) chamado Dcnn em um conjunto de dados de teste X_test e rótulos de teste y_test. A função evaluate do objeto Dcnn calcula a perda (loss) e a acurácia (accuracy) do modelo no conjunto de teste, e armazena essas métricas na variável results. O parâmetro batch_size é usado para definir o tamanho do lote (batch size) a ser usado para a avaliação do modelo. Geralmente, quanto maior o tamanho do lote, mais rápido o processo de avaliação, mas isso pode levar a um aumento do uso de memória e possíveis limitações computacionais."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "8a815644",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 33ms/step - loss: 4.1610 - accuracy: 0.3035\n",
      "[4.160977840423584, 0.30353429913520813]\n"
     ]
    }
   ],
   "source": [
    "#avalia o modelo com o conjunto de teste\n",
    "results = Dcnn.evaluate(X_test, y_test, batch_size=tamanho_batch)\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "fbc11eea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(None, 128)\n",
      "16/16 [==============================] - 0s 11ms/step\n"
     ]
    }
   ],
   "source": [
    "y_pred_test = Dcnn.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "9102ecd6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.0040009e-03, 9.9392408e-01, 3.4654024e-03, 1.6065661e-03],\n",
       "       [9.9502903e-01, 1.6910007e-04, 4.4499536e-04, 4.3567875e-03],\n",
       "       [7.7686983e-01, 2.6583148e-04, 2.2165602e-01, 1.2083526e-03],\n",
       "       ...,\n",
       "       [3.8711768e-02, 1.4757935e-03, 8.5055089e-04, 9.5896184e-01],\n",
       "       [3.3683122e-05, 3.3576097e-02, 4.6109649e-06, 9.6638560e-01],\n",
       "       [9.9737513e-01, 3.9036860e-04, 6.4778520e-04, 1.5867956e-03]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "edbe2ee4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 0, 2, 2, 3, 2, 1, 1, 0, 1, 2, 2, 0, 0, 3, 0, 3, 2, 2, 3, 1,\n",
       "       2, 0, 1, 2, 1, 0, 1, 0, 1, 3, 1, 1, 2, 1, 0, 0, 1, 0, 0, 2, 1, 1,\n",
       "       1, 1, 2, 3, 1, 3, 1, 0, 0, 2, 3, 1, 1, 0, 2, 0, 1, 1, 2, 2, 2, 2,\n",
       "       1, 1, 3, 1, 2, 3, 3, 0, 2, 3, 2, 2, 2, 2, 2, 3, 0, 3, 2, 3, 0, 0,\n",
       "       3, 0, 1, 3, 2, 0, 2, 3, 2, 1, 2, 1, 1, 1, 2, 3, 0, 0, 3, 1, 0, 1,\n",
       "       2, 0, 2, 0, 3, 1, 0, 2, 2, 1, 3, 0, 2, 0, 3, 2, 3, 0, 2, 2, 3, 2,\n",
       "       0, 0, 1, 0, 2, 1, 3, 1, 0, 3, 3, 1, 1, 2, 0, 1, 0, 1, 2, 2, 1, 2,\n",
       "       1, 2, 2, 1, 0, 1, 1, 1, 3, 0, 2, 0, 1, 3, 0, 0, 0, 3, 0, 1, 0, 1,\n",
       "       2, 1, 2, 2, 3, 2, 1, 2, 1, 1, 2, 1, 1, 2, 3, 0, 1, 3, 2, 1, 1, 1,\n",
       "       2, 1, 0, 0, 0, 1, 3, 1, 0, 2, 2, 0, 0, 2, 2, 3, 2, 0, 3, 2, 1, 1,\n",
       "       3, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 3, 2, 0, 3, 1, 1, 2, 1, 0, 1, 2,\n",
       "       3, 1, 3, 1, 1, 2, 3, 3, 2, 1, 1, 2, 3, 1, 0, 1, 3, 0, 2, 0, 0, 1,\n",
       "       1, 2, 2, 2, 3, 3, 0, 3, 2, 3, 1, 2, 3, 1, 1, 1, 3, 0, 1, 1, 3, 2,\n",
       "       2, 3, 2, 2, 2, 0, 1, 2, 1, 2, 2, 0, 2, 3, 3, 0, 0, 2, 0, 1, 1, 2,\n",
       "       2, 3, 0, 2, 1, 0, 3, 3, 3, 1, 1, 1, 2, 0, 3, 1, 0, 0, 0, 0, 0, 1,\n",
       "       2, 0, 3, 0, 0, 2, 3, 2, 1, 1, 1, 0, 1, 3, 0, 2, 0, 0, 1, 0, 1, 0,\n",
       "       1, 2, 3, 2, 1, 1, 2, 1, 0, 0, 2, 0, 3, 3, 1, 2, 1, 3, 1, 3, 0, 1,\n",
       "       3, 0, 2, 1, 2, 1, 2, 2, 0, 3, 3, 3, 0, 0, 2, 3, 0, 1, 1, 3, 0, 2,\n",
       "       2, 0, 1, 1, 1, 3, 1, 1, 0, 0, 0, 2, 0, 0, 1, 0, 2, 0, 0, 1, 1, 0,\n",
       "       1, 2, 3, 3, 3, 1, 0, 3, 2, 1, 2, 0, 0, 0, 0, 1, 2, 2, 3, 1, 0, 1,\n",
       "       1, 1, 0, 2, 3, 2, 2, 3, 1, 1, 1, 2, 1, 2, 0, 1, 1, 0, 1, 2, 1, 2,\n",
       "       0, 2, 1, 1, 2, 1, 0, 2, 2, 0, 2, 3, 1, 1, 2, 3, 3, 3, 0],\n",
       "      dtype=int64)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#valores previstos\n",
    "y_pred_test_values = []\n",
    "for y_ in y_pred_test:\n",
    "    #obtem o valor máximo do array de probabilidades\n",
    "    y_pred_test_values.append(np.argmax(y_))\n",
    "\n",
    "y_pred_test_values = np.array(y_pred_test_values)\n",
    "y_pred_test_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "21cf5e74",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[35, 37, 29, 19],\n",
       "       [28, 44, 29, 19],\n",
       "       [24, 40, 37, 19],\n",
       "       [33, 28, 30, 30]], dtype=int64)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cm = confusion_matrix(y_test, y_pred_test_values)\n",
    "cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "a8f2c3ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "parâmetro de discriminação\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "print('parâmetro de discriminação')\n",
    "xlabels = ['<=1.581', '>1.581 e <=2.09', '>2.092 e <=2.735', '>2.735']\n",
    "ylabels = ['predito: <=1.581', '>1.581 e <=2.09', 'predito: >2.092 e <=2.735', 'predito:  >2.735']\n",
    "sns.heatmap(cm, annot=True, fmt = 'g', xticklabels = xlabels, yticklabels = ylabels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "c0562236",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.29      0.29      0.29       120\n",
      "           1       0.30      0.37      0.33       120\n",
      "           2       0.30      0.31      0.30       120\n",
      "           3       0.34      0.25      0.29       121\n",
      "\n",
      "    accuracy                           0.30       481\n",
      "   macro avg       0.31      0.30      0.30       481\n",
      "weighted avg       0.31      0.30      0.30       481\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_pred_test_values))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0422943b",
   "metadata": {},
   "source": [
    "Esses são resultados de métricas de avaliação de um modelo de classificação. \"Precision\" representa a proporção de exemplos positivos que o modelo classificou corretamente. \"Recall\" representa a proporção de exemplos positivos que o modelo conseguiu identificar. \"F1-score\" é a média harmônica entre precisão e recall, fornecendo uma métrica equilibrada que reflete tanto a precisão quanto a capacidade de identificação do modelo. \"Support\" representa o número de exemplos na classe.\n",
    "\n",
    "Com base nas métricas fornecidas, podemos ver que o modelo tem baixa precisão, baixo recall e baixo f1-score, o que indica que ele está tendo dificuldade em classificar corretamente os exemplos positivos e ainda não está conseguindo identificar a maioria deles, sendo que ele foi testado em 120 exemplos da classe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "2e09d1e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history.history.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "865e52ac",
   "metadata": {},
   "source": [
    "Ao comparar o erro de treinamento e o erro de validação em um gráfico, é possível realizar várias análises importantes. Algumas delas são:\n",
    "\n",
    "- Overfitting: Se o erro de treinamento estiver caindo enquanto o erro de validação estiver aumentando, é provável que o modelo esteja sofrendo de overfitting. Isso significa que o modelo está se ajustando muito bem aos dados de treinamento, mas não está generalizando bem para os dados de validação.\n",
    "\n",
    "- Underfitting: Se ambos os erros estiverem aumentando, é possível que o modelo esteja underfitting, ou seja, não está se ajustando suficientemente aos dados de treinamento e validação.\n",
    "\n",
    "- Ideal fit: Se o erro de treinamento estiver diminuindo enquanto o erro de validação estiver diminuindo, é provável que o modelo esteja se ajustando de maneira adequada aos dados de treinamento e validação, ou seja, o modelo está aprendendo e generalizando corretamente.\n",
    "\n",
    "Além disso, também é importante observar a velocidade de aprendizado, ou seja, quanto o erro está diminuindo com cada época. Uma diminuição muito lenta pode indicar que o modelo precisa de mais épocas ou que o tamanho do batch precisa ser ajustado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "c0c9f84c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x2ebcd1dec10>"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('Progresso de erro do modelo durante o treinamento e validação')\n",
    "plt.xlabel('Época')\n",
    "plt.ylabel('Erro')\n",
    "plt.legend(['Erro de treinamento', 'Erro de validação'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cac990c1",
   "metadata": {},
   "source": [
    "A análise dos gráficos de comparação da acurácia de treinamento e acurácia de validação pode fornecer informações importantes sobre o modelo e o seu desempenho. Aqui estão algumas das possíveis análises que se pode fazer:\n",
    "\n",
    "- Overfitting: Se o gráfico de treinamento mostra uma acurácia muito alta e o gráfico de validação mostra uma acurácia muito baixa, isso pode indicar overfitting, ou seja, o modelo está memorizando o conjunto de treinamento, mas não é geral o suficiente para prever corretamente dados desconhecidos.\n",
    "\n",
    "- Underfitting: Se ambos os gráficos de treinamento e validação mostram baixa acurácia, isso pode indicar sub-ajuste, ou seja, o modelo é muito simples e não está capturando a complexidade da relação entre as características e as classes.\n",
    "\n",
    "- Convergência: Se o gráfico de treinamento mostra uma tendência crescente na acurácia e o gráfico de validação mostra uma tendência estacionária, isso pode indicar que o modelo está convergindo e que mais épocas de treinamento não seriam úteis.\n",
    "\n",
    "- Viés: Se o gráfico de treinamento mostra uma acurácia muito alta, mas o gráfico de validação mostra uma acurácia muito baixa, isso pode indicar viés, ou seja, o modelo está otimizando a métrica de avaliação de forma inadequada e não está levando em conta todas as características do conjunto de dados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "ebd0e4cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x2ebce0546d0>"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('Progresso da acurácia do modelo durante o treinamento e validação')\n",
    "plt.xlabel('Época')\n",
    "plt.ylabel('Acurácia')\n",
    "plt.legend(['Acurácia de treino', 'Acurácia de validação'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0acf5bc0",
   "metadata": {},
   "source": [
    "O **método de bootstrap** é uma técnica para estimar a **incerteza** em métricas com base em **amostragem com reposição**. A idéia é que, ao realizarmos várias amostragens de nosso conjunto de dados com reposição, podemos obter diferentes valores para nossa métrica. Então, podemos estimar a variabilidade da nossa métrica e, portanto, seu desvio padrão.\n",
    "\n",
    "O método de bootstrap é frequentemente usado em métricas de modelos de machine learning, como precisão, recall e F1-score, para estimar o erro padrão. Isso pode ser útil para entender a incerteza em nossas métricas e para determinar se o desempenho de nossos modelos é estatisticamente significativo.\n",
    "\n",
    "O método de bootstrap é uma técnica estatística usada para estimar o **desvio padrão** de uma métrica de desempenho da rede neural. Ele pode ser comparado ao ato de tirar amostras aleatórias de uma população para entender a variação da população. Da mesma forma, o método de bootstrap tira amostras aleatórias do conjunto de dados usado para treinar a rede e, em seguida, avalia o desempenho da rede usando a métrica escolhida. Isso é feito várias vezes, e a variação na métrica é usada para estimar o desvio padrão da métrica. É uma maneira de avaliar a incerteza associada às métricas de desempenho da rede e ajuda a entender se a rede está realmente tendo desempenho melhor ou pior do que o esperado.\n",
    "\n",
    "O parâmetro \"B\" representa o número de vezes que o método bootstrap será aplicado para estimar o desvio padrão das métricas usadas para medir o desempenho da rede. Esse valor é usado para determinar o número de amostras aleatórias que serão selecionadas da base de dados de teste para realizar a avaliação do modelo. Quanto maior for o valor de \"B\", maior será a precisão da estimativa do desvio padrão, mas também aumentará o tempo de processamento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "bff3f486",
   "metadata": {},
   "outputs": [],
   "source": [
    "#função que realiza o método bootstrap\n",
    "def bootstrap(X_test, y_test, model, nn=False, B=250):\n",
    "    #Creating dictionary to store results\n",
    "    out={}\n",
    "    out['accuracy']=[]\n",
    "    out['macro avg']={}\n",
    "    out['macro avg']['f1-score']=[]\n",
    "    out['macro avg']['recall']=[]\n",
    "    out['macro avg']['precision']=[]\n",
    "    out['weighted avg']={}\n",
    "    out['weighted avg']['f1-score']=[]\n",
    "    out['weighted avg']['recall']=[]\n",
    "    out['weighted avg']['precision']=[]\n",
    "\n",
    "    #Running Bootstrap on the test set\n",
    "    for b in tqdm(range(B)):\n",
    "        ind = np.random.choice(range(y_test.shape[0]),y_test.shape[0])\n",
    "        X_test_boot, y_test_boot = X_test[ind,:], y_test[ind]\n",
    "\n",
    "        y_pred=model.predict(X_test_boot)\n",
    "        \n",
    "        if nn:\n",
    "            y_pred=np.argmax(y_pred,axis=1)\n",
    "            report=classification_report(y_test_boot, y_pred, labels=[0, 1, 2, 3], output_dict=True)\n",
    "        else:\n",
    "            report=classification_report(y_test_boot, y_pred, labels=[0, 1, 2, 3], output_dict=True)\n",
    "\n",
    "        out['accuracy'].append(report['accuracy'])\n",
    "        out['macro avg']['f1-score'].append(report['macro avg']['f1-score'])\n",
    "        out['macro avg']['recall'].append(report['macro avg']['recall'])\n",
    "        out['macro avg']['precision'].append(report['macro avg']['precision'])\n",
    "        out['weighted avg']['f1-score'].append(report['weighted avg']['f1-score'])\n",
    "        out['weighted avg']['recall'].append(report['weighted avg']['recall'])\n",
    "        out['weighted avg']['precision'].append(report['weighted avg']['precision'])\n",
    "\n",
    "    #Preparing output\n",
    "    y_pred=model.predict(X_test)\n",
    "    \n",
    "    if nn:\n",
    "        y_pred=np.argmax(y_pred,axis=1)\n",
    "        report=classification_report(y_test, y_pred, labels=[0, 1, 2, 3], output_dict=True)\n",
    "    else:\n",
    "        report=classification_report(y_test, y_pred, labels=[0, 1, 2, 3], output_dict=True)\n",
    "\n",
    "    out['accuracy'] = [report['accuracy'], np.std(out['accuracy'])]\n",
    "    out['macro avg']['f1-score'] = [report['macro avg']['f1-score'], np.std(out['macro avg']['f1-score'])] \n",
    "    out['macro avg']['recall'] = [report['macro avg']['recall'], np.std(out['macro avg']['recall'])] \n",
    "    out['macro avg']['precision'] = [report['macro avg']['precision'], np.std(out['macro avg']['precision'])] \n",
    "    out['weighted avg']['f1-score'] = [report['weighted avg']['f1-score'], np.std(out['weighted avg']['f1-score'])] \n",
    "    out['weighted avg']['recall'] = [report['weighted avg']['recall'], np.std(out['weighted avg']['recall'])] \n",
    "    out['weighted avg']['precision'] = [report['weighted avg']['precision'], np.std(out['weighted avg']['precision'])]\n",
    "    \n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "cfb4b93c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                                                          | 0/250 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 11ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|▎                                                                                 | 1/250 [00:00<01:23,  2.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 12ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  1%|▋                                                                                 | 2/250 [00:00<01:28,  2.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 12ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  1%|▉                                                                                 | 3/250 [00:01<01:28,  2.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 12ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  2%|█▎                                                                                | 4/250 [00:01<01:27,  2.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 11ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  2%|█▋                                                                                | 5/250 [00:01<01:26,  2.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 11ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  2%|█▉                                                                                | 6/250 [00:02<01:26,  2.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 11ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  3%|██▎                                                                               | 7/250 [00:02<01:26,  2.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 12ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  3%|██▌                                                                               | 8/250 [00:02<01:27,  2.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 11ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  4%|██▉                                                                               | 9/250 [00:03<01:25,  2.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 11ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  4%|███▏                                                                             | 10/250 [00:03<01:23,  2.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 14ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  4%|███▌                                                                             | 11/250 [00:03<01:26,  2.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 12ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  5%|███▉                                                                             | 12/250 [00:04<01:27,  2.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 11ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  5%|████▏                                                                            | 13/250 [00:04<01:24,  2.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 13ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  6%|████▌                                                                            | 14/250 [00:05<01:26,  2.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 11ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  6%|████▊                                                                            | 15/250 [00:05<01:23,  2.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 11ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  6%|█████▏                                                                           | 16/250 [00:05<01:21,  2.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 11ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  7%|█████▌                                                                           | 17/250 [00:06<01:22,  2.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 11ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  7%|█████▊                                                                           | 18/250 [00:06<01:20,  2.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 11ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  8%|██████▏                                                                          | 19/250 [00:06<01:19,  2.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 11ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  8%|██████▍                                                                          | 20/250 [00:07<01:21,  2.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 11ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  8%|██████▊                                                                          | 21/250 [00:07<01:19,  2.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 11ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  9%|███████▏                                                                         | 22/250 [00:07<01:18,  2.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 11ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  9%|███████▍                                                                         | 23/250 [00:08<01:20,  2.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 11ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 10%|███████▊                                                                         | 24/250 [00:08<01:18,  2.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 11ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 10%|████████                                                                         | 25/250 [00:08<01:17,  2.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 11ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 10%|████████▍                                                                        | 26/250 [00:09<01:16,  2.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 11ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 11%|████████▋                                                                        | 27/250 [00:09<01:15,  2.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 12ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 11%|█████████                                                                        | 28/250 [00:09<01:15,  2.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 11ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 12%|█████████▍                                                                       | 29/250 [00:10<01:17,  2.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 11ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 12%|█████████▋                                                                       | 30/250 [00:10<01:15,  2.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 13ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 12%|██████████                                                                       | 31/250 [00:10<01:16,  2.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 11ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 13%|██████████▎                                                                      | 32/250 [00:11<01:17,  2.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 11ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 13%|██████████▋                                                                      | 33/250 [00:11<01:16,  2.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 13ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 14%|███████████                                                                      | 34/250 [00:11<01:17,  2.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 11ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 14%|███████████▎                                                                     | 35/250 [00:12<01:16,  2.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 11ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 14%|███████████▋                                                                     | 36/250 [00:12<01:14,  2.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 12ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 15%|███████████▉                                                                     | 37/250 [00:13<01:15,  2.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 11ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 15%|████████████▎                                                                    | 38/250 [00:13<01:14,  2.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 11ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 16%|████████████▋                                                                    | 39/250 [00:13<01:13,  2.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 11ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 16%|████████████▉                                                                    | 40/250 [00:14<01:12,  2.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 11ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 16%|█████████████▎                                                                   | 41/250 [00:14<01:12,  2.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 11ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 17%|█████████████▌                                                                   | 42/250 [00:14<01:11,  2.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 11ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 17%|█████████████▉                                                                   | 43/250 [00:15<01:11,  2.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 11ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 18%|██████████████▎                                                                  | 44/250 [00:15<01:11,  2.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 11ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 18%|██████████████▌                                                                  | 45/250 [00:15<01:10,  2.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 11ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 18%|██████████████▉                                                                  | 46/250 [00:16<01:10,  2.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 11ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 19%|███████████████▏                                                                 | 47/250 [00:16<01:10,  2.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 11ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 19%|███████████████▌                                                                 | 48/250 [00:16<01:08,  2.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 11ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 20%|███████████████▉                                                                 | 49/250 [00:17<01:08,  2.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 11ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 20%|████████████████▏                                                                | 50/250 [00:17<01:08,  2.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 11ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 20%|████████████████▌                                                                | 51/250 [00:17<01:07,  2.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 12ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 21%|████████████████▊                                                                | 52/250 [00:18<01:07,  2.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 10ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 21%|█████████████████▏                                                               | 53/250 [00:18<01:07,  2.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 12ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 22%|█████████████████▍                                                               | 54/250 [00:18<01:07,  2.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 11ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 22%|█████████████████▊                                                               | 55/250 [00:19<01:07,  2.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 11ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 22%|██████████████████▏                                                              | 56/250 [00:19<01:07,  2.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 13ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 23%|██████████████████▍                                                              | 57/250 [00:19<01:07,  2.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 11ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 23%|██████████████████▊                                                              | 58/250 [00:20<01:06,  2.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 12ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 24%|███████████████████                                                              | 59/250 [00:20<01:07,  2.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 13ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 24%|███████████████████▍                                                             | 60/250 [00:20<01:07,  2.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 11ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 24%|███████████████████▊                                                             | 61/250 [00:21<01:06,  2.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 11ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 25%|████████████████████                                                             | 62/250 [00:21<01:06,  2.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 11ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 25%|████████████████████▍                                                            | 63/250 [00:22<01:05,  2.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 11ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 26%|████████████████████▋                                                            | 64/250 [00:22<01:04,  2.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 11ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 26%|█████████████████████                                                            | 65/250 [00:22<01:04,  2.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 12ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 26%|█████████████████████▍                                                           | 66/250 [00:23<01:04,  2.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 11ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 27%|█████████████████████▋                                                           | 67/250 [00:23<01:03,  2.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 11ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 27%|██████████████████████                                                           | 68/250 [00:23<01:04,  2.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 11ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 28%|██████████████████████▎                                                          | 69/250 [00:24<01:03,  2.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 11ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 28%|██████████████████████▋                                                          | 70/250 [00:24<01:02,  2.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 11ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 28%|███████████████████████                                                          | 71/250 [00:24<01:02,  2.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 11ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 29%|███████████████████████▎                                                         | 72/250 [00:25<01:02,  2.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 11ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 29%|███████████████████████▋                                                         | 73/250 [00:25<01:01,  2.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 12ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 30%|███████████████████████▉                                                         | 74/250 [00:25<01:02,  2.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 11ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 30%|████████████████████████▎                                                        | 75/250 [00:26<01:00,  2.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 11ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 30%|████████████████████████▌                                                        | 76/250 [00:26<00:59,  2.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 12ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 31%|████████████████████████▉                                                        | 77/250 [00:26<01:00,  2.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 11ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 31%|█████████████████████████▎                                                       | 78/250 [00:27<00:59,  2.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 11ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 32%|█████████████████████████▌                                                       | 79/250 [00:27<00:58,  2.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 16ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 32%|█████████████████████████▉                                                       | 80/250 [00:28<01:02,  2.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 10ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 32%|██████████████████████████▏                                                      | 81/250 [00:28<01:00,  2.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 11ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 33%|██████████████████████████▌                                                      | 82/250 [00:28<00:58,  2.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 11ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 33%|██████████████████████████▉                                                      | 83/250 [00:29<00:58,  2.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 11ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 34%|███████████████████████████▏                                                     | 84/250 [00:29<00:56,  2.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 11ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 34%|███████████████████████████▌                                                     | 85/250 [00:29<00:55,  2.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 11ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 34%|███████████████████████████▊                                                     | 86/250 [00:30<00:57,  2.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 11ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 35%|████████████████████████████▏                                                    | 87/250 [00:30<00:55,  2.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 11ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 35%|████████████████████████████▌                                                    | 88/250 [00:30<00:54,  2.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 11ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 36%|████████████████████████████▊                                                    | 89/250 [00:31<00:55,  2.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 11ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 36%|█████████████████████████████▏                                                   | 90/250 [00:31<00:55,  2.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 11ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 36%|█████████████████████████████▍                                                   | 91/250 [00:31<00:54,  2.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 11ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 37%|█████████████████████████████▊                                                   | 92/250 [00:32<00:55,  2.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 10ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 37%|██████████████████████████████▏                                                  | 93/250 [00:32<00:53,  2.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 11ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 38%|██████████████████████████████▍                                                  | 94/250 [00:32<00:52,  2.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 11ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 38%|██████████████████████████████▊                                                  | 95/250 [00:33<00:53,  2.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 11ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 38%|███████████████████████████████                                                  | 96/250 [00:33<00:52,  2.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 10ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 39%|███████████████████████████████▍                                                 | 97/250 [00:33<00:51,  3.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 11ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 39%|███████████████████████████████▊                                                 | 98/250 [00:34<00:51,  2.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 11ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 40%|████████████████████████████████                                                 | 99/250 [00:34<00:50,  2.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 11ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 40%|████████████████████████████████                                                | 100/250 [00:34<00:50,  2.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 11ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 40%|████████████████████████████████▎                                               | 101/250 [00:35<00:50,  2.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 11ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 41%|████████████████████████████████▋                                               | 102/250 [00:35<00:50,  2.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 12ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 41%|████████████████████████████████▉                                               | 103/250 [00:35<00:50,  2.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 11ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 42%|█████████████████████████████████▎                                              | 104/250 [00:36<00:50,  2.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 11ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 42%|█████████████████████████████████▌                                              | 105/250 [00:36<00:49,  2.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 12ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 42%|█████████████████████████████████▉                                              | 106/250 [00:36<00:49,  2.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 11ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 43%|██████████████████████████████████▏                                             | 107/250 [00:37<00:49,  2.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 11ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 43%|██████████████████████████████████▌                                             | 108/250 [00:37<00:48,  2.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 13ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 44%|██████████████████████████████████▉                                             | 109/250 [00:37<00:48,  2.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 11ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 44%|███████████████████████████████████▏                                            | 110/250 [00:38<00:48,  2.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 11ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 44%|███████████████████████████████████▌                                            | 111/250 [00:38<00:47,  2.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 13ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 45%|███████████████████████████████████▊                                            | 112/250 [00:38<00:47,  2.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 11ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 45%|████████████████████████████████████▏                                           | 113/250 [00:39<00:47,  2.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 11ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 46%|████████████████████████████████████▍                                           | 114/250 [00:39<00:46,  2.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 12ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 46%|████████████████████████████████████▊                                           | 115/250 [00:39<00:46,  2.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 11ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 46%|█████████████████████████████████████                                           | 116/250 [00:40<00:46,  2.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 11ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 47%|█████████████████████████████████████▍                                          | 117/250 [00:40<00:45,  2.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 12ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 47%|█████████████████████████████████████▊                                          | 118/250 [00:40<00:45,  2.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 11ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 48%|██████████████████████████████████████                                          | 119/250 [00:41<00:45,  2.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 11ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 48%|██████████████████████████████████████▍                                         | 120/250 [00:41<00:44,  2.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 11ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 48%|██████████████████████████████████████▋                                         | 121/250 [00:42<00:44,  2.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 11ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 49%|███████████████████████████████████████                                         | 122/250 [00:42<00:44,  2.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 11ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 49%|███████████████████████████████████████▎                                        | 123/250 [00:42<00:43,  2.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 11ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 50%|███████████████████████████████████████▋                                        | 124/250 [00:43<00:42,  2.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 11ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 50%|████████████████████████████████████████                                        | 125/250 [00:43<00:42,  2.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 11ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 50%|████████████████████████████████████████▎                                       | 126/250 [00:43<00:42,  2.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 11ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 51%|████████████████████████████████████████▋                                       | 127/250 [00:44<00:42,  2.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 11ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 51%|████████████████████████████████████████▉                                       | 128/250 [00:44<00:42,  2.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 11ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 52%|█████████████████████████████████████████▎                                      | 129/250 [00:44<00:41,  2.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 13ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 52%|█████████████████████████████████████████▌                                      | 130/250 [00:45<00:43,  2.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 13ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 52%|█████████████████████████████████████████▉                                      | 131/250 [00:45<00:44,  2.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 13ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 53%|██████████████████████████████████████████▏                                     | 132/250 [00:45<00:44,  2.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 11ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 53%|██████████████████████████████████████████▌                                     | 133/250 [00:46<00:42,  2.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 11ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 54%|██████████████████████████████████████████▉                                     | 134/250 [00:46<00:42,  2.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 12ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 54%|███████████████████████████████████████████▏                                    | 135/250 [00:47<00:41,  2.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 11ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 54%|███████████████████████████████████████████▌                                    | 136/250 [00:47<00:40,  2.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 11ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 55%|███████████████████████████████████████████▊                                    | 137/250 [00:47<00:40,  2.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 11ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 55%|████████████████████████████████████████████▏                                   | 138/250 [00:48<00:39,  2.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 11ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 56%|████████████████████████████████████████████▍                                   | 139/250 [00:48<00:38,  2.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 11ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 56%|████████████████████████████████████████████▊                                   | 140/250 [00:48<00:37,  2.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 11ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 56%|█████████████████████████████████████████████                                   | 141/250 [00:49<00:37,  2.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 11ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 57%|█████████████████████████████████████████████▍                                  | 142/250 [00:49<00:36,  2.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 11ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 57%|█████████████████████████████████████████████▊                                  | 143/250 [00:49<00:36,  2.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 12ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 58%|██████████████████████████████████████████████                                  | 144/250 [00:50<00:36,  2.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 11ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 58%|██████████████████████████████████████████████▍                                 | 145/250 [00:50<00:35,  2.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 11ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 58%|██████████████████████████████████████████████▋                                 | 146/250 [00:50<00:35,  2.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 11ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 59%|███████████████████████████████████████████████                                 | 147/250 [00:51<00:35,  2.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 11ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 59%|███████████████████████████████████████████████▎                                | 148/250 [00:51<00:34,  2.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 11ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 60%|███████████████████████████████████████████████▋                                | 149/250 [00:51<00:34,  2.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 11ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 60%|████████████████████████████████████████████████                                | 150/250 [00:52<00:34,  2.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 11ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 60%|████████████████████████████████████████████████▎                               | 151/250 [00:52<00:33,  2.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 12ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 61%|████████████████████████████████████████████████▋                               | 152/250 [00:52<00:34,  2.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 11ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 61%|████████████████████████████████████████████████▉                               | 153/250 [00:53<00:33,  2.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 11ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 62%|█████████████████████████████████████████████████▎                              | 154/250 [00:53<00:32,  2.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 12ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 62%|█████████████████████████████████████████████████▌                              | 155/250 [00:53<00:33,  2.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 13ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 62%|█████████████████████████████████████████████████▉                              | 156/250 [00:54<00:33,  2.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 11ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 63%|██████████████████████████████████████████████████▏                             | 157/250 [00:54<00:32,  2.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 13ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 63%|██████████████████████████████████████████████████▌                             | 158/250 [00:55<00:33,  2.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 11ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 64%|██████████████████████████████████████████████████▉                             | 159/250 [00:55<00:31,  2.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 11ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 64%|███████████████████████████████████████████████████▏                            | 160/250 [00:55<00:31,  2.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 12ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 64%|███████████████████████████████████████████████████▌                            | 161/250 [00:56<00:32,  2.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 11ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 65%|███████████████████████████████████████████████████▊                            | 162/250 [00:56<00:31,  2.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 11ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 65%|████████████████████████████████████████████████████▏                           | 163/250 [00:56<00:30,  2.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 11ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 66%|████████████████████████████████████████████████████▍                           | 164/250 [00:57<00:30,  2.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 11ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 66%|████████████████████████████████████████████████████▊                           | 165/250 [00:57<00:29,  2.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 11ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 66%|█████████████████████████████████████████████████████                           | 166/250 [00:57<00:28,  2.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 11ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 67%|█████████████████████████████████████████████████████▍                          | 167/250 [00:58<00:28,  2.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 11ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 67%|█████████████████████████████████████████████████████▊                          | 168/250 [00:58<00:28,  2.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 11ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 68%|██████████████████████████████████████████████████████                          | 169/250 [00:58<00:27,  2.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 11ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 68%|██████████████████████████████████████████████████████▍                         | 170/250 [00:59<00:27,  2.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 11ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 68%|██████████████████████████████████████████████████████▋                         | 171/250 [00:59<00:27,  2.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 12ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 69%|███████████████████████████████████████████████████████                         | 172/250 [00:59<00:26,  2.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 11ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 69%|███████████████████████████████████████████████████████▎                        | 173/250 [01:00<00:26,  2.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 10ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 70%|███████████████████████████████████████████████████████▋                        | 174/250 [01:00<00:25,  2.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 12ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 70%|████████████████████████████████████████████████████████                        | 175/250 [01:00<00:25,  2.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 11ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 70%|████████████████████████████████████████████████████████▎                       | 176/250 [01:01<00:25,  2.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 11ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 71%|████████████████████████████████████████████████████████▋                       | 177/250 [01:01<00:25,  2.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 14ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 71%|████████████████████████████████████████████████████████▉                       | 178/250 [01:01<00:25,  2.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 11ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 72%|█████████████████████████████████████████████████████████▎                      | 179/250 [01:02<00:25,  2.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 11ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 72%|█████████████████████████████████████████████████████████▌                      | 180/250 [01:02<00:24,  2.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 13ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 72%|█████████████████████████████████████████████████████████▉                      | 181/250 [01:03<00:24,  2.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 11ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 73%|██████████████████████████████████████████████████████████▏                     | 182/250 [01:03<00:24,  2.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 11ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 73%|██████████████████████████████████████████████████████████▌                     | 183/250 [01:03<00:23,  2.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 11ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 74%|██████████████████████████████████████████████████████████▉                     | 184/250 [01:04<00:22,  2.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 10ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 74%|███████████████████████████████████████████████████████████▏                    | 185/250 [01:04<00:22,  2.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 11ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 74%|███████████████████████████████████████████████████████████▌                    | 186/250 [01:04<00:21,  2.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 12ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 75%|███████████████████████████████████████████████████████████▊                    | 187/250 [01:05<00:21,  2.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 11ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 75%|████████████████████████████████████████████████████████████▏                   | 188/250 [01:05<00:22,  2.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 11ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 76%|████████████████████████████████████████████████████████████▍                   | 189/250 [01:05<00:21,  2.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 11ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 76%|████████████████████████████████████████████████████████████▊                   | 190/250 [01:06<00:21,  2.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 12ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 76%|█████████████████████████████████████████████████████████████                   | 191/250 [01:06<00:21,  2.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 11ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 77%|█████████████████████████████████████████████████████████████▍                  | 192/250 [01:06<00:20,  2.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 11ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 77%|█████████████████████████████████████████████████████████████▊                  | 193/250 [01:07<00:20,  2.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 11ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 78%|██████████████████████████████████████████████████████████████                  | 194/250 [01:07<00:19,  2.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 12ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 78%|██████████████████████████████████████████████████████████████▍                 | 195/250 [01:07<00:19,  2.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 11ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 78%|██████████████████████████████████████████████████████████████▋                 | 196/250 [01:08<00:19,  2.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 11ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 79%|███████████████████████████████████████████████████████████████                 | 197/250 [01:08<00:18,  2.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 12ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 79%|███████████████████████████████████████████████████████████████▎                | 198/250 [01:09<00:18,  2.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 11ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 80%|███████████████████████████████████████████████████████████████▋                | 199/250 [01:09<00:17,  2.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 11ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 80%|████████████████████████████████████████████████████████████████                | 200/250 [01:09<00:17,  2.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 11ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 80%|████████████████████████████████████████████████████████████████▎               | 201/250 [01:10<00:16,  2.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 11ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 81%|████████████████████████████████████████████████████████████████▋               | 202/250 [01:10<00:16,  2.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 11ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 81%|████████████████████████████████████████████████████████████████▉               | 203/250 [01:10<00:16,  2.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 11ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 82%|█████████████████████████████████████████████████████████████████▎              | 204/250 [01:11<00:15,  2.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 11ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 82%|█████████████████████████████████████████████████████████████████▌              | 205/250 [01:11<00:15,  2.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 11ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 82%|█████████████████████████████████████████████████████████████████▉              | 206/250 [01:11<00:15,  2.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 11ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 83%|██████████████████████████████████████████████████████████████████▏             | 207/250 [01:12<00:14,  2.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 11ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 83%|██████████████████████████████████████████████████████████████████▌             | 208/250 [01:12<00:14,  2.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 11ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 84%|██████████████████████████████████████████████████████████████████▉             | 209/250 [01:12<00:14,  2.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 11ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 84%|███████████████████████████████████████████████████████████████████▏            | 210/250 [01:13<00:14,  2.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 12ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 84%|███████████████████████████████████████████████████████████████████▌            | 211/250 [01:13<00:13,  2.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 14ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 85%|███████████████████████████████████████████████████████████████████▊            | 212/250 [01:13<00:14,  2.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 11ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 85%|████████████████████████████████████████████████████████████████████▏           | 213/250 [01:14<00:13,  2.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 11ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 86%|████████████████████████████████████████████████████████████████████▍           | 214/250 [01:14<00:12,  2.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 13ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 86%|████████████████████████████████████████████████████████████████████▊           | 215/250 [01:15<00:12,  2.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 11ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 86%|█████████████████████████████████████████████████████████████████████           | 216/250 [01:15<00:12,  2.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 11ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 87%|█████████████████████████████████████████████████████████████████████▍          | 217/250 [01:15<00:11,  2.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 11ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 87%|█████████████████████████████████████████████████████████████████████▊          | 218/250 [01:16<00:11,  2.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 11ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 88%|██████████████████████████████████████████████████████████████████████          | 219/250 [01:16<00:10,  2.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 11ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 88%|██████████████████████████████████████████████████████████████████████▍         | 220/250 [01:16<00:10,  2.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 12ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 88%|██████████████████████████████████████████████████████████████████████▋         | 221/250 [01:17<00:10,  2.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 11ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 89%|███████████████████████████████████████████████████████████████████████         | 222/250 [01:17<00:09,  2.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 11ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 89%|███████████████████████████████████████████████████████████████████████▎        | 223/250 [01:17<00:09,  2.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 11ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 90%|███████████████████████████████████████████████████████████████████████▋        | 224/250 [01:18<00:09,  2.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 11ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 90%|████████████████████████████████████████████████████████████████████████        | 225/250 [01:18<00:08,  2.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 11ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 90%|████████████████████████████████████████████████████████████████████████▎       | 226/250 [01:18<00:08,  2.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 11ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 91%|████████████████████████████████████████████████████████████████████████▋       | 227/250 [01:19<00:08,  2.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 11ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 91%|████████████████████████████████████████████████████████████████████████▉       | 228/250 [01:19<00:07,  2.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 12ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 92%|█████████████████████████████████████████████████████████████████████████▎      | 229/250 [01:19<00:07,  2.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 11ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 92%|█████████████████████████████████████████████████████████████████████████▌      | 230/250 [01:20<00:06,  2.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 11ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 92%|█████████████████████████████████████████████████████████████████████████▉      | 231/250 [01:20<00:06,  2.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 13ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 93%|██████████████████████████████████████████████████████████████████████████▏     | 232/250 [01:20<00:06,  2.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 12ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 93%|██████████████████████████████████████████████████████████████████████████▌     | 233/250 [01:21<00:06,  2.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 11ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 94%|██████████████████████████████████████████████████████████████████████████▉     | 234/250 [01:21<00:05,  2.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 12ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 94%|███████████████████████████████████████████████████████████████████████████▏    | 235/250 [01:22<00:05,  2.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 11ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 94%|███████████████████████████████████████████████████████████████████████████▌    | 236/250 [01:22<00:05,  2.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 11ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 95%|███████████████████████████████████████████████████████████████████████████▊    | 237/250 [01:22<00:04,  2.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 12ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 95%|████████████████████████████████████████████████████████████████████████████▏   | 238/250 [01:23<00:04,  2.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 11ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 96%|████████████████████████████████████████████████████████████████████████████▍   | 239/250 [01:23<00:03,  2.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 11ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 96%|████████████████████████████████████████████████████████████████████████████▊   | 240/250 [01:23<00:03,  2.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 11ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 96%|█████████████████████████████████████████████████████████████████████████████   | 241/250 [01:24<00:03,  2.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 11ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 97%|█████████████████████████████████████████████████████████████████████████████▍  | 242/250 [01:24<00:02,  2.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 13ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 97%|█████████████████████████████████████████████████████████████████████████████▊  | 243/250 [01:24<00:02,  2.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 12ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 98%|██████████████████████████████████████████████████████████████████████████████  | 244/250 [01:25<00:02,  2.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 12ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 98%|██████████████████████████████████████████████████████████████████████████████▍ | 245/250 [01:25<00:01,  2.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 12ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 98%|██████████████████████████████████████████████████████████████████████████████▋ | 246/250 [01:25<00:01,  2.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 11ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 99%|███████████████████████████████████████████████████████████████████████████████ | 247/250 [01:26<00:01,  2.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 12ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 99%|███████████████████████████████████████████████████████████████████████████████▎| 248/250 [01:26<00:00,  2.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 12ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "100%|███████████████████████████████████████████████████████████████████████████████▋| 249/250 [01:27<00:00,  2.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 12ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 250/250 [01:27<00:00,  2.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/16 [=================>............] - ETA: 0s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 11ms/step\n",
      "\n",
      "\n",
      "accuracy                   : 0.30 ± 0.02\n",
      "macro avg        f1-score  : 0.30 ± 0.02\n",
      "macro avg        recall    : 0.30 ± 0.02\n",
      "macro avg        precision : 0.31 ± 0.02\n",
      "weighted avg     f1-score  : 0.30 ± 0.02\n",
      "weighted avg     recall    : 0.30 ± 0.02\n",
      "weighted avg     precision : 0.31 ± 0.02\n"
     ]
    }
   ],
   "source": [
    "report_boot=bootstrap(np.array(X_test), np.array(y_test), Dcnn, nn = True)\n",
    "\n",
    "for i in ['accuracy', 'macro avg', 'weighted avg']:\n",
    "    if i == 'accuracy':\n",
    "        print(\"\\n\\n{:27}: {:.2f} ± {:.2f}\".format(i, report_boot[i][0], report_boot[i][1]))\n",
    "    for j in ['f1-score', 'recall', 'precision']:\n",
    "        if i != 'accuracy':\n",
    "            print(\"{:15}  {:10}: {:.2f} ± {:.2f}\".format(i, j, report_boot[i][j][0], report_boot[i][j][1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28279b5e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
